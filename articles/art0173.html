<html>
<head><base href="https://kurzweilai-brain.gothdyke.mom/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>Tearing Toward the Spike</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20071011093741/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20071011093741/http://www.kurzweilai.net/meme/memelist.html?m=1">The Singularity</a> &gt; 
Tearing Toward the Spike
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20071011093741/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0173.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0173.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20071011093741/http://www.kurzweilai.net/articles/art0173.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">Tearing Toward the Spike</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20071011093741/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0054.html" target="_top">Damien Broderick</a><br></span></td>
</table>
<br>
<div class="TeaserText">We will live forever; or we will all perish most horribly; our minds will emigrate to cyberspace, and start the most ferocious overpopulation race ever seen on the planet; or our machines will transcend and take us with them, or leave us in some peaceful backwater where the meek shall inherit the Earth. Or something else, something far weirder and... unimaginable.</div>
<br>
<br><p>Originally presented as a paper at the three-day symposium <i>Australia at the Crossroads? Scenarios and Strategies for the </i><a class="thought" href="entries/future_entry.html">Future</a>, April 31 - May 2, 2000, at the John Curtin International Institute, Curtin University of <a class="thought" href="entries/technology_entry.html">Technology</a>, Perth, WA, Australia. Published on KurzweilAI.net May 7, 2001.</p>
<p>I wish I could show you the real <a class="thought" href="entries/future_entry.html">future</a>, in detail, just the way it's going to unfold. In fact, I wish I knew its shape myself. But the unreliability of trends is due precisely to <i>relentless, unpredictable change,</i> which makes the <a class="thought" href="entries/future_entry.html">future</a> interesting but also renders it opaque.</p>
<p>This important notion has been described metaphorically--both in <a class="thought" href="entries/science_fiction_entry.html">science fiction</a> and in serious essays--as a technological <a class="thought" href="entries/singularity_entry.html">Singularity</a>. That term is due to Professor <a class="thought" href="entries/vinge_entry.html">Vernor Vinge</a>, a mathematician in the Department of Mathematical <a class="thought" href="entries/science_entry.html">Science</a>s, San Diego State University (although a few others had anticipated the insight).[1] `The term "<a class="thought" href="entries/singularity_entry.html">singularity</a>" tied to the notion of radical change is very evocative,' Vinge says, adding: `I used the term "<a class="thought" href="entries/singularity_entry.html">singularity</a>" in the <a class="thought" href="entries/sense_entry.html">sense</a> of a place where a model of physical reality fails. (I was also attracted to the term by one of the characteristics of many singularities in General <a class="thought" href="entries/relativity_entry.html">Relativity</a>--namely the unknowability of things close to or in the <a class="thought" href="entries/singularity_entry.html">singularity</a>.)'[2] In <a class="thought" href="entries/mathematics_entry.html">mathematics</a>, singularities arises when quantities go infinite; in <a class="thought" href="entries/cosmology_entry.html">cosmology</a>, a <a class="thought" href="entries/black_hole_entry.html">black hole</a> is the physical, literal <a class="thought" href="entries/expression_entry.html">expression</a> of that relativistic effect</p>
<p>For Vinge, accelerating trends in <a class="thought" href="entries/computer_science_entry.html">computer science</a>s converge somewhere between 2030 and 2100 to form a wall of technological novelties blocking the <a class="thought" href="entries/future_entry.html">future</a> from us. However hard we try, we cannot plausibly imagine what lies beyond that wall. `My "technological <a class="thought" href="entries/singularity_entry.html">singularity</a>" is really quite limited,' Vinge stated. `I say that it seems plausible that in the near historical <a class="thought" href="entries/future_entry.html">future</a>, we will cause superhuman <a class="thought" href="entries/intelligence_entry.html">intelligence</a>s to exist. Prediction beyond that point is qualitatively different from futurisms of the past. I don't necessarily see any vertical asymptotes.' Some proponents of this perspective (including me) take the idea much farther than Vinge, because we <i>do</i> anticipate the arrival of an asymptote in the rate of change. That exponential curve will be composed of a series of lesser sigmoid curves, each mapping a key technological process, rising fast and then saturating its possibilities before being gazumped by its successor, as <a class="thought" href="entries/vacuum_tube_entry.html">vacuum tube</a>s were replaced by <a class="thought" href="entries/transistor_entry.html">transistor</a>s at the dawn of <a class="thought" href="entries/electronic_entry.html">electronic</a> computing. Humanity itself--or rather, ourselves--will become first `transhuman', it is argued, and then `posthuman'.</p>
<p>While Vinge first advanced his insight in works of imaginative fiction, he has featured it more rigorously in such formal papers as his address to the VISION-21 Symposium, sponsored by <a class="thought" href="entries/nasa_entry.html">NASA</a> Lewis <a class="thought" href="entries/research_entry.html">Research</a> Center and the Ohio Aerospace Institute, March 30-31, 1993. He opened that paper with the following characteristic statement, which can serve as a fair summary of my own starting point</p>
<p>`The acceleration of technological <a class="thought" href="entries/progress_entry.html">progress</a> has been the central feature of this century. I argue in this paper that we are on the edge of change comparable to the rise of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/life_entry.html">life</a> on <a class="thought" href="entries/earth_entry.html">Earth</a>. The precise cause of this change is the imminent creation by <a class="thought" href="entries/technology_entry.html">technology</a> of entities with greater than <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a>.</p>
<p>The impact of that distressing but apparently free-floating prediction is much greater than you might imagine. In 1970, Alvin Toffler had already grasped the notion of accelerating change. In <a class="thought" href="entries/future_entry.html">Future</a><i> Shock</i> he noted: `New discoveries, new technologies, new social arrangements in the external world erupt into our lives in the form of increased turn-over rates--shorter and shorter relational durations. They force a faster and faster pace of daily <a class="thought" href="entries/life_entry.html">life</a>.'[3] This is the very definition of `future shock'.</p>
<p>Thirtysomething years on, we see that this increased pace of change is going to disrupt the <a class="thought" href="entries/nature_entry.html">nature</a> of humanity as well, due to the emergence of a new kind of mind: AIs (<a class="thought" href="entries/ai_entry.html">artificial intelligence</a>s). With self-bootstrapping minds abruptly arrived in the world, able to enhance and rewrite their own cognitive and affective coding in seconds, <a class="thought" href="entries/science_entry.html">science</a> will no longer be restricted to the slow, limited apertures granted by <a class="thought" href="entries/human_entry.html">human</a> senses (however augmented by wonderful <a class="thought" href="entries/instrument_entry.html">instrument</a>s) and sluggish brains (however glorious by the standards of other <a class="thought" href="entries/animal_entry.html">animal</a>s). We'll find ourselves, Vinge suggests, in a world where nothing much can be predicted reliably.</p>
<p>Is that strictly true? There are some negative constraints we can feel fairly confident about. The sheer reliability and practical effectiveness of quantum theory, and the robust way <a class="thought" href="entries/relativity_entry.html">relativity</a> holds up under strenuous challenge, argues that they will remain at the core of <a class="thought" href="entries/future_entry.html">future</a> <a class="thought" href="entries/science_entry.html">science</a>--in <i>some</i> form, which is rather baffling, since at the deepest levels they disagree with each other about what kind of cosmos we inhabit.[4] In other words, we do already know a great deal, a tremendous amount, corroborated <a class="thought" href="entries/knowledge_entry.html">knowledge</a> will not go away.</p>
<p>Meanwhile, what I call the Spike in my book of that title--<a class="thought" href="entries/vinge_entry.html">Vernor Vinge</a>'s technological <a class="thought" href="entries/singularity_entry.html">Singularity</a>--apparently looms ahead of us: a horizon of ever-swifter change we can't yet see past. The Spike is a kind of <a class="thought" href="entries/black_hole_entry.html">black hole</a> in the <a class="thought" href="entries/future_entry.html">future</a>, created by runaway change and accelerating <a class="thought" href="entries/computer_entry.html">computer</a> power. We can only try to imagine the unimaginable up to a point. That is what scientists and artists (and visionaries and explorers) have always attempted as part of their job description. <a class="thought" href="entries/clarke_entry.html">Arthur C. Clarke</a> did it rather wonderfully in his 1962 <a class="thought" href="entries/futurist_entry.html">futurist</a> book <i>Profiles of the </i><a class="thought" href="entries/future_entry.html">Future</a>. I was greatly encouraged to read something he said about <i>The Spike</i> in his revised millennium edition: `Damien's book will serve as a more imaginative sequel to the one you are reading now.' If anyone else had said that, I might be worried, but I'm pretty sure that, for Sir Arthur, `imaginative' is not a term of abuse. So let's see if we can sketch a number of possible pathways into and beyond the coming technological <a class="thought" href="entries/singularity_entry.html">singularity</a>.</p>
<p>First, though, one must ask if the postulate is even remotely plausible. In mid-March 2000, the chief scientist and co-founder of <a class="thought" href="entries/sun_microsystems_entry.html">Sun Microsystems</a>, <a class="thought" href="entries/joy_entry.html">Bill Joy</a>, published a now much-discussed warning that took such prospects very seriously indeed. He declared with trepidation: `The vision of near <a class="thought" href="entries/immortality_entry.html">immortality</a> that [software expert Ray] Kurzweil sees in his <a class="thought" href="entries/robot_entry.html">robot</a> dreams drives us forward; genetic <a class="thought" href="entries/engine_entry.html">engine</a>ering may soon provide treatments, if not outright cures, for most diseases; and <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> and <a class="thought" href="entries/nanomedicine_entry.html">nanomedicine</a> can address yet more ills. Together they could significantly extend our average <a class="thought" href="entries/life_entry.html">life</a> span and improve the quality of our lives. Yet, with each of these technologies, a sequence of small, individually sensible advances leads to an accumulation of great power and, concomitantly, great danger' (<a class="thought" href="entries/wired_entry.html">Wired</a><i> Magazine</i>, April 2000).[5] He is right to be concerned, but I believe the risks are worth taking. Let's consider the way this deck of novelties might play out.</p>
<p>We need to simplify in <a class="thought" href="entries/order_entry.html">order</a> to do that, take just one card at a <a class="thought" href="entries/time_entry.html">time</a> and give it priority, treat it as if it were the only big change, modulating everything else that falls under its shadow. It's a risky gambit, since it has never been true in the past and will not strictly be true in the <a class="thought" href="entries/future_entry.html">future</a>. The only exception is the dire (and possibly false) prediction that something we do, or something from beyond our control, brings down the curtain, blows the whistle to end the game. So let's call that option</p><h2> [A i] No Spike, because the sky is falling</h2><p>In the second half of the 20th century, people feared that nuclear war (especially nuclear winter) might snuff us all out. Later, with the arrival of subtle sensors and global meteorological studies, we worried about ozone holes and industrial pollution and an anthropogenic Greenhouse effect combining to blight the biosphere. Later still, the public became aware of the small but assured probability that our world will sooner or later be struck by a `dinosaur-killer' asteroid, which could arrive at any moment. For the longer term, we started to grasp the cosmic reality of the sun's <a class="thought" href="entries/mortality_entry.html">mortality</a>, and hence our <a class="thought" href="entries/planet_entry.html">planet</a>'s: solar dynamics will brighten the sun in the next half billion years, roasting the surface of our fair world and killing everything that still lives upon it. Beyond that, the <a class="thought" href="entries/universe_entry.html">universe</a> as a whole will surely perish one way or another.</p>
<p>Take a more optimistic view of things. Suppose we survive as a <a class="thought" href="entries/species_entry.html">species</a>, and maybe as individuals, at least for the medium term (forget the asteroids and <i>Independence Day</i>). That still doesn't mean there must be a Spike, at least in the next century or two. Perhaps <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> will be far more intractable than <a class="thought" href="entries/moravec_entry.html">Hans Moravec</a> and Ray Kurzweil and other enthusiasts proclaim. Perhaps molecular <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> stalls at the level of micro-<a class="thought" href="entries/electronic_entry.html">electronic</a> <a class="thought" href="entries/machine_entry.html">machine</a>s (<a class="thought" href="entries/mems_entry.html">MEMS</a>) that have a major impact but never approach the fecund cornucopia of a true molecular <a class="thought" href="entries/assembler_entry.html">assembler</a> (a `mint', or Anything Box). Perhaps <a class="thought" href="entries/matter_entry.html">matter</a> <a class="thought" href="entries/compiler_entry.html">compiler</a>s or replicators will get developed, but the security states of the world agree to suppress them, imprison or kill their inventors, prohibit their use at the cost of extreme penalties. Then we have option</p><h2> [A ii] No Spike, steady as she goes</h2><p>This obviously forks into a variety of alternative <a class="thought" href="entries/future_entry.html">future</a> histories, the two most apparent being</p><h3> [A ii a] Nothing much ever changes ever again</h3><p>which is the day-to-day working assumption I suspect most of us default to, unless we force ourselves to think hard. It's that illusion of unaltered <a class="thought" href="entries/identity_entry.html">identity</a> that preserves us sanely from year to year, decade to decade, allows us to retain our equilibrium in a lifetime of such smashing disruption that some people alive now went through the whole mind-wrenching transition from agricultural to industrial to <a class="thought" href="entries/knowledge_entry.html">knowledge</a>/<a class="thought" href="entries/electronic_entry.html">electronic</a> societies. It's an illusion, and perhaps a comforting one, but I think we can be pretty sure the <a class="thought" href="entries/future_entry.html">future</a> is not going to stop happening just as we arrive in the 21st century.</p>
<p>The clearest alternative to that impossibility is</p><h3> [A ii b] Things change slowly (haven't they always?)</h3><p>Well, no, they haven't. This option pretends to acknowledge a century of vast change, but insists that, even so, <i><a class="thought" href="entries/human_entry.html">human</a> </i><a class="thought" href="entries/nature_entry.html">nature</a><i> itself</i> has not changed. True, racism and homophobia are increasingly despised rather than mandatory. True, <a class="thought" href="entries/warfare_entry.html">warfare</a> is now widely deplored (at least in rich, complacent places) rather than extolled as honorable and glorious. Granted, people who drive fairly safe cars while chatting on the mobile phone live rather... <i>strange</i>... lives, by the standards of the horse-and-buggy era only a century behind us. Still, once everyone in the world is drawn into the global market, once peasants in India and villagers in Africa also have mobile phones and learn to use the <a class="thought" href="entries/internet_entry.html">Internet</a> and buy from IKEA, things will... <i>settle down</i>. Nations overburdened by gasping population pressures will pass through the demographic transition, easily or cruelly, and we'll top out at around 10 billion humans living a modest but comfortable, ecologically sustainable existence for the rest of <a class="thought" href="entries/time_entry.html">time</a> (or until that big rock arrives).</p>
<p>A bolder variant of this model is</p><h2>[A iii] Increasing <a class="thought" href="entries/computer_entry.html">computer</a> power will lead to <a class="thought" href="entries/human_entry.html">human</a>-scale <a class="thought" href="entries/ai_entry.html">AI</a>, and then stall.</h2><p>But why should <a class="thought" href="entries/technology_entry.html">technology</a> abruptly run out of puff in this fashion? Perhaps there is some technical barrier to improved miniaturisation, or connectivity, or dense, elegant coding (but experts argue that there will be ways around such road-blocks, and advanced <a class="thought" href="entries/research_entry.html">research</a> points to some possibilities: <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>, nanoscale processors). Still, natural selection has not managed to leap to a superintelligent variant of humankind in the last 100,000 years, so maybe there is some structural <a class="thought" href="entries/reason_entry.html">reason</a> why brains top out at the Murasaki, Einstein or van Gogh level.</p>
<p>So <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a> might reach the low-hanging fruit, all the way to <a class="thought" href="entries/human_entry.html">human</a> equivalence, and then find it impossible (even with <a class="thought" href="entries/machine_entry.html">machine</a> aid) to discern a path through murky <a class="thought" href="entries/search_entry.html">search</a> <a class="thought" href="entries/space_entry.html">space</a> to a higher level of mental <a class="thought" href="entries/complexity_entry.html">complexity</a>. Still, using the <a class="thought" href="entries/machine_entry.html">machine</a>s we already have will not leave our world unchanged. far from it. And even if this story has some likelihood, a grislier variant seems even more plausible.</p><h2> [A iv] Things go to hell, and if we don't die we'll wish we had</h2><p>This isn't the nuclear winter scenario, or any other kind of doom by weapons of mass destruction--let alone gray nano goo, which by hypothesis never gets invented in this denuded <a class="thought" href="entries/future_entry.html">future</a>. <a class="thought" href="entries/technology_entry.html">Technology</a>'s benefits demand a toll from the <a class="thought" href="entries/planet_entry.html">planet</a>'s resource base, and our polluted environment. The rich nations, numerically in a minority, notoriously use more <a class="thought" href="entries/energy_entry.html">energy</a> and materials than the rest, pour more crap into air and sea. That can change--<i>must</i> change, or we are all in bad trouble--but in the short term one can envisage a nightmare decade or two during which the Third World `catches up' with the wealthy consumers, burning cheap, hideously polluting soft coal, running the exhaust of a billion and more extra cars into the biosphere...</p>
<p>Some Green activists mock `technical fixes' for these problems, but those seem to me our best last hope.[6] We are moving toward manufacturing and control <a class="thought" href="entries/system_entry.html">system</a>s very different from the wasteful, heavy-industrial, pollutive kind that helped drive up the world's surface temperature by 0.4 to 0.8 degrees Celsius in the 20th century.[7]</p>
<p>Pollsters have noted incredulously that people overwhelmingly state that their individual lives are quite <a class="thought" href="entries/content_entry.html">content</a>ed and their prospects good, while agreeing that the nation or the world generally is heading for hell in a hand-basket. It's as if we've forgotten that the vice and brutality of television entertainments do <i>not</i> reflect the true state of the world, that it's almost the reverse: we revel in such violent cartoons because, for almost all of us, our lives are comparatively placid, safe and measured. If you doubt this, go and live for a while in medieval Paris, or palaeolithic Egypt (you're not allowed to be a noble).</p><h1>Roads from here and now to the Spike</h1><p>I assert that all of these <i>No Spike</i> options are of low probability, unless they are brought forcibly into reality by the hand of some Luddite demagogue using our confusions and fears against our own best hopes for local and global prosperity. If I'm right, we are then pretty much on course for an inevitable Spike. We might still ask: what, exactly, is the motor that will propel technological culture up its exponential curve?</p>
<p>Here are seven obvious distinct candidates for paths to the Spike (separate lines of development that in reality will interact, generally hastening but sometimes slowing each other):</p><h2> [B i] Increasing <a class="thought" href="entries/computer_entry.html">computer</a> power will lead to <a class="thought" href="entries/human_entry.html">human</a>-scale <a class="thought" href="entries/ai_entry.html">AI</a>, and then will swiftly self-bootstrap to incomprehensible <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a>.</h2><p>This is the `classic' model of the <a class="thought" href="entries/singularity_entry.html">singularity</a>, the path to the ultraintelligent <a class="thought" href="entries/machine_entry.html">machine</a> and beyond. But it seems unlikely that there will be an abrupt leap from today's moderately fast <a class="thought" href="entries/machine_entry.html">machine</a>s to a fully-functioning artificial mind equal to our own, let alone its self-redesigned kin--although this proviso, too, can be countered, as we'll see. If we can trust <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's Law</a>--<a class="thought" href="entries/computer_entry.html">computer</a> power currently doubling every year--as a guide (and strictly we can't, since it's only a record of the past rather than an oracle), we get the kinds of timelines presented by Ray Kurzweil, <a class="thought" href="entries/moravec_entry.html">Hans Moravec</a>, Michio Kaku, Peter Cochrane and others, explored at length in <i>The Spike</i>. Let's briefly sample those predictions:</p>
<p>Peter Cochrane: several years ago, the British Telecom <a class="thought" href="entries/future_entry.html">future</a>s team, led by their <a class="thought" href="entries/guru_entry.html">guru</a> Cochrane, saw <a class="thought" href="entries/human_entry.html">human</a>-level <a class="thought" href="entries/machine_entry.html">machine</a>s as early as 2016. Their remit did not encompass a sufficiently deep range to sight a <a class="thought" href="entries/singularity_entry.html">Singularity</a>.</p>
<p>Ray Kurzweil:[8] around 2019, a standard cheap <a class="thought" href="entries/computer_entry.html">computer</a> has the capacity of a <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a>, and some claim to have met the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> (that is, passed as conscious, fully responsive minds). By 2029, such <a class="thought" href="entries/machine_entry.html">machine</a>s are a thousand times more powerful. <a class="thought" href="entries/machine_entry.html">Machine</a>s not only ace the <a class="thought" href="entries/turing_test_entry.html">Turing test</a>, they <i>claim to be conscious</i>, and are accepted as such. His sketch of 2099 is effectively a Spike: fusion between <a class="thought" href="entries/human_entry.html">human</a> and <a class="thought" href="entries/machine_entry.html">machine</a>, uploads more numerous than the embodied, <a class="thought" href="entries/immortality_entry.html">immortality</a>. It's not clear why this takes an extra 70 years to achieve.</p>
<p>Ralph Merkle:[9] while Dr Merkle's special field is <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>, this plainly has a possible bearing on <a class="thought" href="entries/ai_entry.html">AI</a>. His is the standard case, although the timeline is still `fuzzy', he told me in January: various computing parameters go about as small as we can imagine between 2010 and 2020, if <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's Law</a> holds up. To get there will require `a manufacturing <a class="thought" href="entries/technology_entry.html">technology</a> that can arrange individual atoms in the precise structures required for molecular <a class="thought" href="entries/logic_entry.html">logic</a> <a class="thought" href="entries/element_entry.html">element</a>s, connect those <a class="thought" href="entries/logic_entry.html">logic</a> <a class="thought" href="entries/element_entry.html">element</a>s in the complex patterns required for a <a class="thought" href="entries/computer_entry.html">computer</a>, and do so inexpensively for billions of billions of gates.' So the imperatives of the <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/hardware_entry.html">hardware</a> industry will create nanoassemblers by 2020 at latest. Choose your own timetable for the resulting Spike once both nano and <a class="thought" href="entries/ai_entry.html">AI</a> are in hand.</p>
<p>Has Moravec:[10] multipurpose `universal' robots by 2010, with `humanlike competence' in cheap <a class="thought" href="entries/computer_entry.html">computer</a>s by around 2039--a more conservative estimate than Ray Kurzweil's, but astonishing none the less. Even so, Dr Moravec considers a Vingean <a class="thought" href="entries/singularity_entry.html">singularity</a> as likely within 50 years.</p>
<p>Michio Kaku: superstring physicist Kaku surveyed some 150 scientists and devised a profile of the next century and farther. He concludes broadly that from `2020 to 2050, the world of <a class="thought" href="entries/computer_entry.html">computer</a>s may well be dominated by invisible, <a class="thought" href="entries/network_entry.html">network</a>ed <a class="thought" href="entries/computer_entry.html">computer</a>s which have the power of <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>: <a class="thought" href="entries/reason_entry.html">reason</a>, speech recognition, even <a class="thought" href="entries/common_sense_entry.html">common sense</a>'.[11] In the next century or two, he expects humanity to achieve a Type I Kardeshev <a class="thought" href="entries/civilization_entry.html">civilization</a>, with <a class="thought" href="entries/planet_entry.html">planet</a>ary governance and <a class="thought" href="entries/technology_entry.html">technology</a> able to control weather but essentially restricted to <a class="thought" href="entries/earth_entry.html">Earth</a>. Only later, between 800 and 2500 years farther on, will humanity pass to Type II, with command of the entire <a class="thought" href="entries/solar_system_entry.html">solar system</a>. This projection seems to me excessively conservative.</p>
<p><a class="thought" href="entries/vinge_entry.html">Vernor Vinge</a>: his part-playful, part-serious proposal was that a <a class="thought" href="entries/singularity_entry.html">singularity</a> was due around 2020, marking the end of the <a class="thought" href="entries/human_entry.html">human</a> era. Maybe as soon as 2014.</p>
<p><a class="thought" href="entries/yudkowsky_entry.html">Eliezer Yudkowsky</a>: once we have a <a class="thought" href="entries/human_entry.html">human</a>-level <a class="thought" href="entries/ai_entry.html">AI</a> able to understand and redesign its own <a class="thought" href="entries/architecture_entry.html">architecture</a>, there will be a swift escalation into a Spike. Could be as soon as 2010, with 2005 and 2020 as the outer limits, if his proposed <a class="thought" href="entries/singularity_entry.html">Singularity</a> Institute has anything to do with it (this will be option [C]). Yudkowsky, I should warn you, is a 20 year old autodidact <a class="thought" href="entries/genius_entry.html">genius</a>, perhaps his generation's equivalent of Norbert Wiener or Murray Gell-Mann. Or maybe he's talking through his hat. Take a look at his site and decide for yourselves.</p><h2> [B ii] Increasing <a class="thought" href="entries/computer_entry.html">computer</a> power will lead to direct <a class="thought" href="entries/augmentation_entry.html">augmentation</a> of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a> and other abilities.</h2><p>Why build an <a class="thought" href="entries/artificial_brain_entry.html">artificial brain</a> when we each have one already? Well, it is regarded as impolite to delve intrusively into a living <a class="thought" href="entries/brain_entry.html">brain</a> purely for experimental purposes, whether by drugs or surgery (sometimes dubbed `neurohacking'), except if no other course of treatment for an illness is available. Increasingly subtle scanning <a class="thought" href="entries/machine_entry.html">machine</a>s are now available, allowing us to watch as the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> does its stuff, and a few brave pioneers are coupling chips to parts of themselves, but few expect us to wire ourselves to <a class="thought" href="entries/machine_entry.html">machine</a>s in the immediate <a class="thought" href="entries/future_entry.html">future</a>. That might be mistaken, however. Professor <a class="thought" href="entries/warwick_entry.html">Kevin Warwick</a>, of Reading University, successfully implanted a sensor-trackable <a class="thought" href="entries/chip_entry.html">chip</a> into his arm in 1998. A year later, he allowed an implanted <a class="thought" href="entries/chip_entry.html">chip</a> to monitor his neural and muscular patterns, then had a <a class="thought" href="entries/computer_entry.html">computer</a> use this <a class="thought" href="entries/information_entry.html">information</a> to copy the signals back to his body and cause his limbs to move; he was thus a kind of puppet, driven by the <a class="thought" href="entries/computer_entry.html">computer</a> signals. He plans experiments where the <a class="thought" href="entries/computer_entry.html">computer</a>, via similar chips, takes control of his <a class="thought" href="entries/emotion_entry.html">emotion</a>s as well as his <a class="thought" href="entries/action_entry.html">action</a>s.[12]</p>
<p>As we gradually learn to read the <a class="thought" href="entries/language_entry.html">language</a> of the <a class="thought" href="entries/brain_entry.html">brain</a>'s neural nets more closely, and finally to write directly back to them, we will find ways to expand our senses, directly experience distant sensors and <a class="thought" href="entries/robot_entry.html">robot</a> bodies (perhaps giving us <a class="thought" href="entries/access_entry.html">access</a> to horribly inhospitable environments like the depths of the oceans or the blazing surface of Venus). Instead of hammering keyboards or <a class="thought" href="entries/calculator_entry.html">calculator</a>s, we might <a class="thought" href="entries/access_entry.html">access</a> chips or the global net directly via implanted <a class="thought" href="entries/interface_entry.html">interface</a>s. Perhaps sensitive monitors will track brainwaves, myoelectricity (muscles) and other indices, and even impose patterns on our brains using powerful, directed magnetic fields. <a class="thought" href="entries/augmentation_entry.html">Augmentation</a>s of this kind, albeit rudimentary, are already seen at the lab level. Perhaps by 2020 we'll see boosted humans able to share their <a class="thought" href="entries/thought_entry.html">thought</a>s directly with <a class="thought" href="entries/computer_entry.html">computer</a>s. If so, it is a fair bet that <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a> and <a class="thought" href="entries/computer_science_entry.html">computer science</a> will combine to map the processes and <a class="thought" href="entries/algorithm_entry.html">algorithm</a>s of the naturally evolved <a class="thought" href="entries/brain_entry.html">brain</a>, and try to emulate it in <a class="thought" href="entries/machine_entry.html">machine</a>s. Unless there actually <i>is</i> a mysterious non-replicable <a class="thought" href="entries/spirit_entry.html">spirit</a>ual <a class="thought" href="entries/component_entry.html">component</a>, a <a class="thought" href="entries/soul_entry.html">soul</a>, we'd then expect to see a rapid transition to self-augmenting <a class="thought" href="entries/machine_entry.html">machine</a>s--and we'd be back to path [B i].</p><h2> [B iii] Increasing <a class="thought" href="entries/computer_entry.html">computer</a> power and advances in <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a> will lead to rapid <a class="thought" href="entries/uploading_entry.html">uploading</a> of <a class="thought" href="entries/human_entry.html">human</a> minds.</h2><p>On the other hand, if [B ii] turns out to be easier than [B i], we would open the door to rapid <a class="thought" href="entries/uploading_entry.html">uploading</a> technologies. Once the <a class="thought" href="entries/brain_entry.html">brain</a>/mind can be put into a parallel <a class="thought" href="entries/circuit_entry.html">circuit</a> with a <a class="thought" href="entries/machine_entry.html">machine</a> as complex as a <a class="thought" href="entries/human_entry.html">human</a> cortex (available, as we've seen, somewhere 2020 and 2040), we might expect a complete, real-<a class="thought" href="entries/time_entry.html">time</a> emulation of the scanned <a class="thought" href="entries/brain_entry.html">brain</a> to be run inside the <a class="thought" href="entries/machine_entry.html">machine</a> that's copied it. Again, unless the `soul' fails to <a class="thought" href="entries/port_entry.html">port</a> over along with the <a class="thought" href="entries/information_entry.html">information</a> and topological structure, you'd then find your perfect twin (although grievously short on, ahem, a body) dwelling inside the <a class="thought" href="entries/device_entry.html">device</a>.</p>
<p>Your uploaded double would need to be provided with adequate sensors (possibly <i>enhanced</i>, compared with our limited eyes and ears and tastebuds), plus means of acting with ordinary intuitive grace on the world (via physical effectors of some kind--robotic limbs, say, or a robotic telepresence). Or perhaps your upload twin would inhabit a <a class="thought" href="entries/cyberspace_entry.html">cyberspace</a> reality, less detailed than ours but more conducive to being rewritten closer to heart's desire. Such VR protocols should lend themselves readily to <a class="thought" href="entries/life_entry.html">life</a> as an uploaded personality.</p>
<p>Once personality <a class="thought" href="entries/uploading_entry.html">uploading</a> is shown to be possible and tolerable or, better still, enjoyable, we can expect at least some people to copy themselves into <a class="thought" href="entries/cyberspace_entry.html">cyberspace</a>. How rapidly this new world is colonised will depend on how expensive it is to <a class="thought" href="entries/port_entry.html">port</a> somebody there, and to sustain them. <a class="thought" href="entries/computer_entry.html">Computer</a> storage and run-<a class="thought" href="entries/time_entry.html">time</a> should be far cheaper by then, of course, but still not entirely free. As economist Robin Hanson has argued, the problem is amenable to traditional economic analysis. `I see very little chance that cheap fast upload copying <a class="thought" href="entries/technology_entry.html">technology</a> would not be used to cheaply create so many copies that the typical copy would have an income near `subsistence' level.'[13] On the other hand, `If you so choose to limit your copying, you might turn an initial nest egg into fabulous wealth, making your few descendants very rich and able to afford lots of <a class="thought" href="entries/memory_entry.html">memory</a>.'</p>
<p>If an explosion of uploads is due to occur quite quickly after the <a class="thought" href="entries/technology_entry.html">technology</a> emerges, early adopters would gobble up most of the available computing resources. But this assumes that uploaded personalities would retain the same apparent continuity we fleshly humans prize. Being <a class="thought" href="entries/binary_entry.html">binary</a> <a class="thought" href="entries/code_entry.html">code</a>, after all (however complicated), such people might find it easier to alter themselves--to rewrite their <a class="thought" href="entries/source_code_entry.html">source code</a>, so to speak, and to link themselves directly to other uploaded people, and AIs if there are any around. This looks like a recipe for a Spike to me. How soon? It depends. If true <a class="thought" href="entries/ai_entry.html">AI</a>-level <a class="thought" href="entries/machine_entry.html">machine</a>s are needed, and perhaps medical <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> to perform <a class="thought" href="entries/neuron_entry.html">neuron</a>-by-<a class="thought" href="entries/neuron_entry.html">neuron</a>, <a class="thought" href="entries/synapse_entry.html">synapse</a>-by <a class="thought" href="entries/synapse_entry.html">synapse</a> <a class="thought" href="entries/brain_scan_entry.html">brain scan</a>ning, we'll wait until both technologies are out of beta-testing and fairly stable. That would be 2040 or 2050, I'd guesstimate.</p><h2> [B iv] Increasing connectivity of the <a class="thought" href="entries/internet_entry.html">Internet</a> will allow individuals or small groups to amplify the effectiveness of their conjoined <a class="thought" href="entries/intelligence_entry.html">intelligence</a>.</h2><p>Routine disseminated <a class="thought" href="entries/software_entry.html">software</a> advances will create (or evolve) ever smarter and more useful support <a class="thought" href="entries/system_entry.html">system</a>s for <a class="thought" href="entries/thinking_entry.html">thinking</a>, gathering <a class="thought" href="entries/data_entry.html">data</a>, writing new <a class="thought" href="entries/program_entry.html">program</a>s--and the outcome will be a `in-one-bound-Jack-was-free' surge into <a class="thought" href="entries/ai_entry.html">AI</a>. That is the garage band model of a <a class="thought" href="entries/singularity_entry.html">singularity</a>, and while it has a certain cheesy appeal, I very much doubt that's how it will happen.</p>
<p>But the <a class="thought" href="entries/internet_entry.html">Internet</a> is growing and complexifying at a tremendous rate. It is barely possible that one day, as <a class="thought" href="entries/clarke_entry.html">Arthur C. Clarke</a> suggested decades ago of the telephone <a class="thought" href="entries/system_entry.html">system</a>, it will just... <i>wake up</i>. After all, that's what happened to a smart African ape, and unlike <a class="thought" href="entries/computer_entry.html">computer</a>s it and its close genetic cousins weren't already designed to handle <a class="thought" href="entries/language_entry.html">language</a> and <a class="thought" href="entries/mathematics_entry.html">mathematics</a>.</p><h2> [B v] <a class="thought" href="entries/research_entry.html">Research</a> and development of <a class="thought" href="entries/mems_entry.html">microelectromechanical systems</a> (<a class="thought" href="entries/mems_entry.html">MEMS</a>) and fullerene-based <a class="thought" href="entries/device_entry.html">device</a>s will lead to industrial nanoassembly, and thence to `anything boxes'.</h2><p>Here we have the `classic' molecular <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> pathway, as predicted by Drexler's <a class="thought" href="entries/foresight_institute_entry.html">Foresight Institute</a> and <a class="thought" href="entries/nasa_entry.html">NASA</a>,[14] but also by the mainstream of conservative chemists and adjacent scientists working in <a class="thought" href="entries/mems_entry.html">MEMS</a>, and funded <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> labs around the world. In a 1995 <a class="thought" href="entries/wired_entry.html">Wired</a> article, Eric Drexler predicted <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> within 20 years. Is 2015 too soon? Not, surely, for the early stage <a class="thought" href="entries/device_entry.html">device</a>s under development by <a class="thought" href="entries/zyvex_entry.html">Zyvex</a> Corporation in Texas, who hope to have at least preliminary results by 2010, if not sooner.[15] For many years <a class="thought" href="entries/ai_entry.html">AI</a> was granted huge amounts of <a class="thought" href="entries/research_entry.html">research</a> funding, without much result (until recently, with a shift in direction and the wind of <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's Law</a> at its back). Nano is now starting to catch the <a class="thought" href="entries/research_entry.html">research</a> dollars, with substantial investment from <a class="thought" href="entries/government_entry.html">government</a>s (half a billion promised by Clinton; and in Japan, even Australia) and mega-companies such as <a class="thought" href="entries/ibm_entry.html">IBM</a>. The prospect of successful <a class="thought" href="entries/nanotechnology_entry.html">nanotech</a> is exciting, but should also make you afraid, very afraid. If nano remains (or rather, becomes) a closely guarded national secret, contained by munitions laws, a new balance of terror might take us back to something like the Cold War in international relations--but this would be a polyvalent, fragmented, perhaps tribalised balance.</p>
<p>Or building and using <a class="thought" href="entries/nanotechnology_entry.html">nanotech</a> might be like the manufacture of dangerous drugs or nuclear materials: centrally produced by big corporations' mints, under stringent protocols (you hope, fearful visions of Homer Simpson's nuclear plant dancing in the back of your <a class="thought" href="entries/brain_entry.html">brain</a>), except for those in Colombia and the local bikers' fortress...</p>
<p>Or it might be a Ma &amp; Pa business<i>:</i> a local plant equal, perhaps, to a used car yard, with a fair-sized raw materials pool, mass transport to shift raw or partly processed feed stocks in, and finished product out. This level of implementation might resemble a small <a class="thought" href="entries/internet_entry.html">internet</a> <a class="thought" href="entries/server_entry.html">server</a>, with some hundreds or thousands of customers. One might expect the <a class="thought" href="entries/technology_entry.html">technology</a> to grow more sophisticated quite quickly, as minting allows the emergence of cheap and amazingly powerful <a class="thought" href="entries/computer_entry.html">computer</a>s. Ultimately, we might find ourselves with the fabled anything box in every household, protected against malign uses by an internal <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a> as smart as a <a class="thought" href="entries/human_entry.html">human</a>, but without <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/consciousness_entry.html">consciousness</a> and distractibility. We should be so lucky. But it could happen that way.</p>
<p>A quite different outcome is foreshadowed in a prescient 1959 <a class="thought" href="entries/novel_entry.html">novel</a> by Damon Knight, <i>A for Anything,</i> in which a `matter duplicator' leads not to <a class="thought" href="entries/utopian_entry.html">utopian</a> prosperity for all but to cruel feudalism, a regression to brutal personal power held by those clever thugs who manage to monopolise the <a class="thought" href="entries/device_entry.html">device</a>. A slightly less <a class="thought" href="entries/dystopian_entry.html">dystopian</a> <a class="thought" href="entries/future_entry.html">future</a> is portrayed in Neal Stephenson's satirical but seriously intended <i>The Diamond Age</i>, where tribes and nations and new optional tetherings of people under flags of affinity or convenience tussle for advantage in a world where the <a class="thought" href="entries/basic_entry.html">basic</a> needs of the many poor are provided free, but with galling drab uniformity, at street corner <a class="thought" href="entries/matter_entry.html">matter</a> <a class="thought" href="entries/compiler_entry.html">compiler</a>s owned by authorities. That is one way to prevent global ruination at the hands of crackers, lunatics and criminals, but it's not one that especially appeals--if an alternative can be found.</p>
<p>Meanwhile, will nanoassembly allow the rich to get richer--to hug this magic cornucopia to their selfish breasts--while the poor get poorer? Why should it be so? In a world of 10 billion flesh-and-blood humans (ignoring the uploads for now), there is plenty of <a class="thought" href="entries/space_entry.html">space</a> for everyone to own decent housing, transport, clothing, arts, <a class="thought" href="entries/music_entry.html">music</a>, sporting opportunities... once we grant the ready availability of nano mints. Why would the rich permit the poor to own the <a class="thought" href="entries/machine_entry.html">machine</a>ries of freedom from want? Some optimists adduce benevolence, others prudence. Above all, perhaps, is the <a class="thought" href="entries/basic_entry.html">basic</a> law of an <a class="thought" href="entries/information_entry.html">information</a>/<a class="thought" href="entries/knowledge_entry.html">knowledge</a> economy: the more people you have <a class="thought" href="entries/thinking_entry.html">thinking</a> and solving and inventing and finding the bugs and figuring out the patches, the better a nano minting world is for everyone (just as it is for an <a class="thought" href="entries/open_source_entry.html">open source</a> computing world). Besides, how could they stop us?[16] (Well, by brute force, or in the name of all that's decent, or for our own moral good. None of these methods will long prevail in a world of free-flowing <a class="thought" href="entries/information_entry.html">information</a> and cheap material assembly. Even China has trouble keeping dissidents and mystics silenced.)</p>
<p>The big necessary step is the prior development of early nano <a class="thought" href="entries/assembler_entry.html">assembler</a>s, and this will be funded by university and <a class="thought" href="entries/corporate_entry.html">corporate</a> (and <a class="thought" href="entries/military_entry.html">military</a>) money for <a class="thought" href="entries/research_entry.html">research</a>ers, as well as by increasing numbers of private investors who see the marginal pay-offs in owning a piece of each consecutive improvement in micro- and nano-scale <a class="thought" href="entries/device_entry.html">device</a>s. So yes, the rich will get richer--but the poor will get richer too, as by and large they do now, in the developed world at least. Not <i>as</i> rich, of course, nor <i>as</i> fast. By the <a class="thought" href="entries/time_entry.html">time</a> the nano and <a class="thought" href="entries/ai_entry.html">AI</a> revolutions have attained maturity, these classifications will have shifted ground. Economists insist that rich and poor will still be with us, but the metric will have changed so drastically, so strangely, that we here-and-now can make little <a class="thought" href="entries/sense_entry.html">sense</a> of it.</p><h2> [B vi] <a class="thought" href="entries/research_entry.html">Research</a> and development in <a class="thought" href="entries/genomics_entry.html">genomics</a> (the <a class="thought" href="entries/human_genome_entry.html">Human Genome Project</a>, etc) will lead to new `wet' <a class="thought" href="entries/biotechnology_entry.html">biotechnology</a>, lifespan extension, and ultimately to <a class="thought" href="entries/transhuman_entry.html">transhuman</a> enhancements.</h2><p>This is a rather different approach, and increasingly I see experts arguing that it is the short-cut to mastery of the worlds of the very small and the very complex. <a class="thought" href="entries/biology_entry.html">Biology</a><i>, not computing!</i> is the slogan. After all, <a class="thought" href="entries/bacteria_entry.html">bacteria</a>, ribosomes, viruses, cells for that <a class="thought" href="entries/matter_entry.html">matter</a>, already operate beautifully at the micro- and even the nano-scales.</p>
<p>Still, even if <a class="thought" href="entries/technology_entry.html">technology</a> takes a major turn away from mechanosynthesis and `hard' minting, this approach will require a vast armory of traditional and innovative <a class="thought" href="entries/computer_entry.html">computer</a>s and appropriately ingenious <a class="thought" href="entries/software_entry.html">software</a>. The <a class="thought" href="entries/ibm_entry.html">IBM</a> petaflop project Blue Gene (doing a quadrillion operations a second) will be a huge <a class="thought" href="entries/system_entry.html">system</a> of parallel processors designed to explore <a class="thought" href="entries/protein_entry.html">protein</a> folding, crucial once the <a class="thought" href="entries/genome_entry.html">genome</a> projects have compiled their immense catalog of genes. Knowing a gene's recipe is little value unless you know, as well, how the <a class="thought" href="entries/protein_entry.html">protein</a> it encodes twists and curls in three-dimensional <a class="thought" href="entries/space_entry.html">space</a>. That is the promise of the first couple of decades of the 21st century, and it will surely unlock many secrets and open new pathways.</p>
<p>Exploring those paths will require all the help molecular biologists can get from advanced <a class="thought" href="entries/computer_entry.html">computer</a>s, <a class="thought" href="entries/virtual_reality_entry.html">virtual reality</a> displays, and <a class="thought" href="entries/ai_entry.html">AI</a> adjuncts. Once again, we can <a class="thought" href="entries/reason_entry.html">reason</a>ably expect those paths to track right into the foothills of the Spike. Put a date on it? Nobody knows--but recall that <a class="thought" href="entries/dna_entry.html">DNA</a> was first decoded in 1953, and by around half a century later the whole <a class="thought" href="entries/genome_entry.html">genome</a> will be in the bag. How long until the next transcendent step--complete understanding of all our genes, how they express themselves in tissues and organs and abilities and behavioural bents, how they can be tweaked to improve them dramatically? Cautiously, the same interval: around 2050. More likely (if <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> keeps chugging along), half that time: 2025 or 2030.</p>
<p>The usual timetable for the Spike, in other words.</p><h2> [C] The <a class="thought" href="entries/singularity_entry.html">Singularity</a> happens when we go out and make it happen.</h2><p>That's <a class="thought" href="entries/yudkowsky_entry.html">Eliezer Yudkowsky</a>'s sprightly, in-your-face declaration of intent, which dismisses as uncomprehending all the querulous cautions about the transition to <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a> and the <a class="thought" href="entries/singularity_entry.html">Singularity</a> on its far side.[17]</p>
<p>Just getting to <a class="thought" href="entries/human_entry.html">human</a>-level <a class="thought" href="entries/ai_entry.html">AI</a>, this analysis claims, is enough for the final push to a Spike. How so? Don't we need unique competencies to do that' Isn't the emergence of ultra-<a class="thought" href="entries/intelligence_entry.html">intelligence</a>, either augmented-<a class="thought" href="entries/human_entry.html">human</a> or artificial, the very definition of a Vingean <a class="thought" href="entries/singularity_entry.html">singularity</a>?</p>
<p>Yes, but this is most likely to happen when a <a class="thought" href="entries/system_entry.html">system</a> with the innate ability to view and reorganise its own cognitive structure gains the conscious power of a <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a>. A <a class="thought" href="entries/machine_entry.html">machine</a> might have that facility, since its <a class="thought" href="entries/program_entry.html">program</a>ming is listable, you could literally print it out--in many, many volumes--and check each line. Not so an equivalent <a class="thought" href="entries/human_entry.html">human</a>, with our <a class="thought" href="entries/protein_entry.html">protein</a> spaghetti brains, compiled by gene recipes and chemical gradients rather than exact <a class="thought" href="entries/algorithm_entry.html">algorithm</a>s; we clearly just can't do that.</p>
<p>So intelligent design turned back upon itself, a cascading multiplier that has no obvious bounds. The primary challenge becomes <a class="thought" href="entries/software_entry.html">software</a>, not <a class="thought" href="entries/hardware_entry.html">hardware</a>. The raw petaflop end of the project is chugging along nicely now, mapped by <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's Law</a>, but even if it tops out, it doesn't <a class="thought" href="entries/matter_entry.html">matter</a>. A self-improving seed <a class="thought" href="entries/ai_entry.html">AI</a> could run glacially slowly on a limited <a class="thought" href="entries/machine_entry.html">machine</a> <a class="thought" href="entries/substrate_entry.html">substrate</a>. The point is, so long as it has the capacity to improve itself, at some point it will do so convulsively, bursting through any architectural bottlenecks to <i>design</i> its own improved <a class="thought" href="entries/hardware_entry.html">hardware</a>, maybe even build it (if it's allowed control of tools in a fabrication plant). So what determines the arrival of the <a class="thought" href="entries/singularity_entry.html">Singularity</a> is just the amount of effort invested in getting the original seed <a class="thought" href="entries/software_entry.html">software</a> written and debugged.</p>
<p>This particular argument is detailed in Yudkowsky's ambitious web documents `Coding a <a class="thought" href="entries/transhuman_entry.html">Transhuman</a> <a class="thought" href="entries/ai_entry.html">AI</a>', `Singularity Analysis' and `The Plan to <a class="thought" href="entries/singularity_entry.html">Singularity</a>'. It doesn't <a class="thought" href="entries/matter_entry.html">matter</a> much, though, whether these specific plans hold up under detailed expert scrutiny; they serve as a <a class="thought" href="entries/access_entry.html">access</a>ible model for the process we're discussing.</p>
<p>Here we see conventional open-source <a class="thought" href="entries/machine_entry.html">machine</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, starting with industrial <a class="thought" href="entries/ai_entry.html">AI</a>, leading to a self-rewriting seed <a class="thought" href="entries/ai_entry.html">AI</a> which runs right into takeoff to a <a class="thought" href="entries/singularity_entry.html">singularity</a>. You'd have a <a class="thought" href="entries/machine_entry.html">machine</a> that combines the brains of a <a class="thought" href="entries/human_entry.html">human</a> (maybe literally, in coded format, although that is not part of Yudkowsky's scheme) with the speed and <a class="thought" href="entries/memory_entry.html">memory</a> of a shockingly fast <a class="thought" href="entries/computer_entry.html">computer</a>. It won't be like anything we've ever seen on <a class="thought" href="entries/earth_entry.html">earth</a>. It should be able to optimise its abilities, compress its <a class="thought" href="entries/source_code_entry.html">source code</a>, turn its <a class="thought" href="entries/architecture_entry.html">architecture</a> from a swamp of <a class="thought" href="entries/mud_entry.html">mud</a> huts into a gleaming, compact, ergonomic office (with a spa and a bar in the penthouse, lest we think this is all grim earnest).[18] Here is quite a compelling portrait of what it might be like, `human high-level <a class="thought" href="entries/consciousness_entry.html">consciousness</a> and <a class="thought" href="entries/ai_entry.html">AI</a> rapid <a class="thought" href="entries/algorithm_entry.html">algorithm</a>ic performance combined synergetically,' to be such a <a class="thought" href="entries/machine_entry.html">machine</a>:</p>
<p>Combining <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a> with Kasparov... yields a Kasparov who can wonder `How can I put a queen here?' and blink out for a fraction of a second while a million moves are automatically examined. At a higher level of integration, Kasparov's conscious perceptions of each consciously examined <a class="thought" href="entries/chess_entry.html">chess</a> position may incorporate <a class="thought" href="entries/data_entry.html">data</a> culled from a million possibilities, and Kasparov's dozen examined positions may not be consciously simulated moves, but `skips' to the dozen most plausible <a class="thought" href="entries/future_entry.html">future</a>s five moves ahead.[19]</p>
<p>Such a <a class="thought" href="entries/machine_entry.html">machine</a>, we see, is not really <a class="thought" href="entries/human_entry.html">human</a>-equivalent after all. If it isn't already <a class="thought" href="entries/transhuman_entry.html">transhuman</a> or superhuman, it will be as soon as it has hacked through its own <a class="thought" href="entries/code_entry.html">code</a> and revised it (<a class="thought" href="entries/bit_entry.html">bit</a> by <a class="thought" href="entries/bit_entry.html">bit</a>, module by module, making mistakes and rebooting and trying again until the whole package comes out right). If that account has any validity, we also see why the decades-long pauses in the <a class="thought" href="entries/time_entry.html">time</a>-tables cited earlier are dubious, if not preposterous. Given a <a class="thought" href="entries/human_entry.html">human</a>-level <a class="thought" href="entries/ai_entry.html">AI</a> by 2039, it is not going to wait around biding its <a class="thought" href="entries/time_entry.html">time</a> until 2099 before creating a discontinuity in cognitive and technological <a class="thought" href="entries/history_entry.html">history</a>. That will happen quite fast, since a self-optimising <a class="thought" href="entries/machine_entry.html">machine</a> (or upload, perhaps) will start to function so much faster than its <a class="thought" href="entries/human_entry.html">human</a> colleagues that it will simply leave them behind, along with Moore's plodding Law. A key distinguishing feature, if Yudkowsky's analysis is sound, is that we never will see <a class="thought" href="entries/hal_entry.html">HAL</a>, the autonomous <a class="thought" href="entries/ai_entry.html">AI</a> in the movie <i>2001</i>. All we will see is <a class="thought" href="entries/ai_entry.html">AI</a> specialized to develop <a class="thought" href="entries/software_entry.html">software</a>.</p>
<p>Since I don't know the true shape of the <a class="thought" href="entries/future_entry.html">future</a> any more than you do, I certainly don't know whether an <a class="thought" href="entries/ai_entry.html">AI</a> or nano-minted <a class="thought" href="entries/singularity_entry.html">Singularity</a> will be brought about (assuming it does actually occur) by careful, effortful design in an Institute with a Spike engraved on its door, by a congeries of industrial and scientific <a class="thought" href="entries/research_entry.html">research</a> vectors, or by <a class="thought" href="entries/military_entry.html">military</a> ambitions pouring zillions of dollars into a new arena that promises endless power through mayhem, or mayhem threatened.</p>
<p>It does strike me as excessively unlikely that we will skid to a stop anytime soon, or even that a conventional utopia minus any runaway <a class="thought" href="entries/singularity_entry.html">singularity</a> sequel (<a class="thought" href="entries/star_entry.html">Star</a><i> Trek</i>'s complacent <a class="thought" href="entries/future_entry.html">future</a>, say) will roll off the mechanosynthesising assembly line.[20]</p>
<p>Are there boringly obvious technical obstacles to a Spike? Granted, particular techniques will surely saturate and pass through inflexions points, tapering off their headlong thrust. If the past is any guide, new improved techniques will arrive (or be forced into reality by the lure of profit and sheer curiosity) in <a class="thought" href="entries/time_entry.html">time</a> to carry the curves upward at the same acceleration. If not? Well, then, it will take longer to reach the Spike, but it is hard to see why <a class="thought" href="entries/progress_entry.html">progress</a> in the necessary technologies would simply <i>stop</i>.</p>
<p>Well, perhaps some of these options will become technically feasible but remain simply unattractive, and hence bypassed. Dr Russell Blackford, a lawyer, former industrial advocate and literary theorist who has written interestingly about social resistance to major innovation, notes that manned exploration of Mars has been a technical possibility for the past three decades, yet that challenge has not been taken up. Video-conferencing is available but few use it (unlike the instant adoption of mobile phones). While a concerted <a class="thought" href="entries/program_entry.html">program</a> involving enough money and with widespread public support could bring us conscious <a class="thought" href="entries/ai_entry.html">AI</a> by 2050, he argues, it won't happen. Conflicting social priorities will emerge, the task will be difficult and horrendously expensive. Are these objections valid? <a class="thought" href="entries/ai_entry.html">AI</a> and nano need not be impossibly hard and costly, since they will flow from current work powered by <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's Law</a> improvements. Missions to Mars, by contrast, have no obvious social or consumer or even scientific benefits beyond their simple feel-good achievement. Profound <a class="thought" href="entries/science_entry.html">science</a> can be done by remote vehicles. By contrast, minting and <a class="thought" href="entries/ai_entry.html">AI</a> or IA will bring immediate and copious benefits to those developing them--and will become less and less expensive, just as desktop <a class="thought" href="entries/computer_entry.html">computer</a>s have.</p>
<p>What of social forces taking up arms against this <a class="thought" href="entries/future_entry.html">future</a>? We've seen the start of a new round of protests and civil disruptions aimed at genetically <a class="thought" href="entries/engine_entry.html">engine</a>ered foods and work in cloning and <a class="thought" href="entries/genomics_entry.html">genomics</a>, but not yet targeted at longevity or computing <a class="thought" href="entries/research_entry.html">research</a>. It will come, inevitably. We shall see strange bedfellows arrayed against the <a class="thought" href="entries/machine_entry.html">machine</a>ries of major change. The only question is how effective its impact will be.</p>
<p>In 1999, for example, emeritus professor Alan Kerr, winner of the lucrative inaugural Australia Prize for his work in plant pathology, radio-broadcast a heartfelt denunciation of the Green's adamant opposition to new genetically <a class="thought" href="entries/engine_entry.html">engine</a>ered crops that allow use of <a class="thought" href="entries/insect_entry.html">insect</a>icide to be cut by half. Some aspects of <a class="thought" href="entries/science_entry.html">science</a>, though, did concern Dr Kerr. He admitted that he'd been `scared witless' by the `thesis is that within a generation or two, <a class="thought" href="entries/science_entry.html">science</a> will have conquered <a class="thought" href="entries/death_entry.html">death</a> and that humans will become immortal. Have you ever <a class="thought" href="entries/thought_entry.html">thought</a> of the consequences to society and the environment of such an achievement? If you're anything like me, there might be a few sleepless nights ahead of you. Why don't the greenies get stuck into this potentially horrifying area of <a class="thought" href="entries/science_entry.html">science</a>, instead of attacking genetic <a class="thought" href="entries/engine_entry.html">engine</a>ering with all its promise for agriculture and the environment?'[21] This, I suspect, is a short-sighted and ineffective diversionary tactic. It will arouse confused opposition to <a class="thought" href="entries/life_extension_entry.html">life extension</a> and other beneficial on-going <a class="thought" href="entries/research_entry.html">research</a> <a class="thought" href="entries/program_entry.html">program</a>s, but will lash back as well against any ill-understood <a class="thought" href="entries/technology_entry.html">technology</a>.</p>
<p>Cultural objections to <a class="thought" href="entries/ai_entry.html">AI</a> might emerge, as venomous as yesterday's and today's attacks on contraception and abortion rights, or anti-racist struggles. If opposition to the Spike, or any of its contributing factors, gets attached to one or more influential <a class="thought" href="entries/religion_entry.html">religion</a>s, that might <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> back or divert the current. Alternatively, careful study of the risks of general <a class="thought" href="entries/assembler_entry.html">assembler</a>s and autonomous <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> might lead to just the kinds of moratoriums that Greens now urge upon genetically <a class="thought" href="entries/engine_entry.html">engine</a>ered crops and herds. Given the <a class="thought" href="entries/time_entry.html">time</a> lag we can expect before a <a class="thought" href="entries/singularity_entry.html">singularity</a> occurs--at least a decade, and far more probably two or three--there's room for plenty of informed specializt and public debate. Just as the <a class="thought" href="entries/basic_entry.html">basic</a> technologies of the Spike will depend on design-ahead projects, so too we'll need a kind of think-ahead <a class="thought" href="entries/program_entry.html">program</a> to prepare us for changes that might, indeed, scare us witless. And of course, the practical impact of new technologies condition the sorts of social values that emerge; recall the subtle interplay between the oral contraceptive pill and sexual mores, and the swift, easy acceptance of <i>in vitro</i> conception.</p>
<p>Despite these possible impediments to the arrival of the Spike, I suggest that while it might be delayed, almost certainly it's not going to be halted. If anything, the surging advances I see every day coming from labs around the world convince me that we already are racing up the lower slopes of its curve into the incomprehensible.</p>
<p>In short, it makes little <a class="thought" href="entries/sense_entry.html">sense</a> to try to pin down the <a class="thought" href="entries/future_entry.html">future</a>. Too many strange changes are occurring already, with more lurking just out of sight, ready to leap from the equations and surprise us. True <a class="thought" href="entries/ai_entry.html">AI</a>, when it occurs, might rush within days or months to SI (<a class="thought" href="entries/superintelligence_entry.html">superintelligence</a>), and from there into a realm of Powers whose motives and plans we can't even start to second-guess. Nano minting could go feral or worse, used by crackpots or statesmen to squelch their foes and rapidly smear us all into paste. Or sublime <a class="thought" href="entries/ai_entry.html">AI</a> Powers might use it to the same end, recycling our atoms into better living through femtotechnology.</p>
<p>The single thing I feel confident of is that one of these trajectories will start its visible run up the right-hand side of the graph within 10 or 20 years, and by 2030 (or 2050 at latest) will have put everything we hold self-evident into question. We will live forever; or we will all perish most horribly; our minds will emigrate to <a class="thought" href="entries/cyberspace_entry.html">cyberspace</a>, and start the most ferocious overpopulation race ever seen on the <a class="thought" href="entries/planet_entry.html">planet</a>; or our <a class="thought" href="entries/machine_entry.html">machine</a>s will transcend and take us with them, or leave us in some peaceful backwater where the meek shall inherit the <a class="thought" href="entries/earth_entry.html">Earth</a>. Or something else, something far weirder and... <i>unimaginable</i>. Don't blame me. That's what I promised you.</p><h1>NOTES</h1><a name="r1"></a>
<p class="Reference">1. See <a class="thought" href="entries/vinge_entry.html">Vernor Vinge</a>, <i>True Names... and Other Dangers,</i> New York: Baen Books, 1987; <i>Threats... and Other Promises,</i> New York: Baen Books, 1988; and especially <i>Marooned in Realtime,</i> London: Pan Books, 1987. An important source is his Address to <a class="thought" href="entries/nasa_entry.html">NASA</a> VISION-21 Symposium, March 30-31, 1993, <a class="thought" href="entries/download_entry.html">download</a>able from <a href="http://web.archive.org/web/20071011093741/http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html" target="_new">http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html</a>  or <a href="http://web.archive.org/web/20071011093741/http://www.frc.ri.cmu.edu/~hpm/book98/com.ch1/vinge.%20singularity.html" target="_new">http://www.frc.ri.cmu.edu/
~hpm/book98/com.ch1/vinge.singularity.html</a>
</p>
<a name="r2"></a>
<p class="Reference">For a general survey of this topic in far greater detail than I can provide in this essay, see my <i>The Spike: Accelerating into the Unimaginable </i><a class="thought" href="entries/future_entry.html">Future</a> (Melbourne, Australia: Reed Books/New Holland, 1997; the revised, expanded and updated edition is: <i>The Spike: How our Lives are Being Changed by Rapidly Advancing Technologies</i> New York: Tor/Forge, February 2001).</p>
<a name="r3"></a>
<p class="Reference">2. Private <a class="thought" href="entries/communication_entry.html">communication</a>, August, 1996. Vinge's own most recent picture of a plausible 2020, cautiously <i>sans</i> <a class="thought" href="entries/singularity_entry.html">Singularity</a>, emphasises the role of embedded <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/network_entry.html">network</a>s so ubiquitous that finally they link into a kind of <a class="thought" href="entries/cyberspace_entry.html">cyberspace</a> Gaia, even merge with the original Gaia, that geological and <a class="thought" href="entries/biological_entry.html">biological</a> macro-ecosystem of the globe (<a class="thought" href="entries/vinge_entry.html">Vernor Vinge</a>, `The <a class="thought" href="entries/digital_entry.html">Digital</a> Gaia,' <a class="thought" href="entries/wired_entry.html">Wired</a>, January 2000, pp. 74-8). However, on the last day of 1999, Vinge told me in an email: `The <a class="thought" href="entries/basic_entry.html">basic</a> argument hasn't changed.'</p>
<a name="r4"></a>
<p class="Reference">3. Alvin Toffler, <a class="thought" href="entries/future_entry.html">Future</a><i> Shock</i>, [1970] London: Pan Books, 1972, p. 170.</p>
<a name="r5"></a>
<p class="Reference">4. See, for a simplified discussion, Nobelist Steven Weinberg's summary article `A Unified <a class="thought" href="entries/physics_entry.html">Physics</a> by 2050?', <i>Scientific American</i>, December 1999, pp. 36-43.</p>
<a name="r6"></a>
<p class="Reference">5. <a href="http://web.archive.org/web/20071011093741/http://www.wired.com/wired/archive/8.04/joy.html" target="_new">http://www.wired.com/wired/archive/8.04/joy.html</a>
</p>
<a name="r7"></a>
<p class="Reference">6. See the late economist Julian Simon's readable and optimistic book <i>The Ultimate Resource</i> at <a href="http://web.archive.org/web/20071011093741/http://www.inform.umd.edu/EdRes/Colleges/BMGT/.Faculty/JSimon/Ultimate_Resource/" target="_new">http://www.inform.umd.edu/EdRes/Colleges/BMGT/ .Faculty/JSimon/Ultimate_Resource/</a>
</p>
<a name="r8"></a>
<p class="Reference">7. <a href="http://web.archive.org/web/20071011093741/http://www4.nationalacademies.org/news.nsf/isbn/0309068916?OpenDocument" target="_new">http://www4.nationalacademies.org/ news.nsf/isbn/0309068916?OpenDocument</a>
</p>
<a name="r9"></a>
<p class="Reference">8. Ray Kurzweil, The <a class="thought" href="entries/age_of_spiritual_machines_entry.html">Age of Spiritual Machines</a>: When <a class="thought" href="entries/computer_entry.html">Computer</a>s Exceed <a class="thought" href="entries/human_entry.html">Human</a> <a class="thought" href="entries/intelligence_entry.html">Intelligence</a>, Sydney: Allen &amp; Unwin, 1999.</p>
<a name="r10"></a>
<p class="Reference">9. <a href="http://web.archive.org/web/20071011093741/http://merkle.com/merkle" target="_new">http://merkle.com/merkle</a>
</p>
<a name="r11"></a>
<p class="Reference">10. <a href="http://web.archive.org/web/20071011093741/http://www.frc.ri.cmu.edu/~hpm/book98/" target="_new">http://www.frc.ri.cmu.edu/~hpm/book98/</a>
</p>
<a name="r12"></a>
<p class="Reference">11. Michio Kaku, Visions: How <a class="thought" href="entries/science_entry.html">Science</a> Will Revolutionize the 21st Century and Beyond, Oxford University Press, 1998, p. 28.</p>
<a name="r13"></a>
<p class="Reference">12. <a href="http://web.archive.org/web/20071011093741/http://news.bbc.co.uk/hi/english/sci/tech/newsid_503000/503552.stm" target="_new">http://news.bbc.co.uk/hi/
english/sci/tech/newsid_503000/503552.stm</a>
</p>
<a name="r14"></a>
<p class="Reference">13. Personal <a class="thought" href="entries/communication_entry.html">communication</a>, 8 December, 1999.</p>
<a name="r15"></a>
<p class="Reference">14. <a href="http://web.archive.org/web/20071011093741/http://www.nas.nasa.gov/Groups/SciTech/nano/index.html" target="_new">http://www.nas.nasa.gov/Groups/
SciTech/nano/index.html</a>
</p>
<a name="r16"></a>
<p class="Reference">15. <a href="http://web.archive.org/web/20071011093741/http://www.zyvex.com/" target="_new">http://www.zyvex.com</a>
</p>
<a name="r17"></a>
<p class="Reference">16. Some <a class="thought" href="entries/thought_entry.html">thought</a>s on the difficult of containing <a class="thought" href="entries/nanotechnology_entry.html">nanotech</a> (with some comparisons to <a class="thought" href="entries/software_entry.html">software</a> piracy `warez'), and the likely evaporation of our current economy, can be found in: <a href="http://web.archive.org/web/20071011093741/http://www.cabell.org/Quincy/Documents/Nanotechnology/hello_nanotechnology.html" target="_new">http://www.cabell.org/Quincy/Documents/
Nanotechnology/hello_nanotechnology.html</a>
</p>
<a name="r18"></a>
<p class="Reference">17. http://pobox.<a class="thought" href="entries/com_entry.html">com</a>/~sentience/<a class="thought" href="entries/singularity_entry.html">singularity</a>.<a class="thought" href="entries/html_entry.html">html</a></p>
<a name="r19"></a>
<p class="Reference">18. Sorry, that's me again; Yudkowsky didn't say it.</p>
<a name="r20"></a>
<p class="Reference">19.<a href="%20http://www.pobox.com/~sentience/AI_design.temp.html#view_advantage" target="_new"> http://www.pobox.com/~sentience/
AI_design.temp.html#view_advantage</a>
</p>
<a name="r21"></a>
<p class="Reference">20. To be fair, the <a class="thought" href="entries/star_entry.html">Star</a><i> Trek</i> franchise has always made room for alien civilisations that have passed through a <a class="thought" href="entries/singularity_entry.html">singularity</a> and become as gods. It's just that television's notion of post-Spike entities stops short at mimicry of Greek and Roman mythology (Xena the Warrior Princess goes to the <a class="thought" href="entries/future_entry.html">future</a>), <a class="thought" href="entries/spirit_entry.html">spirit</a>ualised transformations of humans into a sort of angel (familiar also from <i>Babylon-5</i>), down-market cyberpunk collectivity (the Borg), or sardonic whimsy (the entertaining character Q, from the Q dimension, where almost anything can happen and usually does). It's hard not to wonder why <a class="thought" href="entries/immortality_entry.html">immortality</a> is not assured by the transporter or the replicator, which can obviously encode a whole person as easily as a piping hot cup of Earl Gray tea, or why people age and die despite the <a class="thought" href="entries/future_entry.html">future</a>'s superb <a class="thought" href="entries/medicine_entry.html">medicine</a>. The <a class="thought" href="entries/reason_entry.html">reason</a>s, obviously, have nothing to do with plausible extrapolation and everything to do with telling an entertaining tale, using a range of contemporary <a class="thought" href="entries/human_entry.html">human</a> actors, that appeals to the largest demographic and ruffles as few feathers as possible while still delivering some faint frisson of difference and <a class="thought" href="entries/future_entry.html">future</a> shock.</p>
<a name="r22"></a>
<p class="Reference">21. <a href="http://web.archive.org/web/20071011093741/http://abc.net.au/rn/science/ockham/stories/s54399.htm" target="_new">http://abc.net.au/rn/science/
ockham/stories/s54399.htm</a>
</p>
<a name="r23"></a>
<p class="Reference">The book that frightened Dr Kerr was my <i>The Last Mortal Generation</i> (Sydney, Australia: New Holland, 1999). <i>The Spike,</i> by contrast, would surely shock him rigid. <a class="thought" href="entries/clarke_entry.html">Arthur C. Clarke</a>, by the way, took a different view of <i>Last Mortal:</i> in <i>Profiles of the </i><a class="thought" href="entries/future_entry.html">Future</a> (London: Gollancz, 1999), he generously called it `this truly mind-stretching book' (p. 189). I much prefer to stretch minds than scare them witless.</p>
<p>This paper was given at the three-day symposium <i>Australia at the Crossroads? Scenarios and Strategies for the </i><a class="thought" href="entries/future_entry.html">Future</a>, 31 April-2 May 2000, at the John Curtin International Institute. Curtin University of <a class="thought" href="entries/technology_entry.html">Technology</a>, Perth, WA, Australia.</p>
</td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20071011093741/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10528" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id10529"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Beyond...<br><span class="mindxheader"><i>posted on 10/04/2002 12:27 AM by pmaloka@entertaininggames.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011093741/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D10528%23id10529" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011093741/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10529" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>In attempting to see "beyond", we need to think beyond...
<br>
<br>
Perhaps the universe is empty because every previous intelligence has reached singularity. 
<br>
<br>
Perhaps, post singularity, the universe as we know it becomes unimportant. 
<br>
<br>
Perhaps, we reach a level of understanding and perception where we see all new horizons that are for more compelling. 
<br>
<br>
Perhaps the universe of the mathematics, perhaps the universe of mind. 
<br>
<br>
Perhaps, with technology to "amplify" our abilities, we are able to establish true communications with other dimensions. Would these 3 dimensions still be so exciting then?
<br>
<br>
Even more intersting to me, is perhaps, we are able to link with our Creator. Perhaps, heaven is real after all. And we could all be just a few years from reaching it.
<br>
<br>
Perhaps, the end is near. And what a beautiful ending it could be.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16556"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Tearing Toward the Spike<br><span class="mindxheader"><i>posted on 04/27/2003 5:07 AM by <a href="https://web.archive.org/web/20071011093741/http://www.kurzweilai.net/mindx/profile.php?id=264">hans123</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011093741/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D10528%23id16556" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011093741/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16556" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>quote 
<br>
In attempting to see "beyond", we need to think beyond... 
<br>
<br>
Perhaps the universe is empty because every previous intelligence has reached singularity. 
<br>
<br>
Perhaps, post singularity, the universe as we know it becomes unimportant. 
<br>
<br>
Perhaps, we reach a level of understanding and perception where we see all new horizons that are for more compelling. 
<br>
<br>
Perhaps the universe of the mathematics, perhaps the universe of mind. 
<br>
<br>
Perhaps, with technology to "amplify" our abilities, we are able to establish true communications with other dimensions. Would these 3 dimensions still be so exciting then? 
<br>
<br>
Even more interesting to me, is perhaps, we are able to link with our Creator. Perhaps, heaven is real after all. And we could all be just a few years from reaching it. 
<br>
<br>
Perhaps, the end is near. And what a beautiful ending it could be.
<br>
/quote
<br>
<br>
Maybe maybe...
<br>
Maybe we all live in some sort of 'matrix' virtual reality without knowing it. 
<br>
Maybe that's the origin of the quantum uncertainty principle. When you look too close at the building bricks of reality it becomes fuzzy..
<br>
Maybe UFO's and 'alien encounters' are time travelling visitors from the post singularity universe.
<br>
Maybe crop circles are some joke on us practised by post singularity time travelers. 
<br>
Maybe excist only an eternal now with all possible alternate time lines or futures at once.
<br>
Maybe ( I think sure) we lack the overall view and can only see the universe as a time line: past-present-future.
<br>
Maybe the universe is only existing in the mind of God, acting as a virtual reality environment.
<br>
Maybe only at rare occasions as deep meditation some people experience some of 'reality.
<br>
Maybe paranormal events are more reality than mainstream scientists are aware of.
<br>
Maybe we all sleep.
<br>
Maybe we are al at school in this live.  
<br>
Maybe humanity will 'evolve' into a godlike supermind and than go back in time and creates the universe and life. Nice circle....
<br>
Maybe in 'the end' God will be all and in all (revelation).
<br>
Maybe the core teachings of all religions and scientific speculations are essential about the same stuff.
<br>
Maybe we haven't any clue about reality 'an sich'.
<br>
Maybe nothing of this all is true.
<br>
Maybe this all sucks.
<br>
Maybe even that isn't true.
<br>
Maybe this all is pointless speculation.
<br>
Maybe we just have to do our best with our daily lives and  have to wait until events become clear....
<br>
<br>
Regards from Hans</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16558"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Tearing Toward the Spike<br><span class="mindxheader"><i>posted on 04/27/2003 6:41 AM by <a href="https://web.archive.org/web/20071011093741/http://www.kurzweilai.net/mindx/profile.php?id=264">hans123</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011093741/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D10528%23id16558" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011093741/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16558" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Something went wrong with quoting. Sorry...
<br>
<center><p class="mindxquote">
<br>
In attempting to see "beyond", we need to think beyond... 
<br>
<br>
Perhaps the universe is empty because every previous intelligence has reached singularity. 
<br>
<br>
Perhaps, post singularity, the universe as we know it becomes unimportant. 
<br>
<br>
Perhaps, we reach a level of understanding and perception where we see all new horizons that are for more compelling. 
<br>
<br>
Perhaps the universe of the mathematics, perhaps the universe of mind. 
<br>
<br>
Perhaps, with technology to "amplify" our abilities, we are able to establish true communications with other dimensions. Would these 3 dimensions still be so exciting then? 
<br>
<br>
Even more interesting to me, is perhaps, we are able to link with our Creator. Perhaps, heaven is real after all. And we could all be just a few years from reaching it. 
<br>
<br>
Perhaps, the end is near. And what a beautiful ending it could be. 
<br>
</p></center>
<br>
Maybe maybe... 
<br>
Maybe we all live in some sort of 'matrix' virtual reality without knowing it. 
<br>
Maybe that's the origin of the quantum uncertainty principle. When you look too close at the building bricks of reality it becomes fuzzy.. 
<br>
Maybe UFO's and 'alien encounters' are time travelling visitors from the post singularity universe. 
<br>
Maybe crop circles are some joke on us practised by post singularity time travelers. 
<br>
Maybe excist only an eternal now with all possible alternate time lines or futures at once. 
<br>
Maybe ( I think sure) we lack the overall view and can only see the universe as a time line: past-present-future. 
<br>
Maybe the universe is only existing in the mind of God, acting as a virtual reality environment. 
<br>
Maybe only at rare occasions as deep meditation some people experience some of 'reality. 
<br>
Maybe paranormal events are more reality than mainstream scientists are aware of. 
<br>
Maybe we all sleep. 
<br>
Maybe we are al at school in this live. 
<br>
Maybe humanity will 'evolve' into a godlike supermind and than go back in time and creates the universe and life. Nice circle.... 
<br>
Maybe in 'the end' God will be all and in all (revelation). 
<br>
Maybe the core teachings of all religions and scientific speculations are essential about the same stuff. 
<br>
Maybe we haven't any clue about reality 'an sich'. 
<br>
Maybe nothing of this all is true. 
<br>
Maybe this all sucks. 
<br>
Maybe even that isn't true. 
<br>
Maybe this all is pointless speculation. 
<br>
Maybe we just have to do our best with our daily lives and have to wait until events become clear.... 
<br>
<br>
Regards from Hans
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011093741im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>