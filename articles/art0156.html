<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>Promise And Peril</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/meme/memelist.html?m=2">Dangerous Futures</a> &gt; 
Promise And Peril
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20100613223219/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0156.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0156.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/articles/art0156.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">Promise And Peril</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0005.html" target="_top">Ray Kurzweil</a><br></span></td>
</table>
<br>
<div class="TeaserText">Bill Joy wrote a controversial article in Wired advocating "relinquishment" of research on self-replicating technologies, such as nanobots. In this rebuttal, originally published in Interactive Week, Ray Kurzweil argues that these developments are inevitable and advocates ethical guidelines and responsible oversight.</div>
<br>
<br><p>Originally published October 23, 2000 at <a href="http://web.archive.org/web/20100613223219/http://www.zdnet.com/intweek/" target="_new">Interactive Week</a>. Published on KurzweilAI.net April 9, 2001. Read <a class="thought" href="entries/more_entry.html">Max More</a>'s response to <a class="thought" href="entries/joy_entry.html">Bill Joy</a> <a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/articles/art0106.html" target="_self">here</a>.</p>
<p>A response to <a class="thought" href="entries/joy_entry.html">Bill Joy</a>'s <a class="thought" href="entries/wired_entry.html">Wired</a> article <a href="http://web.archive.org/web/20100613223219/http://www.wired.com/wired/archive/8.04/joy.html" target="_new">Why The Future Doesn't Need Us</a>.</p>
<p><a class="thought" href="entries/joy_entry.html">Bill Joy</a>, cofounder of <a class="thought" href="entries/sun_microsystems_entry.html">Sun Microsystems</a> and principal developer of the <a class="thought" href="entries/java_entry.html">Java</a> <a class="thought" href="entries/program_entry.html">program</a>ming <a class="thought" href="entries/language_entry.html">language</a>, has recently taken up a personal mission to warn us of the impending dangers from the emergence of self-replicating technologies in the fields of <a class="thought" href="entries/genetics_entry.html">genetics</a>, <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> and <a class="thought" href="entries/robotics_entry.html">robotics</a>, which he aggregates under the label "<a class="thought" href="entries/gnr_entry.html">GNR</a>."</p>
<p>Although his warnings are not entirely new, they have attracted considerable attention because of Joy's credibility as one of our leading technologists. It reminds me of the attention that George Soros, the currency arbitrager and arch capitalist, received when he made vaguely critical comments about the excesses of unrestrained <a class="thought" href="entries/capitalism_entry.html">capitalism</a>.</p>
<p>According to Joy, the day is close at hand when it will be feasible to create genetically altered designer <a class="thought" href="entries/pathogen_entry.html">pathogen</a>s in college laboratories. Then, at a later date, we'll have to contend with self-replicating entities created through <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>, the field devoted to manipulating <a class="thought" href="entries/matter_entry.html">matter</a> on the scale of individual atoms. Although nanoengineered "self-replicators" are at least one decade, and probably more than two decades, away, the specter that concerns Joy can be described as an unstoppable, non-<a class="thought" href="entries/biological_entry.html">biological</a> <a class="thought" href="entries/cancer_entry.html">cancer</a>.</p>
<p>Finally, if we manage to survive these first two perils, we'll encounter robots whose <a class="thought" href="entries/intelligence_entry.html">intelligence</a> will rival and ultimately exceed our own. Such robots may make great assistants, but who's to say that we can count on them to remain reliably friendly to mere humans?</p>
<p>Although I am often cast as the <a class="thought" href="entries/technology_entry.html">technology</a> optimist who counters Joy's pessimism, I do share his concerns regarding self-replicating technologies; indeed, I played a role in bringing these dangers to Bill's attention. In many of the dialogues and forums in which I have participated on this subject, I end up defending Joy's position with regard to the feasibility of these technologies and scenarios when they come under attack by commentators who I believe are being quite shortsighted in their skepticism. Even so, I do find fault with Joy's prescription--halting the advance of <a class="thought" href="entries/technology_entry.html">technology</a> and the pursuit of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> in broad fields such as <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>.</p>
<p>Before addressing our differences, let me first discuss the <a class="thought" href="entries/salient_entry.html">salient</a> issue of feasibility. Many long-range forecasts of technical feasibility dramatically underestimate the power of <a class="thought" href="entries/future_entry.html">future</a> <a class="thought" href="entries/technology_entry.html">technology</a> for one simple <a class="thought" href="entries/reason_entry.html">reason</a>: They are based on what I call the "intuitive linear" view of technological <a class="thought" href="entries/progress_entry.html">progress</a> rather than the "<a class="thought" href="entries/historical_exponential_view_entry.html">historical exponential view</a>."</p>
<p>When people think of a <a class="thought" href="entries/future_entry.html">future</a> period, they intuitively assume that the current rate of <a class="thought" href="entries/progress_entry.html">progress</a> will continue for the period being considered. In fact, the rate of technological <a class="thought" href="entries/progress_entry.html">progress</a> is not constant, but since it is <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/nature_entry.html">nature</a> to adapt to the changing pace, the intuitive view is that the pace will continue at the current rate. It is typical, therefore, that even sophisticated commentators, when considering the <a class="thought" href="entries/future_entry.html">future</a>, extrapolate the current pace of change over the next 10 years or 100 years to determine their expectations--the "intuitive linear" view.</p>
<p>But any serious examination of the <a class="thought" href="entries/history_entry.html">history</a> of <a class="thought" href="entries/technology_entry.html">technology</a> reveals that technological change is at least exponential. There are a great many examples of this, including constantly accelerating developments in <a class="thought" href="entries/computation_entry.html">computation</a>, <a class="thought" href="entries/communication_entry.html">communication</a>, <a class="thought" href="entries/brain_scan_entry.html">brain scan</a>ning, multiple aspects of <a class="thought" href="entries/biotechnology_entry.html">biotechnology</a> and <a class="thought" href="entries/miniaturization_entry.html">miniaturization</a>. One can examine these <a class="thought" href="entries/data_entry.html">data</a> in many different ways, on many different <a class="thought" href="entries/time_entry.html">time</a> scales and for a wide variety of phenomena. Whatever the approach, we find--at least--double <a class="thought" href="entries/exponential_growth_entry.html">exponential growth</a>.</p>
<p>This phenomenon, which I call the "<a class="thought" href="entries/law_of_accelerating_returns_entry.html">law of accelerating returns</a>," does not rely on a mere assumption of the continuation of <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's Law</a>, which predicts, in effect, the quadrupling of <a class="thought" href="entries/computer_entry.html">computer</a> power every 24 months. Rather, it is based on a rich model of diverse technological processes, a model I have been developing over the past couple of decades.</p>
<p>What it clearly shows is that <a class="thought" href="entries/technology_entry.html">technology</a>, particularly the pace of technological change, has been advancing at least exponentially since the advent of <a class="thought" href="entries/technology_entry.html">technology</a>. Thus, while people often overestimate what can be achieved in the short term because there is a tendency to leave out necessary details, we typically underestimate what can be achieved in the long term because <a class="thought" href="entries/exponential_growth_entry.html">exponential growth</a> is ignored.</p>
<p>This observation also applies to rates of <a class="thought" href="entries/paradigm_shift_entry.html">paradigm shift</a>s, which are currently doubling approximately every decade. At that rate, the technological <a class="thought" href="entries/progress_entry.html">progress</a> in the 21st century will be equivalent to changes that in the linear view would require on the <a class="thought" href="entries/order_entry.html">order</a> of 20,000 years.</p>
<p>This exponential <a class="thought" href="entries/progress_entry.html">progress</a> in <a class="thought" href="entries/computation_entry.html">computation</a> and <a class="thought" href="entries/communication_entry.html">communication</a> technologies is greatly empowering the individual. That's good news in many ways, because those technologies are largely responsible for the pervasive trend toward democratization and the reshaping of power relations at all levels of society. But these technologies are also empowering and amplifying our destructive impulses. It's not necessary to anticipate all the ultimate uses of a <a class="thought" href="entries/technology_entry.html">technology</a> to see danger in, for example, every college <a class="thought" href="entries/biotechnology_entry.html">biotechnology</a> lab's having the ability to create self-replicating <a class="thought" href="entries/biological_entry.html">biological</a> <a class="thought" href="entries/pathogen_entry.html">pathogen</a>s.</p>
<p>Nevertheless, I do reject Joy's call for relinquishing broad areas of <a class="thought" href="entries/technology_entry.html">technology</a>--for example, <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>. <a class="thought" href="entries/technology_entry.html">Technology</a> has always been a double-edged sword. We don't need to look any further than today's <a class="thought" href="entries/technology_entry.html">technology</a> to see this. Take <a class="thought" href="entries/biotechnology_entry.html">biotechnology</a>. We have already seen substantial benefits: more effective AIDS treatments, <a class="thought" href="entries/human_entry.html">human</a> insulin and many others. In the years ahead, we will see enormous gains in overcoming <a class="thought" href="entries/cancer_entry.html">cancer</a> and many other diseases, as well as in greatly extending <a class="thought" href="entries/human_entry.html">human</a> longevity, all presumably positive developments--although even these are controversial.</p>
<p>On the other hand, the means will soon exist in a routine <a class="thought" href="entries/biotechnology_entry.html">biotechnology</a> laboratory to create a <a class="thought" href="entries/pathogen_entry.html">pathogen</a> that could be more destructive to humans or other living organisms than an atomic bomb.</p>
<p>If we imagine describing the dangers that exist today--enough nuclear explosive power to destroy all <a class="thought" href="entries/mammal_entry.html">mammal</a>ian <a class="thought" href="entries/life_entry.html">life</a>, just for starters--to people who lived a couple of hundred years ago, they would think it mad to take such risks. On the other hand, how many people in the <a class="thought" href="entries/y2k_entry.html">year 2000</a> would really want to go back to the short, disease-filled, poverty-stricken, disaster-prone lives that 99 percent of the <a class="thought" href="entries/human_entry.html">human</a> race struggled through a couple of centuries ago? We may romanticize the past, but until fairly recently, most of humanity lived extremely fragile lives, in which a single common misfortune could spell disaster. Substantial portions of our <a class="thought" href="entries/species_entry.html">species</a> still live this precarious existence, which is at least one <a class="thought" href="entries/reason_entry.html">reason</a> to continue technological <a class="thought" href="entries/progress_entry.html">progress</a> and the social and economic enhancements that accompany it.</p>
<p>People often go through three stages in examining the impact of <a class="thought" href="entries/future_entry.html">future</a> <a class="thought" href="entries/technology_entry.html">technology</a>: awe and wonderment at its potential to overcome age-old problems, a <a class="thought" href="entries/sense_entry.html">sense</a> of dread at a new <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of grave dangers that accompany these new technologies, followed, finally and hopefully, by the realization that the only viable and responsible path is to <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> a careful course that can realize the promise while managing the peril.</p>
<p>Joy eloquently describes the plagues of centuries past and how new, self-replicating technologies, such as mutant bioengineered <a class="thought" href="entries/pathogen_entry.html">pathogen</a>s or "<a class="thought" href="entries/nanobot_entry.html">nanobot</a>s" (<a class="thought" href="entries/molecule_entry.html">molecule</a>-sized robots), run amok may bring back the fading notion of pestilence. As I stated earlier, these are real dangers. It is also the case, which Joy acknowledges, that it has been technological advances, such as <a class="thought" href="entries/antibiotic_entry.html">antibiotic</a>s and improved sanitation, that have freed us from the prevalence of such plagues.</p>
<p><a class="thought" href="entries/human_entry.html">Human</a> suffering continues and demands our steadfast attention. Should we tell the millions of people afflicted with <a class="thought" href="entries/cancer_entry.html">cancer</a> and other devastating conditions that we are canceling the development of all bioengineered treatments because there is a risk that these same technologies might one day be used for malevolent purposes? That should be a rhetorical question. Yet, there is a movement to do exactly that. Most people, I believe, would agree that such broad-based <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> of <a class="thought" href="entries/research_entry.html">research</a> and development is not the answer.</p>
<p>In addition to the continued opportunity to alleviate <a class="thought" href="entries/human_entry.html">human</a> distress, another important motivation for continuing technological advancement is economic gain. The continued acceleration of many intertwined technologies are roads paved with gold. (I use the plural here because <a class="thought" href="entries/technology_entry.html">technology</a> is clearly not a single path.) In a competitive environment, it is an economic imperative to go down these roads. Relinquishing technological advancement would be economic suicide for individuals, companies and nations.</p><h1>The <a class="thought" href="entries/relinquishment_entry.html">Relinquishment</a> Issue</h1><p>Which brings us to the issue of <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a>--the wholesale abandonment of certain fields of <a class="thought" href="entries/research_entry.html">research</a>--which is Joy's most controversial recommendation and personal commitment. I do feel that <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> at the right level is part of a responsible and constructive response to genuine perils. The issue, however, is exactly this: At what level are we to relinquish <a class="thought" href="entries/technology_entry.html">technology</a>?</p>
<p><a class="thought" href="entries/kaczynski_entry.html">Ted Kaczynski</a>, the infamous <a class="thought" href="entries/unabomber_entry.html">Unabomber</a>, would have us renounce all of it. This, in my view, is neither desirable nor feasible, and the futility of such a position is only underscored by the senselessness of Kaczynski's deplorable tactics.</p>
<p>Another level would be to forgo certain fields, <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>, for example, that might be regarded as too dangerous. But even these slightly less sweeping strokes of <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> are also untenable. <a class="thought" href="entries/nanotechnology_entry.html">Nanotechnology</a> is simply the inevitable result of a persistent trend toward <a class="thought" href="entries/miniaturization_entry.html">miniaturization</a> that pervades all of <a class="thought" href="entries/technology_entry.html">technology</a>. It is far from a single, centralized effort, but rather is being pursued by myriad projects with diverse goals.</p>
<p>One observer wrote:</p>
<blockquote>A further <a class="thought" href="entries/reason_entry.html">reason</a> why industrial society cannot be reformed . . . is that modern <a class="thought" href="entries/technology_entry.html">technology</a> is a unified <a class="thought" href="entries/system_entry.html">system</a> in which all parts are dependent on one another. You can't get rid of the 'bad' parts of <a class="thought" href="entries/technology_entry.html">technology</a> and retain only the 'good' parts. Take modern <a class="thought" href="entries/medicine_entry.html">medicine</a>, for example. <a class="thought" href="entries/progress_entry.html">Progress</a> in medical <a class="thought" href="entries/science_entry.html">science</a> depends on <a class="thought" href="entries/progress_entry.html">progress</a> in <a class="thought" href="entries/chemistry_entry.html">chemistry</a>, <a class="thought" href="entries/physics_entry.html">physics</a>, <a class="thought" href="entries/biology_entry.html">biology</a>, <a class="thought" href="entries/computer_science_entry.html">computer science</a> and other fields. Advanced medical treatments require expensive, high-tech equipment that can be made available only by a technologically <a class="thought" href="entries/progress_entry.html">progress</a>ive, economically rich society. Clearly you can't have much <a class="thought" href="entries/progress_entry.html">progress</a> in <a class="thought" href="entries/medicine_entry.html">medicine</a> without the whole technological <a class="thought" href="entries/system_entry.html">system</a> and everything that goes with it.</blockquote>
<p>The observer I am quoting is Kaczynski. Although one might properly resist him as an authority, I believe he is correct on the deeply entangled <a class="thought" href="entries/nature_entry.html">nature</a> of the benefits and risks of <a class="thought" href="entries/technology_entry.html">technology</a>. Where Kaczynski and I clearly part company is in our overall assessment of the relative balance between the two. Joy and I have engaged in dialogues on this issue both publicly and privately, and we concur that <a class="thought" href="entries/technology_entry.html">technology</a> will and should <a class="thought" href="entries/progress_entry.html">progress</a> and that we need to be actively concerned with its dark side. If Bill and I disagree, it's on the granularity of <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> that is both feasible and desirable.</p>
<p>Abandonment of broad areas of <a class="thought" href="entries/technology_entry.html">technology</a> will only push these technologies underground where development would continue unimpeded by <a class="thought" href="entries/ethics_entry.html">ethics</a> or regulation. In such a situation, less stable, less responsible practitioners--for example, terrorists--would have a monopoly on deadly expertise.</p>
<p>I do think that <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> at the right level needs to be part of our ethical response to the dangers of 21st century technologies. One <a class="thought" href="entries/salient_entry.html">salient</a> and constructive example of this is the proposed ethical guideline by the <a class="thought" href="entries/foresight_institute_entry.html">Foresight Institute</a>, founded by <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> pioneer Eric Drexler. This guideline would call on <a class="thought" href="entries/nanotechnology_entry.html">nanotech</a>nologists to relinquish the development of physical entities that can self-replicate in a natural environment. Another example is a ban on self-replicating physical entities that contain their own codes for <a class="thought" href="entries/self_replication_entry.html">self-replication</a>. In a design that <a class="thought" href="entries/nanotechnology_entry.html">nanotech</a>nologist Ralph Merkle calls the "Broadcast <a class="thought" href="entries/architecture_entry.html">Architecture</a>," such entities would have to obtain such codes from a centralized secure <a class="thought" href="entries/server_entry.html">server</a>, which would guard against undesirable replication.</p>
<p>The Broadcast <a class="thought" href="entries/architecture_entry.html">Architecture</a> is impossible in the <a class="thought" href="entries/biological_entry.html">biological</a> world, which represents at least one way in which <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> can be made safer than <a class="thought" href="entries/biotechnology_entry.html">biotechnology</a>. In other ways, <a class="thought" href="entries/nanotechnology_entry.html">nanotech</a> is potentially more dangerous because <a class="thought" href="entries/nanobot_entry.html">nanobot</a>s can be physically stronger than <a class="thought" href="entries/protein_entry.html">protein</a>-based entities and more intelligent. But it will eventually be possible to combine the two by having <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> provide the codes within <a class="thought" href="entries/biological_entry.html">biological</a> entities (replacing <a class="thought" href="entries/dna_entry.html">DNA</a>), in which case we can use the much safer Broadcast <a class="thought" href="entries/architecture_entry.html">Architecture</a>.</p>
<p>As responsible technologists, our <a class="thought" href="entries/ethics_entry.html">ethics</a> should include such "fine-grained" <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a>, among other professional ethical guidelines. Other protections will need to include oversight by regulatory bodies, the development of <a class="thought" href="entries/technology_entry.html">technology</a>-specific "immune" responses, as well as <a class="thought" href="entries/computer_entry.html">computer</a>-assisted surveillance by law enforcement organizations. Many people are not aware that our <a class="thought" href="entries/intelligence_entry.html">intelligence</a> agencies already use advanced technologies such as automated word spotting to monitor a substantial flow of telephone conversations. As we go forward, balancing our cherished rights of privacy with our need to be protected from the malicious use of powerful 21st century technologies will be one of many profound challenges. This is the <a class="thought" href="entries/reason_entry.html">reason</a> recent issues of an <a class="thought" href="entries/encryption_entry.html">encryption</a> "trap door," in which law enforcement authorities would have <a class="thought" href="entries/access_entry.html">access</a> to otherwise secure <a class="thought" href="entries/information_entry.html">information</a>, and the FBI's <a class="thought" href="entries/carnivore_entry.html">Carnivore</a> e-mail snooping <a class="thought" href="entries/system_entry.html">system</a> have been so <a class="thought" href="entries/content_entry.html">content</a>ious.</p>
<p>As a test case, we can take a small measure of comfort from how we have dealt with one recent technological challenge. There exists today a new form of fully non-<a class="thought" href="entries/biological_entry.html">biological</a>, self-replicating <a class="thought" href="entries/entity_entry.html">entity</a> that didn't exist just a few decades ago: the <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/virus_entry.html">virus</a>. When this form of destructive intruder first appeared, strong concerns were voiced that as such viruses became more sophisticated, <a class="thought" href="entries/software_entry.html">software</a> <a class="thought" href="entries/pathogen_entry.html">pathogen</a>s had the potential to destroy the <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/network_entry.html">network</a> medium in which they live. Yet the "<a class="thought" href="entries/immune_system_entry.html">immune system</a>" that has evolved in response to this challenge has been largely effective.</p>
<p>Although destructive, self-replicating <a class="thought" href="entries/software_entry.html">software</a> entities do cause damage from <a class="thought" href="entries/time_entry.html">time</a> to <a class="thought" href="entries/time_entry.html">time</a>, the injury is but a small fraction--much less than one-tenth of 1 percent--of the benefit we receive from the <a class="thought" href="entries/computer_entry.html">computer</a>s and <a class="thought" href="entries/communication_entry.html">communication</a> links that harbor them.</p>
<p>One might counter that <a class="thought" href="entries/computer_entry.html">computer</a> viruses lack the lethal potential of <a class="thought" href="entries/biological_entry.html">biological</a> viruses or of destructive <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>. Although true, this strengthens my observation. The fact that <a class="thought" href="entries/computer_entry.html">computer</a> viruses are not usually deadly to humans only encourages more people to create and release them. It also means that our response to the danger is relatively relaxed. Conversely, when it comes to self-replicating entities that are potentially lethal on a large scale, our response on all levels will be vastly more intense.</p>
<p><a class="thought" href="entries/technology_entry.html">Technology</a> will remain a double-edged sword, and the story of the 21st century has not yet been written. So, while we must acknowledge and deal with the dangers, we must also recognize that <a class="thought" href="entries/technology_entry.html">technology</a> represents vast power to be used for all humankind's purposes. We have no choice but to work hard to apply these quickening technologies to advance our <a class="thought" href="entries/human_entry.html">human</a> values, despite what often appears to be a lack of consensus on what those values should be.</p>
<p>Reprinted from <a href="http://web.archive.org/web/20100613223219/http://www.zdnet.com/intweek/" target="_new">Interactive Week</a>, October 23, 2000, with permission.  Copyright c2001 Ziff Davis <a class="thought" href="entries/media_entry.html">Media</a> Inc.  All rights reserved.</p>
</td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D19714" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id19715"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>hey there<br><span class="mindxheader"><i>posted on 08/25/2003 9:05 AM by <a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/profile.php?id=574">goofey</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D19714%23id19715" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D19715" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>i just wanted to say... ure article was very good and it helped me a lot in my college essay... thanx</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id21430"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Promise And Peril<br><span class="mindxheader"><i>posted on 11/05/2003 12:38 PM by <a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/profile.php?id=754">connected</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D19714%23id21430" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D21430" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Hi,
<br>
<br>
I agree with some of the points you make in response to Bill Joy's article (orig at <a href="http://web.archive.org/web/20100613223219/http://www.wired.com/wired/archive/8.04/joy.html)." target="_blank">http://www.wired.com/wired/archive/8.04/joy.html).  </a>
<br>
<br>
Firstly, I agree with with a your opinion about completely dropping _all_ technology - that's clearly unfeasible. Those who suggest otherwise, should try living without electricity and water for 1 week - needless to say we'll see 99% of them come back and not speak another word of relinquishing all technology.
<br>
<br>
Dropping parts of technology (i.e. lets stop development of microchips only, or of dangerous viruses only) is also unfeasible - pretty much anything these days can be used as a weapon or can present danger when misused. And even if it can't, as you mention, what if a potential weapon can be derived from it? Or based on a given invention?
<br>
<br>
A better way to overcome this is, in my opinion, a combination of 3: scientific responsibility (on the part of the scientist that's developing it) to try to protect from steering a project in a "bad" direction; governmental oversight (to protect companies from taking too many freedoms with the development of dangerous products); and finally public awareness about the project, in a form of national forums where possible, so that decisions about, for example, nuclear tests, can be decided by all of us.
<br>
<br>
What I disagree with:
<br>
<br>
You spent a bit of time arguing that technology advances at some rate. I can't really see the point of this ' we all know technology advances, and Bill Joy's article is not about rate of advancement ' it's rather about stopping it or letting it continue at all. So overall, this had very little to do with the topic of the article (at least in my opinion), and didn't really answer the question: should we stop developing new technologies, or do we continue and possibly suffer the consequences.
<br>
<br>
You've also spent some time on saying that any science and technology is a double-edged sword ' and can be used for both good and bad. In my opinion, advanced science (such as nanotechnology coupled with computer science) is actually a triple-edged sword. More to the point: once we achieve self-replicating autonomous machines that are smarter than us, we will no longer need to worry about our scientists coming up with 'bad' ideas ' I'd rather worry about somebody as emotionless as a computer, especially one as smart as all of humankind combined! In this regard, Bill Joy has a point which ought to be heard.
<br>
<br>
<center><p class="mindxquote"> Substantial portions of our species still live this precarious existence, which is at least one reason to continue technological progress and the social and economic enhancements that accompany it. </p></center>  I have an issue with this ' do a search on google and look for 'poverty line world population' ' that will give you small-ish idea of how many people really do need new technology. What they really need is old and proven technology (such as basic food, contraceptives and antibiotics). This will form the basics of the new economy, out of which our new science may develop. People in Africa that are dying every day need food today, and not nano-robots and new TCP/IP versions of tomorrow. Sure, I can accept the fact that nano-robots may solve future health problems, and maybe even food-related problems ' except by that time we may not have the billion people to solve it for. Stopping some ridiculously expensive research and spending the saved cash on developing the infrastructure of a less fortunate country is maybe a touch less scientific, but much more noble and human. Also note I did not say 'donate' - donations will keep Africa and other nations poor ' developing the basic infrastructure will give them the start they need!
<br>
<br>
Another point: I see a lot of noble words come out of many mouths saying that research may help people in the future ' say it like it is: economic profit drives research. All of the nobility in the world is not enough to make a greedy CEO of a pharmaceutical company move into a new antibiotic development unless he or she sees the profit. This should be a caveat to all such articles touting technology: technological advancement is here to give profit, and maybe help humanity. A scientist may have such thoughts of nobility, but ultimately it's not the scientist who makes the final decision about development of new technologies.
<br>
<br>
Finally, as a minor point, you argue that computer networks have developed an immune system to resist viruses. I realize that the original article was written awhile ago, and not in light of the recent MSBlast et all attacks. But keeping those in mind, have computer networks really developed an immune system? One single person can bring down the internet to a crawl ' for a day or two ' hardly a worthy immune system.
<br>
<br>
Overall, your article is engaging and shows that you have a true passion for technology ' but you fail to mention that many of the issues are simply not being addressed by new  technology: the society doesn't change as fast as we would like it to, and no new development is going to advance us further as human beings until we ourselves change first.
<br>
<br>
-Roman
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id21434"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Promise And Peril<br><span class="mindxheader"><i>posted on 11/05/2003 1:51 PM by <a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/profile.php?id=336">billmerit</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D19714%23id21434" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D21434" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>One point.  We have immune systems, but that won't make much difference if you get SARS or EBOLA.
<br>
<br>
I pay McAfee a fee each year for my computer's immune system.
<br>
<br>
bill </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id33855"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Promise And Peril<br><span class="mindxheader"><i>posted on 03/22/2005 2:09 AM by <a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/profile.php?id=1838">jackey</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D19714%23id33855" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D33855" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>
<br>
<br>
	I agree with Kurzweil that relinquishment of all technology is completely infeasible.  Now a day human are too reliant on technology and it can be described as the life support for our human race.  In my opinion, relinquishing all technologies would consider harmful to us and consequences would be disastrous.  The people''s panics during the black out in August 2003 is the evident that greatly reflects our dependences from technology.  If the black out was extended for weeks or even months, the result will be catastrophic.  Without electricity, all the health maintaining facilities (water filtration plants, hospitals, etc) would not be able to work properly and possibly being forced to stop their operations.  Thus diseases could have been outbreak and without help of technologies there is virtually impossible stop this kind of disaster.  As in December 2004, the tsunami in Southeast Asia provides a valid example showing that relinquishment of all technologies is doubtlessly ridiculous.  It is well understood that if the tsunami detection and alarming technology was in place, victims in the tsunami disaster would have enough time to escape and the catastrophic death tolls and economical damages can be dramatically reduced.  By above evidence, it is enough to convince people to believe that relinquishment of all technologies is undesirable and clearly infeasible.
<br>
<br>
	Furthermore, I think that to relinquish technology at a right level is perhaps a too idealistic approach to prevent the human from being overtaken by spiritual machine.  Obviously, the question arise, how practical is it?  As Kurzweil mentioned that, it is difficult to find a baseline to set the right level of technological relinquishment.  But even though if  we are able to find the right level of relinquishment, will you be convinced that every single of us especially for our world leader in militaries technologies will be obeying to relinquish their technologies at the level that we defined as the ''right'' level?  The militaries and economical power exists today are the driven force that prevents the all and partial technological relinquishments from happening.  It is the natural instinct that human desire to maintain and to gain more authorities to protect themselves and rule the others.  It implies that stronger countries will keep advancing their technology to maintain their power and perhaps over take other countries either economically or physically.   On the other hand, weaker countries would desperately try to advance their technologies to prevent from being overtaken.  This creates an on going phenomenon, and the partial technological relinquishment is simply not reliable enough and impractical to convince all countries that we are safe enough to stop the technological advancement. 
<br>
<br>
	In response to the computer immune system, I really do agree that it evolved in response to the computer virus challenges effectively.  However, these evolvements have only being reactive processes.  Each time our computer immune system has to evolve in order to protect our computer system safely when a new virus is discovered.  As far as I concern, we will eventually reaches to a point that a new self replicate computer viruses can be created, thus they will be destructive and intelligent enough that our computer immune system will not be able to evolve quickly enough to protect our computer systems.  We all understand self-replicating computer viruses are potentially lethal on much larger scale, but can we do anything about it?  I do believe that proactive computer immune system against self replicate computer viruses is not possible, due to the nature of virus detecting.  In addition, as I mentioned above that both all or partial technological relinquishment are infeasible and that may help those unethical software developers to create such self-replicating computer viruses.  I think that will inevitably lead us to the point that is beyond our computer immune system''s capability to even protect our computer systems.  
<br>
<br>
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id33856"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Promise And Peril<br><span class="mindxheader"><i>posted on 03/22/2005 2:14 AM by <a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/profile.php?id=1736">mars22</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D19714%23id33856" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D33856" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>and there would be no tv.no cartoons.no internet.
<br>
what the hell would we do while drinking beer?
<br>
that would be warm!warm fucking beer !
<br>
we all need to get off the grid so we can have tv and cold beer incase of powergid snafu</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id33878"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Promise And Peril<br><span class="mindxheader"><i>posted on 03/22/2005 12:19 PM by <a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/profile.php?id=1833">Spinning Cloud</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D19714%23id33878" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100613223219/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D33878" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>First of all human nature wouldn't even allow us to move away from advancing technology. We're curious and we're always looking for a way to make our lives 'easier'. We're driven by our curiosity and survival instincts...the short term ones predominately. Visions of future doom have never disuaded the human race previously and I seriously doubt it ever will.
<br>
<br>
We will always be scurringy to survive and clean up after our misadventures, be they nuclear holocaust, misguided wars here and there, justified wars here and there, dangerous technology, religious fanatasism, etc. etc. ad nauseum.
<br>
<br>
I don't look at Joy's article as a serious call for us to abandon technology...I doubt he really believes that would be possible.
<br>
<br>
It hardly makes any sense to even discuss if it would be a good idea or not. A more reasonable and useful discussion would be how to deal with the results of various technological advancements; should we turn specific scientific discoveries into technology?</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100613223219im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>