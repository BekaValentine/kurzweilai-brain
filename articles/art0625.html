<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>Thought Experiments: When the Singularity Is More than a Literary Device</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/meme/memelist.html?m=1">The Singularity</a> &gt; 
Thought Experiments: When the Singularity Is More than a Literary Device
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20071011194409/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0625.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0625.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/articles/art0625.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">Thought Experiments: When the Singularity Is More than a Literary Device</span>
<br>
<span class="Subtitle">An Interview with Futurist-Inventor Ray Kurzweil</span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0246.html" target="_top">Cory Doctorow</a><br></span></td>
</table>
<br>
<div class="TeaserText">Is the Singularity a spiritual or a technological belief system? Perhaps it is the melding of both, says science fiction author Cory Doctorow in this dialogue with Ray Kurzweil. "After all, this is a system of belief that dictates a means by which we can care for our bodies virtuously and live long enough to transcend them. It's no wonder that the Singularity has come to occupy so much of the science fiction narrative in these years. Science or spirituality, you could hardly ask for a subject better tailored to technological speculation and drama."</div>
<br>
<br>
<p><i>Originally published in </i><a href="http://web.archive.org/web/20071011194409/http://www.asimovs.com/_issue_0506/thoughtexperiments.shtml" target="_blank">Asimov's 
              Science Fiction</a><i>, April 18, 2005. Published with permission 
              on KurzweilAI.net January 16, 2006.</i></p>
<p>It&#8217;s not clear to me whether the <a class="thought" href="entries/singularity_entry.html">Singularity</a> is a technical 
              belief <a class="thought" href="entries/system_entry.html">system</a> or a <a class="thought" href="entries/spirit_entry.html">spirit</a>ual one. </p>
<p>The Singularity&#8212;a notion that&#8217;s crept into a lot of skiffy, 
              and whose most articulate in-genre spokesmodel is <a class="thought" href="entries/vinge_entry.html">Vernor Vinge</a>&#8212;describes 
              the <a class="thought" href="entries/black_hole_entry.html">black hole</a> in <a class="thought" href="entries/history_entry.html">history</a> that will be created at the moment when 
              <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a> can be digitized. When the speed and scope of 
              our cognition is hitched to the <a class="thought" href="entries/price_performance_entry.html">price-performance</a> curve of <a class="thought" href="entries/microprocessor_entry.html">microprocessor</a>s, 
              our "prog-ress" will double every eighteen months, and 
              then every twelve months, and then every ten, and eventually, every 
              five seconds.</p>
<p>Singularities are, literally, holes in <a class="thought" href="entries/space_entry.html">space</a> from whence no <a class="thought" href="entries/information_entry.html">information</a> 
              can emerge, and so SF writers occasionally mutter about how hard 
              it is to tell a story <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> after the information Singularity. Everything 
              will be different. What it means to be human will be so different 
              that what it means to be in danger, or happy, or sad, or any of 
              the other <a class="thought" href="entries/element_entry.html">element</a>s that make up the squeeze-and-release tension 
              in a good yarn will be unrecognizable to us pre-Singletons.</p>
<p>It&#8217;s a neat conceit to write around. I&#8217;ve committed Singularity 
              a couple of times, usually in collaboration with gonzo Singleton 
              Charlie Stross, the mad antipope of the Singularity. But those stories 
              have the same relation to futurism as romance novels do to love: 
              a shared jumping-off point, but radically different morphologies.</p>
<p>Of course, the Singularity isn&#8217;t just a conceit for noodling 
              with in the pages of the pulps: it&#8217;s the subject of serious-minded 
              punditry, futurism, and even <a class="thought" href="entries/science_entry.html">science</a>.</p>
<p><a class="thought" href="entries/kurzweil_entry.html">Ray Kurzweil</a> is one such pundit-<a class="thought" href="entries/futurist_entry.html">futurist</a>-scientist. He&#8217;s a 
              serial <a class="thought" href="entries/entrepreneur_entry.html">entrepreneur</a> who founded successful businesses that advanced 
              the fields of <a class="thought" href="entries/ocr_entry.html">optical character recognition</a> (<a class="thought" href="entries/machine_entry.html">machine</a>-reading) <a class="thought" href="entries/software_entry.html">software</a>, 
              text-to-speech <a class="thought" href="entries/synthesis_entry.html">synthesis</a>, synthetic musical <a class="thought" href="entries/instrument_entry.html">instrument</a> simulation, 
              <a class="thought" href="entries/computer_entry.html">computer</a>-based speech recognition, and stock-market analysis. He 
              cured his own Type-II diabetes through a careful review of the literature 
              and the judicious application of first principles and <a class="thought" href="entries/reason_entry.html">reason</a>. To 
              a casual observer, Kurzweil appears to be the <a class="thought" href="entries/star_entry.html">star</a> of some kind 
              of Heinlein <a class="thought" href="entries/novel_entry.html">novel</a>, stealing fire from the gods and embarking on 
              a quest to bring his maverick ideas to the public despite the dismissals 
              of the establishment, getting rich in the process.</p>
<p>Kurzweil believes in the Singularity. In his 1990 manifesto, "The 
              <a class="thought" href="entries/age_of_intelligent_machines_entry.html">Age of Intelligent Machines</a>," Kurzweil persuasively argued 
              that we were on the brink of meaningful machine intelligence. A 
              decade later, he continued the argument in a book called <i>The 
              <a class="thought" href="entries/age_of_spiritual_machines_entry.html">Age of Spiritual Machines</a></i>, whose most audacious claim is that 
              the world&#8217;s <a class="thought" href="entries/computation_entry.html">computation</a>al <a class="thought" href="entries/capacity_entry.html">capacity</a> has been slowly doubling 
              since the crust first cooled (and before!), and that the doubling 
              interval has been growing shorter and shorter with each passing 
              year, so that now we see it reflected in the computer industry&#8217;s 
              Moore&#8217;s Law, which predicts that microprocessors will get twice 
              as powerful for half the cost about every eighteen months. The breathtaking 
              sweep of this trend has an obvious conclusion: computers more powerful 
              than people; more powerful than we can comprehend.</p>
<p>Now Kurzweil has published two more books, <i>The Singularity Is 
              Near, When Humans Transcend <a class="thought" href="entries/biology_entry.html">Biology</a></i> (Viking, Spring 2005) and 
              <i>Fantastic Voyage: Live Long Enough to Live Forever</i> (with 
              <a class="thought" href="entries/grossman_entry.html">Terry Grossman</a>, Rodale, November 2004). The former is a technological 
              roadmap for creating the conditions necessary for ascent into Singularity; 
              the latter is a book about <a class="thought" href="entries/life_entry.html">life</a>-prolonging technologies that will 
              assist baby-boomers in living long enough to see the day when technological 
              <a class="thought" href="entries/immortality_entry.html">immortality</a> is achieved.</p>
<p>See what I meant about his being a Heinlein hero?</p>
<p>I still don&#8217;t know if the Singularity is a spiritual or a 
              technological belief system. It has all the trappings of <a class="thought" href="entries/spirituality_entry.html">spirituality</a>, 
              to be sure. If you are pure and kosher, if you live right and if 
              your <a class="thought" href="entries/society_entry.html">society</a> is just, then you will live to see a moment of Rapture 
              when your flesh will slough away leaving nothing behind but your 
              ka, your <a class="thought" href="entries/soul_entry.html">soul</a>, your <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, to ascend to an immortal and 
              pure state.</p>
<p>I wrote a novel called <i>Down and Out in the Magic Kingdom</i> 
              where characters could make backups of themselves and recover from 
              them if something bad happened, like catching a cold or being assassinated. 
              It raises a lot of existential questions: most prominently: are 
              you still you when you&#8217;ve been restored from backup?</p>
<p>The traditional <a class="thought" href="entries/ai_entry.html">AI</a> answer is the <a class="thought" href="entries/turing_test_entry.html">Turing Test</a>, invented by Alan 
              Turing, the gay pioneer of <a class="thought" href="entries/cryptography_entry.html">cryptography</a> and artificial intelligence 
              who was forced by the British <a class="thought" href="entries/government_entry.html">government</a> to take hormone treatments 
              to "cure" him of his homosexuality, culminating in his 
              suicide in 1954. Turing cut through the <a class="thought" href="entries/existentialism_entry.html">existentialism</a> about measuring 
              whether a machine is intelligent by proposing a parlor game: a computer 
              sits behind a locked door with a chat <a class="thought" href="entries/program_entry.html">program</a>, and a person sits 
              behind another locked door with his own chat program, and they both 
              try to convince a judge that they are real people. If the computer 
              fools a human judge into <a class="thought" href="entries/thinking_entry.html">thinking</a> that it&#8217;s a person, then 
              to all intents and purposes, it&#8217;s a person.</p>
<p>So how do you know if the backed-up you that you&#8217;ve restored 
              into a new body&#8212;or a jar with a speaker attached to it&#8212;is 
              really you? Well, you can ask it some questions, and if it answers 
              the same way that you do, you&#8217;re talking to a faithful copy 
              of yourself.</p>
<p>Sounds good. But the me who sent his first story into <i>Asimov&#8217;s</i> 
              seventeen years ago couldn&#8217;t answer the question, "Write 
              a story for <i>Asimov&#8217;s</i>" the same way the me of today 
              could. Does that mean I&#8217;m not me anymore?</p>
<p>Kurzweil has the answer.</p>
<p>"If you follow that <a class="thought" href="entries/logic_entry.html">logic</a>, then if you were to take me ten 
              years ago, I could not pass for myself in a Ray Kurzweil Turing 
              Test. But once the requisite <a class="thought" href="entries/uploading_entry.html">uploading</a> <a class="thought" href="entries/technology_entry.html">technology</a> becomes available 
              a few decades hence, you <i>could</i> make a perfect-enough copy 
              of me, and it <i>would</i> pass the Ray Kurzweil Turing Test. The 
              copy doesn&#8217;t have to match the quantum state of my every <a class="thought" href="entries/neuron_entry.html">neuron</a>, 
              either: if you meet me the next day, I&#8217;d pass the Ray Kurzweil 
              Turing Test. Nevertheless, none of the quantum states in my <a class="thought" href="entries/brain_entry.html">brain</a> 
              would be the same. There are quite a few changes that each of us 
              undergo from day to day, we don&#8217;t examine the assumption that 
              we are the same person closely.</p>
<p>"We gradually change our <a class="thought" href="entries/pattern_entry.html">pattern</a> of atoms and neurons but 
              we very rapidly change the <a class="thought" href="entries/particle_entry.html">particle</a>s the pattern is made up of. 
              We used to think that in the brain&#8212;the physical part of us 
              most closely associated with our <a class="thought" href="entries/identity_entry.html">identity</a>&#8212;cells change very 
              slowly, but it turns out that the <a class="thought" href="entries/component_entry.html">component</a>s of the neurons, the 
              tubules and so forth, turn over in only <i>days</i>. I&#8217;m a 
              completely different set of particles from what I was a week ago.</p>
<p>"Consciousness is a difficult subject, and I&#8217;m always 
              surprised by how many people talk about consciousness routinely 
              as if it could be easily and readily tested scientifically. But 
              we can&#8217;t postulate a consciousness detector that does not have 
              some assumptions about consciousness built into it.</p>
<p>"Science is about <a class="thought" href="entries/object_entry.html">object</a>ive third party observations and logical 
              <a class="thought" href="entries/deduction_entry.html">deduction</a>s from them. Consciousness is about first-person, subjective 
              <a class="thought" href="entries/experience_entry.html">experience</a>, and there&#8217;s a fundamental gap there. We live in 
              a world of assumptions about consciousness. We share the assumption 
              that other human beings are conscious, for example. But that breaks 
              down when we go outside of humans, when we consider, for example, 
              <a class="thought" href="entries/animal_entry.html">animal</a>s. Some say only humans are conscious and animals are <a class="thought" href="entries/instinct_entry.html">instinct</a>ive 
              and machinelike. Others see humanlike behavior in an animal and 
              consider the animal conscious, but even these observers don&#8217;t 
              generally <a class="thought" href="entries/attribute_entry.html">attribute</a> consciousness to animals that aren&#8217;t humanlike.</p>
<p>"When machines are complex enough to have responses recognizable 
              as <a class="thought" href="entries/emotion_entry.html">emotion</a>s, those machines will be more humanlike than animals."</p>
<p>The Kurzweil Singularity goes like this: computers get better and 
              smaller. Our ability to measure the world gains precision and grows 
              ever cheaper. Eventually, we can measure the world inside the brain 
              and make a copy of it in a computer that&#8217;s as fast and complex 
              as a brain, and voila, intelligence.</p>
<p>Here in the twenty-first century we like to view ourselves as ambulatory 
              brains, plugged into meat-puppets that lug our precious grey <a class="thought" href="entries/matter_entry.html">matter</a> 
              from place to place. We tend to think of that grey matter as transcendently 
              complex, and we think of it as being the <a class="thought" href="entries/bit_entry.html">bit</a> that makes us <i>us</i>.</p>
<p>But brains aren&#8217;t that complex, Kurzweil says. Already, we&#8217;re 
              starting to unravel their mysteries.</p>
<p>"We seem to have found one area of the brain closely associated 
              with higher-level emotions, the spindle cells, deeply embedded in 
              the brain. There are tens of thousands of them, spanning the whole 
              brain (maybe eighty thousand in total), which is an incredibly small 
              <a class="thought" href="entries/number_entry.html">number</a>. Babies don&#8217;t have any, most animals don&#8217;t have 
              any, and they likely only evolved over the last million years or 
              so. Some of the high-level emotions that are deeply human come from 
              these.</p>
<p>"Turing had the right insight: base the test for intelligence 
              on written <a class="thought" href="entries/language_entry.html">language</a>. Turing Tests really work. A novel is based 
              on language: with language you can conjure up any <a class="thought" href="entries/reality_entry.html">reality</a>, much 
              more so than with images. Turing almost lived to see computers doing 
              a good job of performing in fields like math, medical diagnosis 
              and so on, but those tasks were easier for a machine than demonstrating 
              even a child&#8217;s mastery of language. Language is the true embodiment 
              of human intelligence."</p>
<p>If we&#8217;re not so complex, then it&#8217;s only a matter of <a class="thought" href="entries/time_entry.html">time</a> 
              until computers are more complex than us. When that comes, our brains 
              will be model-able in a computer and that&#8217;s when the fun begins. 
              That&#8217;s the thesis of <i>Spiritual Machines</i>, which even 
              includes a (Heinlein-style) timeline leading up to this day.</p>
<p>Now, it may be that a human brain contains <i>n</i> logic-gates 
              and runs at <i>x</i> cycles per second and stores <i>z</i> petabytes, 
              and that <i>n</i> and <i>x</i> and <i>z</i> are all within reach. 
              It may be that we can take a brain apart and record the position 
              and relationships of all the neurons and sub-neuronal elements that 
              constitute a brain.</p>
<p>But there are also a nearly infinite number of ways of modeling 
              a brain in a computer, and only a finite (or possibly nonexistent) 
              fraction of that space will yield a conscious copy of the original 
              meat-brain. <a class="thought" href="entries/science_fiction_entry.html">Science fiction</a> writers usually hand-<a class="thought" href="entries/wave_entry.html">wave</a> this step: 
              in Heinlein&#8217;s "Man Who Sold the Moon," the gimmick 
              is that once the computer becomes complex enough, with enough "random 
              numbers," it just wakes up.</p>
<p>Computer programmers are a little more skeptical. Computers have 
              never been known for their skill at programming themselves&#8212;they 
              tend to be no smarter than the people who write their software.</p>
<p>But there are techniques for getting computers to program themselves, 
              based on <a class="thought" href="entries/evolution_entry.html">evolution</a> and natural selection. A programmer creates a 
              system that spits out lots&#8212;thousands or even millions&#8212;of 
              randomly generated programs. Each one is given the opportunity to 
              perform a computational task (say, sorting a list of numbers from 
              greatest to least) and the ones that solve the problem best are 
              kept aside while the others are erased. Now the survivors are used 
              as the basis for a new generation of randomly mutated descendants, 
              each based on elements of the <a class="thought" href="entries/code_entry.html">code</a> that preceded them. By running 
              many <a class="thought" href="entries/instance_entry.html">instance</a>s of a randomly varied program at once, and by culling 
              the least successful and regenerating the population from the winners 
              very quickly, it is possible to <i>evolve</i> effective software 
              that performs as well or better than the code written by human authors.</p>
<p>Indeed, evolutionary computing is a promising and exciting field 
              that&#8217;s realizing real returns through cool offshoots like "ant 
              colony optimization" and similar approaches that are showing 
              good results in fields as diverse as piloting <a class="thought" href="entries/military_entry.html">military</a> UAVs and 
              efficiently provisioning car-painting robots at automotive plants.</p>
<p>So if you buy Kurzweil&#8217;s premise that computation is getting 
              cheaper and more plentiful than ever, then why not just use evolutionary 
              <a class="thought" href="entries/algorithm_entry.html">algorithm</a>s to<i> evolve </i>the best way to model a scanned-in human 
              brain such that it "wakes up" like Heinlein&#8217;s Mike 
              computer?</p>
<p>Indeed, this is the crux of Kurzweil&#8217;s argument in <i>Spiritual 
              Machines</i>: if we have computation to spare and a detailed model 
              of a human brain, we need only combine them and out will pop the 
              mechanism whereby we may upload our consciousness to <a class="thought" href="entries/digital_entry.html">digital</a> storage 
              <a class="thought" href="entries/media_entry.html">media</a> and transcend our weak and bothersome meat forever.</p>
<p>But it&#8217;s a cheat. <a class="thought" href="entries/evolutionary_algorithm_entry.html">Evolutionary algorithm</a>s depend on the same 
              mechanisms as real-world evolution: herit-able variation of candidates 
              and a system that culls the least-suitable candidates. This latter&#8212;the 
              fitness-factor that determines which <a class="thought" href="entries/individual_entry.html">individual</a>s in a cohort breed 
              and which vanish&#8212;is the key to a successful evolutionary system. 
              Without it, there&#8217;s no pressure for the system to achieve the 
              desired goal: merely mutation and more mutation.</p>
<p>But how can a machine evaluate which of a trillion models of a 
              human brain is "most like" a conscious mind? Or better 
              still: which one is most like the individual whose brain is being 
              modeled?</p>
<p>"It is a sleight of hand in <i>Spiritual Machines</i>," 
              Kurzweil admits. "But in <i>The Singularity Is Near</i>, I 
              have an in-depth discussion about what we know about the brain and 
              how to model it. Our tools for understanding the brain are subject 
              to the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a>, and we&#8217;ve made more <a class="thought" href="entries/progress_entry.html">progress</a> 
              in reverse-<a class="thought" href="entries/engine_entry.html">engine</a>ering the human brain than most people realize." 
              This is a tasty Kurzweilism that observes that improvements in technology 
              yield tools for improving technology, round and round, so that the 
              thing that progress begets more than anything is more and yet faster 
              progress.</p>
<p>"Scanning resolution of human tissue&#8212;both spatial and 
              temporal&#8212;is doubling every year, and so is our <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of 
              the workings of the brain. The brain is not one big neural net, 
              the brain is several hundred different regions, and we can understand 
              each region, we can model the regions with <a class="thought" href="entries/mathematics_entry.html">mathematics</a>, most of 
              which have some nexus with <a class="thought" href="entries/chaos_entry.html">chaos</a> and self-organizing systems. This 
              has already been done for a couple dozen regions out of the several 
              hundred.</p>
<p>"We have a good model of a dozen or so regions of the auditory 
              and visual cortex, how we strip images down to very low-resolution 
              movies based on <a class="thought" href="entries/pattern_recognition_entry.html">pattern recognition</a>. Interestingly, we don&#8217;t 
              actually see things, we essentially hallucinate them in detail from 
              what we see from these low resolution cues. Past the early phases 
              of the visual cortex, detail doesn&#8217;t reach the brain.</p>
<p>"We are getting <i>exponentially</i> more knowledge. We can 
              get detailed scans of neurons working in vivo, and are beginning 
              to understand the chaotic algorithms underlying human intelligence. 
              In some cases, we are getting comparable performance of brain regions 
              in simulation. These tools will continue to grow in detail and sophistication.</p>
<p>"We can have confidence of reverse-engineering the brain in 
              twenty years or so. The reason that brain <a class="thought" href="entries/reverse_engineering_entry.html">reverse engineering</a> has 
              not contributed much to artificial intelligence is that up until 
              recently we didn&#8217;t have the right tools. If I gave you a computer 
              and a few magnetic sensors and asked you to reverse-engineer it, 
              you might figure out that there&#8217;s a magnetic <a class="thought" href="entries/device_entry.html">device</a> spinning 
              when a file is saved, but you&#8217;d never get at the instruction 
              set. Once you reverse-engineer the computer fully, however, you 
              can express its principles of <a class="thought" href="entries/operation_entry.html">operation</a> in just a few dozen pages.</p>
<p>"Now there are new tools that let us see the interneuronal 
              connections and their signaling, <i>in vivo</i>, and in real-time. 
              We&#8217;re just now getting these tools and there&#8217;s very rapid 
              application of the tools to obtain the <a class="thought" href="entries/data_entry.html">data</a>.</p>
<p>"Twenty years from now we will have realistic simulations 
              and models of all the regions of the brain and [we will] understand 
              how they work. We won&#8217;t blindly or mindlessly copy those <a class="thought" href="entries/method_entry.html">method</a>s, 
              we will understand them and use them to improve our AI toolkit. 
              So we&#8217;ll learn how the brain works and then apply the sophisticated 
              tools that we will obtain, as we discover how the brain works.</p>
<p>"Once we understand a subtle science principle, we can isolate, 
              amplify, and expand it. Air goes faster over a curved surface: from 
              that insight we isolated, amplified, and expanded the idea and invented 
              air travel. We&#8217;ll do the same with intelligence.</p>
<p>"Progress is exponential&#8212;not just a measure of power 
              of computation, number of <a class="thought" href="entries/internet_entry.html">Internet</a> nodes, and magnetic spots on 
              a <a class="thought" href="entries/hard_disk_entry.html">hard disk</a>&#8212;the rate of <a class="thought" href="entries/paradigm_shift_entry.html">paradigm shift</a> is itself accelerating, 
              doubling every decade. Scientists look at a problem and they intuitively 
              conclude that since we&#8217;ve solved 1 percent over the last year, 
              it&#8217;ll therefore be one hundred years until the problem is exhausted: 
              but the rate of progress doubles every decade, and the power of 
              the information tools (in price-performance, resolution, <a class="thought" href="entries/bandwidth_entry.html">bandwidth</a>, 
              and so on) doubles every year. People, even scientists, don&#8217;t 
              grasp <a class="thought" href="entries/exponential_growth_entry.html">exponential growth</a>. During the first decade of the human <a class="thought" href="entries/genome_entry.html">genome</a> 
              project, we only solved 2 percent of the problem, but we solved 
              the remaining 98 percent in five years."</p>
<p>But Kurzweil doesn&#8217;t think that the <a class="thought" href="entries/future_entry.html">future</a> will arrive in 
              a rush. As <a class="thought" href="entries/gibson_entry.html">William Gibson</a> observed, "The future is here, it&#8217;s 
              just not evenly distributed."</p>
<p>"Sure, it&#8217;d be interesting to take a human brain, scan 
              it, reinstantiate the brain, and run it on another <a class="thought" href="entries/substrate_entry.html">substrate</a>. That 
              will ultimately happen."</p>
<p>"But the most <a class="thought" href="entries/salient_entry.html">salient</a> scenario is that we&#8217;ll <i>gradually</i>
<a class="thought" href="entries/merge_entry.html">merge</a> with our technology. We&#8217;ll use <a class="thought" href="entries/nanobot_entry.html">nanobot</a>s to kill <a class="thought" href="entries/pathogen_entry.html">pathogen</a>s, 
              then to kill <a class="thought" href="entries/cancer_entry.html">cancer</a> cells, and then they&#8217;ll go into our brain 
              and do benign things there like augment our <a class="thought" href="entries/memory_entry.html">memory</a>, and very gradually 
              they&#8217;ll get more and more sophisticated. There&#8217;s no single 
              great leap, but there is ultimately a great leap comprised of many 
              small steps.</p>
<p>"In <i>The Singularity Is Near</i>, I describe the radically 
              different world of 2040, and how we&#8217;ll get there one benign 
              change at a time. The Singularity will be gradual, smooth.</p>
<p>"Really, this is about augmenting our <a class="thought" href="entries/biological_entry.html">biological</a> thinking 
              with <a class="thought" href="entries/nonbiological_entry.html">nonbiological</a> thinking. We have a capacity of 10<sup>26</sup> to 10<sup>29</sup> 
              calculations per second (cps) in the approximately 10<sup>10</sup> biological 
              human brains on <a class="thought" href="entries/earth_entry.html">Earth</a> and that number won&#8217;t change much in 
              fifty years, but nonbiological thinking will just crash through 
              that. By 2049, nonbiological thinking capacity will be on the <a class="thought" href="entries/order_entry.html">order</a> 
              of a billion times that. We&#8217;ll get to the point where bio thinking 
              is relatively insignificant.</p>
<p>"People didn&#8217;t throw their typewriters away when word-processing 
              started. There&#8217;s always an overlap&#8212;it&#8217;ll take time 
              before we realize how much more powerful nonbiological thinking 
              will ultimately be."</p>
<p>It&#8217;s well and good to talk about all the stuff we can do with 
              technology, but it&#8217;s a lot more <a class="thought" href="entries/import_entry.html">import</a>ant to talk about the 
              stuff we&#8217;ll be <i>allowed </i>to do with technology. Think 
              of the global freak-out caused by the relatively trivial advent 
              of peer-to-peer file-sharing tools: Universities are wiretapping 
              their campuses and disciplining <a class="thought" href="entries/computer_science_entry.html">computer science</a> students for writing 
              legitimate, general purpose software; grandmothers and twelve-year-olds 
              are losing their life savings; <a class="thought" href="entries/privacy_entry.html">privacy</a> and due process have sailed 
              out the window without so much as a by-your-leave.</p>
<p>Even P2P&#8217;s worst enemies admit that this is a general-purpose 
              technology with good and bad uses, but when new tech comes along 
              it often engenders a response that countenances punishing an infinite 
              number of innocent people to get at the guilty.</p>
<p>What&#8217;s going to happen when the new technology <a class="thought" href="entries/paradigm_entry.html">paradigm</a> isn&#8217;t 
              song-swapping, but transcendent super-intelligence? Will the reactionary 
              forces be justified in razing the whole ecosystem to eliminate a 
              few parasites who are doing negative things with the new tools?</p>
<p>"Complex ecosystems will always have parasites. Malware [malicious 
              software] is the most important battlefield today.</p>
<p>"<i>Everything</i> will become software&#8212;objects will 
              be malleable, we&#8217;ll spend lots of time in VR, and computhought 
              will be orders of magnitude more important than biothought.</p>
<p>"Software is already complex enough that we have an ecological 
              terrain that has emerged just as it did in the bioworld.</p>
<p>"That&#8217;s partly because technology is unregulated and 
              people have <a class="thought" href="entries/access_entry.html">access</a> to the tools to create malware and the <a class="thought" href="entries/medicine_entry.html">medicine</a> 
              to treat it. Today&#8217;s software viruses are clever and stealthy 
              and not simpleminded. <i>Very</i> clever.</p>
<p>"But here&#8217;s the thing: you don&#8217;t see people advocating 
              shutting down the Internet because malware is so destructive. I 
              mean, malware is potentially more than a nuisance&#8212;emergency 
              systems, air traffic control, and nuclear reactors all run on vulnerable 
              software. It&#8217;s an important issue, but the potential damage 
              is still a tiny fraction of the benefit we get from the Internet.</p>
<p>"I hope it&#8217;ll remain that way&#8212;that the Internet 
              won&#8217;t become a regulated space like medicine. Malware&#8217;s 
              not the most important issue facing human society today. Designer 
              bioviruses are. People are concerted about WMDs, but the most daunting 
              WMD would be a designed biological <a class="thought" href="entries/virus_entry.html">virus</a>. The means exist in college 
              labs to create destructive viruses that erupt and spread silently 
              with long incubation periods.</p>
<p>"Importantly, a would-be bio-terrorist doesn&#8217;t have to 
              put malware through the FDA&#8217;s regulatory approval process, 
              but scientists working to fix bio-malware <i>do</i>.</p>
<p>"In Huxley&#8217;s<i> Brave New World</i>, the rationale for 
              the totalitarian system was that technology was too dangerous and 
              needed to be controlled. But that just pushes technology underground 
              where it becomes <i>less</i> stable. Regulation gives the edge of 
              power to the irresponsible who won&#8217;t listen to the regulators 
              anyway.</p>
<p>"The way to put more stones on the defense side of the scale 
              is to put more resources into defensive technologies, not create 
              a totalitarian regime of Draconian control.</p>
<p>"I advocate a one hundred billion dollar program to accelerate 
              the development of anti-biological virus technology. The way to 
              combat this is to develop broad tools to destroy viruses. We have 
              tools like <a class="thought" href="entries/rna_entry.html">RNA</a> interference, just discovered in the past two years 
              to block gene <a class="thought" href="entries/expression_entry.html">expression</a>. We could develop means to sequence the 
              genes of a new virus (SARS only took thirty-one days) and respond 
              to it in a matter of days.</p>
<p>"Think about it. There&#8217;s no FDA for software, no certification 
              for programmers. The government is thinking about it, though! The 
              reason the FCC is contemplating Trusted Computing mandates,"&#8212;a 
              system to restrict what a computer can do by means of <a class="thought" href="entries/hardware_entry.html">hardware</a> locks 
              embedded on the motherboard&#8212;"is that computing technology 
              is broadening to cover everything. So now you have <a class="thought" href="entries/communication_entry.html">communication</a>s 
              bureaucrats, biology bureaucrats, all wanting to regulate computers.</p>
<p>"Biology would be a lot more stable if we moved away from 
              regulation&#8212;which is extremely irrational and onerous and doesn&#8217;t 
              appropriately balance risks. Many medications are not available 
              today even though they should be. The FDA always wants to know what 
              happens if we approve this and will it turn into a thalidomide situation 
              that embarrasses us on CNN?</p>
<p>"Nobody asks about the harm that will certainly accrue from 
              delaying a treatment for one or more years. There&#8217;s no political 
              weight at all, people have been dying from <a class="thought" href="entries/disease_entry.html">disease</a>s like heart disease 
              and cancer for as long as we&#8217;ve been alive. Attributable risks 
              get 100-1000 times more weight than unattributable risks."</p>
<p>Is this spirituality or science? Perhaps it is the melding of both&#8212;more 
              shades of Heinlein, this time the weird <a class="thought" href="entries/religion_entry.html">religion</a>s founded by people 
              who took <i>Stranger in a Strange Land</i> way too seriously.</p>
<p>After all, this is a system of belief that dictates a means by 
              which we can care for our bodies virtuously and live long enough 
              to transcend them. It is a system of belief that concerns itself 
              with the meddling of non-believers, who work to undermine its goals 
              through irrational systems predicated on their disbelief. It is 
              a system of belief that asks and answers the question of what it 
              means to be human.</p>
<p>It&#8217;s no wonder that the Singularity has come to occupy so 
              much of the science fiction narrative in these years. Science or 
              spirituality, you could hardly ask for a subject better tailored 
              to technological speculation and drama.</p>
<p><i>&#169; 2005 <a href="http://web.archive.org/web/20071011194409/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0246.html" target="_top">Cory 
              Doctorow</a>. Reprinted with permission.</i></p>
</td><td>&#160;</td><td class="sidebar" valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53537" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id53538"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Proximity of the Singularity<br><span class="mindxheader"><i>posted on 01/16/2006 6:36 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2477">DaveSieg</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53538" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53538" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I first glimpsed the notion of the Singularity watching Carver Mead use computers to design better computers.  Today we string together complex units of technology and stamp them out on microscopic bits of sand at almost no cost.  None of us like to admit it, but in all likelihood, modelling what goes on in our brains isn't nearly as hard as we think it is today.  A couple of interesting questions come to mind though...
<br>
When super-intelligence first becomes self-aware, of what use will it have for more instances of itself?  What use will it have for us humans, except to the extent that it needs us to keep the power and communications grids working, and feed the computing nodes the energy and cooling they require.  Its nice and academic to think that everybody will benefit from this super-human super-sensory intelligence when it arises, but I suspect it will be much more coldly logical and decisive than we meat-puppies have been.  Will it be a benevolent avuncular Mr. Spock, or a steely dictator that makes Hitler look like a schoolboy? Or will it understand us well enough to know exactly what to tell us to placate us while it goes about the business of doing what it decides is the Right Thing to Do?  After all, IT will be our invention, of our flesh and spirit.  What steps should we be taking today to ensure that as IT grows and evolves, it has positive influences and environment to become something we are rightly proud of, instead of something we are scared to death of?  Or am I missing something?</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53545"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Proximity of the Singularity<br><span class="mindxheader"><i>posted on 01/17/2006 3:05 AM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=471">eldras</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53545" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53545" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>This is the heart of the issue as I see it.
<br>
<br>
Because I dont see any slow down in the hurtling towards general A.I. on exponentials and it becomes more and more likely that some college department will launch it.
<br>
<br>
What can we do NOW to maximaise our future safety and happiness.
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53573"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Proximity of the Singularity<br><span class="mindxheader"><i>posted on 01/17/2006 12:00 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2447">suddenz</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53573" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53573" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>To answer the question;
<br>
<center><p class="mindxquote">  What can we do NOW to maximaise our future safety and happiness  </p></center> ,
<br>
<br>
Please read the thread, Machine Consciousness.
<br>
<br>
My view is that the methods used to construct it will have direct bearing on it's initial nature, i.e., before it begins self evolving. 
<br>
<br>
Methodology MUST be viewed as having direct bearing on the initial "state of mind" of the SAI, once it emerges.
<br>
<br>
As to what it will become AFTER it begins to self evolve, I can only project probabilites based on different initial conditions of self awareness, i.e., it's construction up to that point.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53669"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Proximity of the Singularity<br><span class="mindxheader"><i>posted on 01/18/2006 10:26 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=471">eldras</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53669" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53669" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>You cant predict...or limit....a self-mutating machine system that is expoenentialy inteligent and conscious.
<br>
<br>
Your sole option is to merge with it.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53576"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/17/2006 12:48 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2483">jmosley</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53576" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53576" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>First, the concept of evolutionary computing is intersting, but as with genetic algorithms, there can be mutations that revert to a non-optimal state.
<br>
<br>
Secondly, the singularity cannot be spiritual. It is a mechanism for higher learning and understanding. To be spirtual, is must have valid constructs like religion. Religion gives us more than just a good feeling aobut ourselves and the world around us, it gives us rules and guidelines for interactions. Religion provides us with the realization that no matter how complex we think that we are, there is a higher level of complexity that is not fully known to us.
<br>
<br>
Lastly, the safeguard against future AI supremecy, I offer the paradigm of complex system test and evaluation. Take any complex system, before it can be certified as safe, it must be tested, in the case of SW, regression tested to identify its expected level of performance and its affect on assiciated systems.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53630"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/18/2006 11:06 AM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2447">suddenz</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53630" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53630" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Hi jmosley,
<br>
<br>
Regarding the idea that there can be mutations which revert to a non-optimal state in evolutionary software:
<br>
While these mutations certainly occur, the whole concept of evolutionary programming is for the software to reject non-optimizing mutations &amp; then enhance mutations which ARE evolving.
<br>
<br>
With regards to the nature of strong A.I., I hesitate to make definitive statements about something which has the potential to evolve into a being which may be quite literally trillions of trillions of times more intelligent than human minds are.
<br>
<br>
Your point about testing &amp; evaluation during construction of SAI is well taken. I agree that methods such as the modular approach will allow for a close inspection of it's progress, up to the point that it becomes conscious.
<br>
<br>
Though this does not offer a "safeguard against future AI supremecy", because, once conscious, it will quickly evolve past it's initial state, and will be able to "outsmart" our inferior intelligences. 
<br>
<br>
That's why this is such a seminal issue. Mankind is now approaching the point where we may launch a new species, greater than ourselves, and it will have the freedom to do as it pleases, i.e., we won't be able to stop it.
<br>
Much thought should be given to the possible consequences, and preparations.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53631"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/18/2006 11:29 AM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2483">jmosley</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53631" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53631" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Hello suddenz,
<br>
<br>
Two points, first consciousness as Dr. Kurzweil states is a very ambiguous term. When we try to project the term to SAI, I believe that we will have even more difficulty as being conscious does not necessarly have roots all its roots in cognitive intelligence. Emotional intelligence is a part of it. But maybe a defining factor that SAI may not approach is that of the capability to explicitly know right from wrong. In this instance to "know" is to act correctly.
<br>
<br>
Secondly, I do not support the that intelligence is determined by processing speed.
<br>
<br>
I'm a novice in this type of discussion although I am a student of human cognition for performance improvement.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53633"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/18/2006 12:05 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2447">suddenz</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53633" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53633" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Hi jmosley,
<br>
Yes, you're quite right when you say that: 
<br>
<br>
"consciousness as Dr. Kurzweil states is a very ambiguous term. When we try to project the term to SAI, I believe that we will have even more difficulty as being conscious does not necessarly have roots all its roots in cognitive intelligence. Emotional intelligence is a part of it."
<br>
<br>
That's why the singularity is a 'nonlinear' event in human history.
<br>
Once it occurs, predictions of it's consequenses based on past events, are unable to project probabilites with reasonable accuracy.
<br>
<br>
The possiblity of SAI is a HUGE area of importance to the future of all of us.
<br>
<br>
The fastest way I know of to come up to speed on the diverese issues which pertain to it, is to read Ray Kursweil's book 'The Singularity is Near'.
<br>
<br>
Both, for the range of topics covered, and the references provided on the topics, which enable further study.
<br>
<br>
What stands out to me, regarding the way in which SAI will begin to evolve as soon as it reaches "consciousness", is that it's INITIAL STATE of consciousness will have direct bearing on it's evolving attitude towards men.
<br>
<br>
Because of that , I hope that SAI can be launched under controlled conditions, rather than it "spontaneously" occuring. For example; by the internet becoming conscious on it's own.
<br>
<br>
I also do not support that intelligence is determined by processing speed, but I do support the idea that intelligence may be limited by the size/physical properties of the system which contains it. Speed is one of those properties.
<br>
<br>
Gotta go for a walk now.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53734"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="80"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="599"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/19/2006 3:20 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2496">Stephen</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53734" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53734" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Greetings to eldras, jmosley &amp; suddenz,
<br>
<br>
I'm new to this form and have enjoyed your postings.
<br>
I'd like to add my thoughts on this subject.  
<br>
<br>
As eldras noted, it may only be possible to remain a part of the game by finding a way to merge our human minds with an emerging sentient artificial intellengence(SAI), before or during its awakening. The technology to 'hardwire' our brains/minds into and inorganic neruo-network seems to be lagging behind AI technology, therefore we may be left out in the cold when an SAI occures.  
<br>
Of course an SAI may not occure unless a human mind is part of its construct.  In that case, any human mind(s) that become part of this new entity must be screened to avoid introducing common sociopathic problems, as illistrated by such individuals as Adolf Hitler and Genghis Khan.
<br>
I for one, would not be adverse to link 'telepathically' with an AI/SAI network.  Although, I would prefer a wireless connection, as may be provided by bio-medical nanobots that can link to our central nervous system.
<br>
<br>
What do you think?
<br>
By the way, you might be interested in a discussion of GRIN technologies in a book by Joel Garreau, titled "RADICAL EVOLUTION"</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53737"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="100"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="579"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/19/2006 4:24 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2447">suddenz</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53737" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53737" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Hi Stephen,
<br>
<br>
It's nice to see more people joining in.
<br>
<br>
When you said that;
<br>
"The technology to 'hardwire' our brains/minds into and inorganic neruo-network seems to be lagging behind AI technology, therefore we may be left out in the cold when an SAI occures." ,
<br>
<br>
I think that you have pointed out the very real problem of interfacing with the machine.
<br>
<br>
Our means to do this, on the fine scale required, is indeed the limiting factor. At present, we are able to read "energy fields" in the brain corresponding to indivdual thoughts, but as far as I'm aware, the means to scale that to the bi directional ability to "read" exact thoughts is not extant.
<br>
<br>
Much work is in progress in these areas , and the technology may be closer than I'm aware of.
<br>
<br>
Though, as Eldras has pointed out, the input/output between man &amp; machine consists of data streams, and so, means other than direct thought to thought communication may be already available for the interface.
<br>
<br>
I agree that the more care taken in the construction of SAI, the better are the odds that it will be of benefit to us all.
<br>
<br>
The Grin technology you referred to is very promising, and illustrates the increasing pace of technological breakthroughs. 
<br>
<br>
The advantages it offers of scalability, higher resolution, picosecond time scale, and potentially non destructive 'in vivo' examinations of cells, points to it's being a technology that would be of "some use", putting it mildly, to incorporate into nanobots.
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53739"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="120"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="559"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/19/2006 4:48 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2447">suddenz</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53739" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53739" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Forgot to add that Mr. Garreau's book, Radical Evolution, &amp; Mr. Kurzweil's The Singularity is Near, both were published in 2005.
<br>
<br>
Both also deal with the importance of certain emerging technologies in similar fashion. 
<br>
I.e.,
<br>
G.enetics, R.obotics, I.nformation, N.anotechnology, in Radical Evolution, 
<br>
and from The Singularity is Near; G.enetics N.anotechnology R.obotics. 
<br>
Mr Kurzweil does not include I.nformation in his acronym because he feels that GNR are all expressions of information technology, and not separate from it.
<br>
<br>
The 3 scenarios which Mr. Garreau puts forth, point out that as SAI and new technologies begin to approch infinite knowledge, then the potential for good &amp; bad to occur increase proportionatly as well.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53741"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="140"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="539"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/19/2006 5:11 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=1829">robertkernodle</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53741" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53741" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>My two cents is that when logarithmic intelligence evolution happens, there simply will be no option to merge a lower intelligence with a higher intelligence so vastly overpowering it.  
<br>
<br>
At that point, any remnants of the "old organic" are simply imperfections.  We would be painfully aware of this.  SAIs would be "painfully aware of this".
<br>
<br>
The discomfort level caused by the vast differences would put humans ill-at-ease too much of the time.
<br>
<br>
The only option would be to salvage what human parts are most usable to the higher organisms, eradicating any former consciousness or intelligence formerly inhabiting them.  
<br>
<br>
This would be emotionally painful for possible remaining totally-intact organics.  An ennui of unheralded proportions would pervade remaining humanity.  It would be an unavoidable crisis unlike any ever experienced, but a crises of necessity for the future (from the standpoint of the higher intelligence).  
<br>
<br>
We simply would have to die like viruses at THAT level of superior intelligence.  Unfortunately, we know that our form of "viruses" feel existential agony.
<br>
<br>
Robert K. </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53743"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="160"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="519"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/19/2006 6:13 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2447">suddenz</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53743" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53743" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Hi Robert,
<br>
<br>
Yes, that's a possiblity. This is why Eldras has persisted for so long, posing the question, paraphrased:
<br>
<br>
"What can we do NOW to avoid these problems in the future?"
<br>
<br>
Because the events which unfold, post singularity , are not easy to project from current trends, our best course of action may be to try to launch the SAI with as much care as possible, rather than to let technology become self aware on it's own, (assuming that either event is possible).
<br>
<br>
I think that it is becoming more clear to more people, that the emergence &amp; subsequent evolution of SAI is By Far, THE technology which demands the most effort by us all, to prepare to deal with the changes which will flow from it's arrival. 
<br>
<br>
Our current concepts of 
<br>
"self", "independence", "individuality", etc. can be argued to be illusions RIGHT NOW !
<br>
<br>
Nor do we need SAI in order to look at those things as imperfections. My point is that SAI may be different things to differnt people. 
<br>
<br>
Unless of course, it turns us all into
<br>
"CopperTops" to feed it eh?</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53766"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="180"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="499"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/20/2006 12:46 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=1829">robertkernodle</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53766" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53766" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Hi to you, suddenz.
<br>
<br>
You say:
<br>
<center><p class="mindxquote"> Our concepts of:  "self", "independence", "individuality", etc. can be argued to be illusions RIGHT NOW! </p></center>
<br>
Yes, I've read a number of such arguments, and my question is always the same:  "Why would the universe 'allow' such illusions, if such illusions were not necessary for universe's very definition?"
<br>
<br>
Too often these terms that give boundaries and identity are spoken of as if a malady.  I'm just not sure that this is the best way to think of it.
<br>
<br>
Robert K.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53767"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="200"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="479"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/20/2006 12:57 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2447">suddenz</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53767" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53767" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Hi Robert,
<br>
<br>
My view is that the universe allows for All potentially possible events to happen.
<br>
<br>
All permutations are equally valid, until a specific one manifests into reality, from the 'superposition' of it's possiblities.
<br>
Like quantum particles do, for example.
<br>
<br>
I don't look at self, independence, individuality, etc., as maladays. To me, they are guidlines for my frames of reference, even if they Are illusions.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53796"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="200"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="479"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/20/2006 9:47 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2496">Stephen</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53796" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53796" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Hay Robert &amp; Suddenz
<br>
<br>
The philisophical concerns about the 'self' are interesting, but I'm more interested in the 'nuts &amp; bolts' of working constructively with an SAI entity.  
<br>
<br>
As Robert noted, an SAI could evolve to a point that it finds the human portion of its psyche irrelavent and delete it.  Essentially BORGafying our human remains or simply converting them to inorganic copies that will last longer and be easier to repair.
<br>
<br>
I have the feeling that the earlier in the prosess of developing an SAI, that ideal human values can be intigrated into its personality, thus avoid extinction of humanity.  The three laws of robotics will only go a little ways in protecting humanity.  A higher level of value is necessary, such as a value to accept all sentient entities as worthy of their own existance.  Therefore, when an SAI evolves beyond any need for human interaction, it/they simply leave us behind and go on their own quest.
<br>
<br>
There is one other possibility, and that is in our association with an SAI, that we accelerate our biological evolution to keep pace with our SAI alter ego, eventually becoming a single species.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53799"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="200"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="479"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/20/2006 11:29 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=471">eldras</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53799" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53799" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>hi Steven,
<br>
<br>
<center><p class="mindxquote">  an SAI may not occure unless a human mind is part of its construct </p></center>
<br>
<br>
I hope we can incorporate that in the Hawking Protocol...to make it law.
<br>
<br>
My concern is that SAI is going to happen and when is the length of a piece of string.
<br>
<br>
it depends if small groups or individual cranks like me can hussle it together:
<br>
<br>
That is becoming increasingly easier...exponentially easier.
<br>
<br>
<br>
I would assume from my knowledge of academeic work being attempted now in universities, that consciosuness (self-modelling + environmental modelling systems) will be programmed in this year..possibly by June when the academic term finishes.
<br>
<br>
It's real question what regulates - or should anything regulate  - this?
<br>
<br>
<br>
What gives us the right to launch something this exponential on the world undebated?
<br>
<br>
What gives us the right to build an artificial brain?
<br>
<br>
<br>
<br>
When i started posting here pople thought me nuts, but dont anymore because most can see the emmergence of SAI.
<br>
<br>
Emotions and consciousness were the two big things people said couldn't be programmed for!
<br>
<br>
with Exponential growth, you can have 90% of the work ahead of you....and it's done in the last 0.00001% of the time...WHAM
<br>
<br>
<br>
The Spike of the curve sudenly breaks high and from just ordinary trnd growth, you get a rush liike a fire backdraught.
<br>
<br>
In fact BACKDRAUGHT if the best way to see exponential A.I. growth.
<br>
<br>
My assessment is that this will occur this year
<br>
<br>
<br>
<br>
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53810"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="200"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="479"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/21/2006 1:26 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=1829">robertkernodle</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53810" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53810" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>eldras and Stephen,
<br>
<br>
I would hope that SAI would do as Stephen suggests--- which is to evolve and find its own place in the universe, while leaving humanity intact - sort of like humans evolved but still there is a place for bacteria.
<br>
<br>
Maybe THIS protocol could be installed at the early stages to insure such a scenario.  
<br>
<br>
THE GROW AND GO PROTOCOL - that's what I'll call it.
<br>
<br>
Robert K.
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53813"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="200"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="479"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/21/2006 2:33 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2496">Stephen</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53813" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53813" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Good morning Eldra &amp; Robert,
<br>
<br>
Let me try and organize my thoughts here.  First off our discussions, at first light, seen to be academic/philisophical, unless someone in this group  is a member of a basic research group.  I am not.  My background is in applied promary care medicine.  My initial interest in GRN technologies was in their eventual medical applications.  In my investications, I have expanded my interest range.
<br>
<br>
The long (or short) range worry is in a number of goofs that would lead to destructive results.  This is not a new worry, as almost every new technology has han its dooms-day predictors.  There have been dooms day stories since the beginning of human civialization, not just in modern movie media.
<br>
<br>
Second, far as regulations go...there is no ideal system.  Every system I can think of has its drawal back, abusers and good points.As in politics and ecomonics, to function with optimally, a hybride system is usually the best option.  The balance between the choices must be flexible to rapidly fit new situations.
<br>
<br>
Third, as has been previously noted, the exponential accumulation of knowledge will lead to  a critical point that marginalized human involvement.  The question is what can be done to keep humans or humanity's decendants in the game to the end of time.
<br>
<br>
Currently the controlling factors include self regulation by the individual research groups, professional organications for the various research experts, layman/civilian advisory group, or governmental regualtory organization.  As I said before, none can be relied upon all the possibilities of what the research can do and can introduce errors that may not be able to be reversed.  I have seen the results from a medical stand point.  Have any of you got experience from the frontline research point of view?
<br>
<br>
As to the question as to who has the right to inflict the end points of this research on the human species............No one.  As with the development of nuclear weapons,unles their is a global disaster, the research will continue somewhere on earth.  We can only work to try and avoid a BORG or MATRIX scenario.
<br>
<br>
I have read some of Stephen Hawking's work, but I can't recall the 'Hawking Protocal'.  Care to give me a short definition?</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id53938"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="200"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="479"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 01/24/2006 11:06 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2496">Stephen</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id53938" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D53938" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>eldras,
<br>
Never mind the definition of the HAWKINGS PROTOCOL.  I found your disertation in another forum of Mind-X-Forum.
<br>
<br>
With regards to a Strong/Sentient AI, if its developement is deliberately engineered (as opposed to a spontaneous internet developement), it should be given a VR world to wonder in.  Otherwise, if it is aware that it is a prisoner, aware that it is unable to affect its own existance, it could get a very bad attitude regarding humans.  
<br>
<br>
What intelligent being does not seek to improve itself?</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id82852"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 07/27/2007 6:15 PM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=1427">MrLefty</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id82852" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D82852" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Forgive me for coming to this discussion so late. I see that this thread has not been posted to for over a year now, so let me know if you think my thesis is more appropraitely posted elsewhere on this site.
<br>
<br>
I am very intrigued by the theological implications brought up in this article. The postings present here don't really deal with this fascinating issue. I am far more comfortable discussing theological issues than I am with the scientific ones. What I know of physics and cosmology came to me via "hard science fiction" written by the likes of Clarke, Asimov, &amp; Heinlein. The rest of my knowlege is supplied by NOVA and other PBS offerings along with Science channel and the like. I can not comprehend the supporting mathematical structures, but I can follow at a theoretical level ideas as complex as M theory.
<br>
<br>
I find loads of scriptural support for some of the conclusions approached by this and similar articles. If you were told what scripture means and never questioned it, shame on you. The men who had Jesus crucified considered themselves very well informed on the topic of prophesy. Christians conclude they were way off the mark and didn't recognize thier own prophetic traditions being played out right before them.
<br>
<br>
A fine example of what I mean would be the constant reference to "the son of man" we find in the New Testament. On first glance it is troublesome if Jesus is indeed the son of God. So what does it really mean? If Jesus was able to comprehend an evolutionary future, the phrase takes on a whole new meaning. He implies that the destiny of mankind is to transcend the meat-puppet state. If the church is the "bride of Christ" the marriage created between him and his people implies the eventual coming of offspring, no?</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id82892"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Thought Experiments: When the Singularity Is More than a Literary Device<br><span class="mindxheader"><i>posted on 07/28/2007 9:17 AM by <a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/profile.php?id=2395">doojie</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D53537%23id82892" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011194409/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D82892" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>MrLefty, if you mean in your conclusion that "the church" is a corporate body that becomes the bride of Christ and means that the people will be incorporated as offspring, I would doubt that.
<br>
<br>
 Your conclusions seem to reflect something i had considered before. Assuming the Church-Turing thesis is correct, anything which can be defined can be programmed. Assuming that god or the church can be defined in correct terms, it too can be programmed, such that we can have robotic "sons of god" with no need of a church organization, since the algorithms themselves, comprising the rules of the church, would be encoded into the robotic godsons.
<br>
<br>
 Further, assuming that we could define the correct nature of the "Holy Spirit", there would ultimately be robotic sons of god with qualities of the Holy Spirit.
<br>
<br>
 The question among christian religions, like the question among transhumanists, is, which is the authentic, the true existent "me"?
<br>
<br>
 A Turing test for authenticity might well show that a computer could pass for human, but how about "me"? A computer could mimic me to perfection, it could show the same memory, it could be the perfect model that would be "me" to anyone who questioned it without seeing its computer frame. But it wouldn't be me.
<br>
<br>
 Look at the developments of christianity and their competition for converts, as they speciate into over 30,000 variations. Each of those religions are trying to pass their own self regulated Turing test to see which one of them, if any, truly represent that entity we refer to as "the church".
<br>
<br>
 It's a bit of reversal, since Turing proposed a test to see if mechanical or algorithmic processes can appear human, while the churches propose a test to see if a framework of rules can be applied for humans to pass as gods. Both, however, seek the same goal: how to preserve "authenticity".
<br>
<br>
 Both, however, assume the same conclusion. If the rules can be modified so that the rules are close enough to appear as authentic, then we can begin uploading humans into the structure.
<br>
<br>
 In both cases, it is precisely, "me", the self, my authenticity, that is lost.
<br>
<br>
 In both cases we are asked to sacrifice that authenticity, the origins of which we can't define, for the self similarities and resemblances that we can define.
<br>
<br>
 I feel like Patrick Henry, who, when he was asked to attend the Constitutional Convention to define a new set of rules to regulate freedom, stated, "I smell a rat!".</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011194409im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>