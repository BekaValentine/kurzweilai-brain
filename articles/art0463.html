<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>Intelligence as an Emergent Behavior or, The Songs of Eden</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/meme/memelist.html?m=4">Will Machines Become Conscious?</a> &gt; 
Intelligence as an Emergent Behavior or, The Songs of Eden
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20071011120812/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0463.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0463.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/articles/art0463.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">Intelligence as an Emergent Behavior or, The Songs of Eden</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0178.html" target="_top">W. Daniel Hillis</a><br></span></td>
</table>
<br>
<div class="TeaserText">Could we build a thinking machine by simply hooking together a large network of artificial neurons and waiting for intelligence to spontaneously emerge? Not likely, but by studying the properties of biological and emergent systems, a carefully constructed network of artificial neurons could be inoculated with thought, similar to yeast's role in making beer. The clue may be in the "songs" of apes. </div>
<br>
<br><b> </b><i>Originally published 
            Winter 1988 in <a href="http://web.archive.org/web/20071011120812/http://www.daedalus.amacad.org/" target="_blank">Daedalus, 
            Journal of the American Academy of Arts and Sciences</a>. Published 
            on KurzweilAI.net on May 2, 2002.</i><br>
<p>Sometimes a <a class="thought" href="entries/system_entry.html">system</a> with many simple <a class="thought" href="entries/component_entry.html">component</a>s will exhibit a behavior 
              of the whole that seems more organized than the behavior of the 
              <a class="thought" href="entries/individual_entry.html">individual</a> parts. Consider the intricate <a class="thought" href="entries/structure_entry.html">structure</a> of a snowflake. 
              Symmetric shapes within the crystals of ice repeat in threes and 
              sixes, with <a class="thought" href="entries/pattern_entry.html">pattern</a>s recurring from place to place and within themselves 
              at different scales. The shapes formed by the ice are consequences 
              of the local rules of interaction that govern the <a class="thought" href="entries/molecule_entry.html">molecule</a>s of water, 
              although the connection between the shapes and the rules is far 
              from obvious. After all, these are the same rules of interaction 
              that cause water to suddenly turn to steam at its boiling point 
              and cause whirlpools to form in a stream. The rules that govern 
              the forces between water <a class="thought" href="entries/molecule_entry.html">molecule</a>s seem much simpler than crystals 
              or whirlpools or boiling points, yet all of these complex phenomena 
              are called <i>emergent behaviors</i> of the <a class="thought" href="entries/system_entry.html">system</a>. <br>
</p>
<p>It would be very convenient if <a class="thought" href="entries/intelligence_entry.html">intelligence</a> were an emergent behavior 
              of randomly connected <a class="thought" href="entries/neuron_entry.html">neuron</a>s in the same <a class="thought" href="entries/sense_entry.html">sense</a> that snowflakes 
              and whirlpools are the emergent behaviors of water <a class="thought" href="entries/molecule_entry.html">molecule</a>s. It 
              might then be possible to build a <a class="thought" href="entries/thinking_entry.html">thinking</a> <a class="thought" href="entries/machine_entry.html">machine</a> by simply hooking 
              together a sufficiently large <a class="thought" href="entries/network_entry.html">network</a> of artificial <a class="thought" href="entries/neuron_entry.html">neuron</a>s. The 
              notion of emergence would suggest that such a <a class="thought" href="entries/network_entry.html">network</a>, once it reached 
              some critical mass, would spontaneously begin to think. <br>
</p>
<p>This is a seductive idea, since it allows for the possibility of 
              constructing <a class="thought" href="entries/intelligence_entry.html">intelligence</a> without first understanding it. Understanding 
              <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is difficult and probably a long way off. The possibility 
              that it might spontaneously emerge from the interactions of a large 
              collection of simple parts has considerable appeal to a would-be 
              builder of <a class="thought" href="entries/thinking_entry.html">thinking</a> <a class="thought" href="entries/machine_entry.html">machine</a>s. Unfortunately, as a practical approach 
              to construction, the idea tends to be unproductive. The <a class="thought" href="entries/concept_entry.html">concept</a> 
              of emergence, in itself, offers neither guidance on how to construct 
              such a <a class="thought" href="entries/system_entry.html">system</a> nor insight into why it would work. <br>
</p>
<p>Ironically, this apparent inscrutability accounts for much of the 
              idea's continuing popularity, since it offers a way to believe in 
              physical causality while simultaneously maintaining the impossibility 
              of a <a class="thought" href="entries/reduction_entry.html">reduction</a>ist explanation of <a class="thought" href="entries/thought_entry.html">thought</a>. For some, our ignorance 
              of how local interactions produce emergent behavior offers a reassuring 
              fog in which to hide <a class="thought" href="entries/free_will_entry.html">free will</a>. <br>
</p>
<p>There has been a renewal of interest in emergent behavior in the 
              form of <a class="thought" href="entries/neural_network_entry.html">neural network</a>s and connectionist models, spin glasses and 
              <a class="thought" href="entries/cellular_automata_entry.html">cellular automata</a>, and <a class="thought" href="entries/evolution_entry.html">evolution</a>ary models. The <a class="thought" href="entries/reason_entry.html">reason</a>s for this 
              interest have little to do with <a class="thought" href="entries/philosophy_entry.html">philosophy</a> in one way or the other, 
              but rather are a combination of new insights and new tools. The 
              insights come primarily from a branch of <a class="thought" href="entries/physics_entry.html">physics</a> called "dynamical 
              <a class="thought" href="entries/system_entry.html">system</a>s theory." The tools come from the development of new 
              types of computing <a class="thought" href="entries/device_entry.html">device</a>s. Just as in the 1950's we <a class="thought" href="entries/thought_entry.html">thought</a> of 
              <a class="thought" href="entries/intelligence_entry.html">intelligence</a> in terms of servomechanism, and in the 60's and 70's 
              in terms of sequential <a class="thought" href="entries/computer_entry.html">computer</a>s, we are now beginning to think 
              in terms of parallel <a class="thought" href="entries/machine_entry.html">machine</a>s. This is not a deep philosophical 
              shift, but it is of great practical <a class="thought" href="entries/import_entry.html">import</a>ance, since it is now 
              possible to study large emergent <a class="thought" href="entries/system_entry.html">system</a>s <a class="thought" href="entries/experiment_entry.html">experiment</a>ally. <br>
</p>
<p>Inevitably, anti-<a class="thought" href="entries/reduction_entry.html">reduction</a>ists interpret such <a class="thought" href="entries/progress_entry.html">progress</a> as a schism 
              within the field between <a class="thought" href="entries/symbol_entry.html">symbol</a>ic rationalists who oppose them and 
              gestaltists who support them. I have often been asked which "side" 
              I am on. Not being a philosopher, my inclination is to focus on 
              the practical aspects of this question: How would we go about constructing 
              an emergent <a class="thought" href="entries/intelligence_entry.html">intelligence</a>? What <a class="thought" href="entries/information_entry.html">information</a> would we need to know 
              in <a class="thought" href="entries/order_entry.html">order</a> to succeed? How can this <a class="thought" href="entries/information_entry.html">information</a> be determined by <a class="thought" href="entries/experiment_entry.html">experiment</a>? 
              <br>
</p>
<p>The emergent <a class="thought" href="entries/system_entry.html">system</a> that I can most easily imagine would be an 
              <a class="thought" href="entries/implement_entry.html">implement</a>ation of <a class="thought" href="entries/symbol_entry.html">symbol</a>ic <a class="thought" href="entries/thought_entry.html">thought</a>, rather than a refutation of 
              it. <a class="thought" href="entries/symbol_entry.html">Symbol</a>ic <a class="thought" href="entries/thought_entry.html">thought</a> would be an emergent property of the <a class="thought" href="entries/system_entry.html">system</a>. 
              The point of view is best explained by the following parable about 
              the origin of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. As far as I know, this parable 
              of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/evolution_entry.html">evolution</a> is consistent with the available evidence (as 
              are many others), but since it is chosen to illustrate a point it 
              should be read as a story rather than as a theory. It is reversed 
              from most accepted theories of <a class="thought" href="entries/human_entry.html">human</a> development in that it presents 
              features that are measurable in the archeological records such as 
              increased <a class="thought" href="entries/brain_entry.html">brain</a> size, food sharing, and neoteny, as consequences 
              rather than as causes of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. <br>
</p>
<p>Once upon a <a class="thought" href="entries/time_entry.html">time</a>, about two and a half million years ago, there 
              lived a race of apes that walked upright. In terms of intellect 
              and habit they were similar to modern chimpanzees. The young apes, 
              like many young apes today, had a tendency to mimic the <a class="thought" href="entries/action_entry.html">action</a>s 
              of others. In particular, they had a tendency to imitate sounds. 
              If one ape went "ooh, eeh, eeh," it would be likely that 
              the other one would repeat, "ooh, eeh, eeh." (I do not 
              know why apes do this, but they do. As do many <a class="thought" href="entries/species_entry.html">species</a> of birds.) 
              Some sequences of sounds were more likely to be repeated than others. 
              I will call these "songs." <br>
</p>
<p>For the moment let us ignore the <a class="thought" href="entries/evolution_entry.html">evolution</a> of the apes and consider 
              the <a class="thought" href="entries/evolution_entry.html">evolution</a> of the songs. Since the songs were replicated by the 
              apes, and since they sometimes died away and were occasionally combined 
              with others, we may consider them, very loosely, a form of <a class="thought" href="entries/life_entry.html">life</a>. 
              They survived, bred, competed with one another, and evolved according 
              to their own criterion of fitness. If a song contained a particularly 
              catchy phrase that caused it to be repeated often, then that phrase 
              was likely to be repeated and incorporated into other songs. Only 
              songs that had a strong tendency to be repeated survived. <br>
</p>
<p>The survival of the song was only indirectly related to the survival 
              of the apes. It was more directly affected by the survival of other 
              songs. Since the apes were a limited resource, the songs had to 
              compete with one another for a chance to be sung. One successful 
              strategy for competition was for a song to specialize; that is, 
              for it to find a particular niche where it would be likely to be 
              repeated. Songs that fit particularly well with a specific mood 
              or activity of an ape had a special survival value for this <a class="thought" href="entries/reason_entry.html">reason</a>. 
              (I do not know why some songs fit well with particular moods, but 
              since it is true for me I do not find it hard to believe for my 
              ancestors.) <br>
</p>
<p>Up to this point the songs were not of any particular value to 
              the apes. In a <a class="thought" href="entries/biological_entry.html">biological</a> <a class="thought" href="entries/sense_entry.html">sense</a> they were parasites, taking advantage 
              of the apes' tendency to imitate. Once the songs began to specialize, 
              however, it became advantageous for an ape to pay attention to the 
              songs of others and to differentiate between them. By listening 
              to songs, a clever ape could gain useful <a class="thought" href="entries/information_entry.html">information</a>. For example, 
              an ape could infer that another ape had found food, or that it was 
              likely to attack. Once the apes began to take advantage of the songs, 
              a mutually beneficial symbiosis developed. Songs enhanced their 
              survival by conveying useful <a class="thought" href="entries/information_entry.html">information</a>. Apes enhanced their survival 
              by improving their <a class="thought" href="entries/capacity_entry.html">capacity</a> to remember, replicate, and understand 
              songs. The blind forces of <a class="thought" href="entries/evolution_entry.html">evolution</a> created a partnership between 
              the songs and the apes that thrived on the basis of mutual self-interest. 
              Eventually this partnership evolved into one of the world's most 
              successful symbionts: us. <br>
</p>
<p>Unfortunately, songs do not leave fossils, so unless some natural 
              process has left a phonographic trace, we may never know if this 
              is what really happened. But if the story is true, the apes and 
              the songs became the two <a class="thought" href="entries/component_entry.html">component</a>s of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. The songs 
              evolved into the <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, mores, and mechanism of <a class="thought" href="entries/thought_entry.html">thought</a> that 
              together are the <a class="thought" href="entries/symbol_entry.html">symbol</a>ic portion of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. The apes 
              became apes with bigger brains, perhaps optimized for late maturity 
              so that they could learn more songs. "Homo Sapiens" is 
              a cooperative combination of the two. <br>
</p>
<p>It is not unusual in <a class="thought" href="entries/nature_entry.html">nature</a> for two <a class="thought" href="entries/species_entry.html">species</a> to live together so 
              interdependently that they appear to be a single <a class="thought" href="entries/organism_entry.html">organism</a>. Lichens 
              are symbionts of a fungus and an alga living so closely intertwined 
              that they can only be separated under a microscope. Bean plants 
              need living <a class="thought" href="entries/bacteria_entry.html">bacteria</a> in their roots to fix the <a class="thought" href="entries/nitrogen_entry.html">nitrogen</a> from the 
              soil, and in return the <a class="thought" href="entries/bacteria_entry.html">bacteria</a> need nutrients from the bean plants. 
              Even the single celled "Paramecium Bursarra" uses green 
              algae living inside itself to synthesize food. <br>
</p>
<p>There may be an example even closer to the songs and the apes, 
              where two entirely different forms of "life" form a symbiosis. 
              In "The Origins of <a class="thought" href="entries/life_entry.html">Life</a>," Freeman Dyson suggests that 
              <a class="thought" href="entries/biological_entry.html">biological</a> <a class="thought" href="entries/life_entry.html">life</a> is a symbiotic combination of two different self-reproducing 
              entities with very different forms of replication. Dyson suggests 
              that <a class="thought" href="entries/life_entry.html">life</a> originated in two stages. While most theories of the origin 
              of <a class="thought" href="entries/life_entry.html">life</a> start with <a class="thought" href="entries/nucleotide_entry.html">nucleotide</a>s replicating in some "primeval 
              soup," Dyson's theory starts with metabolizing drops of oil. 
              <br>
</p>
<p>In the beginning, these hypothetical replicating oil drops had 
              no genetic material, but were self-perpetuating chemical <a class="thought" href="entries/system_entry.html">system</a>s 
              that absorbed raw materials from their surroundings. When a drop 
              reached a certain size it would split, with about half of the constituents 
              going to each part. Such drops evolved efficient metabolic <a class="thought" href="entries/system_entry.html">system</a>s 
              even though their rules of replication were very different from 
              the Mendelian rules of modern <a class="thought" href="entries/life_entry.html">life</a>. Once the oil drops became good 
              at metabolizing, they were infected by another form of replicators, 
              which, like the songs, have no metabolism of their own. These were 
              parasitic <a class="thought" href="entries/molecule_entry.html">molecule</a>s of <a class="thought" href="entries/dna_entry.html">DNA</a> which, like modern viruses, took advantage 
              of the existing <a class="thought" href="entries/machine_entry.html">machine</a>ry of the cells to reproduce. The metabolizers 
              and the <a class="thought" href="entries/dna_entry.html">DNA</a> eventually co-evolved into a mutually beneficial symbiosis 
              that we know today as <a class="thought" href="entries/life_entry.html">life</a>. <br>
</p>
<p>This two-part theory of <a class="thought" href="entries/life_entry.html">life</a> is not <a class="thought" href="entries/concept_entry.html">concept</a>ually far from the two-part 
              story of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. Both suggest that a pre-existing homeostatic 
              mechanism was infected by an opportunistic parasite. The two parts 
              reproduced according to different <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of rules, but were able to 
              co-evolve so successfully that the resulting symbiont appears to 
              be a single <a class="thought" href="entries/entity_entry.html">entity</a>. <br>
</p>
<p>Viewed in this <a class="thought" href="entries/light_entry.html">light</a>, choosing between emergence and <a class="thought" href="entries/symbol_entry.html">symbol</a>ic <a class="thought" href="entries/computation_entry.html">computation</a> 
              in the study of <a class="thought" href="entries/intelligence_entry.html">intelligence</a> would be like choosing between metabolism 
              and genetic replication in the study of <a class="thought" href="entries/life_entry.html">life</a>. Just as the metabolic 
              <a class="thought" href="entries/system_entry.html">system</a> provides a <a class="thought" href="entries/substrate_entry.html">substrate</a> in which the genetic <a class="thought" href="entries/system_entry.html">system</a> can work, 
              so an emergent <a class="thought" href="entries/system_entry.html">system</a> may provide a <a class="thought" href="entries/substrate_entry.html">substrate</a> in which the <a class="thought" href="entries/symbol_entry.html">symbol</a>ic 
              <a class="thought" href="entries/system_entry.html">system</a> can operate. <br>
</p>
<p>Currently, the metabolic <a class="thought" href="entries/system_entry.html">system</a> of <a class="thought" href="entries/life_entry.html">life</a> is far too complex for 
              us to fully understand or reproduce. By comparison, the Mendelian 
              rules of genetic replication are almost trivial, and it is possible 
              to study them as a <a class="thought" href="entries/system_entry.html">system</a> unto themselves without worrying about 
              the details of metabolism which supports them. In the same <a class="thought" href="entries/sense_entry.html">sense</a>, 
              it seems likely that <a class="thought" href="entries/symbol_entry.html">symbol</a>ic <a class="thought" href="entries/thought_entry.html">thought</a> can be fruitfully studied 
              and perhaps even recreated without worrying about the details of 
              the emergent <a class="thought" href="entries/system_entry.html">system</a> that supports it. So far this has been the dominant 
              approach in <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> and the approach that has yielded 
              the most <a class="thought" href="entries/progress_entry.html">progress</a>. <br>
</p>
<p>The other approach is to build a model of the emergent <a class="thought" href="entries/substrate_entry.html">substrate</a> 
              of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. This artificial <a class="thought" href="entries/substrate_entry.html">substrate</a> for <a class="thought" href="entries/thought_entry.html">thought</a> would not 
              need to mimic in detail the mechanisms of the <a class="thought" href="entries/biological_entry.html">biological</a> <a class="thought" href="entries/system_entry.html">system</a>, 
              but it would need to exhibit those emergent properties that are 
              necessary to support the <a class="thought" href="entries/operation_entry.html">operation</a>s of <a class="thought" href="entries/thought_entry.html">thought</a>. <br>
</p>
<p>What is the minimum that we would need to understand in <a class="thought" href="entries/order_entry.html">order</a> to 
              construct such a <a class="thought" href="entries/system_entry.html">system</a>? For one thing, we would need to know how 
              big a <a class="thought" href="entries/system_entry.html">system</a> to build. How many bits are required to store the acquired 
              portion of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of a typical human? We need to know an 
              approximate answer in <a class="thought" href="entries/order_entry.html">order</a> to construct an emergent <a class="thought" href="entries/intelligence_entry.html">intelligence</a> 
              with <a class="thought" href="entries/human_entry.html">human</a>-like performance. Currently the amount of <a class="thought" href="entries/information_entry.html">information</a> 
              stored by a <a class="thought" href="entries/human_entry.html">human</a> is not known to within even two orders of magnitude, 
              but it can in principle be determined by <a class="thought" href="entries/experiment_entry.html">experiment</a>. There are at 
              least three ways the question might be answered. <br>
</p>
<p>One way to estimate the storage requirements for emergent <a class="thought" href="entries/intelligence_entry.html">intelligence</a> 
              would be from an understanding of the physical mechanisms of <a class="thought" href="entries/memory_entry.html">memory</a> 
              in the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a>. If that <a class="thought" href="entries/information_entry.html">information</a> is stored primarily by modifications 
              of <a class="thought" href="entries/synapse_entry.html">synapse</a>s, then it would be possible to measure the <a class="thought" href="entries/information_entry.html">information</a> 
              storage <a class="thought" href="entries/capacity_entry.html">capacity</a> of the <a class="thought" href="entries/brain_entry.html">brain</a> by counting the <a class="thought" href="entries/number_entry.html">number</a> of <a class="thought" href="entries/synapse_entry.html">synapse</a>s. 
              Elsewhere in this issue, Schwartz shows that this <a class="thought" href="entries/method_entry.html">method</a> leads to 
              an upper bound on the storage <a class="thought" href="entries/capacity_entry.html">capacity</a> of the <a class="thought" href="entries/brain_entry.html">brain</a> of 10 to the 
              15th bits. Even knowing the exact amount of physical storage in 
              the <a class="thought" href="entries/brain_entry.html">brain</a> would not completely answer the question of storage requirement, 
              since much of the potential storage might be unused or used inefficiently. 
              But at least this <a class="thought" href="entries/method_entry.html">method</a> can help establish an upper bound on the 
              requirements. <br>
</p>
<p>A second <a class="thought" href="entries/method_entry.html">method</a> for estimating the <a class="thought" href="entries/information_entry.html">information</a> in <a class="thought" href="entries/symbol_entry.html">symbol</a>ic <a class="thought" href="entries/knowledge_entry.html">knowledge</a> 
              would be to measure it by some form of statistical sampling. For 
              <a class="thought" href="entries/instance_entry.html">instance</a>, it is possible to estimate the size of an <a class="thought" href="entries/individual_entry.html">individual</a>'s 
              vocabulary by testing specific words randomly sampled from a dictionary. 
              The fraction of words known by the <a class="thought" href="entries/individual_entry.html">individual</a> is a good estimate 
              of the fraction of words known in the complete dictionary. The estimated 
              vocabulary size is this fraction times the <a class="thought" href="entries/number_entry.html">number</a> of words in the 
              dictionary. The <a class="thought" href="entries/experiment_entry.html">experiment</a> depends on having a predetermined body 
              of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> against which to measure. For example, it would be 
              possible to estimate how many facts in the "Encyclopedia Britannica" 
              were known by a given <a class="thought" href="entries/individual_entry.html">individual</a>, but this would give no measure 
              of facts not contained within the encyclopedia. The <a class="thought" href="entries/method_entry.html">method</a> is useful 
              only in establishing a lower bound. <br>
</p>
<p>A related <a class="thought" href="entries/experiment_entry.html">experiment</a> is the game of "20 questions" in 
              which one player identifies an <a class="thought" href="entries/object_entry.html">object</a> chosen by the other by asking 
              a series of 20 yes-or-no questions. Since each answer provides no 
              more than a single <a class="thought" href="entries/bit_entry.html">bit</a> of <a class="thought" href="entries/information_entry.html">information</a>, and since skillful players 
              generally require almost all of the 20 questions to choose correctly, 
              we can estimate that the <a class="thought" href="entries/number_entry.html">number</a> of allowable choices is on the <a class="thought" href="entries/order_entry.html">order</a> 
              of 2 to the 20th, or about one million. This gives an estimated 
              <a class="thought" href="entries/number_entry.html">number</a> of allowable <a class="thought" href="entries/object_entry.html">object</a>s known in common by the two players. 
              Of course, the measure is inaccurate since the questions are not 
              perfect and the choices of <a class="thought" href="entries/object_entry.html">object</a>s are not random. It is possible 
              that a refined version of the game could be developed and used to 
              provide another lower bound. <br>
</p>
<p>A third approach to measuring the amount of <a class="thought" href="entries/information_entry.html">information</a> of the 
              <a class="thought" href="entries/symbol_entry.html">symbol</a>ic portion of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/knowledge_entry.html">knowledge</a> is to estimate the rate of acquisition 
              and to integrate over <a class="thought" href="entries/time_entry.html">time</a>. For example, <a class="thought" href="entries/experiment_entry.html">experiment</a>s on memorizing 
              random sequences of syllables indicate that the maximum memorization 
              rate of this type of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> is about one "chunk" per 
              second. A "chunk" in this <a class="thought" href="entries/context_entry.html">context</a> can be safely assumed 
              to contain less than 100 bits of <a class="thought" href="entries/information_entry.html">information</a>, so the results suggest 
              that the maximum rate that a <a class="thought" href="entries/human_entry.html">human</a> is able to commit <a class="thought" href="entries/information_entry.html">information</a> 
              to long-term <a class="thought" href="entries/memory_entry.html">memory</a> is significantly less than 100 bits per second. 
              If this is true, a 20-year-old <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/learning_entry.html">learning</a> at the maximum rate 
              for 16 hours a day would know less than 50 gigabits of <a class="thought" href="entries/information_entry.html">information</a>. 
              I find this <a class="thought" href="entries/number_entry.html">number</a> surprisingly small. <br>
</p>
<p>A difficulty with this estimate of the rate of acquisition is that 
              the <a class="thought" href="entries/experiment_entry.html">experiment</a> measures only <a class="thought" href="entries/information_entry.html">information</a> coming through one sensory 
              channel under one particular <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of circumstances. The visual <a class="thought" href="entries/system_entry.html">system</a> 
              sends more than a million times this rate of <a class="thought" href="entries/information_entry.html">information</a> to the 
              optic <a class="thought" href="entries/nerve_entry.html">nerve</a>, and it is conceivable that all of this <a class="thought" href="entries/information_entry.html">information</a> 
              is committed to <a class="thought" href="entries/memory_entry.html">memory</a>. If it turns out that images are stored directly, 
              it will be necessary to significantly increase the 100 <a class="thought" href="entries/bit_entry.html">bit</a> per second 
              limit, but there is no current evidence that this is the case. In 
              <a class="thought" href="entries/experiment_entry.html">experiment</a>s measuring the ability of exceptional <a class="thought" href="entries/individual_entry.html">individual</a>s to 
              store "eidetic" images of random dot stereograms, the 
              subjects are given about 5 minutes to "memorize" a 128x128 
              image. Memorizing only a few hundred of these bits is probably sufficient 
              to pass the test. <br>
</p>
<p>I am aware of no evidence that suggests more than a few bits per 
              second of any type of <a class="thought" href="entries/information_entry.html">information</a> can be committed to long-term 
              <a class="thought" href="entries/memory_entry.html">memory</a>. Even if we accept at face value reports of extraordinary 
              feats of <a class="thought" href="entries/memory_entry.html">memory</a>, such as those of Luria's showman in "Mind 
              of the Mnemonist", the average rate of commitment to <a class="thought" href="entries/memory_entry.html">memory</a> 
              never seems to exceed a few bits per second. <a class="thought" href="entries/experiment_entry.html">Experiment</a>s should 
              be able to refine this estimate, but even if we knew the maximum 
              rate exactly, the rate averaged over a lifetime would probably be 
              very much less. Knowing the maximum rate would establish an upper 
              bound on the requirements of storage. <br>
</p>
<p>The sketchy <a class="thought" href="entries/data_entry.html">data</a> cited above would suggest that an intelligent 
              <a class="thought" href="entries/machine_entry.html">machine</a> would require 10 to the 9th bits of storage, plus or minus 
              two orders of magnitude. This assumes that the <a class="thought" href="entries/information_entry.html">information</a> is encoded 
              in such a way that it requires a minimum amount of storage, which 
              for the purpose of processing <a class="thought" href="entries/information_entry.html">information</a> would probably not be 
              the most practical representation. As a would-be builder of <a class="thought" href="entries/thinking_entry.html">thinking</a>
<a class="thought" href="entries/machine_entry.html">machine</a>s, I find this <a class="thought" href="entries/number_entry.html">number</a> encouragingly small, since it is well 
              within the range of current <a class="thought" href="entries/electronic_entry.html">electronic</a> <a class="thought" href="entries/computer_entry.html">computer</a>s. As a <a class="thought" href="entries/human_entry.html">human</a> with 
              an ego, I find it distressing. I do not like to think that my entire 
              lifetime of memories could be placed on a reel of magnetic tape. 
              Hopefully <a class="thought" href="entries/experiment_entry.html">experiment</a>al evidence will clear this up one way or the 
              other. <br>
</p>
<p>There are a few subtleties in the question of storage requirements, 
              in defining the quantity of <a class="thought" href="entries/information_entry.html">information</a> in a way that is independent 
              of the representation. Defining the <a class="thought" href="entries/number_entry.html">number</a> of bits in the <a class="thought" href="entries/information_entry.html">information</a>-theoretical 
              <a class="thought" href="entries/sense_entry.html">sense</a> requires a measure of the probabilities over the ensemble 
              of possible states. This means assigning an "a priori" 
              probability to each possible <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, which is the role 
              of inherited <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. Inherited <a class="thought" href="entries/intelligence_entry.html">intelligence</a> provides a framework 
              in which the <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of acquired <a class="thought" href="entries/intelligence_entry.html">intelligence</a> can be interpreted. 
              Inherited <a class="thought" href="entries/intelligence_entry.html">intelligence</a> defines what is knowable; acquired <a class="thought" href="entries/intelligence_entry.html">intelligence</a> 
              determines which of the knowable is known. <br>
</p>
<p>Another potential difficulty is how to count the storage of <a class="thought" href="entries/information_entry.html">information</a> 
              that can be deduced from other <a class="thought" href="entries/data_entry.html">data</a>. In the strict <a class="thought" href="entries/information_entry.html">information</a>-theoretical 
              <a class="thought" href="entries/sense_entry.html">sense</a>, <a class="thought" href="entries/data_entry.html">data</a> that can be inferred from other <a class="thought" href="entries/data_entry.html">data</a> add no <a class="thought" href="entries/information_entry.html">information</a> 
              at all. An accurate measure would have to take into account the 
              possibility that <a class="thought" href="entries/knowledge_entry.html">knowledge</a> is inconsistent, and that only limited 
              inferences are actually made. These are the kind of issues currently 
              being studied on the <a class="thought" href="entries/symbol_entry.html">symbol</a>ic side of the field of <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>. 
              <br>
</p>
<p>One issue that does not need to be resolved to measure storage 
              <a class="thought" href="entries/capacity_entry.html">capacity</a> is distributed versus localized representation. Knowing 
              what types of representation are used in what parts of the <a class="thought" href="entries/human_entry.html">human</a>
<a class="thought" href="entries/brain_entry.html">brain</a> would be of considerable scientific interest, but it does 
              not have a profound impact on the amount of storage in the <a class="thought" href="entries/system_entry.html">system</a>, 
              or on our ability to measure it. Non-technical commentators have 
              a tendency to <a class="thought" href="entries/attribute_entry.html">attribute</a> almost mystical qualities to distributed 
              storage mechanisms such as those in <a class="thought" href="entries/hologram_entry.html">hologram</a>s and <a class="thought" href="entries/neural_network_entry.html">neural network</a>s, 
              but the limitations on their storage capacities are well understood. 
              <br>
</p>
<p>Distributed representations with similar properties are often used 
              within conventional <a class="thought" href="entries/digital_entry.html">digital</a> <a class="thought" href="entries/computer_entry.html">computer</a>s, and they are invisible to 
              most users except in the <a class="thought" href="entries/system_entry.html">system</a>'s <a class="thought" href="entries/capacity_entry.html">capacity</a> to tolerate errors. The 
              error correcting <a class="thought" href="entries/memory_entry.html">memory</a> used in most <a class="thought" href="entries/computer_entry.html">computer</a>s is a good example. 
              The <a class="thought" href="entries/system_entry.html">system</a> is composed of many physically separate <a class="thought" href="entries/memory_entry.html">memory</a> chips, 
              but any single <a class="thought" href="entries/chip_entry.html">chip</a> can be removed without loosing any <a class="thought" href="entries/data_entry.html">data</a>. This 
              is because the <a class="thought" href="entries/data_entry.html">data</a> is not stored in any one place, but in a distributed 
              non-local representation across all of the units. In spite of the 
              "holographic" representation, the <a class="thought" href="entries/information_entry.html">information</a> storage 
              <a class="thought" href="entries/capacity_entry.html">capacity</a> of the <a class="thought" href="entries/system_entry.html">system</a> is no greater than it would be with a conventional 
              representation. In fact, it is slightly less. This is typical of 
              distributed representations. <br>
</p>
<p>Storage <a class="thought" href="entries/capacity_entry.html">capacity</a> offers one measure of the requirements of a <a class="thought" href="entries/human_entry.html">human</a>-like 
              emergent <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. Another measure is the required rate of <a class="thought" href="entries/computation_entry.html">computation</a>. 
              Here there is no agreed upon metric, and it is particularly difficult 
              to define a unit of measure that is completely independent of representation. 
              The measure suggested below is simple and the answer is certainly 
              <a class="thought" href="entries/import_entry.html">import</a>ant, if not sufficient. <br>
</p>
<p>Given an efficiently stored representation of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, 
              what is the rate of <a class="thought" href="entries/access_entry.html">access</a> to that storage (in bits per second) 
              required to achieve <a class="thought" href="entries/human_entry.html">human</a>-like performance? Here "efficiently 
              stored representation" means any representation requiring only 
              a multiplicative constant of storage over the <a class="thought" href="entries/number_entry.html">number</a> of bits of 
              <a class="thought" href="entries/information_entry.html">information</a>. This restriction eliminates the formal possibility 
              of a representation storing a pre-computed answer to every question. 
              Allowing storage within a multiplicative constant of the optimum 
              does restrict the range of possible representations, but it allows 
              most representations that we would regard as <a class="thought" href="entries/reason_entry.html">reason</a>able. In particular, 
              it allows both distributed and local representations. <br>
</p>
<p>The question of the <a class="thought" href="entries/bandwidth_entry.html">bandwidth</a> required for <a class="thought" href="entries/human_entry.html">human</a>-like performance 
              is <a class="thought" href="entries/access_entry.html">access</a>ible by <a class="thought" href="entries/experiment_entry.html">experiment</a>, along similar approaches as those outlined 
              for the question of storage <a class="thought" href="entries/capacity_entry.html">capacity</a>. If the "cycle time" 
              of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/memory_entry.html">memory</a> is limited by the firing <a class="thought" href="entries/time_entry.html">time</a> of a <a class="thought" href="entries/neuron_entry.html">neuron</a>, then 
              the ratio of this answer to the total <a class="thought" href="entries/number_entry.html">number</a> of bits tells the fraction 
              of the <a class="thought" href="entries/memory_entry.html">memory</a> that is <a class="thought" href="entries/access_entry.html">access</a>ed simultaneously. This gives an indication 
              of the parallel or serial <a class="thought" href="entries/nature_entry.html">nature</a> of the <a class="thought" href="entries/computation_entry.html">computation</a>. Informed opinions 
              differ greatly in this <a class="thought" href="entries/matter_entry.html">matter</a>. The bulk of the quantitative evidence 
              favors the serial approach. <a class="thought" href="entries/memory_entry.html">Memory</a> retrieval times for items in 
              lists, for example, depend on the position and the <a class="thought" href="entries/number_entry.html">number</a> of items 
              in the list. Except for sensory processing, most successful artificial 
              <a class="thought" href="entries/intelligence_entry.html">intelligence</a> <a class="thought" href="entries/program_entry.html">program</a>s have been based on serial models of <a class="thought" href="entries/computation_entry.html">computation</a>, 
              although this may be a distortion caused by the availability of 
              serial <a class="thought" href="entries/machine_entry.html">machine</a>s. <br>
</p>
<p>My own guess is that the reaction <a class="thought" href="entries/time_entry.html">time</a> <a class="thought" href="entries/experiment_entry.html">experiment</a>s are misleading 
              and that <a class="thought" href="entries/human_entry.html">human</a>-level performance will require <a class="thought" href="entries/access_entry.html">access</a>ing of large 
              fractions of the <a class="thought" href="entries/knowledge_entry.html">knowledge</a> several times per second. Given a representation 
              of acquired <a class="thought" href="entries/intelligence_entry.html">intelligence</a> with a realistic representation efficiency 
              of 10%, the 10 to the 9th bits of <a class="thought" href="entries/memory_entry.html">memory</a> mentioned above would require 
              a <a class="thought" href="entries/memory_entry.html">memory</a> <a class="thought" href="entries/bandwidth_entry.html">bandwidth</a> about 10 to the 11th bits per second. This <a class="thought" href="entries/bandwidth_entry.html">bandwidth</a> 
              seems physiologically plausible since it corresponds to about a 
              <a class="thought" href="entries/bit_entry.html">bit</a> per second per <a class="thought" href="entries/neuron_entry.html">neuron</a> in the <a class="thought" href="entries/cerebral_cortex_entry.html">cerebral cortex</a>. <br>
</p>
<p>By way of comparison, the <a class="thought" href="entries/memory_entry.html">memory</a> <a class="thought" href="entries/bandwidth_entry.html">bandwidth</a> of a conventional <a class="thought" href="entries/electronic_entry.html">electronic</a>
<a class="thought" href="entries/computer_entry.html">computer</a> is in the range of 10 to the 6th to 10 to the 8th bits 
              per second. This is less than 0.1% of the imagined requirement. 
              For parallel <a class="thought" href="entries/computer_entry.html">computer</a>s the <a class="thought" href="entries/bandwidth_entry.html">bandwidth</a> is considerably higher. For 
              example, a 65,536 processor <a class="thought" href="entries/connection_machine_entry.html">Connection Machine</a> can <a class="thought" href="entries/access_entry.html">access</a> its <a class="thought" href="entries/memory_entry.html">memory</a> 
              at approximately 10 to the 11th bits per second. It is not entirely 
              coincidence that this fits well with the estimate above. <br>
</p>
<p>Another <a class="thought" href="entries/import_entry.html">import</a>ant question is: What sensory-motor functions are 
              necessary to sustain <a class="thought" href="entries/symbol_entry.html">symbol</a>ic <a class="thought" href="entries/intelligence_entry.html">intelligence</a>? An ape is a complex 
              sensory-motor <a class="thought" href="entries/machine_entry.html">machine</a>, and it is possible that much of this <a class="thought" href="entries/complexity_entry.html">complexity</a> 
              is necessary to sustain <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. Large portions of the <a class="thought" href="entries/brain_entry.html">brain</a> 
              seem to be devoted to visual, auditory, and motor processing, and 
              it is unknown how much of this <a class="thought" href="entries/machine_entry.html">machine</a>ry is needed for <a class="thought" href="entries/thought_entry.html">thought</a>. 
              A person who is blind and deaf or totally paralyzed can undoubtedly 
              be intelligent, but this does not prove that the portion of the 
              <a class="thought" href="entries/brain_entry.html">brain</a> devoted to these functions is unnecessary for <a class="thought" href="entries/thought_entry.html">thought</a>. It 
              may be, for example, that a blind person takes advantage of the 
              visual processing apparatus of the <a class="thought" href="entries/brain_entry.html">brain</a> for spatial <a class="thought" href="entries/reason_entry.html">reason</a>ing. 
              <br>
</p>
<p>As we begin to understand more of the functional <a class="thought" href="entries/architecture_entry.html">architecture</a> of 
              the <a class="thought" href="entries/brain_entry.html">brain</a>, it should be possible to identify certain functions as 
              being unnecessary for <a class="thought" href="entries/thought_entry.html">thought</a> by studying patients whose cognitive 
              abilities are unaffected by locally confined damage to the <a class="thought" href="entries/brain_entry.html">brain</a>. 
              For example, binocular stereo fusion is known to take place in a 
              specific area of the cortex near the back of the head. Patients 
              with damage to this area of the cortex have visual handicaps, but 
              show no obvious impairment in their ability to think. This suggests 
              that stereo fusion is not necessary for <a class="thought" href="entries/thought_entry.html">thought</a>. This is a simple 
              example, and the conclusion is not surprising, but it should be 
              possible by such <a class="thought" href="entries/experiment_entry.html">experiment</a>s to establish that many sensory-motor 
              functions are unnecessary. One can imagine, metaphorically, whittling 
              away at the <a class="thought" href="entries/brain_entry.html">brain</a> until it is reduced to its essential core. Of 
              course it is not quite this simple. Accidental damage rarely incapacitates 
              completely and exclusively a single area of the <a class="thought" href="entries/brain_entry.html">brain</a>. Also, it 
              may be difficult to eliminate one function at a <a class="thought" href="entries/time_entry.html">time</a> since one mental 
              <a class="thought" href="entries/capacity_entry.html">capacity</a> may compensate for the lack of another. <br>
</p>
<p>It may be more productive to assume that all sensory-motor apparatus 
              is unnecessary until proven useful for <a class="thought" href="entries/thought_entry.html">thought</a>, but this is contrary 
              to the usual point of view. Our current understanding of the philogenic 
              development of the nervous <a class="thought" href="entries/system_entry.html">system</a> suggests a point of view in which 
              <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is an elaborate refinement of the connection between 
              input and output. This is reinforced by the <a class="thought" href="entries/experiment_entry.html">experiment</a>al convenience 
              of studying simple nervous <a class="thought" href="entries/system_entry.html">system</a>s, or studying complicated nervous 
              <a class="thought" href="entries/system_entry.html">system</a>s by concentrating on those portions most directly related 
              to input and output. By necessity, most everything we know about 
              the function of the nervous <a class="thought" href="entries/system_entry.html">system</a> comes from <a class="thought" href="entries/experiment_entry.html">experiment</a>s on those 
              portions that are closely related to sensory inputs or motor outputs. 
              It would not be surprising if we have overestimated the <a class="thought" href="entries/import_entry.html">import</a>ance 
              of these functions to intelligent <a class="thought" href="entries/thought_entry.html">thought</a>. <br>
</p>
<p>Sensory-motor functions are clearly <a class="thought" href="entries/import_entry.html">import</a>ant for the application 
              of <a class="thought" href="entries/intelligence_entry.html">intelligence</a> and for its <a class="thought" href="entries/evolution_entry.html">evolution</a>, but these are separate issues 
              from the question above. <a class="thought" href="entries/intelligence_entry.html">Intelligence</a> would not be of much use without 
              an elaborate <a class="thought" href="entries/system_entry.html">system</a> of sensory apparatus to measure the environment 
              and an elaborate <a class="thought" href="entries/system_entry.html">system</a> motor apparatus to change it, nor would 
              it have been likely to have evolved. But the apparatus necessary 
              to exercise and evolve <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is probably very much more than 
              the apparatus necessary to sustain it. One can believe in the necessity 
              of the opposable thumb for the development of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, without 
              doubting a <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/capacity_entry.html">capacity</a> for thumbless <a class="thought" href="entries/thought_entry.html">thought</a>. It is quite possible 
              that even the meager sensor-motor capabilities that we currently 
              know how to provide would be sufficient for the <a class="thought" href="entries/operation_entry.html">operation</a> of emergent 
              <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. <br>
</p>
<p>These questions of <a class="thought" href="entries/capacity_entry.html">capacity</a> and scope are necessary in defining 
              the magnitude of the task of constructing an emergent <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, 
              but the key question is one of understanding. While it is possible 
              that we will be able to recreate the emergent <a class="thought" href="entries/substrate_entry.html">substrate</a> of <a class="thought" href="entries/intelligence_entry.html">intelligence</a> 
              without fully understanding the details of how it works, it seems 
              likely that we would at least need to understand some of its principles. 
              There are at least three paths by which such understanding could 
              be achieved. One is to study the properties of specific emergent 
              <a class="thought" href="entries/system_entry.html">system</a>s, to build a theory of their capabilities and limitations. 
              This kind of <a class="thought" href="entries/experiment_entry.html">experiment</a>al study is currently being conducted on 
              several classes of promising <a class="thought" href="entries/system_entry.html">system</a>s including <a class="thought" href="entries/neural_network_entry.html">neural network</a>s, 
              spin glasses, <a class="thought" href="entries/cellular_automata_entry.html">cellular automata</a>, classifier <a class="thought" href="entries/system_entry.html">system</a>s and adaptive 
              automata. Another possible path to understanding is the study of 
              <a class="thought" href="entries/biological_entry.html">biological</a> <a class="thought" href="entries/system_entry.html">system</a>s, which are our only real examples of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, 
              and our only example of an emergent <a class="thought" href="entries/system_entry.html">system</a> which has produced <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. 
              The disciplines that have provided the most useful <a class="thought" href="entries/information_entry.html">information</a> of 
              this type so far have been neurophysiology, cognitive <a class="thought" href="entries/psychology_entry.html">psychology</a>, 
              and <a class="thought" href="entries/evolution_entry.html">evolution</a>ary <a class="thought" href="entries/biology_entry.html">biology</a>. A third path would be a theoretical understanding 
              of the requirements of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, or of the phenomena of emergence. 
              Examples of relevant disciplines of theories of <a class="thought" href="entries/logic_entry.html">logic</a> and computability, 
              <a class="thought" href="entries/linguistics_entry.html">linguistics</a>, and dynamical <a class="thought" href="entries/system_entry.html">system</a>s theory. Anyone who looks to emergent 
              <a class="thought" href="entries/system_entry.html">system</a>s as a way of defending <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/thought_entry.html">thought</a> from the scrutiny of 
              <a class="thought" href="entries/science_entry.html">science</a> is likely to be disappointed. <br>
</p>
<p>One cannot conclude, however, that a <a class="thought" href="entries/reduction_entry.html">reduction</a>ist understanding 
              is necessary for the creation of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. Even a little understanding 
              could go a long way toward the construction of an emergent <a class="thought" href="entries/system_entry.html">system</a>. 
              A good example of this is how <a class="thought" href="entries/cellular_automata_entry.html">cellular automata</a> have been used to 
              simulate the emergent behavior of fluids. <br>
</p>
<p>The whirlpools that form as a fluid flows past a barrier are not 
              well understood analytically, yet they are of great practical <a class="thought" href="entries/import_entry.html">import</a>ance 
              in the design of boats and airplanes. Equations that describe the 
              flow of a fluid have been known for almost a century, but except 
              for a few simple cases they cannot be solved. In practice the flow 
              is generally analyzed by simulation. The most common <a class="thought" href="entries/method_entry.html">method</a> of simulation 
              is the numerical solution of the continuous equations. <br>
</p>
<p>On a highly parallel <a class="thought" href="entries/computer_entry.html">computer</a> it is possible to simulate fluids 
              with even less understanding of the <a class="thought" href="entries/system_entry.html">system</a>, by simulating billions 
              of colliding <a class="thought" href="entries/particle_entry.html">particle</a>s that reproduce the emergent phenomena such 
              as vortices. Calculating the detailed molecular interactions for 
              so many <a class="thought" href="entries/particle_entry.html">particle</a>s would be extremely difficult, but a few simple 
              aspects of the <a class="thought" href="entries/system_entry.html">system</a> such as conservations of <a class="thought" href="entries/energy_entry.html">energy</a> and <a class="thought" href="entries/particle_entry.html">particle</a>
<a class="thought" href="entries/number_entry.html">number</a> are sufficient to reproduce the large-scale behavior. A <a class="thought" href="entries/system_entry.html">system</a> 
              of simplified <a class="thought" href="entries/particle_entry.html">particle</a>s that obey these two laws, but are otherwise 
              unrealistic, can reproduce the same emergent phenomena as <a class="thought" href="entries/reality_entry.html">reality</a>. 
              For example, it is possible to use <a class="thought" href="entries/particle_entry.html">particle</a>s of unit mass that move 
              only at unit speed along a hexagonal lattice, colliding according 
              to the rules of billiard balls. <a class="thought" href="entries/experiment_entry.html">Experiment</a>s show that this model 
              produces laminar flow, vortex streams, and even turbulence that 
              is indistinguishable from the behavior of real fluids. Although 
              the detailed rules of interaction are very different than the interactions 
              of real <a class="thought" href="entries/molecule_entry.html">molecule</a>s, the emergent phenomena are the same. The emergent 
              phenomena can be created without understanding the details of the 
              forces between the <a class="thought" href="entries/molecule_entry.html">molecule</a>s or the equations that describe the 
              flow of the fluid. <br>
</p>
<p>The recreation of intricate <a class="thought" href="entries/pattern_entry.html">pattern</a>s of ebbs and flows within a 
              fluid offers an example of how it is possible to produce a <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a> 
              without fully understanding it. But the model was constructed by 
              physicists who knew a lot about fluids. That <a class="thought" href="entries/knowledge_entry.html">knowledge</a> helped to 
              determine which features of the physical <a class="thought" href="entries/system_entry.html">system</a> were <a class="thought" href="entries/import_entry.html">import</a>ant to 
              <a class="thought" href="entries/implement_entry.html">implement</a>, and which were not. <br>
</p>
<p><a class="thought" href="entries/physics_entry.html">Physics</a> is an unusually exact <a class="thought" href="entries/science_entry.html">science</a>. Perhaps a better example 
              of an emergent <a class="thought" href="entries/system_entry.html">system</a> which we can simulate with only a limited 
              understanding is <a class="thought" href="entries/evolution_entry.html">evolution</a>ary <a class="thought" href="entries/biology_entry.html">biology</a>. We understand, in a weak 
              <a class="thought" href="entries/sense_entry.html">sense</a>, how creatures with Mendelian <a class="thought" href="entries/pattern_entry.html">pattern</a>s of inheritance, and 
              different propensities for survival can evolve toward better fitness 
              in their environments. In certain simple situations we can even 
              write down equations that describe how quickly this adaptation will 
              take place. But there are many gaps in our understanding of the 
              processes of <a class="thought" href="entries/evolution_entry.html">evolution</a>. We can explain in terms of natural selection 
              why flying <a class="thought" href="entries/animal_entry.html">animal</a>s have <a class="thought" href="entries/light_entry.html">light</a> bones, but we cannot explain why certain 
              <a class="thought" href="entries/animal_entry.html">animal</a>s have evolved flight and others have not. We have some qualitative 
              understanding of the forces that cause <a class="thought" href="entries/evolution_entry.html">evolution</a>ary change, but 
              except in the simplest cases, we cannot explain the rate or even 
              the direction of that change. <br>
</p>
<p>In spite of these limitations, our understanding is sufficient 
              to write <a class="thought" href="entries/program_entry.html">program</a>s of simulated <a class="thought" href="entries/evolution_entry.html">evolution</a> that show interesting emergent 
              behaviors. For example, I have recently been using an <a class="thought" href="entries/evolution_entry.html">evolution</a>ary 
              simulation to evolve <a class="thought" href="entries/program_entry.html">program</a>s to sort <a class="thought" href="entries/number_entry.html">number</a>s. In this <a class="thought" href="entries/system_entry.html">system</a>, the 
              genetic material of each simulated <a class="thought" href="entries/individual_entry.html">individual</a> is interpreted as 
              a <a class="thought" href="entries/program_entry.html">program</a> specifying a <a class="thought" href="entries/pattern_entry.html">pattern</a> of comparisons and exchanges. The 
              probability of an <a class="thought" href="entries/individual_entry.html">individual</a> survival in the <a class="thought" href="entries/system_entry.html">system</a> is dependent 
              on the efficiency and accuracy of this <a class="thought" href="entries/program_entry.html">program</a> in sorting <a class="thought" href="entries/number_entry.html">number</a>s. 
              Surviving <a class="thought" href="entries/individual_entry.html">individual</a>s produce offspring by sexual combination of 
              their genetic material with occasional random mutation. After tens 
              of thousands of generations, a population of hundreds of thousands 
              of such <a class="thought" href="entries/individual_entry.html">individual</a>s will evolve very efficient <a class="thought" href="entries/program_entry.html">program</a>s for sorting. 
              Although I wrote the simulation producing these sorting <a class="thought" href="entries/program_entry.html">program</a>s, 
              I do not understand in detail how they were produced or how they 
              work. If the simulation had not produced working <a class="thought" href="entries/program_entry.html">program</a>s, I would 
              have had very little idea about how to fix it. <br>
</p>
<p>The fluid flow and simulated <a class="thought" href="entries/evolution_entry.html">evolution</a> examples suggest that it 
              is possible to make a great deal of use of a small amount of understanding. 
              The emergent behaviors exhibited by these <a class="thought" href="entries/system_entry.html">system</a>s are a consequence 
              of the simple underlying rules, which are defined by the <a class="thought" href="entries/program_entry.html">program</a>. 
              Although the <a class="thought" href="entries/system_entry.html">system</a>s succeed in producing the desired results, their 
              detailed behaviors are beyond our ability to analyze and predict. 
              One can imagine if a similar process produced a <a class="thought" href="entries/system_entry.html">system</a> of emergent 
              <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, we would have a similar lack of understanding about 
              how it worked. <br>
</p>
<p>My own guess is that such an emergent <a class="thought" href="entries/system_entry.html">system</a> would not be an intelligent 
              <a class="thought" href="entries/system_entry.html">system</a> itself, but rather the metabolic <a class="thought" href="entries/substrate_entry.html">substrate</a> on which <a class="thought" href="entries/intelligence_entry.html">intelligence</a> 
              might grow. In terms of the apes and the songs, the emergent portion 
              of the <a class="thought" href="entries/system_entry.html">system</a> would play the role of the ape, or at least that part 
              of the ape that hosts the songs. This artificial <a class="thought" href="entries/mind_entry.html">mind</a> would need 
              to be inoculated with <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/knowledge_entry.html">knowledge</a>. I imagine this process to 
              be not so different from teaching a child. This would be a tricky 
              and uncertain procedure since, like a child, this emergent <a class="thought" href="entries/mind_entry.html">mind</a> 
              would presumably be susceptible to bad ideas as well as good. The 
              result would be not so much an <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>, but rather 
              a <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a> sustained within an artificial <a class="thought" href="entries/mind_entry.html">mind</a>. <br>
</p>
<p>Of course, I understand that this is just a <a class="thought" href="entries/dream_entry.html">dream</a>. And I will admit 
              that I am more propelled by hope than by the probability of success. 
              But if, within this artificial <a class="thought" href="entries/mind_entry.html">mind</a>, the seed of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/knowledge_entry.html">knowledge</a> 
              begins to sustain itself and grow of its own accord, then for the 
              first <a class="thought" href="entries/time_entry.html">time</a> <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/thought_entry.html">thought</a> will live free of bones and flesh, giving 
              this child of <a class="thought" href="entries/mind_entry.html">mind</a> an earthly <a class="thought" href="entries/immortality_entry.html">immortality</a> denied to us. <br>
</p>
<p>Attempts to create emergent <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, at least those that are 
              far enough in the past for us to judge, have been disappointing. 
              Many <a class="thought" href="entries/computation_entry.html">computation</a>al <a class="thought" href="entries/system_entry.html">system</a>s, such as homeostats, <a class="thought" href="entries/perceptron_entry.html">perceptron</a>s, and 
              <a class="thought" href="entries/cellular_automata_entry.html">cellular automata</a> exhibit clear examples of emergent behavior, but 
              that behavior falls far short of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. A <a class="thought" href="entries/perceptron_entry.html">perceptron</a>, for 
              example, is a collection of artificial <a class="thought" href="entries/neuron_entry.html">neuron</a>s that can recognize 
              simple <a class="thought" href="entries/pattern_entry.html">pattern</a>s. Considerable <a class="thought" href="entries/optimism_entry.html">optimism</a> was generated in the 1960's 
              when it was proved that anything a <a class="thought" href="entries/perceptron_entry.html">perceptron</a> could recognize, it 
              could learn to recognize from examples. This was followed by considerable 
              disappointment when it was realized that the <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of things that 
              could be recognized at all was very limited. What appeared to be 
              complicated behavior of the <a class="thought" href="entries/system_entry.html">system</a> turned out in the final analysis 
              to be surprisingly simple. <br>
</p>
<p>In spite of such disappointments, I believe that the notion of 
              emergence contains an <a class="thought" href="entries/element_entry.html">element</a> of truth, an <a class="thought" href="entries/element_entry.html">element</a> that can be isolated 
              and put to use. <br>
</p>
<p>A helpful <a class="thought" href="entries/analogy_entry.html">analogy</a> is the brewing of beer. The brewmaster creates 
              this product by making a soup of barley and hops, and infecting 
              it with yeast. Chemically speaking most of the real work is done 
              by the yeast, which converts the starch to alcohol. The brewmaster 
              is responsible for creating and maintaining the conditions under 
              which that conversion can take place. The brewmaster does not need 
              to understand exactly how the yeast does its work, but does need 
              to understand the properties of the environment in which the yeast 
              will thrive. By providing the right combination of ingredients at 
              the right temperature in the right container, the brewmaster is 
              able to create the necessary conditions for the production of beer. 
              <br>
</p>
<p>Something <a class="thought" href="entries/analog_entry.html">analog</a>ous to this process may be possible in the creation 
              of an <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>. It is unlikely that <a class="thought" href="entries/intelligence_entry.html">intelligence</a> 
              would spontaneously appear in a random <a class="thought" href="entries/network_entry.html">network</a> of <a class="thought" href="entries/neuron_entry.html">neuron</a>s, just 
              as it is unlikely that <a class="thought" href="entries/life_entry.html">life</a> would spontaneously appear in barley 
              soup. But just as carefully mixed soup can be inoculated with yeast, 
              it may be that a carefully constructed <a class="thought" href="entries/network_entry.html">network</a> of artificial <a class="thought" href="entries/neuron_entry.html">neuron</a>s 
              can be inoculated with <a class="thought" href="entries/thought_entry.html">thought</a>. <br>
</p>
<p>The approach depends on the possibility of separating <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a> 
              into two parts, corresponding to the soup and the yeast. Depending 
              on one's point of view, these two parts can be viewed as <a class="thought" href="entries/hardware_entry.html">hardware</a> 
              and <a class="thought" href="entries/software_entry.html">software</a>, intellect and <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, <a class="thought" href="entries/nature_entry.html">nature</a> and nurture, or <a class="thought" href="entries/program_entry.html">program</a> 
              and <a class="thought" href="entries/data_entry.html">data</a>. Each point of view carries with it a particular <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of 
              <a class="thought" href="entries/intuition_entry.html">intuition</a>s about the <a class="thought" href="entries/nature_entry.html">nature</a> of the split and the relative <a class="thought" href="entries/complexity_entry.html">complexity</a> 
              of the parts. <br>
</p>
<p>One way that biologists determine if a living <a class="thought" href="entries/entity_entry.html">entity</a> is a symbiont 
              is to see if the <a class="thought" href="entries/individual_entry.html">individual</a> <a class="thought" href="entries/component_entry.html">component</a>s can be kept alive separately. 
              For example, biologists have tried (unsuccessfully) to prove the 
              oil-drop theory by sustaining metabolizing oil drops in an artificial 
              nutrient broth. Such an <a class="thought" href="entries/experiment_entry.html">experiment</a> for <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a> would 
              have two parts. One would be a test of the <a class="thought" href="entries/human_entry.html">human</a> ape's ability to 
              live without the ideas of <a class="thought" href="entries/human_entry.html">human</a> culture. This <a class="thought" href="entries/experiment_entry.html">experiment</a> is occasionally 
              conducted in an uncontrolled form when feral children are reared 
              by <a class="thought" href="entries/animal_entry.html">animal</a>s. The two-part theory would predict that such children, 
              before <a class="thought" href="entries/human_entry.html">human</a> contact, would not be significantly brighter than nonhuman 
              primates. The <a class="thought" href="entries/complementary_entry.html">complementary</a> <a class="thought" href="entries/experiment_entry.html">experiment</a>, sustaining <a class="thought" href="entries/human_entry.html">human</a> ideas and 
              culture in an artificial broth, is the one in which we are more 
              specifically interested. If this were successful we would have a 
              <a class="thought" href="entries/thinking_entry.html">thinking</a> <a class="thought" href="entries/machine_entry.html">machine</a>, although perhaps it would not be accurate to call 
              it an <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>. It would be natural <a class="thought" href="entries/intelligence_entry.html">intelligence</a> 
              sustained within an artificial <a class="thought" href="entries/mind_entry.html">mind</a>. <br>
</p>
<p>To pursue the consequences of this point of view, we will assume 
              that <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a> can be cleanly divided into two portions 
              that we will refer to as acquired and inherited <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. These 
              correspond to the songs and to the apes, respectively, or in the 
              fermentation metaphor, the yeast and the barley soup. We will consider 
              only those features of inherited <a class="thought" href="entries/intelligence_entry.html">intelligence</a> that are necessary 
              to support acquired <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, only those features of acquired 
              <a class="thought" href="entries/intelligence_entry.html">intelligence</a> that impose requirements on inherited <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. 
              We will study the <a class="thought" href="entries/interface_entry.html">interface</a> between the two. <br>
</p>
<p>Even accepting this definition of the problem, it is not obvious 
              that the <a class="thought" href="entries/interface_entry.html">interface</a> is easy to understand or recreate. This leads 
              to a specific question about the scope of the <a class="thought" href="entries/interface_entry.html">interface</a> that can 
              presumably be answered by <a class="thought" href="entries/experiment_entry.html">experiment</a>. <br>
</p>
<p>The functional scope of the <a class="thought" href="entries/interface_entry.html">interface</a> between acquired and inherited 
              <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is not the only property that can be investigated. 
              To build a home for an <a class="thought" href="entries/animal_entry.html">animal</a>, the first thing we would need to 
              know is the <a class="thought" href="entries/animal_entry.html">animal</a>'s size. This is also one of the first things 
              we need to know in building an artificial home for acquired <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. 
              This leads to question <a class="thought" href="entries/number_entry.html">number</a> two: <br>
</p>
<p>The guesses to answers that I have given are imprecise, but the 
              questions are not. In principle they can be answered by <a class="thought" href="entries/experiment_entry.html">experiment</a>. 
              The final question I will pose is more problematic. What I would 
              like to ask is "What are the organizing principles of inherited 
              <a class="thought" href="entries/intelligence_entry.html">intelligence</a>?" but this question is vague and it is not clear 
              what would be an acceptable answer. I shall substitute a more specific 
              question that hopefully captures the same intent: <br>
</p>
<p>"Question IV: What quantities remain constant during the <a class="thought" href="entries/computation_entry.html">computation</a> 
              of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>; or, equivalently, what functions of state are minimized?" 
              <br>
</p>
<p>This question assumes that inheritable <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is some form 
              of homeostatic process and asks what quantity is held static. It 
              is the most difficult of the four questions, but historically it 
              has been an <a class="thought" href="entries/import_entry.html">import</a>ant question to ask in areas when there was not 
              yet a <a class="thought" href="entries/science_entry.html">science</a> to guide <a class="thought" href="entries/progress_entry.html">progress</a>. <br>
</p>
<p>The study of <a class="thought" href="entries/chemistry_entry.html">chemistry</a> is one example. In chemical reactions between 
              substances it is obvious that a great <a class="thought" href="entries/number_entry.html">number</a> of things change and 
              not so obvious what stays the same. It turns out that if the <a class="thought" href="entries/experiment_entry.html">experiment</a> 
              is done carefully, the weight of the reactants will always equal 
              the weight of the product. The total weight remains the same. This 
              is an <a class="thought" href="entries/import_entry.html">import</a>ant organizing principle in <a class="thought" href="entries/chemistry_entry.html">chemistry</a> and understanding 
              it was a stepping stone to the understanding of an even more <a class="thought" href="entries/import_entry.html">import</a>ant 
              principle: the conservation of the weights of the <a class="thought" href="entries/individual_entry.html">individual</a> <a class="thought" href="entries/element_entry.html">element</a>s. 
              The technical difficulty of defining and creating a truly closed 
              <a class="thought" href="entries/experiment_entry.html">experiment</a>, in particular eliminating the inflow and outflow of 
              gases, explains why chemists did not fully appreciate these principles 
              until the middle of the 19th century. <br>
</p>
<p>Another very different example of a <a class="thought" href="entries/system_entry.html">system</a> that can be understood 
              in terms of what is held constant is the <a class="thought" href="entries/system_entry.html">system</a> of formal <a class="thought" href="entries/logic_entry.html">logic</a>. 
              This is a <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of rules under which sentences may be changed without 
              changing their truth. A similar example, which has also been <a class="thought" href="entries/import_entry.html">import</a>ant 
              to <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>, is the lambda <a class="thought" href="entries/calculus_entry.html">calculus</a>, which is the 
              basis of the <a class="thought" href="entries/language_entry.html">language</a> <a class="thought" href="entries/lisp_entry.html">Lisp</a>. This is a <a class="thought" href="entries/system_entry.html">system</a> of transforming <a class="thought" href="entries/expression_entry.html">expression</a>s 
              in such a way that their "values" do not change, where 
              the values are those forms of the <a class="thought" href="entries/expression_entry.html">expression</a> which are not changed 
              by the transformations. (This sounds circular because it is. A more 
              detailed explanation would show it to be more so.) These formal 
              <a class="thought" href="entries/system_entry.html">system</a>s are <a class="thought" href="entries/concept_entry.html">concept</a>ually organized around that which is held constant. 
              <br>
</p>
<p>In <a class="thought" href="entries/physics_entry.html">physics</a> there are many examples of how conservations have been 
              used successfully to organize our <a class="thought" href="entries/concept_entry.html">concept</a>ion of <a class="thought" href="entries/reality_entry.html">reality</a>, but while 
              conservations of <a class="thought" href="entries/energy_entry.html">energy</a>, momentum, mass, and charge are certainly 
              <a class="thought" href="entries/import_entry.html">import</a>ant, I do not wish to make too much of them in this <a class="thought" href="entries/context_entry.html">context</a>. 
              In this <a class="thought" href="entries/sense_entry.html">sense</a> the principles of conservation will more likely resemble 
              those of <a class="thought" href="entries/biology_entry.html">biology</a> than <a class="thought" href="entries/physics_entry.html">physics</a>. <br>
</p>
<p>One of the most useful conservation principles in <a class="thought" href="entries/biology_entry.html">biology</a> appears 
              in the notion of a gene. This is the unit of character determination 
              that is conserved during reproduction. In sexual reproduction this 
              can get complicated since an <a class="thought" href="entries/individual_entry.html">individual</a> receives a <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of genes 
              from each of two parents. A gene that affects a given trait may 
              not be expressed if it is masked by another, and there is not a 
              simple correspondence between genes and measurable traits. The notion 
              that atomic units of inheritance are always present, even when they 
              are not expressed, was hard to accept and it was not widely believed 
              almost a century after Mendel's initial <a class="thought" href="entries/experiment_entry.html">experiment</a>s. In fact the 
              conservation is not perfect, but it is still one of the most <a class="thought" href="entries/import_entry.html">import</a>ant 
              organizing principles in the study of living <a class="thought" href="entries/organism_entry.html">organism</a>s. <br>
</p>
<p>In <a class="thought" href="entries/biology_entry.html">biology</a>, the rules of conservation are often expressed as minimum 
              principles. The two forms are equivalent. For <a class="thought" href="entries/instance_entry.html">instance</a>, the minimum 
              principle corresponding to the physical conservation of momentum 
              is the principle of least <a class="thought" href="entries/action_entry.html">action</a>. A <a class="thought" href="entries/biological_entry.html">biological</a> example is the principle 
              of optimal adaptation, which states that <a class="thought" href="entries/species_entry.html">species</a> will evolve toward 
              fitness to their environments. The distance to the ideal is minimized. 
              A conservation principle associated with this is the Fischer Theorem 
              of Natural Selection, which states that the rate of change in fitness 
              is equal to the genetic variance. In cases where this minimum principle 
              can be applied, it allows biologists to quantitatively predict the 
              values of various <a class="thought" href="entries/biological_entry.html">biological</a> <a class="thought" href="entries/parameter_entry.html">parameter</a>s. <br>
</p>
<p>For example, sickle-<a class="thought" href="entries/cell_entry.html">cell</a> anemia is a congenital <a class="thought" href="entries/disease_entry.html">disease</a> controlled 
              by a recessive gene. <a class="thought" href="entries/individual_entry.html">Individual</a>s who inherit the gene from both 
              parents are likely to die without reproducing, but <a class="thought" href="entries/individual_entry.html">individual</a>s who 
              inherit the gene from a single parent are resistant to malaria. 
              In certain regions of West Africa 40% of the population carries 
              the gene. From this fact and the principle of optimal fitness, it 
              is possible to predict that the survival advantage of resistance 
              to malaria is about 25% in these regions. This estimate fits well 
              with measured <a class="thought" href="entries/data_entry.html">data</a>. Similar <a class="thought" href="entries/method_entry.html">method</a>s have been used to estimate the 
              <a class="thought" href="entries/number_entry.html">number</a> of eggs laid by a bird, the shape of sponges, and the gait 
              of <a class="thought" href="entries/animal_entry.html">animal</a>s at different speeds. But these examples of applying a 
              minimum principle are not so crisp as those of <a class="thought" href="entries/physics_entry.html">physics</a>. Why, for 
              example, do we not evolve a non-lethal gene that protects against 
              malaria? The answer is complicated, and the principle of fitness 
              offers no help. It is useful in aiding our understanding, but it 
              does not explain all. This is probably the kind of answer to Question 
              IV for which we will have to settle. <br>
</p>
<p>Even in <a class="thought" href="entries/physics_entry.html">physics</a>, <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of the exact law does not really explain 
              all behaviors. The snowflakes and whirlpools of water are examples. 
              The forces that govern the interaction of water <a class="thought" href="entries/molecule_entry.html">molecule</a>s are understood 
              in some detail, but there is no analytical understanding of the 
              connection between these forces and their emergent behaviors of 
              water. <br>
</p>
<p>On the other hand, our goal is not necessarily to understand, but 
              to recreate. In both of the examples mentioned, conservation principles 
              give us sufficient understanding to recreate the phenomena. <br>
</p>
<p>In <a class="thought" href="entries/order_entry.html">order</a> to achieve this kind of understanding for <a class="thought" href="entries/intelligence_entry.html">intelligence</a> 
              it will be necessary to ask and answer the kinds of questions that 
              are mentioned above. <br>
</p>
<p>I do not know the answer to Question IV. It is possible that it 
              will be very complicated and the <a class="thought" href="entries/interface_entry.html">interface</a> between acquired and 
              inherited <a class="thought" href="entries/intelligence_entry.html">intelligence</a> will be difficult to reproduce. But it is 
              also possible that it will be simple. One can imagine this would 
              be the artificial <a class="thought" href="entries/substrate_entry.html">substrate</a> for <a class="thought" href="entries/thought_entry.html">thought</a>. <br>
</p>
<p>Once this is achieved it will still remain to inoculate the artificial 
              <a class="thought" href="entries/mind_entry.html">mind</a> with the seed of <a class="thought" href="entries/knowledge_entry.html">knowledge</a>. I imagine this to be not so different 
              from the process of teaching a child. It will be a tricky and uncertain 
              process since, like a child, this <a class="thought" href="entries/mind_entry.html">mind</a> will presumably be susceptible 
              to bad ideas as well as good. The first steps will be the most delicate. 
              If we have prepared well, it will reach a point where it can sustain 
              itself and grow of its own accord. <br>
</p>
<p>For the first <a class="thought" href="entries/time_entry.html">time</a> <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/thought_entry.html">thought</a> will live free of bones and flesh, 
              giving this child of <a class="thought" href="entries/mind_entry.html">mind</a> an earthly <a class="thought" href="entries/immortality_entry.html">immortality</a> denied to us. <br>
</p>
<p><b>References</b> <br>
</p>
<p>Dyson, Freeman. "The Origins of Life", Cambridge University 
              Press, 1985. <br>
</p>
<p>Haldane, J. B. S. "The Causes of <a class="thought" href="entries/evolution_entry.html">Evolution</a>", Harper &amp; 
              Brothers, 1932. <br>
</p>
<p>Hillis, W. Daniel. "The <a class="thought" href="entries/connection_machine_entry.html">Connection Machine</a>", The MIT 
              Press, 1985. <br>
</p>
<p>Luria, A. R. "Mind of the Mnemonist", <a class="thought" href="entries/basic_entry.html">Basic</a> Books, 1968. 
              <br>
              Newell, Allen. "Human Problem Solving", Prentice Hall, 
              1972. <br>
</p>
<p>Wolfram, Stephen. "Theory of Applications of <a class="thought" href="entries/cellular_automata_entry.html">Cellular Automata</a>", 
              World Scientific, 1986. <br>
</p>
<p><i>"Intelligence as an Emergent Behavior or, The Songs of 
              Eden" reprinted by permission of</i> Daedalus, Journal of the 
              American Academy of Arts and <a class="thought" href="entries/science_entry.html">Science</a>s<i>, from the issue entitled, 
              "Artificial <a class="thought" href="entries/intelligence_entry.html">Intelligence</a>," Winter 1988, Vol. 117, No. 
              1.</i></p>
</td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D6574" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id6575"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Where's the article?<br><span class="mindxheader"><i>posted on 05/03/2002 7:45 AM by roBman@iOFtheSWARM.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6574%23id6575" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D6575" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>The top paragraph sounds interesting, but the rest of the page is just very rough notes promoting another one of Ray's debates!
<br>
<br>
Where's the real content, or are you sarcastically describing that debate as The Songs of Eden 8)
<br>
<br>
<br>
roBman</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7486"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where's the article?<br><span class="mindxheader"><i>posted on 06/15/2002 12:17 AM by <a href="http://web.archive.org/web/20071011120812/mailto:amara@kurzweilai.net">amara@kurzweilai.net</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6574%23id7486" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7486" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Sorry about that. Fixed. Guess we were "waiting for intelligence to spontaneously emerge" and post the right article.  :)</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id6584"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Intelligence as an Emergent Behavior or, The Songs of Eden<br><span class="mindxheader"><i>posted on 05/03/2002 8:15 PM by jhaggerty73@attbi.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6574%23id6584" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D6584" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Ray's presentation of our tech future 20 or 30 years from now sounds great but,in the 1960's didn't they predict flying cars and vacations in space by the late 90's? On the other hand, I work in a medical enviornment and the machines here are much more reliable than their human counterparts! (Scary but true) Here's hoping Ray's future is our future.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id6610"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Intelligence as an Emergent Behavior or, The Songs of Eden<br><span class="mindxheader"><i>posted on 05/05/2002 12:26 PM by tom@novalibra.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6574%23id6610" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D6610" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>We live in an age where machines are being developed to simulate natural reality. 
<br>
<br>
Electronic instruments have been developed to simulate natural sounds. Computer graphics have advanced to the point where visual simulations of reality are perfectly believable. 
<br>
<br>
In the early days of these technologies, the resolution was low and humans can easily percieve the difference between an artificial reality and a natural one. As technology becomes more advanced the resolution passes beyond a threshold where normal human observation cannot distinguish between the artificial and the natural.
<br>
<br>
Thought is the same. As artificial information storage and retrieval systems attain sufficient "resolution", standard human observation will assume the artificial "intelligence" is natural and the Turing test can be passed. 
<br>
<br>
The exact makeup of the technology to achieve this is however as irrelavant as the goal. While it was interesting to see a computer beat a chessmaster, it had no monumental impact on humanity, computer science, or even tournament chess. Machines are developed to do things humans cannot easily do themselves. We do not create machines in our image, we create them ideally suited to perform specific tasks or goals. 
<br>
<br>
The goals humanity sets, and therefore the design of the machines that help achieve them is where our efforts are to be directed.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id6670"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Intelligence as an Emergent Behavior or, The Songs of Eden<br><span class="mindxheader"><i>posted on 05/07/2002 8:41 AM by steve@hotmail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6574%23id6670" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D6670" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>When we compare biotechnology with conventional technology, we often think of biotechnology as being more modern and more advanced. That's literally putting the cart before the horse: in fact, a horse pulling a cart is a perfect example of applied biotechnology, as is milking of cow and growing a crop. An automobile is an imitation of a horse-drawn cart and therefore a later construct. In Victorian times the dangers of biotechnology were more palpable and olfactory than they are today. At that time, calculations were made and the statisticians of the Royal Office of Measurements or some such bureau were trying to figure out how soon the City of London would be buried under horse-shit, taking into account the rate of increase in the horse-drawn vehicles.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id20538"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Intelligence as an Emergent Behavior or, The Songs of Eden<br><span class="mindxheader"><i>posted on 10/03/2003 4:53 PM by <a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/profile.php?id=676">Silvertear</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6574%23id20538" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D20538" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>These are all adorable thoughts on intelligence.
<br>
<br>
But i would like to share one of my phylosophical thoughts on this matter: 
<br>
<br>
In my humble opinion we have already created billions of emergent systems in which symbolic systems reside. And i see no reason what so ever to not declare these entities as bearers of a certain capacity of intelligence. It is clear to me that intelligence is a relative matter depending on the entity judging it.
<br>
If you look upon an ordinary computer system as a living entity, and it would be capable to outline a concept of intelligence in its own world, it would definatly declare other computer systems to be intelligent. But confronted with a human, its judgement would probably be the human not to be intelligent at all. This indicates that in order to judge an entity to be intelligent, the judged entity will require to be very alike to the judging entity. Remark, as an example, that slightly different people, wether by handicap, disease or whatever reason, are easely thought of as less "intelligent".
<br>
Thus, this means that what we appear to be trying to understand in the first place is "human intelligence" rather than "intelligence" itself. For that, as indicated in this paper, we must indeed try to create an emergent system equally complex to a human entity, making it very alike to ourselves so we can judge it as being intelligent. 
<br>
<br>
This approach, in my opinion, if i may make a comparison, would be the same as trying to figure out complex mathematical systems without understanding basic calculation.
<br>
<br>
Therefor i suggest to start with the basics and try to figure out a clear definition of intelligence, independant of the entity being judged or the entity judging.
<br>
<br>
I'd like to continue on this subject, but it would extend the little thought i was going to share.
<br>
<br>
with kind regards,
<br>
Silvertear</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id20551"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Intelligence as an Emergent Behavior or, The Songs of Eden<br><span class="mindxheader"><i>posted on 10/04/2003 7:58 AM by <a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/profile.php?id=662">Tomaz_(Thomas)_Kristan</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6574%23id20551" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011120812/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D20551" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I wrote something like: "What do we already have." - a year or so ago. The main point was, that we don't have a glue yet, to combine every piece of intelligence we created as tools,  together. Your view is close to that, I guess.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011120812im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>