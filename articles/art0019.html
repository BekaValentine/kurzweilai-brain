<html>
<head><base href="https://kurzweilai-brain.gothdyke.mom/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<title></title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#006699" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#006699" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20010814212636im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20010814212636im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20010814212636im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20010814212636im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20010814212636im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20010814212636im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20010814212636/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20010814212636/http://www.kurzweilai.net/meme/memelist.html?m=5">Living Forever</a> &gt; 

<br>
Permanent link to this article: <a href="http://web.archive.org/web/20010814212636/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0019.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0019.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20010814212636/http://www.kurzweilai.net/articles/art0019.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20010814212636im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">Building New Brains ... The Hardware of Intelligence</span>
<br>
<span class="Subtitle">Excerpt from "The Age of Spiritual Machines"</span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td><td><span class="Authors"> <a class="Authors" href="https://web.archive.org/web/20010814212636/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0005.html" target="_top">    Raymond   Kurzweil </a><br>
</span></td>
</table>
<br>
<div class="TeaserText">In this excerpt from The <a class="thought" href="entries/age_of_spiritual_machines_entry.html">Age of Spiritual Machines</a> (chapter 6), <a class="thought" href="entries/kurzweil_entry.html">Raymond Kurzweil</a> describes some key technologies for achieving the capacity of the human brain and downloading your mind into a <a class="thought" href="entries/computer_entry.html">computer</a>.</div>
<br>
<br>
<blockquote>You can only make a certain amount with your hands, but with your mind, it's unlimited.</blockquote>
<blockquote>--Karl Seinfeld's advice to his son, Jerry</blockquote>
<p>Let's review what we need to build an intelligent <a class="thought" href="entries/machine_entry.html">machine</a>. One resource required is the right set of formulas. We examined three quintessential formulas in chapter 4. There are dozens of others in use, and a more complete understanding of the brain will undoubtedly introduce hundreds more. But all of these appear to be variations on the three basic themes: recursive <a class="thought" href="entries/search_entry.html">search</a>, self-organizing networks of elements, and evolutionary improvement through repeated struggle among competing designs.</p>
<p>A second resource needed is <a class="thought" href="entries/knowledge_entry.html">knowledge</a>. Some pieces of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> are needed as seeds for a process to converge on a meaningful result. Much of the rest can be automatically learned by adaptive methods when neural nets or evolutionary algorithms are exposed to the right <a class="thought" href="entries/learning_entry.html">learning</a> environment.</p>
<p>The third resource required is <a class="thought" href="entries/computation_entry.html">computation</a> itself. In this regard, the human brain is eminently capable in some ways, and remarkably weak in others. Its strength is reflected in its massive parallelism, an approach that our computers can also benefit from. The brain's weakness is the extraordinarily slow speed of its <a class="thought" href="entries/computing_medium_entry.html">computing medium</a>, a limitation that computers do not share with us. For this <a class="thought" href="entries/reason_entry.html">reason</a>, <a class="thought" href="entries/dna_entry.html">DNA</a>-based <a class="thought" href="entries/evolution_entry.html">evolution</a> will eventually have to be abandoned. <a class="thought" href="entries/dna_entry.html">DNA</a>-based <a class="thought" href="entries/evolution_entry.html">evolution</a> is good at tinkering with and extending its designs, but it is unable to scrap an entire design and start over. Organisms created through <a class="thought" href="entries/dna_entry.html">DNA</a>-based <a class="thought" href="entries/evolution_entry.html">evolution</a> are stuck with an extremely plodding type of circuitry.</p>
<p>But the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a> tells us that <a class="thought" href="entries/evolution_entry.html">evolution</a> will not remain stuck at a dead end for very long. And indeed, <a class="thought" href="entries/evolution_entry.html">evolution</a> has found a way around the computational limitations of neural circuitry. Cleverly, it has created organisms that in turn invented a computational <a class="thought" href="entries/technology_entry.html">technology</a> a million times faster than <a class="thought" href="entries/carbon_entry.html">carbon</a>-based neurons (which are continuing to get yet faster). Ultimately, the computing conducted on extremely slow mammalian neural circuits will be ported to a far more versatile and speedier <a class="thought" href="entries/electronic_entry.html">electronic</a> (and photonic) equivalent.</p>
<p>When will this happen? Let's take another look at the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a> as applied to <a class="thought" href="entries/computation_entry.html">computation</a>.</p><h1>Achieving the <a class="thought" href="entries/hardware_entry.html">Hardware</a> Capacity of the <a class="thought" href="entries/human_entry.html">Human</a> <a class="thought" href="entries/brain_entry.html">Brain</a></h1><p>In the chapter 1 chart, "The <a class="thought" href="entries/exponential_growth_entry.html">Exponential Growth</a> of Computing, 1900-1998," we saw that the slope of the curve representing <a class="thought" href="entries/exponential_growth_entry.html">exponential growth</a> was itself gradually increasing. <a class="thought" href="entries/computer_entry.html">Computer</a> speed (as measured in calculations per second per thousand dollars) doubled every three years between 1910 and 1950, doubled every two years between 1950 and 1966, and is now doubling every year. This suggests possible <a class="thought" href="entries/exponential_growth_entry.html">exponential growth</a> in the rate of <a class="thought" href="entries/exponential_growth_entry.html">exponential growth</a>.</p>
<p>This apparent acceleration in the acceleration may result, however, from the confounding of the two strands of the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a>, which for the past forty years has expressed itself using the Moore's Law <a class="thought" href="entries/paradigm_entry.html">paradigm</a> of shrinking <a class="thought" href="entries/transistor_entry.html">transistor</a> sizes on an <a class="thought" href="entries/integrated_circuit_entry.html">integrated circuit</a>. As <a class="thought" href="entries/transistor_entry.html">transistor</a> die sizes decrease, the electrons streaming through the <a class="thought" href="entries/transistor_entry.html">transistor</a> have less distance to travel, hence the switching speed of the <a class="thought" href="entries/transistor_entry.html">transistor</a> increases. So exponentially improving speed is the first strand. Reduced <a class="thought" href="entries/transistor_entry.html">transistor</a> die sizes also enable chip manufacturers to squeeze a greater <a class="thought" href="entries/number_entry.html">number</a> of transistors onto an <a class="thought" href="entries/integrated_circuit_entry.html">integrated circuit</a>, so exponentially improving densities of <a class="thought" href="entries/computation_entry.html">computation</a> is the second strand.</p>
<p>In the early years of the <a class="thought" href="entries/computer_entry.html">computer</a> age, it was primarily the first strand-increasing <a class="thought" href="entries/circuit_entry.html">circuit</a> speeds-that improved the overall <a class="thought" href="entries/computation_entry.html">computation</a> rate of computers. During the 1990s, however, advanced microprocessors began using a form of <a class="thought" href="entries/parallel_processing_entry.html">parallel processing</a> called pipelining, in which multiple calculations were performed at the same time (some mainframes going back to the 1970s used this technique). Thus the speed of <a class="thought" href="entries/computer_entry.html">computer</a> processors as measured in instructions per second now also reflects the second strand: greater densities of <a class="thought" href="entries/computation_entry.html">computation</a> resulting from the use of <a class="thought" href="entries/parallel_processing_entry.html">parallel processing</a>.</p>
<p>As we are approaching more perfect harnessing of the improving density of <a class="thought" href="entries/computation_entry.html">computation</a>, processor speeds are now effectively doubling every twelve months. This is fully feasible today when we build <a class="thought" href="entries/hardware_entry.html">hardware</a>-based neural nets because neural net processors are relatively simple and highly parallel. Here we create a processor for each <a class="thought" href="entries/neuron_entry.html">neuron</a> and eventually one for each interneuronal connection. Moore's Law thereby enables us to double both the <a class="thought" href="entries/number_entry.html">number</a> of processors as well as their speed every two years, an effective quadrupling of the <a class="thought" href="entries/number_entry.html">number</a> of interneuronal-connection calculations per second.</p>
<p>This apparent acceleration in the acceleration of <a class="thought" href="entries/computer_entry.html">computer</a> speeds may result, therefore, from an improving ability to benefit from both strands of the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a>. When Moore's Law dies by the year 2020, new forms of circuitry beyond integrated circuits will continue both strands of exponential improvement. But ordinary <a class="thought" href="entries/exponential_growth_entry.html">exponential growth</a>--two strands of it--is dramatic enough. Using the more conservative prediction of just one level of acceleration as our guide, let's consider where the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a> will take us in the twenty-first century.</p>
<p>The human brain has about 100 billion neurons. With an estimated average of one thousand connections between each <a class="thought" href="entries/neuron_entry.html">neuron</a> and its neighbors, we have about 100 trillion connections, each capable of a simultaneous calculation. That's rather massive <a class="thought" href="entries/parallel_processing_entry.html">parallel processing</a>, and one key to the strength of human <a class="thought" href="entries/thinking_entry.html">thinking</a>. A profound weakness, however, is the excruciatingly slow speed of neural circuitry, only 200 calculations per second. For problems that benefit from massive parallelism, such as neural-net-based <a class="thought" href="entries/pattern_recognition_entry.html">pattern recognition</a>, the human brain does a great job. For problems that require extensive sequential <a class="thought" href="entries/thinking_entry.html">thinking</a>, the human brain is only mediocre.</p>
<p>With 100 trillion connections, each computing at 200 calculations per second, we get 20 million billion calculations per second. This is a conservatively high estimate; other estimates are lower by one to three orders of magnitude. So when will we see the computing speed of the human brain in your <a class="thought" href="entries/personal_computer_entry.html">personal computer</a>?</p>
<p>The answer depends on the type of <a class="thought" href="entries/computer_entry.html">computer</a> we are trying to build. The most relevant is a massively parallel neural net <a class="thought" href="entries/computer_entry.html">computer</a>. In 1997, $2,000 of <a class="thought" href="entries/neural_computer_entry.html">neural computer</a> chips using only modest <a class="thought" href="entries/parallel_processing_entry.html">parallel processing</a> could perform around 2 billion connection calculations per second. Since neural net emulations benefit from both strands of the acceleration of computational power, this capacity will double every twelve months. Thus by the year 2020, it will have doubled about twenty-three times, resulting in a speed of about 20 million billion neural connection calculations per second, which is equal to the human brain.</p>
<p>If we apply the same analysis to an "ordinary" <a class="thought" href="entries/personal_computer_entry.html">personal computer</a>, we get the year 2025 to achieve human brain capacity in a $1,000 <a class="thought" href="entries/device_entry.html">device</a>.2 This is because the general-purpose type of computations that a conventional <a class="thought" href="entries/personal_computer_entry.html">personal computer</a> is designed for are inherently more expensive than the simpler, highly repetitive neural-connection calculations. Thus I believe that the 2020 estimate is more accurate because by 2020, most of the computations performed in our computers will be of the neural-connection type.</p>
<p>The <a class="thought" href="entries/memory_entry.html">memory</a> capacity of the human brain is about 100 trillion <a class="thought" href="entries/synapse_entry.html">synapse</a> strengths (<a class="thought" href="entries/neurotransmitter_entry.html">neurotransmitter</a> concentrations at interneuronal connections), which we can estimate at about a million billion bits. In 1998, a billion bits of <a class="thought" href="entries/ram_entry.html">RAM</a> (128 megabytes) cost about $200. The capacity of <a class="thought" href="entries/memory_entry.html">memory</a> circuits has been doubling every eighteen months. Thus by the year 2023, a million billion bits will cost about $1,000.3 However, this <a class="thought" href="entries/silicon_entry.html">silicon</a> equivalent will run more than a billion times faster than the human brain. There are techniques for trading off <a class="thought" href="entries/memory_entry.html">memory</a> for speed, so we can effectively match human <a class="thought" href="entries/memory_entry.html">memory</a> for $1,000 sooner than 2023.</p>
<p>Taking all of this into consideration, it is reasonable to estimate that a $1,000 <a class="thought" href="entries/personal_computer_entry.html">personal computer</a> will match the computing speed and capacity of the human brain by around the year 2020, particularly for the <a class="thought" href="entries/neuron_entry.html">neuron</a>-connection calculation, which appears to comprise the bulk of the <a class="thought" href="entries/computation_entry.html">computation</a> in the human brain. Supercomputers are one thousand to ten thousand times faster than personal computers. As this book is being written, <a class="thought" href="entries/ibm_entry.html">IBM</a> is building a <a class="thought" href="entries/supercomputer_entry.html">supercomputer</a> based on the design of <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a>, its <a class="thought" href="entries/silicon_entry.html">silicon</a> chess champion, capable of 10 teraflops (that is, 10 trillion calculations per second), only 2,000 times slower than the human brain. Japan's Nippon Electric Company hopes to beat that with a 32-teraflop <a class="thought" href="entries/machine_entry.html">machine</a>. <a class="thought" href="entries/ibm_entry.html">IBM</a> then hopes to follow that with 100 teraflops by around the year 2004 (just what Moore's Law predicts, by the way). Supercomputers will reach the 20 million billion calculations per second capacity of the human brain around 2010, a decade earlier than personal computers.</p>
<p>In another approach, projects such as <a class="thought" href="entries/sun_microsystems_entry.html">Sun Microsystems</a>' Jini <a class="thought" href="entries/program_entry.html">program</a> have been initiated to harvest the unused <a class="thought" href="entries/computation_entry.html">computation</a> on the <a class="thought" href="entries/internet_entry.html">Internet</a>. Note that at any particular moment, the significant majority of the computers on the <a class="thought" href="entries/internet_entry.html">Internet</a> are not being used. Even those that are being used are not being used to capacity (for example, typing text uses less than one percent of a typical notebook <a class="thought" href="entries/computer_entry.html">computer</a>'s computing capacity). Under the <a class="thought" href="entries/internet_entry.html">Internet</a> <a class="thought" href="entries/computation_entry.html">computation</a> harvesting proposals, cooperating sites would load special <a class="thought" href="entries/software_entry.html">software</a> that would enable a virtual massively parallel <a class="thought" href="entries/computer_entry.html">computer</a> to be created out of the computers on the <a class="thought" href="entries/network_entry.html">network</a>. Each user would still have priority over his or her own <a class="thought" href="entries/machine_entry.html">machine</a>, but in the background, a significant fraction of the millions of computers on the <a class="thought" href="entries/internet_entry.html">Internet</a> would be harvested into one or more supercomputers. The amount of unused <a class="thought" href="entries/computation_entry.html">computation</a> on the <a class="thought" href="entries/internet_entry.html">Internet</a> today exceeds the computational capacity of the human brain, so we already have available in at least one form the <a class="thought" href="entries/hardware_entry.html">hardware</a> side of human <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. And with the continuation of the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a>, this availability will become increasingly ubiquitous.</p>
<p>After human capacity in a $1,000 <a class="thought" href="entries/personal_computer_entry.html">personal computer</a> is achieved around the year 2020, our <a class="thought" href="entries/thinking_entry.html">thinking</a> machines will improve the cost performance of their computing by a factor of two every twelve months. That means that the capacity of computing will double ten times every decade, which is a factor of one thousand (210) every ten years. So your <a class="thought" href="entries/personal_computer_entry.html">personal computer</a> will be able to simulate the brain power of a small village by the year 2030, the entire population of the United States by 2048, and a trillion human brains by 2060.5 If we estimate the human <a class="thought" href="entries/earth_entry.html">Earth</a> population at 10 billion persons, one penny's worth of computing circa 2099 will have a billion times greater computing capacity than all humans on <a class="thought" href="entries/earth_entry.html">Earth</a>.6</p>
<p>Of course I may be off by a year or two. But computers in the twenty-first century will not be wanting for computing capacity or <a class="thought" href="entries/memory_entry.html">memory</a>.</p><h1>Computing Substrates in the Twenty-First Century</h1><p>I've noted that the continued <a class="thought" href="entries/exponential_growth_entry.html">exponential growth</a> of computing is implied by the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a>, which states that any process that moves toward greater order-<a class="thought" href="entries/evolution_entry.html">evolution</a> in particular-will exponentially speed up its pace as time passes. The two resources that the exploding pace of an evolutionary process--such as the progression of <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/technology_entry.html">technology</a>--requires are (1) its own increasing order, and (2) the chaos in the environment in which it takes place. Both of these resources are essentially without limit.</p>
<p>Although we can anticipate the overall acceleration in technological <a class="thought" href="entries/progress_entry.html">progress</a>, one might still expect that the actual manifestation of this progression would still be somewhat irregular. After all, it depends on such variable phenomena as individual innovation, business conditions, investment patterns, and the like. Contemporary theories of evolutionary processes, such as the Punctuated Equilibrium theories, posit that <a class="thought" href="entries/evolution_entry.html">evolution</a> works by periodic leaps or discontinuities followed by periods of relative stability. It is thus remarkable how predictable <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/progress_entry.html">progress</a> has been.</p>
<p>So, how will the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a> as applied to <a class="thought" href="entries/computation_entry.html">computation</a> roll out in the decades beyond the demise of Moore's Law on Integrated Circuits by the year 2020? For the immediate <a class="thought" href="entries/future_entry.html">future</a>, Moore's Law will continue with ever smaller <a class="thought" href="entries/component_entry.html">component</a> geometries packing greater numbers of yet faster transistors on each chip. But as <a class="thought" href="entries/circuit_entry.html">circuit</a> dimensions reach near atomic sizes, undesirable quantum effects such as unwanted <a class="thought" href="entries/electron_entry.html">electron</a> <a class="thought" href="entries/tunneling_entry.html">tunneling</a> will produce unreliable results. Nonetheless, Moore's standard methodology will get very close to human processing power in a <a class="thought" href="entries/personal_computer_entry.html">personal computer</a> and beyond that in a <a class="thought" href="entries/supercomputer_entry.html">supercomputer</a>.</p>
<p>The next frontier is the third dimension. Already, venture-backed companies (mostly California-based) are competing to build chips with dozens and ultimately thousands of layers of circuitry. With names like Cubic <a class="thought" href="entries/memory_entry.html">Memory</a>, Dense-Pac, and Staktek, these companies are already shipping functional three-dimensional "cubes" of circuitry. Although not yet cost competitive with the customary flat chips, the third dimension will be there when we run out of space in the first two.</p><h1>Computing with <a class="thought" href="entries/light_entry.html">Light</a></h1><p>Beyond that, there is no shortage of exotic computing technologies being developed in <a class="thought" href="entries/research_entry.html">research</a> labs, many of which have already demonstrated promising results. Optical computing uses streams of photons (particles of light) rather than electrons. A laser can produce billions of coherent streams of photons, with each stream performing its own independent series of calculations. The calculations on each stream are performed in parallel by special optical elements such as lenses, mirrors, and diffraction gratings. Several companies, including QuantaImage, Photonics, and Mytec Technologies, have applied optical computing to the recognition of fingerprints. Lockheed has applied optical computing to the automatic identification of malignant breast lesions.</p>
<p>The advantage of an <a class="thought" href="entries/optical_computer_entry.html">optical computer</a> is that it is massively parallel with potentially trillions of simultaneous calculations. Its disadvantage is that it is not programmable and performs a fixed set of calculations for a given <a class="thought" href="entries/configuration_entry.html">configuration</a> of optical computing elements. But for important classes of problems such as recognizing patterns, it combines massive parallelism (a quality shared by the human brain) with extremely high speed (which the human brain lacks).</p><h1>Computing with the Machinery of <a class="thought" href="entries/life_entry.html">Life</a></h1><p>A new field called molecular computing has sprung up to harness the <a class="thought" href="entries/dna_entry.html">DNA</a> <a class="thought" href="entries/molecule_entry.html">molecule</a> itself as a practical computing <a class="thought" href="entries/device_entry.html">device</a>. <a class="thought" href="entries/dna_entry.html">DNA</a> is <a class="thought" href="entries/nature_entry.html">nature</a>'s own nanoengineered <a class="thought" href="entries/computer_entry.html">computer</a> and it is well suited for solving combinatorial problems. Combining attributes is, after all, the essence of <a class="thought" href="entries/genetics_entry.html">genetics</a>. Applying actual <a class="thought" href="entries/dna_entry.html">DNA</a> to practical computing applications got its start when Leonard Adleman, a University of Southern California mathematician, coaxed a test tube full of <a class="thought" href="entries/dna_entry.html">DNA</a> molecules (see the box on page 108) to solve the well-known "traveling salesperson" problem. In this classic problem, we try to find an optimal route for a hypothetical traveler between multiple cities without having to visit a city more than once. Only certain city pairs are connected by routes, so finding the right path is not straightforward. It is an ideal problem for a recursive <a class="thought" href="entries/algorithm_entry.html">algorithm</a>, although if the <a class="thought" href="entries/number_entry.html">number</a> of cities is too large, even a very fast recursive <a class="thought" href="entries/search_entry.html">search</a> will take far too long.</p>
<p>Professor Adleman and other scientists in the molecular-computing field have identified a set of enzyme reactions that corresponds to the logical and arithmetic operations needed to solve a variety of computing problems. Although <a class="thought" href="entries/dna_entry.html">DNA</a> molecular operations produce occasional errors, the <a class="thought" href="entries/number_entry.html">number</a> of <a class="thought" href="entries/dna_entry.html">DNA</a> strands being used is so large that any molecular errors become statistically insignificant. Thus, despite the inherent error rate in <a class="thought" href="entries/dna_entry.html">DNA</a>'s computing and copying processes, a <a class="thought" href="entries/dna_entry.html">DNA</a> <a class="thought" href="entries/computer_entry.html">computer</a> can be highly reliable if properly designed.</p>
<p>
<a class="thought" href="entries/dna_entry.html">DNA</a> computers have subsequently been applied to a range of difficult combinatorial problems. A <a class="thought" href="entries/dna_entry.html">DNA</a> <a class="thought" href="entries/computer_entry.html">computer</a> is more flexible than an <a class="thought" href="entries/optical_computer_entry.html">optical computer</a> but it is still limited to the technique of applying massive parallel <a class="thought" href="entries/search_entry.html">search</a> by assembling combinations of elements.</p>
<p>There is another, more powerful way to apply the computing power of <a class="thought" href="entries/dna_entry.html">DNA</a> that has not yet been explored. I present it below in the section on <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>.</p><h1>HOW TO SOLVE THE TRAVELING-SALESPERSON PROBLEM USING A TEST TUBE OF <a class="thought" href="entries/dna_entry.html">DNA</a></h1><p>One of <a class="thought" href="entries/dna_entry.html">DNA</a>'s advantageous properties is its ability to replicate itself, and the <a class="thought" href="entries/information_entry.html">information</a> it contains. To solve the traveling-salesperson problem, Professor Adleman performed the following steps:</p>
<ul>
<li>&#183; Generate a small strand of <a class="thought" href="entries/dna_entry.html">DNA</a> with a unique code for each city.</li>
<li>&#183; Replicate each such strand (one for each city) trillions of times using a process called "polymerase chain reaction" (PCR).</li>
<li>&#183; Next, put the pools of <a class="thought" href="entries/dna_entry.html">DNA</a> (one for each city) together in a test tube. This step uses <a class="thought" href="entries/dna_entry.html">DNA</a>'s affinity to link strands together. Longer strands will form automatically. Each such longer strand represents a possible route of multiple cities. The small strands representing each city link up with one another in a random fashion, so there is no mathematical certainty that a linked strand representing the correct answer (sequence of cities) will be formed. However, the <a class="thought" href="entries/number_entry.html">number</a> of strands is so vast that it is virtually certain that at least one strand-and probably millions-will be formed that represent the correct answer.</li>
</ul>
<p>The next steps use specially designed enzymes to eliminate the trillions of strands that represent the wrong answer, leaving only the strands representing the correct answer:</p>
<ul>
<li>&#183; Use molecules called primers to destroy those <a class="thought" href="entries/dna_entry.html">DNA</a> strands that do not start with the start city as well as those that do not end with the end city, and replicate these surviving strands (using PCR).</li>
<li>&#183; Use an enzyme reaction to eliminate those <a class="thought" href="entries/dna_entry.html">DNA</a> strands that represent a travel path greater than the total <a class="thought" href="entries/number_entry.html">number</a> of cities.</li>
<li>&#183; Use an enzyme reaction to destroy those strands that do not include the first city. Repeat for each of the cities.</li>
<li>&#183; Now, each of the surviving strands represents the correct answer. Replicate these surviving strands (using PCR) until there are billions of such strands.</li>
<li>&#183; Using a technique called electrophoresis, read out the <a class="thought" href="entries/dna_entry.html">DNA</a> sequence of these correct strands (as a group). The readout looks like a set of distinct lines, which specifies the correct sequence of cities.</li>
</ul><h1>The <a class="thought" href="entries/brain_entry.html">Brain</a> in the Crystal</h1><p>Another approach contemplates growing a <a class="thought" href="entries/computer_entry.html">computer</a> as a crystal directly in three dimensions, with computing elements being the size of large molecules within the crystalline lattice. This is another approach to harnessing the third dimension.</p>
<p>Stanford Professor Lambertus Hesselink has described a <a class="thought" href="entries/system_entry.html">system</a> in which data is stored in a crystal as a <a class="thought" href="entries/hologram_entry.html">hologram</a>--an optical interference pattern. This three-dimensional storage <a class="thought" href="entries/method_entry.html">method</a> requires only a million atoms for each bit and thus could achieve a trillion bits of storage for each cubic centimeter. Other projects hope to harness the regular molecular <a class="thought" href="entries/structure_entry.html">structure</a> of crystals as actual computing elements.</p><h1>The Nanotube: A Variation of Buckyballs</h1><p>Three professors--Richard Smalley and Robert Curl of Rice University, and Harold Kroto of the University of Sussex--shared the 1996 Nobel Prize in <a class="thought" href="entries/chemistry_entry.html">Chemistry</a> for their 1985 discovery of soccer-ball-shaped molecules formed of a large <a class="thought" href="entries/number_entry.html">number</a> of <a class="thought" href="entries/carbon_entry.html">carbon</a> atoms. Organized in hexagonal and pentagonal patterns like R. Buckminster Fuller's building designs, they were dubbed "buckyballs." These unusual molecules, which form naturally in the hot fumes of a furnace, are extremely strong-a hundred times stronger than steel-a property they share with Fuller's architectural innovations.</p>
<p>More recently, Dr. Sumio Iijima of Nippon Electric Company showed that in addition to the spherical buckyballs, the vapor from <a class="thought" href="entries/carbon_entry.html">carbon</a> arc lamps also contained elongated <a class="thought" href="entries/carbon_entry.html">carbon</a> molecules that looked like long tubes.13 Called <a class="thought" href="entries/nanotubes_entry.html">nanotubes</a> because of their extremely small size-fifty thousand of them side by side would equal the thickness of one human hair--they are formed of the same pentagonal patterns of <a class="thought" href="entries/carbon_entry.html">carbon</a> atoms as buckyballs and share the <a class="thought" href="entries/buckyball_entry.html">buckyball</a>'s unusual strength.</p>
<p>What is most remarkable about the nanotube is that it can perform the <a class="thought" href="entries/electronic_entry.html">electronic</a> functions of <a class="thought" href="entries/silicon_entry.html">silicon</a>-based components. If a nanotube is straight, it conducts electricity as well as or better than a metal conductor. If a slight helical twist is introduced, the nanotube begins to act like a <a class="thought" href="entries/transistor_entry.html">transistor</a>. The full range of <a class="thought" href="entries/electronic_entry.html">electronic</a> devices can be built using <a class="thought" href="entries/nanotubes_entry.html">nanotubes</a>.</p>
<p>Since a nanotube is essentially a sheet of graphite that is only one atom thick, it is vastly smaller than the <a class="thought" href="entries/silicon_entry.html">silicon</a> transistors on an integrated chip. Although extremely small, they are far more durable than <a class="thought" href="entries/silicon_entry.html">silicon</a> devices. Moreover, they handle heat much better than <a class="thought" href="entries/silicon_entry.html">silicon</a> and thus can be assembled into three-dimensional arrays more easily than <a class="thought" href="entries/silicon_entry.html">silicon</a> transistors. Dr. Alex Zettl, a <a class="thought" href="entries/physics_entry.html">physics</a> professor at the University of California at Berkeley, envisions three-dimensional arrays of nanotube-based computing elements similar to--but far denser and faster than--the human brain.</p><h1><a class="thought" href="entries/quantum_computing_entry.html">QUANTUM COMPUTING</a>: THE <a class="thought" href="entries/universe_entry.html">UNIVERSE</a> IN A CUP</h1><blockquote>Quantum particles are the dreams that stuff is made of.</blockquote>
<blockquote>--David Moser</blockquote>
<p>So far we have been talking about mere <a class="thought" href="entries/digital_entry.html">digital</a> computing. There is actually a more powerful approach called <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>. It promises the ability to solve problems that even massively parallel <a class="thought" href="entries/digital_entry.html">digital</a> computers cannot solve. Quantum computers harness a paradoxical result of <a class="thought" href="entries/quantum_mechanics_entry.html">quantum mechanics</a>. Actually, I am being redundant--all results of <a class="thought" href="entries/quantum_mechanics_entry.html">quantum mechanics</a> are paradoxical.</p>
<p>Note that the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a> and other projections in this book do not rely on <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>. The projections in this book are based on readily measurable trends and are not relying on discontinuities in technological <a class="thought" href="entries/progress_entry.html">progress</a> that nonetheless occurred in the twentieth century. There will inevitably be technological discontinuities in the twenty-first century, and <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a> would certainly qualify.</p>
<p>What is <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>? <a class="thought" href="entries/digital_entry.html">Digital</a> computing is based on "bits" of <a class="thought" href="entries/information_entry.html">information</a> which are either off or on--zero or one. Bits are organized into larger structures such as numbers, letters, and words, which in turn can represent virtually any form of <a class="thought" href="entries/information_entry.html">information</a>: text, sounds, pictures, moving images. <a class="thought" href="entries/quantum_computing_entry.html">Quantum computing</a>, on the other hand, is based on qu-bits (pronounced cue-bits), which essentially are zero and one at the same time. The <a class="thought" href="entries/qu_bit_entry.html">qu-bit</a> is based on the fundamental ambiguity inherent in <a class="thought" href="entries/quantum_mechanics_entry.html">quantum mechanics</a>. The position, momentum, or other state of a fundamental <a class="thought" href="entries/particle_entry.html">particle</a> remains "ambiguous" until a process of disambiguation causes that <a class="thought" href="entries/particle_entry.html">particle</a> to "decide" where it is, where it has been, and what properties it has. For example, consider a stream of photons that strike a sheet of glass at a 45-degree angle. As each <a class="thought" href="entries/photon_entry.html">photon</a> strikes the glass, it has a choice of traveling either straight through the glass or reflecting off the glass. Each <a class="thought" href="entries/photon_entry.html">photon</a> will actually take both paths (actually more than this, see below) until a process of conscious observation forces each <a class="thought" href="entries/particle_entry.html">particle</a> to decide which path it took. This behavior has been extensively confirmed in numerous contemporary experiments.</p>
<p>In a quantum <a class="thought" href="entries/computer_entry.html">computer</a>, the qu-bits would be represented by a property--nuclear spin is a popular choice--of individual electrons. If set up in the proper way, the electrons will not have decided the direction of their nuclear spin (up or down) and thus will be in both states at the same time. The process of conscious observation of the electrons' spin states--or any subsequent phenomena dependent on a determination of these states--causes the ambiguity to be resolved. This process of disambiguation is called <a class="thought" href="entries/quantum_decoherence_entry.html">quantum decoherence</a>. If it weren't for <a class="thought" href="entries/quantum_decoherence_entry.html">quantum decoherence</a>, the world we live in would be a baffling place indeed.</p>
<p>The key to the quantum <a class="thought" href="entries/computer_entry.html">computer</a> is that we would present it with a problem, along with a way to test the answer. We would set up the <a class="thought" href="entries/quantum_decoherence_entry.html">quantum decoherence</a> of the qu-bits in such a way that only an answer that passes the test survives the decoherence. The failing answers essentially cancel each other out. As with a <a class="thought" href="entries/number_entry.html">number</a> of other approaches (for example, recursive and genetic algorithms), one of the keys to <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a> is, therefore, a careful statement of the problem, including a precise way to test possible answers.</p>
<p>The series of qu-bits represents simultaneously every possible solution to the problem. A single <a class="thought" href="entries/qu_bit_entry.html">qu-bit</a> represents two possible solutions. Two linked qu-bits represent four possible answers. A quantum <a class="thought" href="entries/computer_entry.html">computer</a> with 1,000 qu-bits represents 21,000 (this is approximately equal to a decimal <a class="thought" href="entries/number_entry.html">number</a> consisting of 1, followed by 301 zeroes) possible solutions simultaneously. The statement of the problem--expressed as a test to be applied to potential answers--is presented to the string of qu-bits so that the qu-bits decohere (that is, each <a class="thought" href="entries/qu_bit_entry.html">qu-bit</a> changes from its ambiguous 0-1 state to an actual 0 or a 1), leaving a series of 0's and 1's that pass the test. Essentially all 21,000 possible solutions have been tried simultaneously, leaving only the correct solution.</p>
<p>This process of reading out the answer through <a class="thought" href="entries/quantum_decoherence_entry.html">quantum decoherence</a> is obviously the key to <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>. It is also the most difficult aspect to grasp. Consider the following <a class="thought" href="entries/analogy_entry.html">analogy</a>. Beginning <a class="thought" href="entries/physics_entry.html">physics</a> students learn that if light strikes a mirror at an angle, it will bounce off the mirror in the opposite direction and at the same angle to the surface. But according to quantum theory, that is not what is happening. Each <a class="thought" href="entries/photon_entry.html">photon</a> actually bounces off every possible point on the mirror, essentially trying out every possible path. The vast majority of these paths cancel each other out, leaving only the path that classical <a class="thought" href="entries/physics_entry.html">physics</a> predicts. Think of the mirror as representing a problem to be solved. Only the correct solution--light bounced off at an angle equal to the incoming angle--survives all of the quantum cancellations. A quantum <a class="thought" href="entries/computer_entry.html">computer</a> works the same way. The test of the correctness of the answer to the problem is set up in such a way that the vast majority of the possible answers--those that do not pass the test--cancel each other out, leaving only the sequence of bits that does pass the test. An ordinary mirror, therefore, can be <a class="thought" href="entries/thought_entry.html">thought</a> of as a special example of a quantum <a class="thought" href="entries/computer_entry.html">computer</a>, albeit one that solves a rather simple problem.</p>
<p>As a more useful example, <a class="thought" href="entries/encryption_entry.html">encryption</a> codes are based on factoring large numbers (factoring means determining which smaller numbers, when multiplied together, result in the larger <a class="thought" href="entries/number_entry.html">number</a>). Factoring a <a class="thought" href="entries/number_entry.html">number</a> with several hundred bits is virtually impossible on any <a class="thought" href="entries/digital_entry.html">digital</a> <a class="thought" href="entries/computer_entry.html">computer</a> even if we had billions of years to wait for the answer. A quantum <a class="thought" href="entries/computer_entry.html">computer</a> can try every possible combination of factors simultaneously and break the code in less than a billionth of a second (communicating the answer to human observers does take a bit longer). The test applied by the quantum <a class="thought" href="entries/computer_entry.html">computer</a> during its key disambiguation stage is very simple: just multiply one factor by the other and if the result equals the <a class="thought" href="entries/encryption_entry.html">encryption</a> code, then we have solved the problem.</p>
<p>It has been said that <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a> is to <a class="thought" href="entries/digital_entry.html">digital</a> computing as a <a class="thought" href="entries/hydrogen_entry.html">hydrogen</a> bomb is to a firecracker. This is a remarkable statement when we consider that <a class="thought" href="entries/digital_entry.html">digital</a> computing is quite revolutionary in its own right. The <a class="thought" href="entries/analogy_entry.html">analogy</a> is based on the following observation. Consider (at least in theory) a <a class="thought" href="entries/universe_entry.html">Universe</a>-sized (nonquantum) <a class="thought" href="entries/computer_entry.html">computer</a> in which every <a class="thought" href="entries/neutron_entry.html">neutron</a>, <a class="thought" href="entries/electron_entry.html">electron</a>, and <a class="thought" href="entries/proton_entry.html">proton</a> in the <a class="thought" href="entries/universe_entry.html">Universe</a> is turned into a <a class="thought" href="entries/computer_entry.html">computer</a>, and each one (that is, every <a class="thought" href="entries/particle_entry.html">particle</a> in the <a class="thought" href="entries/universe_entry.html">Universe</a>) is able to compute trillions of calculations per second. Now imagine certain problems that this <a class="thought" href="entries/universe_entry.html">Universe</a>-sized <a class="thought" href="entries/supercomputer_entry.html">supercomputer</a> would be unable to solve even if we ran that <a class="thought" href="entries/computer_entry.html">computer</a> until either the next big bang or until all the stars in the <a class="thought" href="entries/universe_entry.html">Universe</a> died--about ten to thirty billion years. There are many examples of such massively intractable problems; for example, cracking <a class="thought" href="entries/encryption_entry.html">encryption</a> codes that use a thousand bits, or solving the traveling-salesman problem with a thousand cities. While very massive <a class="thought" href="entries/digital_entry.html">digital</a> computing (including our theoretical <a class="thought" href="entries/universe_entry.html">Universe</a>-sized <a class="thought" href="entries/computer_entry.html">computer</a>) is unable to solve this class of problems, a quantum <a class="thought" href="entries/computer_entry.html">computer</a> of microscopic size could solve such problems in less than a billionth of a second.</p>
<p>Are quantum computers feasible? Recent advances, both theoretical and practical, suggest that the answer is yes. Although a practical quantum <a class="thought" href="entries/computer_entry.html">computer</a> has not been built, the means for harnessing the requisite decoherence has been demonstrated. <a class="thought" href="entries/chuang_entry.html">Isaac Chuang</a> of Los Alamos National Laboratory and MIT's Neil Gershenfeld have actually built a quantum <a class="thought" href="entries/computer_entry.html">computer</a> using the <a class="thought" href="entries/carbon_entry.html">carbon</a> atoms in the alanine <a class="thought" href="entries/molecule_entry.html">molecule</a>. Their quantum <a class="thought" href="entries/computer_entry.html">computer</a> was only able to add one and one, but that's a start. We have, of course, been relying on practical applications of other quantum effects, such as the <a class="thought" href="entries/electron_entry.html">electron</a> <a class="thought" href="entries/tunneling_entry.html">tunneling</a> in transistors, for decades.14</p><h1>A Quantum <a class="thought" href="entries/computer_entry.html">Computer</a> in a Cup of Coffee</h1><p>One of the difficulties in designing a practical quantum <a class="thought" href="entries/computer_entry.html">computer</a> is that it needs to be extremely small, basically atom or <a class="thought" href="entries/molecule_entry.html">molecule</a> sized, to harness the delicate quantum effects. But it is very difficult to keep individual atoms and molecules from moving around due to thermal effects. Moreover, individual molecules are generally too unstable to build a reliable <a class="thought" href="entries/machine_entry.html">machine</a>. For these problems, Chuang and Gershenfeld have come up with a theoretical breakthrough. Their solution is to take a cup of liquid and consider every <a class="thought" href="entries/molecule_entry.html">molecule</a> to be a quantum <a class="thought" href="entries/computer_entry.html">computer</a>. Now instead of a single unstable <a class="thought" href="entries/molecule_entry.html">molecule</a>-sized quantum <a class="thought" href="entries/computer_entry.html">computer</a>, they have a cup with about a hundred billion trillion quantum computers. The point here is not more massive parallelism, but rather massive redundancy. In this way, the inevitably erratic behavior of some of the molecules has no effect on the statistical behavior of all the molecules in the liquid. This approach of using the statistical behavior of trillions of molecules to overcome the lack of reliability of a single <a class="thought" href="entries/molecule_entry.html">molecule</a> is similar to Professor Adleman's use of trillions of <a class="thought" href="entries/dna_entry.html">DNA</a> strands to overcome the comparable issue in <a class="thought" href="entries/dna_computing_entry.html">DNA computing</a>.</p>
<p>This approach to <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a> also solves the problem of reading out the answer bit by bit without causing those qu-bits that have not yet been read to decohere prematurely. Chuang and Gershenfeld subject their liquid <a class="thought" href="entries/computer_entry.html">computer</a> to radio-wave pulses, which cause the molecules to respond with signals indicating the spin state of each <a class="thought" href="entries/electron_entry.html">electron</a>. Each pulse does cause some unwanted decoherence, but, again, this decoherence does not affect the statistical behavior of trillions of molecules. In this way, the quantum effects become stable and reliable.</p>
<p>Chuang and Gershenfeld are currently building a quantum <a class="thought" href="entries/computer_entry.html">computer</a> that can factor small numbers. Although this early model will not compete with conventional <a class="thought" href="entries/digital_entry.html">digital</a> computers, it will be an important demonstration of the feasibility of <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>. Apparently high on their list for a suitable quantum liquid is freshly brewed <a class="thought" href="entries/java_entry.html">Java</a> coffee, which, Gershenfeld notes, has "unusually even heating characteristics."</p><h1><a class="thought" href="entries/quantum_computing_entry.html">Quantum Computing</a> with the <a class="thought" href="entries/code_entry.html">Code</a> of <a class="thought" href="entries/life_entry.html">Life</a></h1><p>
<a class="thought" href="entries/quantum_computing_entry.html">Quantum computing</a> starts to overtake <a class="thought" href="entries/digital_entry.html">digital</a> computing when we can link at least 40 qu-bits. A 40-<a class="thought" href="entries/qu_bit_entry.html">qu-bit</a> quantum <a class="thought" href="entries/computer_entry.html">computer</a> would be evaluating a trillion possible solutions simultaneously, which would match the fastest supercomputers. At 60 bits, we would be doing a million trillion simultaneous trials. When we get to hundreds of qu-bits, the capabilities of a quantum <a class="thought" href="entries/computer_entry.html">computer</a> would vastly overpower any conceivable <a class="thought" href="entries/digital_entry.html">digital</a> <a class="thought" href="entries/computer_entry.html">computer</a>.</p>
<p>So here's my idea. The power of a quantum <a class="thought" href="entries/computer_entry.html">computer</a> depends on the <a class="thought" href="entries/number_entry.html">number</a> of qu-bits that we can link together. We need to find a large <a class="thought" href="entries/molecule_entry.html">molecule</a> that is specifically designed to hold large amounts of <a class="thought" href="entries/information_entry.html">information</a>. <a class="thought" href="entries/evolution_entry.html">Evolution</a> has designed just such a <a class="thought" href="entries/molecule_entry.html">molecule</a>: <a class="thought" href="entries/dna_entry.html">DNA</a>. We can readily create any sized <a class="thought" href="entries/dna_entry.html">DNA</a> <a class="thought" href="entries/molecule_entry.html">molecule</a> we wish from a few dozen <a class="thought" href="entries/nucleotide_entry.html">nucleotide</a> rungs to thousands. So once again we combine two elegant ideas--in this case the liquid--<a class="thought" href="entries/dna_entry.html">DNA</a> <a class="thought" href="entries/computer_entry.html">computer</a> and the liquid-quantum <a class="thought" href="entries/computer_entry.html">computer</a>--to come up with a solution greater than the sum of its parts. By putting trillions of <a class="thought" href="entries/dna_entry.html">DNA</a> molecules in a cup, there is the potential to build a highly redundant--and therefore reliable--quantum <a class="thought" href="entries/computer_entry.html">computer</a> with as many qu-bits as we care to harness. Remember you read it here first.</p><h1>Suppose No One Ever Looks at the Answer</h1><p>Consider that the quantum ambiguity a quantum <a class="thought" href="entries/computer_entry.html">computer</a> relies on is decohered, that is, disambiguated, when a conscious <a class="thought" href="entries/entity_entry.html">entity</a> observes the ambiguous <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a>. The conscious entities in this case are us, the users of the quantum <a class="thought" href="entries/computer_entry.html">computer</a>. But in using a quantum <a class="thought" href="entries/computer_entry.html">computer</a>, we are not directly looking at the nuclear spin states of individual electrons. The spin states are measured by an apparatus that in turn answers some question that the quantum <a class="thought" href="entries/computer_entry.html">computer</a> has been asked to solve. These measurements are then processed by other <a class="thought" href="entries/electronic_entry.html">electronic</a> gadgets, manipulated further by conventional computing equipment, and finally displayed or printed on a piece of paper.</p>
<p>Suppose no human or other conscious <a class="thought" href="entries/entity_entry.html">entity</a> ever looks at the printout. In this situation, there has been no conscious observation, and therefore no decoherence. As I discussed earlier, the physical world only bothers to manifest itself in an unambiguous state when one of us conscious entities decides to interact with it. So the page with the answer is ambiguous, undetermined--until and unless a conscious <a class="thought" href="entries/entity_entry.html">entity</a> looks at it. Then instantly all the ambiguity is retroactively resolved, and the answer is there on the page. The implication is that the answer is not there until we look at it. But don't try to sneak up on the page fast enough to see the answerless page; the quantum effects are instantaneous.</p><h1>What Is It Good For?</h1><p>A key requirement for <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a> is a way to test the answer. Such a test does not always exist. However, a quantum <a class="thought" href="entries/computer_entry.html">computer</a> would be a great mathematician. It could simultaneously consider every possible combination of axioms and previously solved theorems (within a quantum <a class="thought" href="entries/computer_entry.html">computer</a>'s <a class="thought" href="entries/qu_bit_entry.html">qu-bit</a> capacity) to prove or disprove virtually any provable or disprovable conjecture. Although a mathematical proof is often extremely difficult to come up with, confirming its validity is usually straightforward, so the quantum approach is well suited.</p>
<p>
<a class="thought" href="entries/quantum_computing_entry.html">Quantum computing</a> is not directly applicable, however, to problems such as playing a board game. Whereas the "perfect" chess move for a given board is a good example of a finite but intractable computing problem, there is no easy way to test the answer. If a person or process were to present an answer, there is no way to test its validity other than to build the same move-countermove tree that generated the answer in the first place. Even for mere "good" moves, a quantum <a class="thought" href="entries/computer_entry.html">computer</a> would have no obvious advantage over a <a class="thought" href="entries/digital_entry.html">digital</a> <a class="thought" href="entries/computer_entry.html">computer</a>.</p>
<p>How about creating art? Here a quantum <a class="thought" href="entries/computer_entry.html">computer</a> would have considerable value. Creating a work of art involves solving a series, possibly an extensive series, of problems. A quantum <a class="thought" href="entries/computer_entry.html">computer</a> could consider every possible combination of elements--words, notes, strokes--for each such decision. We still need a way to test each answer to the sequence of aesthetic problems, but the quantum <a class="thought" href="entries/computer_entry.html">computer</a> would be ideal for instantly searching through a <a class="thought" href="entries/universe_entry.html">Universe</a> of possibilities.</p><h1><a class="thought" href="entries/encryption_entry.html">Encryption</a> Destroyed and Resurrected</h1><p>As mentioned above, the classic problem that a quantum <a class="thought" href="entries/computer_entry.html">computer</a> is ideally suited for is cracking <a class="thought" href="entries/encryption_entry.html">encryption</a> codes, which relies on factoring large numbers. The strength of an <a class="thought" href="entries/encryption_entry.html">encryption</a> code is measured by the <a class="thought" href="entries/number_entry.html">number</a> of bits that needs to be factored. For example, it is illegal in the United States to <a class="thought" href="entries/export_entry.html">export</a> <a class="thought" href="entries/encryption_entry.html">encryption</a> <a class="thought" href="entries/technology_entry.html">technology</a> using more than 40 bits (56 bits if you give a key to law-enforcement authorities). A 40-bit <a class="thought" href="entries/encryption_entry.html">encryption</a> <a class="thought" href="entries/method_entry.html">method</a> is not very secure. In September 1997, Ian Goldberg, a University of California at Berkeley graduate student, was able to crack a 40-bit code in three and a half hours using a <a class="thought" href="entries/network_entry.html">network</a> of 250 small computers.15 A 56-bit code is a bit better (16 bits better, actually). Ten months later, John Gilmore, a <a class="thought" href="entries/computer_entry.html">computer</a> privacy activist, and Paul Kocher, an <a class="thought" href="entries/encryption_entry.html">encryption</a> expert, were able to break the 56-bit code in 56 hours using a specially designed <a class="thought" href="entries/computer_entry.html">computer</a> that cost them $250,000 to build. But a quantum <a class="thought" href="entries/computer_entry.html">computer</a> can easily factor any sized <a class="thought" href="entries/number_entry.html">number</a> (within its capacity). <a class="thought" href="entries/quantum_computing_entry.html">Quantum computing</a> <a class="thought" href="entries/technology_entry.html">technology</a> would essentially destroy <a class="thought" href="entries/digital_entry.html">digital</a> <a class="thought" href="entries/encryption_entry.html">encryption</a>.</p>
<p>But as <a class="thought" href="entries/technology_entry.html">technology</a> takes away, it also gives. A related quantum effect can provide a new <a class="thought" href="entries/method_entry.html">method</a> of <a class="thought" href="entries/encryption_entry.html">encryption</a> that can never be broken. Again, keep in mind that, in view of the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a>, "never" is not as long as it used to be.</p>
<p>This effect is called <a class="thought" href="entries/quantum_entanglement_entry.html">quantum entanglement</a>. Einstein, who was not a fan of <a class="thought" href="entries/quantum_mechanics_entry.html">quantum mechanics</a>, had a different name for it, calling it "spooky <a class="thought" href="entries/action_entry.html">action</a> at a distance." The <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a> was recently demonstrated by Dr. Nicolas Gisin of the University of Geneva in a recent <a class="thought" href="entries/experiment_entry.html">experiment</a> across the city of Geneva.16 Dr. Gisin sent twin photons in opposite directions through optical fibers. Once the photons were about seven miles apart, they each encountered a glass plate from which they could either bounce off or pass through. Thus, they were each forced to make a decision to choose among two equally probable pathways. Since there was no possible <a class="thought" href="entries/communication_entry.html">communication</a> link between the two photons, classical <a class="thought" href="entries/physics_entry.html">physics</a> would predict that their decisions would be independent. But they both made the same decision. And they did so at the same instant in time, so even if there were an unknown <a class="thought" href="entries/communication_entry.html">communication</a> path between them, there was not enough time for a message to travel from one <a class="thought" href="entries/photon_entry.html">photon</a> to the other at the speed of light. The two particles were quantum entangled and communicated instantly with each other regardless of their separation. The effect was reliably repeated over many such <a class="thought" href="entries/photon_entry.html">photon</a> pairs.</p>
<p>The apparent <a class="thought" href="entries/communication_entry.html">communication</a> between the two photons takes place at a speed far greater than the speed of light. In theory, the speed is infinite in that the decoherence of the two <a class="thought" href="entries/photon_entry.html">photon</a> travel decisions, according to quantum theory, takes place at exactly the same instant. Dr. Gisin's <a class="thought" href="entries/experiment_entry.html">experiment</a> was sufficiently sensitive to demonstrate the <a class="thought" href="entries/communication_entry.html">communication</a> was at least ten thousand times faster than the speed of light.</p>
<p>So, does this violate Einstein's Special Theory of <a class="thought" href="entries/relativity_entry.html">Relativity</a>, which postulates the speed of light as the fastest speed at which we can transmit <a class="thought" href="entries/information_entry.html">information</a>? The answer is no--there is no <a class="thought" href="entries/information_entry.html">information</a> being communicated by the entangled photons. The decision of the photons is random--a profound quantum randomness--and randomness is precisely not <a class="thought" href="entries/information_entry.html">information</a>. Both the sender and the receiver of the message simultaneously <a class="thought" href="entries/access_entry.html">access</a> the identical random decisions of the entangled photons, which are used to encode and decode, respectively, the message. So we are communicating randomness--not <a class="thought" href="entries/information_entry.html">information</a>--at speeds far greater than the speed of light. The only way we could convert the random decisions of the photons into <a class="thought" href="entries/information_entry.html">information</a> is if we edited the random sequence of <a class="thought" href="entries/photon_entry.html">photon</a> decisions. But editing this random sequence would require observing the <a class="thought" href="entries/photon_entry.html">photon</a> decisions, which in turn would cause <a class="thought" href="entries/quantum_decoherence_entry.html">quantum decoherence</a>, which would destroy the <a class="thought" href="entries/quantum_entanglement_entry.html">quantum entanglement</a>. So Einstein's theory is preserved.</p>
<p>Even though we cannot instantly transmit <a class="thought" href="entries/information_entry.html">information</a> using <a class="thought" href="entries/quantum_entanglement_entry.html">quantum entanglement</a>, transmitting randomness is still very useful. It allows us to resurrect the process of <a class="thought" href="entries/encryption_entry.html">encryption</a> that <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a> would destroy. If the sender and receiver of a message are at the two ends of an optical fiber, they can use the precisely matched random decisions of a stream of quantum entangled photons to respectively encode and decode a message. Since the <a class="thought" href="entries/encryption_entry.html">encryption</a> is fundamentally random and nonrepeating, it cannot be broken. Eavesdropping would also be impossible, as this would cause <a class="thought" href="entries/quantum_decoherence_entry.html">quantum decoherence</a> that could be detected at both ends. So privacy is preserved.</p>
<p>Note that in <a class="thought" href="entries/quantum_encryption_entry.html">quantum encryption</a>, we are transmitting the code instantly. The actual message will arrive much more slowly--at only the speed of light.</p><h1>Quantum <a class="thought" href="entries/consciousness_entry.html">Consciousness</a> Revisited</h1><p>The prospect of computers competing with the full range of human capabilities generates strong, often adverse feelings, as well as no shortage of arguments that such a specter is theoretically impossible. One of the more interesting such arguments comes from an Oxford mathematician and physicist, <a class="thought" href="entries/penrose_entry.html">Roger Penrose</a>.</p>
<p>In his 1989 best-seller, The Emperor's New <a class="thought" href="entries/mind_entry.html">Mind</a>, Penrose puts forth two conjectures.17 The first has to do with an unsettling theorem proved by a Czech mathematician, Kurt G&#246;del. G&#246;del's famous "incompleteness theorem," which has been called the most important theorem in <a class="thought" href="entries/mathematics_entry.html">mathematics</a>, states that in a mathematical <a class="thought" href="entries/system_entry.html">system</a> powerful enough to generate the natural numbers, there inevitably exist propositions that can be neither proved nor disproved. This was another one of those twentieth-century insights that upset the orderliness of nineteenth-century <a class="thought" href="entries/thinking_entry.html">thinking</a>.</p>
<p>A corollary of G&#246;del's theorem is that there are mathematical propositions that cannot be decided by an <a class="thought" href="entries/algorithm_entry.html">algorithm</a>. In essence, these G&#246;delian impossible problems require an infinite <a class="thought" href="entries/number_entry.html">number</a> of steps to be solved. So Penrose's first conjecture is that machines cannot do what humans can do because machines can only follow an <a class="thought" href="entries/algorithm_entry.html">algorithm</a>. An <a class="thought" href="entries/algorithm_entry.html">algorithm</a> cannot solve a G&#246;delian unsolvable problem. But humans can. Therefore, humans are better.</p>
<p>Penrose goes on to state that humans can solve unsolvable problems because our brains do <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>. Subsequently responding to criticism that neurons are too big to exhibit quantum effects, Penrose cited small structures in the neurons called microtubules that may be capable of quantum <a class="thought" href="entries/computation_entry.html">computation</a>.</p>
<p>However, Penrose's first conjecture--that humans are inherently superior to machines--is unconvincing for at least three reasons:</p>
<ol>
<li>1. It is true that machines can't solve G&#246;delian impossible problems. But humans can't solve them either. Humans can only estimate them. Computers can make estimates as well, and in recent years are doing a better job of this than humans.</li>
<li>2. In any event, <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a> does not permit solving G&#246;delian impossible problems either. Solving a G&#246;delian impossible problem requires an <a class="thought" href="entries/algorithm_entry.html">algorithm</a> with an infinite <a class="thought" href="entries/number_entry.html">number</a> of steps. <a class="thought" href="entries/quantum_computing_entry.html">Quantum computing</a> can turn an intractable problem that could not be solved on a conventional <a class="thought" href="entries/computer_entry.html">computer</a> in trillions of years into an instantaneous <a class="thought" href="entries/computation_entry.html">computation</a>. But it still falls short of infinite computing.</li>
<li>3. Even if (1) and (2) above were wrong, that is, if humans could solve G&#246;delian impossible problems and do so because of their quantum-computing ability, that still does not restrict <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a> from machines. The opposite is the case. If the human brain exhibits <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>, this would only confirm that <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a> is possible, that <a class="thought" href="entries/matter_entry.html">matter</a> following natural laws can perform <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>. Any mechanisms in human neurons capable of <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>, such as the microtubules, would be replicable in a <a class="thought" href="entries/machine_entry.html">machine</a>. Machines use quantum effects--<a class="thought" href="entries/tunneling_entry.html">tunneling</a>--in trillions of devices (that is, transistors) today.18 There is nothing to suggest that the human brain has exclusive <a class="thought" href="entries/access_entry.html">access</a> to <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>.</li>
</ol>
<p>Penrose's second conjecture is more difficult to resolve. It is that an <a class="thought" href="entries/entity_entry.html">entity</a> exhibiting <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a> is conscious. He is saying that it is the human's <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a> that accounts for her <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. Thus <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>--<a class="thought" href="entries/quantum_decoherence_entry.html">quantum decoherence</a>--yields <a class="thought" href="entries/consciousness_entry.html">consciousness</a>.</p>
<p>Now we do know that there is a link between <a class="thought" href="entries/consciousness_entry.html">consciousness</a> and <a class="thought" href="entries/quantum_decoherence_entry.html">quantum decoherence</a>. That is, <a class="thought" href="entries/consciousness_entry.html">consciousness</a> observing a quantum uncertainty causes <a class="thought" href="entries/quantum_decoherence_entry.html">quantum decoherence</a>. Penrose, however, is asserting a link in the opposite direction. This does not follow logically. Of course <a class="thought" href="entries/quantum_mechanics_entry.html">quantum mechanics</a> is not logical in the usual sense--it follows quantum logic (some observers use the word "strange" to describe quantum logic). But even applying quantum logic, Penrose's second conjecture does not appear to follow. On the other hand, I am unable to reject it out of hand because there is a strong nexus between <a class="thought" href="entries/consciousness_entry.html">consciousness</a> and <a class="thought" href="entries/quantum_decoherence_entry.html">quantum decoherence</a> in that the former causes the latter. I have <a class="thought" href="entries/thought_entry.html">thought</a> about this issue for three years, and have been unable to accept it or reject it. Perhaps before writing my next book I will have an opinion on Penrose's second conjecture.</p><h1><a class="thought" href="entries/reverse_engineering_entry.html">REVERSE ENGINEERING</a> A PROVEN DESIGN: THE <a class="thought" href="entries/human_entry.html">HUMAN</a> <a class="thought" href="entries/brain_entry.html">BRAIN</a></h1><blockquote>For many people the mind is the last refuge of mystery against the encroaching spread of science, and they don't like the idea of science engulfing the last bit of terra incognita.</blockquote>
<blockquote>--Herb Simon as quoted by Daniel Dennett</blockquote>
<blockquote>Cannot we let people be themselves, and enjoy life in their own way? You are trying to make another you. One's enough.</blockquote>
<blockquote>--Ralph Waldo Emerson</blockquote>
<blockquote>For the wise men of old . . . the solution has been knowledge and self-discipline, . . . and in the practice of this technique, are ready to do things hitherto regarded as disgusting and impious--such as digging up and mutilating the dead.</blockquote>
<blockquote>--C. S. Lewis</blockquote>
<p>
<a class="thought" href="entries/intelligence_entry.html">Intelligence</a> is: (a) the most complex <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a> in the <a class="thought" href="entries/universe_entry.html">Universe</a>; or (b) a profoundly simple process.</p>
<p>The answer, of course, is (c) both of the above. It's another one of those great dualities that make life interesting. We've already talked about the simplicity of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>: simple paradigms and the simple process of <a class="thought" href="entries/computation_entry.html">computation</a>. Let's talk about the <a class="thought" href="entries/complexity_entry.html">complexity</a>.</p><h1>IS THE <a class="thought" href="entries/brain_entry.html">BRAIN</a> BIG ENOUGH?</h1><p>Is our conception of human <a class="thought" href="entries/neuron_entry.html">neuron</a> functioning and our estimates of the <a class="thought" href="entries/number_entry.html">number</a> of neurons and connections in the human brain consistent with what we know about the brain's capabilities? Perhaps human neurons are far more capable than we think they are. If so, building a <a class="thought" href="entries/machine_entry.html">machine</a> with human-level capabilities might take longer than expected.</p>
<p>We find that estimates of the <a class="thought" href="entries/number_entry.html">number</a> of concepts--"chunks" of <a class="thought" href="entries/knowledge_entry.html">knowledge</a>--that a human expert in a particular field has mastered are remarkably consistent: about 50,000 to 100,000. This approximate range appears to be valid over a wide range of human endeavors: the <a class="thought" href="entries/number_entry.html">number</a> of board positions mastered by a chess grand master, the concepts mastered by an expert in a technical field, such as a physician, the vocabulary of a writer (Shakespeare used 29,000 words;19 this book uses a lot fewer).</p>
<p>This type of professional <a class="thought" href="entries/knowledge_entry.html">knowledge</a> is, of course, only a small subset of the <a class="thought" href="entries/knowledge_entry.html">knowledge</a> we need to function as human beings. Basic <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of the world, including so-called <a class="thought" href="entries/common_sense_entry.html">common sense</a>, is more extensive. We also have an ability to recognize patterns: spoken <a class="thought" href="entries/language_entry.html">language</a>, written <a class="thought" href="entries/language_entry.html">language</a>, objects, faces. And we have our skills: walking, talking, catching balls. I believe that a reasonably conservative estimate of the general <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of a typical human is a thousand times greater than the <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of an expert in her professional field. This provides us a rough estimate of 100 million chunks--bits of understanding, concepts, patterns, specific skills--per human. As we will see below, even if this estimate is low (by a factor of up to a thousand), the brain is still big enough.</p>
<p>The <a class="thought" href="entries/number_entry.html">number</a> of neurons in the human brain is estimated at approximately 100 billion, with an average of 1,000 connections per <a class="thought" href="entries/neuron_entry.html">neuron</a>, for a total of 100 trillion connections. With 100 trillion connections and 100 million chunks of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> (including patterns and skills), we get an estimate of about a million connections per chunk.</p>
<p>Our <a class="thought" href="entries/computer_entry.html">computer</a> simulations of neural nets use a variety of different types of <a class="thought" href="entries/neuron_entry.html">neuron</a> models, all of which are relatively simple. Efforts to provide detailed <a class="thought" href="entries/electronic_entry.html">electronic</a> models of real mammalian neurons appear to show that while <a class="thought" href="entries/animal_entry.html">animal</a> neurons are more complicated than typical <a class="thought" href="entries/computer_entry.html">computer</a> models, the difference in <a class="thought" href="entries/complexity_entry.html">complexity</a> is modest. Even using our simpler <a class="thought" href="entries/computer_entry.html">computer</a> versions of neurons, we find that we can model a chunk of <a class="thought" href="entries/knowledge_entry.html">knowledge</a>--a face, a character shape, a <a class="thought" href="entries/phoneme_entry.html">phoneme</a>, a word sense--using as little as a thousand connections per chunk. Thus our rough estimate of a million neural connections in the human brain per human <a class="thought" href="entries/knowledge_entry.html">knowledge</a> chunk appears reasonable.</p>
<p>Indeed it appears ample. Thus we could make my estimate (of the <a class="thought" href="entries/number_entry.html">number</a> of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> chunks) a thousand times greater, and the calculation still works. It is likely, however, that the brain's encoding of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> is less efficient than the methods we use in our machines. This apparent inefficiency is consistent with our understanding that the human brain is conservatively designed. The brain relies on a large degree of redundancy and a relatively low density of <a class="thought" href="entries/information_entry.html">information</a> storage to gain reliability and to continue to function effectively despite a high rate of <a class="thought" href="entries/neuron_entry.html">neuron</a> loss as we age.</p>
<p>My conclusion is that it does not appear that we need to contemplate a model of <a class="thought" href="entries/information_entry.html">information</a> processing of individual neurons that is significantly more complex than we currently understand in order to explain human capability. The brain is big enough.</p>
<p>We come back to <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, which starts out with simple seeds but ultimately becomes elaborate as the <a class="thought" href="entries/knowledge_entry.html">knowledge</a>--gathering process interacts with the chaotic real world. Indeed, that is how <a class="thought" href="entries/intelligence_entry.html">intelligence</a> originated. It was the result of the evolutionary process we call natural selection, itself a simple <a class="thought" href="entries/paradigm_entry.html">paradigm</a>, that drew its <a class="thought" href="entries/complexity_entry.html">complexity</a> from the pandemonium of its environment. We see the same <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a> when we harness <a class="thought" href="entries/evolution_entry.html">evolution</a> in the <a class="thought" href="entries/computer_entry.html">computer</a>. We start with simple formulas, add the simple process of evolutionary iteration and combine this with the simplicity of massive <a class="thought" href="entries/computation_entry.html">computation</a>. The result is often complex, capable, and intelligent algorithms.</p>
<p>But we don't need to simulate the entire <a class="thought" href="entries/evolution_entry.html">evolution</a> of the human brain in order to tap the intricate secrets it contains. Just as a <a class="thought" href="entries/technology_entry.html">technology</a> company will take apart and "reverse engineer" (analyze to understand the methods of) a rival's products, we can do the same with the human brain. It is, after all, the best example we can get our hands on of an intelligent process. We can tap the <a class="thought" href="entries/architecture_entry.html">architecture</a>, organization, and innate <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of the human brain in order to greatly accelerate our understanding of how to design <a class="thought" href="entries/intelligence_entry.html">intelligence</a> in a <a class="thought" href="entries/machine_entry.html">machine</a>. By probing the brain's circuits, we can copy and imitate a proven design, one that took its original designer several billion years to develop. (And it's not even copyrighted.)</p>
<p>As we approach the computational ability to simulate the human brain--we're not there today, but we will begin to be in about a decade's time--such an effort will be intensely pursued. Indeed, this endeavor has already begun.</p>
<p>For example, Synaptics' <a class="thought" href="entries/vision_chip_entry.html">vision chip</a> is fundamentally a copy of the neural organization, implemented in <a class="thought" href="entries/silicon_entry.html">silicon</a> of course, of not only the human <a class="thought" href="entries/retina_entry.html">retina</a>, but the early stages of mammalian visual processing. It has captured the essence of the <a class="thought" href="entries/algorithm_entry.html">algorithm</a> of early mammalian visual processing, an <a class="thought" href="entries/algorithm_entry.html">algorithm</a> called center surround filtering. It is not a particularly complicated chip, yet it realistically captures the essence of the initial stages of human vision.</p>
<p>There is a popular conceit among observers, both informed and uninformed, that such a <a class="thought" href="entries/reverse_engineering_entry.html">reverse engineering</a> project is infeasible. Hofstadter worries that "our brains may be too weak to understand themselves."20 But that is not what we are finding. As we probe the brain's circuits, we find that the massively parallel algorithms are far from incomprehensible. Nor is there anything like an infinite <a class="thought" href="entries/number_entry.html">number</a> of them. There are hundreds of specialized regions in the brain, and it does have a rather ornate <a class="thought" href="entries/architecture_entry.html">architecture</a>, the consequence of its long <a class="thought" href="entries/history_entry.html">history</a>. The entire puzzle is not beyond our comprehension. It will certainly not be beyond the comprehension of twenty-first-century machines.</p>
<p>The <a class="thought" href="entries/knowledge_entry.html">knowledge</a> is right there in front of us, or rather inside of us. It is not impossible to get at. Let's start with the most straightforward scenario, one that is essentially feasible today (at least to initiate).</p>
<p>We start by freezing a recently deceased brain.</p>
<p>Now, before I get too many indignant reactions, let me wrap myself in <a class="thought" href="entries/da_vinci_entry.html">Leonardo da Vinci</a>'s cloak. Leonardo also received a disturbed reaction from his contemporaries. Here was a guy who stole dead bodies from the morgue, carted them back to his dwelling, and then took them apart. This was before dissecting dead bodies was in style. He did this in the name of <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, not a highly valued pursuit at the time. He wanted to learn how the human body works, but his contemporaries found his activities bizarre and disrespectful. Today we have a different view, that expanding our <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of this wondrous <a class="thought" href="entries/machine_entry.html">machine</a> is the most respectful homage we can pay. We cut up dead bodies all the time to learn more about how living bodies work, and to teach others what we have already learned.</p>
<p>There's no difference here in what I am suggesting. Except for one thing: I am talking about the brain, not the body. This strikes closer to home. We identify more with our brains than our bodies. <a class="thought" href="entries/brain_entry.html">Brain</a> surgery is regarded as more invasive than toe surgery. Yet the value of the <a class="thought" href="entries/knowledge_entry.html">knowledge</a> to be gained from probing the brain is too valuable to ignore. So we'll get over whatever squeamishness remains.</p>
<p>As I was saying, we start by freezing a dead brain. This is not a new concept--Dr. E. Fuller Torrey, a former supervisor at the National Institute of Mental Health and now head of the mental health branch of a private <a class="thought" href="entries/research_entry.html">research</a> foundation, has 44 freezers filled with 226 frozen brains.21 Torrey and his associates hope to gain insight into the causes of schizophrenia, so all of his brains are of deceased schizophrenic patients, which is probably not ideal for our purposes.</p>
<p>We examine one brain layer--one very thin slice--at a time. With suitably sensitive two-dimensional scanning equipment we should be able to see every <a class="thought" href="entries/neuron_entry.html">neuron</a> and every connection represented in each <a class="thought" href="entries/synapse_entry.html">synapse</a>-thin layer. When a layer has been examined and the requisite data stored, it can be scraped away to reveal the next slice. This <a class="thought" href="entries/information_entry.html">information</a> can be stored and assembled into a giant three-dimensional model of the brain's wiring and neural topology.</p>
<p>It would be better if the frozen brains were not already dead long before freezing. A dead brain will reveal a lot about living brains, but it is clearly not the ideal laboratory. Some of that deadness is bound to reflect itself in a deterioration of its neural <a class="thought" href="entries/structure_entry.html">structure</a>. We probably don't want to base our designs for intelligent machines on dead brains. We are likely to be able to take advantage of people who, facing imminent death, will permit their brains to be destructively scanned just slightly before rather than slightly after their brains would have stopped functioning on their own. Recently, a condemned killer allowed his brain and body to be scanned and you can <a class="thought" href="entries/access_entry.html">access</a> all 10 billion bytes of him on the <a class="thought" href="entries/internet_entry.html">Internet</a> at the <a class="thought" href="entries/center_for_human_simulation_entry.html">Center for Human Simulation</a>'s "Visible <a class="thought" href="entries/human_entry.html">Human</a> Project" web site.22 There's an even higher resolution 25-billion-byte <a class="thought" href="entries/female_entry.html">female</a> companion on the site as well. Although the scan of this couple is not high enough resolution for the scenario envisioned here, it's an example of donating one's brain for <a class="thought" href="entries/reverse_engineering_entry.html">reverse engineering</a>. Of course we may not want to base our templates of <a class="thought" href="entries/machine_entry.html">machine</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a> on the brain of a convicted killer, anyway.</p>
<p>Easier to talk about are the emerging noninvasive means of scanning our brains. I began with the more invasive scenario above because it is technically much easier. We have in fact the means to conduct a destructive scan today (although not yet the <a class="thought" href="entries/bandwidth_entry.html">bandwidth</a> to scan the entire brain in a reasonable amount of time). In terms of noninvasive scanning, high-speed, high-resolution magnetic resonance imaging (<a class="thought" href="entries/mri_entry.html">MRI</a>) scanners are already able to view individual somas (<a class="thought" href="entries/neuron_entry.html">neuron</a> cell bodies) without disturbing the living tissue being scanned. More powerful MRIs are being developed that will be capable of scanning individual nerve fibers that are only ten microns (millionths of a meter) in diameter. These will be available during the first decade of the twenty-first century. Eventually we will be able to scan the presynaptic vesicles that are the site of human <a class="thought" href="entries/learning_entry.html">learning</a>.</p>
<p>We can peer inside someone's brain today with <a class="thought" href="entries/mri_entry.html">MRI</a> scanners, which are increasing their resolution with each new generation of this <a class="thought" href="entries/technology_entry.html">technology</a>. There are a <a class="thought" href="entries/number_entry.html">number</a> of technical challenges in accomplishing this, including achieving suitable resolution, <a class="thought" href="entries/bandwidth_entry.html">bandwidth</a> (that is, speed of transmission), lack of vibration, and safety. For a variety of reasons it is easier to scan the brain of someone recently deceased than of someone still living. (It is easier to get someone deceased to sit still, for one thing.) But noninvasively scanning a living brain will ultimately become feasible as <a class="thought" href="entries/mri_entry.html">MRI</a> and other scanning technologies continue to improve in resolution and speed.</p>
<p>A new scanning <a class="thought" href="entries/technology_entry.html">technology</a> called <a class="thought" href="entries/optical_imaging_entry.html">optical imaging</a>, developed by Professor Amiram Grinvald at Israel's Weizmann Institute, is capable of significantly higher resolution than <a class="thought" href="entries/mri_entry.html">MRI</a>. Like <a class="thought" href="entries/mri_entry.html">MRI</a>, it is based on the interaction between electrical activity in the neurons and blood circulation in the capillaries feeding the neurons. Grinvald's <a class="thought" href="entries/device_entry.html">device</a> is capable of resolving features smaller than fifty microns, and can operate in real time, thus enabling scientists to view the firing of individual neurons. Grinvald and researchers at Germany's <a class="thought" href="entries/planck_entry.html">Max Planck</a> Institute were struck by the remarkable regularity of the patterns of neural firing when the brain was engaged in processing visual <a class="thought" href="entries/information_entry.html">information</a>.23 One of the researchers, Dr. Mark H&#252;bener, commented that "our maps of the working brain are so orderly they resemble the street map of Manhattan rather than, say, of a medieval European town." Grinvald, H&#252;bener, and their associates were able to use their brain scanner to distinguish between sets of neurons responsible for <a class="thought" href="entries/perception_entry.html">perception</a> of depth, shape, and color. As these neurons interact with one another, the resulting pattern of neural firings resembles elaborately linked mosaics. From the scans, it was possible for the researchers to see how the neurons were feeding <a class="thought" href="entries/information_entry.html">information</a> to each other. For example, they noted that the depth <a class="thought" href="entries/perception_entry.html">perception</a> neurons were arranged in parallel columns, providing <a class="thought" href="entries/information_entry.html">information</a> to the shape-detecting neurons that formed more elaborate pinwheel-like patterns. Currently, the Grinvald scanning <a class="thought" href="entries/technology_entry.html">technology</a> is only able to image a thin slice of the brain near its surface, but the Weizmann Institute is working on refinements that will extend its three-dimensional capability. Grinvald's scanning <a class="thought" href="entries/technology_entry.html">technology</a> is also being used to boost the resolution of <a class="thought" href="entries/mri_entry.html">MRI</a> scanning. A recent finding that near-infrared light can pass through the skull is also fueling excitement about the ability of <a class="thought" href="entries/optical_imaging_entry.html">optical imaging</a> as a high-resolution <a class="thought" href="entries/method_entry.html">method</a> of brain scanning.</p>
<p>The driving force behind the rapidly improving capability of noninvasive scanning technologies such as <a class="thought" href="entries/mri_entry.html">MRI</a> is again the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a>, because it requires massive computational ability to build the high-resolution, three-dimensional images from the raw magnetic resonance patterns that an <a class="thought" href="entries/mri_entry.html">MRI</a> scanner produces. The exponentially increasing computational ability provided by the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a> (and for another fifteen to twenty years, Moore's Law) will enable us to continue to rapidly improve the resolution and speed of these noninvasive scanning technologies.</p>
<p>Mapping the human brain <a class="thought" href="entries/synapse_entry.html">synapse</a> by <a class="thought" href="entries/synapse_entry.html">synapse</a> may seem like a daunting effort, but so did the <a class="thought" href="entries/human_genome_entry.html">Human</a> <a class="thought" href="entries/genome_entry.html">Genome Project</a>, an effort to map all human genes, when it was launched in 1991. Although the bulk of the human genetic code has still not been decoded, there is confidence at the nine American <a class="thought" href="entries/genome_entry.html">Genome</a> Sequencing Centers that the task will be completed, if not by 2005, then at least within a few years of that target date. Recently, a new private venture with funding from Perkin-Elmer has announced plans to sequence the entire human <a class="thought" href="entries/genome_entry.html">genome</a> by the year 2001. As I noted above, the pace of the human <a class="thought" href="entries/genome_entry.html">genome</a> scan was extremely slow in its early years, and has picked up speed with improved <a class="thought" href="entries/technology_entry.html">technology</a>, particularly <a class="thought" href="entries/computer_entry.html">computer</a> programs that identify the useful genetic <a class="thought" href="entries/information_entry.html">information</a>. The researchers are counting on further improvements in their gene-hunting <a class="thought" href="entries/computer_entry.html">computer</a> programs to meet their deadline. The same will be true of the human-brain-mapping project, as our methods of scanning and recording the 100 trillion neural connections pick up speed from the <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a>.</p><h1>What to Do with the <a class="thought" href="entries/information_entry.html">Information</a></h1><p>There are two scenarios for using the results of detailed brain scans. The most immediate--scanning the brain to understand it--is to scan portions of the brain to ascertain the <a class="thought" href="entries/architecture_entry.html">architecture</a> and implicit algorithms of interneuronal connections in different regions. The exact position of each and every nerve fiber is not as important as the overall pattern. With this <a class="thought" href="entries/information_entry.html">information</a> we can design simulated neural nets that operate similarly. This process will be rather like peeling an onion as each layer of human <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is revealed.</p>
<p>This is essentially what Synaptics has done in its chip that mimics mammalian neural-<a class="thought" href="entries/image_processing_entry.html">image processing</a>. This is also what Grinvald, H&#252;bener, and their associates plan to do with their visual-cortex scans. And there are dozens of other contemporary projects designed to scan portions of the brain and apply the resulting insights to the design of intelligent systems.</p>
<p>Within a region, the brain's circuitry is highly repetitive, so only a small portion of a region needs to be fully scanned. The computationally relevant activity of a <a class="thought" href="entries/neuron_entry.html">neuron</a> or group of neurons is sufficiently straightforward that we can understand and model these methods by examining them. Once the <a class="thought" href="entries/structure_entry.html">structure</a> and topology of the neurons, the organization of the interneuronal wiring, and the sequence of neural firing in a region have been observed, recorded, and analyzed, it becomes feasible to reverse engineer that region's parallel algorithms. After the algorithms of a region are understood, they can be refined and extended prior to being implemented in synthetic neural equivalents. The methods can certainly be greatly sped up given that electronics is already more than a million times faster than neural circuitry.</p>
<p>We can combine the revealed algorithms with the methods for building intelligent machines that we already understand. We can also discard aspects of human computing that may not be useful in a <a class="thought" href="entries/machine_entry.html">machine</a>. Of course, we'll have to be careful that we don't throw the baby out with the bathwater.</p><h1>Downloading Your <a class="thought" href="entries/mind_entry.html">Mind</a> to Your <a class="thought" href="entries/personal_computer_entry.html">Personal Computer</a></h1><p>A more challenging but also ultimately feasible scenario will be to scan someone's brain to map the locations, interconnections, and contents of the somas, axons, dendrites, presynaptic vesicles, and other neural components. Its entire organization could then be re-created on a <a class="thought" href="entries/neural_computer_entry.html">neural computer</a> of sufficient capacity, including the contents of its <a class="thought" href="entries/memory_entry.html">memory</a>.</p>
<p>This is harder in an obvious way than the scanning-the-brain-to-understand-it scenario. In the former, we need only sample each region until we understand the <a class="thought" href="entries/salient_entry.html">salient</a> algorithms. We can then combine those insights with <a class="thought" href="entries/knowledge_entry.html">knowledge</a> we already have. In this-scanning the brain to <a class="thought" href="entries/download_entry.html">download</a> it-scenario, we need to capture every little detail. On the other hand, we don't need to understand all of it; we need only to literally copy it, connection by connection, <a class="thought" href="entries/synapse_entry.html">synapse</a> by <a class="thought" href="entries/synapse_entry.html">synapse</a>, <a class="thought" href="entries/neurotransmitter_entry.html">neurotransmitter</a> by <a class="thought" href="entries/neurotransmitter_entry.html">neurotransmitter</a>. It requires us to understand local brain processes, but not necessarily the brain's global organization, at least not in full. It is likely that by the time we can do this, we will understand much of it, anyway.</p>
<p>To do this right, we do need to understand what the <a class="thought" href="entries/salient_entry.html">salient</a> <a class="thought" href="entries/information_entry.html">information</a>-processing mechanisms are. Much of a <a class="thought" href="entries/neuron_entry.html">neuron</a>'s elaborate <a class="thought" href="entries/structure_entry.html">structure</a> exists to support its own structural integrity and life processes and does not directly contribute to its handling of <a class="thought" href="entries/information_entry.html">information</a>. We know that <a class="thought" href="entries/neuron_entry.html">neuron</a>-computing processing is based on hundreds of different neurotransmitters and that different neural mechanisms in different regions allow for different types of computing. The early vision neurons, for example, are good at accentuating sudden color changes to facilitate finding the edges of objects. Hippocampus neurons are likely to have structures for enhancing the long-term retention of memories. We also know that neurons use a combination of <a class="thought" href="entries/digital_entry.html">digital</a> and <a class="thought" href="entries/analog_entry.html">analog</a> computing that needs to be accurately modeled. We need to identify structures capable of <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>, if any. All of the key features that affect <a class="thought" href="entries/information_entry.html">information</a> processing need to be recognized if we are to copy them accurately.</p>
<p>How well will this work? Of course, like any new <a class="thought" href="entries/technology_entry.html">technology</a>, it won't be perfect at first, and initial downloads will be somewhat imprecise. Small imperfections won't necessarily be immediately noticeable because people are always changing to some degree. As our understanding of the mechanisms of the brain improves and our ability to accurately and noninvasively scan these features improves, reinstantiating (reinstalling) a person's brain should alter a person's mind no more than it changes from day to day.</p><h1>What Will We Find When We Do This?</h1><p>We have to consider this question on both the objective and subjective levels. "Objective" means everyone except me, so let's start with that. Objectively, when we scan someone's brain and reinstantiate their personal <a class="thought" href="entries/mind_file_entry.html">mind file</a> into a suitable <a class="thought" href="entries/computing_medium_entry.html">computing medium</a>, the newly emergent "person" will appear to other observers to have very much the same personality, <a class="thought" href="entries/history_entry.html">history</a>, and <a class="thought" href="entries/memory_entry.html">memory</a> as the person originally scanned. Interacting with the newly instantiated person will feel like interacting with the original person. The new person will claim to be that same old person and will have a <a class="thought" href="entries/memory_entry.html">memory</a> of having been that person, having grown up in Brooklyn, having walked into a scanner here, and woken up in the <a class="thought" href="entries/machine_entry.html">machine</a> there. He'll say, "Hey, this <a class="thought" href="entries/technology_entry.html">technology</a> really works."</p>
<p>There is the small <a class="thought" href="entries/matter_entry.html">matter</a> of the "new person's" body. What kind of body will a reinstantiated personal <a class="thought" href="entries/mind_file_entry.html">mind file</a> have: the original human body, an upgraded body, a synthetic body, a nanoengineered body, a <a class="thought" href="entries/virtual_body_entry.html">virtual body</a> in a virtual environment? This is an important question, which I will discuss in the next chapter.</p>
<p>Subjectively, the question is more subtle and profound. Is this the same <a class="thought" href="entries/consciousness_entry.html">consciousness</a> as the person we just scanned? As we saw in chapter 3, there are strong arguments on both sides. The position that fundamentally we are our "pattern" (because our particles are always changing) would argue that this new person is the same because their patterns are essentially identical. The counter argument, however, is the possible continued <a class="thought" href="entries/existence_entry.html">existence</a> of the person who was originally scanned. If he--Jack--is still around, he will convincingly claim to represent the continuity of his <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. He may not be satisfied to let his mental clone carry on in his stead. We'll keep bumping into this issue as we explore the twenty-first century.</p>
<p>But once over the divide, the new person will certainly think that he was the original person. There will be no ambivalence in his mind as to whether or not he committed suicide when he agreed to be transferred into a new computing <a class="thought" href="entries/substrate_entry.html">substrate</a> leaving his old slow <a class="thought" href="entries/carbon_entry.html">carbon</a>-based neural-computing machinery behind. To the extent that he wonders at all whether or not he is really the same person that he thinks he is, he'll be glad that his old self took the plunge, because otherwise he wouldn't exist.</p>
<p>Is he-the newly installed mind-conscious? He certainly will claim to be. And being a lot more capable than his old neural self, he'll be persuasive and effective in his position. We'll believe him. He'll get mad if we don't.</p><h1>A Growing Trend</h1><p>In the second half of the twenty-first century, there will be a growing trend toward making this leap. Initially, there will be partial porting--replacing aging <a class="thought" href="entries/memory_entry.html">memory</a> circuits, extending pattern-recognition and reasoning circuits through neural implants. Ultimately, and well before the twenty-first century is completed, people will port their entire <a class="thought" href="entries/mind_file_entry.html">mind file</a> to the new <a class="thought" href="entries/thinking_entry.html">thinking</a> <a class="thought" href="entries/technology_entry.html">technology</a>.</p>
<p>There will be nostalgia for our humble <a class="thought" href="entries/carbon_entry.html">carbon</a>-based roots, but there is nostalgia for vinyl records also. Ultimately, we did copy most of that <a class="thought" href="entries/analog_entry.html">analog</a> music to the more flexible and capable world of transferable <a class="thought" href="entries/digital_entry.html">digital</a> <a class="thought" href="entries/information_entry.html">information</a>. The leap to port our minds to a more capable <a class="thought" href="entries/computing_medium_entry.html">computing medium</a> will happen gradually but inexorably nonetheless.</p>
<p>As we port ourselves, we will also vastly extend ourselves. Remember that $1,000 of computing in 2060 will have the computational capacity of a trillion human brains. So we might as well multiply <a class="thought" href="entries/memory_entry.html">memory</a> a trillion fold, greatly extend recognition and reasoning abilities, and plug ourselves into the pervasive <a class="thought" href="entries/wireless_entry.html">wireless</a>-communications <a class="thought" href="entries/network_entry.html">network</a>. While we are at it, we can add all human <a class="thought" href="entries/knowledge_entry.html">knowledge</a>--as a readily accessible internal <a class="thought" href="entries/database_entry.html">database</a> as well as already processed and learned <a class="thought" href="entries/knowledge_entry.html">knowledge</a> using the human type of distributed understanding.</p><h1>The Age of Neural Implants Has Already Started</h1><p>The patients are wheeled in on stretchers. Suffering from an advanced stage of Parkinson's <a class="thought" href="entries/disease_entry.html">disease</a>, they are like statues, their muscles frozen, their bodies and faces totally immobile. Then in a dramatic demonstration at a French clinic, the doctor in charge throws an electrical <a class="thought" href="entries/switch_entry.html">switch</a>. The patients suddenly come to life, get up, walk around, and calmly and expressively describe how they have overcome their debilitating symptoms. This is the dramatic result of a new <a class="thought" href="entries/neural_implant_entry.html">neural implant</a> therapy that is approved in Europe, and still awaits FDA approval in the United States.</p>
<p>The diminished levels of the <a class="thought" href="entries/neurotransmitter_entry.html">neurotransmitter</a> <a class="thought" href="entries/dopamine_entry.html">dopamine</a> in a Parkinson's patient causes overactivation of two tiny regions in the brain: the ventral posterior <a class="thought" href="entries/nucleus_entry.html">nucleus</a> and the subthalmic <a class="thought" href="entries/nucleus_entry.html">nucleus</a>. This overactivation in turn causes the slowness, stiffness, and gait difficulties of the <a class="thought" href="entries/disease_entry.html">disease</a>, and ultimately results in total paralysis and death. Dr. A. L. Benebid, a French physician at Fourier University in Grenoble, discovered that stimulating these regions with a permanently implanted electrode paradoxically inhibits these overactive regions and reverses the symptoms. The electrodes are wired to a small <a class="thought" href="entries/electronic_entry.html">electronic</a> control unit placed in the patient's chest. Through radio signals, the unit can be programmed, even turned on and off. When switched off, the symptoms immediately return. The treatment has the promise of controlling the most devastating symptoms of the <a class="thought" href="entries/disease_entry.html">disease</a>.24</p>
<p>Similar approaches have been used with other brain regions. For example, by implanting an electrode in the ventral lateral thalamus, the tremors associated with cerebral palsy, multiple sclerosis, and other tremor--causing conditions can be suppressed.</p>
<p> "We used to treat the brain like soup, adding chemicals that enhance or suppress certain neurotransmitters," says Rick Trosch, one of the American physicians helping to perfect "deep brain stimulation" therapies. "Now we're treating it like circuitry."25</p>
<p>Increasingly, we are starting to combat cognitive and sensory afflictions by treating the brain and nervous <a class="thought" href="entries/system_entry.html">system</a> like the complex computational <a class="thought" href="entries/system_entry.html">system</a> that it is. Cochlear implants together with <a class="thought" href="entries/electronic_entry.html">electronic</a> speech processors perform frequency analysis of sound waves, similar to that performed by the inner ear. About 10 percent of the formerly deaf persons who have received this neural replacement <a class="thought" href="entries/device_entry.html">device</a> are now able to hear and understand voices well enough that they can hold conversations using a normal telephone.</p>
<p>Neurologist and ophthalmologist at Harvard Medical School Dr. Joseph Rizzo and his colleagues have developed an experimental <a class="thought" href="entries/retina_entry.html">retina</a> implant. Rizzo's <a class="thought" href="entries/neural_implant_entry.html">neural implant</a> is a small solar-powered <a class="thought" href="entries/computer_entry.html">computer</a> that communicates to the optic nerve. The user wears special glasses with tiny television cameras that communicate to the implanted <a class="thought" href="entries/computer_entry.html">computer</a> by laser signal.  26 Researchers at Germany's <a class="thought" href="entries/planck_entry.html">Max Planck</a> Institute for Biochemistry have developed special <a class="thought" href="entries/silicon_entry.html">silicon</a> devices that can communicate with neurons in both directions. Directly stimulating neurons with an electrical current is not the ideal approach since it can cause corrosion to the electrodes and create chemical by-products that damage the cells. In contrast, the <a class="thought" href="entries/planck_entry.html">Max Planck</a> Institute devices are capable of triggering an adjacent <a class="thought" href="entries/neuron_entry.html">neuron</a> to fire without a direct electrical link. The Institute scientists demonstrated their <a class="thought" href="entries/invention_entry.html">invention</a> by controlling the movements of a living leech from their <a class="thought" href="entries/computer_entry.html">computer</a>.</p>
<p>Going in the opposite direction--from neurons to electronics--is a <a class="thought" href="entries/device_entry.html">device</a> called a "<a class="thought" href="entries/neuron_entry.html">neuron</a> <a class="thought" href="entries/transistor_entry.html">transistor</a>,"27 which can detect the firing of a <a class="thought" href="entries/neuron_entry.html">neuron</a>. The scientists hope to apply both technologies to the control of artificial human limbs by connecting spinal nerves to computerized prostheses. The Institute's Peter Fromherz says, "These two devices join the two worlds of <a class="thought" href="entries/information_entry.html">information</a> processing: the <a class="thought" href="entries/silicon_entry.html">silicon</a> world of the <a class="thought" href="entries/computer_entry.html">computer</a> and the water world of the brain."</p>
<p>Neurobiologist Ted Berger and his colleagues at Hedco Neurosciences and Engineering have built integrated circuits that precisely match the properties and <a class="thought" href="entries/information_entry.html">information</a> processing of groups of <a class="thought" href="entries/animal_entry.html">animal</a> neurons. The chips exactly mimic the <a class="thought" href="entries/digital_entry.html">digital</a> and <a class="thought" href="entries/analog_entry.html">analog</a> characteristics of the neurons they have analyzed. They are currently scaling up their <a class="thought" href="entries/technology_entry.html">technology</a> to systems with hundreds of neurons.28 Professor <a class="thought" href="entries/mead_entry.html">Carver Mead</a> and his colleagues at the California Institute of <a class="thought" href="entries/technology_entry.html">Technology</a> have also built <a class="thought" href="entries/digital_entry.html">digital</a>-<a class="thought" href="entries/analog_entry.html">analog</a> integrated circuits that match the processing of mammalian neural circuits comprising hundreds of neurons.29</p>
<p>The age of neural implants is under way, albeit at an early stage. Directly enhancing the <a class="thought" href="entries/information_entry.html">information</a> processing of our brain with synthetic circuits is focusing at first on correcting the glaring defects caused by neurological and sensory diseases and disabilities. Ultimately we will all find the benefits of extending our abilities through neural implants difficult to resist.</p><h1>The New <a class="thought" href="entries/mortality_entry.html">Mortality</a></h1><p>Actually there won't be <a class="thought" href="entries/mortality_entry.html">mortality</a> by the end of the twenty-first century. Not in the sense that we have known it. Not if you take advantage of the twenty-first century's brain-porting <a class="thought" href="entries/technology_entry.html">technology</a>. Up until now, our <a class="thought" href="entries/mortality_entry.html">mortality</a> was tied to the longevity of our <a class="thought" href="entries/hardware_entry.html">hardware</a>. When the <a class="thought" href="entries/hardware_entry.html">hardware</a> crashed, that was it. For many of our forebears, the <a class="thought" href="entries/hardware_entry.html">hardware</a> gradually deteriorated before it disintegrated. Yeats lamented our dependence on a physical self that was "but a paltry thing, a tattered coat upon a stick."30 As we cross the divide to instantiate ourselves into our computational <a class="thought" href="entries/technology_entry.html">technology</a>, our <a class="thought" href="entries/identity_entry.html">identity</a> will be based on our evolving <a class="thought" href="entries/mind_file_entry.html">mind file</a>. We will be <a class="thought" href="entries/software_entry.html">software</a>, not <a class="thought" href="entries/hardware_entry.html">hardware</a>.</p>
<p>And evolve it will. Today, our <a class="thought" href="entries/software_entry.html">software</a> cannot grow. It is stuck in a brain of a mere 100 trillion connections and synapses. But when the <a class="thought" href="entries/hardware_entry.html">hardware</a> is trillions of times more capable, there is no <a class="thought" href="entries/reason_entry.html">reason</a> for our minds to stay so small. They can and will grow.</p>
<p>As <a class="thought" href="entries/software_entry.html">software</a>, our <a class="thought" href="entries/mortality_entry.html">mortality</a> will no longer be dependent on the survival of the computing circuitry. There will still be <a class="thought" href="entries/hardware_entry.html">hardware</a> and bodies, but the essence of our <a class="thought" href="entries/identity_entry.html">identity</a> will <a class="thought" href="entries/switch_entry.html">switch</a> to the permanence of our <a class="thought" href="entries/software_entry.html">software</a>. Just as, today, we don't throw our files away when we change personal computers--we transfer them, at least the ones we want to keep. So, too, we won't throw our <a class="thought" href="entries/mind_file_entry.html">mind file</a> away when we periodically port ourselves to the latest, ever more capable, "personal" <a class="thought" href="entries/computer_entry.html">computer</a>. Of course, computers won't be the discrete objects they are today. They will be deeply embedded in our bodies, brains, and environment. Our <a class="thought" href="entries/identity_entry.html">identity</a> and survival will ultimately become independent of the <a class="thought" href="entries/hardware_entry.html">hardware</a> and its survival.</p>
<p>Our <a class="thought" href="entries/immortality_entry.html">immortality</a> will be a <a class="thought" href="entries/matter_entry.html">matter</a> of being sufficiently careful to make frequent backups. If we're careless about this, we'll have to load an old backup copy and be doomed to repeat our recent past.</p>
<p>Let's jump to the other side of this coming century. You said that by 2099 a penny of computing will be equal to a billion times the computing power of all human brains combined. Sounds like human <a class="thought" href="entries/thinking_entry.html">thinking</a> is going to be pretty trivial.</p>
<p>Unassisted, that's true.</p>
<blockquote>So how will we human beings fare in the midst of such competition?</blockquote>
<p>First, we have to recognize that the more powerful <a class="thought" href="entries/technology_entry.html">technology</a>--the technologically more sophisticated <a class="thought" href="entries/civilization_entry.html">civilization</a>--always wins. That appears to be what happened when our <a class="thought" href="entries/homo_sapiens_sapiens_entry.html">Homo sapiens sapiens</a> subspecies met the <a class="thought" href="entries/homo_sapiens_neanderthalensis_entry.html">Homo sapiens neanderthalensis</a> and other nonsurviving subspecies of <a class="thought" href="entries/homo_sapiens_entry.html">Homo sapiens</a>. That is what happened when the more technologically advanced Europeans encountered the <a class="thought" href="entries/indigenous_entry.html">indigenous</a> peoples of the Americas. This is happening today as the more advanced <a class="thought" href="entries/technology_entry.html">technology</a> is the key determinant of economic and <a class="thought" href="entries/military_entry.html">military</a> power.</p>
<blockquote>So we're going to be slaves to these smart machines?</blockquote>
<p>Slavery is not a fruitful economic <a class="thought" href="entries/system_entry.html">system</a> to either side in an age of intellect. We would have no value as slaves to machines. Rather, the relationship is starting out the other way.</p>
<blockquote>It's true that my personal computer does what I ask it to do--sometimes! Maybe I should start being nicer to it.</blockquote>
<p>No, it doesn't care how you treat it, not yet. But ultimately our native <a class="thought" href="entries/thinking_entry.html">thinking</a> capacities will be no match for the all-encompassing <a class="thought" href="entries/technology_entry.html">technology</a> we're creating.</p>
<blockquote>Maybe we should stop creating it.</blockquote>
<p>We can't stop. The <a class="thought" href="entries/law_of_accelerating_returns_entry.html">Law of Accelerating Returns</a> forbids it! It's the only way to keep <a class="thought" href="entries/evolution_entry.html">evolution</a> going at an accelerating pace.</p>
<blockquote>Hey, calm down. It's fine with me if evolution slows down a tad. Since when have we adopted your acceleration law as the law of the land?</blockquote>
<p>We don't have to. Stopping <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/technology_entry.html">technology</a>, or any fruitful <a class="thought" href="entries/technology_entry.html">technology</a>, would mean repealing basic realities of economic competition, not to mention our quest for <a class="thought" href="entries/knowledge_entry.html">knowledge</a>. It's not going to happen. Furthermore, the road we're going down is a road paved with gold. It's full of benefits that we're never going to resist--continued <a class="thought" href="entries/growth_entry.html">growth</a> in economic prosperity, better health, more intense <a class="thought" href="entries/communication_entry.html">communication</a>, more effective <a class="thought" href="entries/education_entry.html">education</a>, more engaging <a class="thought" href="entries/entertainment_entry.html">entertainment</a>, better sex.</p>
<blockquote>Until the computers take over.</blockquote>
<p>Look, this is not an alien invasion. Although it sounds unsettling, the advent of machines with vast <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is not necessarily a bad thing.</p>
<blockquote>I guess if we can't beat them, we'll have to join them.</blockquote>
<p>That's exactly what we're going to do. Computers started out as extensions of our minds, and they will end up extending our minds. Machines are already an integral part of our <a class="thought" href="entries/civilization_entry.html">civilization</a>, and the sensual and spiritual machines of the twenty-first century will be an even more intimate part of our <a class="thought" href="entries/civilization_entry.html">civilization</a>.</p>
<blockquote>Okay, in terms of extending my mind, let's get back to implants for my French Lit class. Is this going to be like I've read this stuff? Or is it just going to be like a smart personal computer that I can communicate with quickly because it happens to be located in my head?</blockquote>
<p>That's a key question, and I think it will be controversial. It gets back to the issue of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. Some people will feel that what goes in their neural implants is indeed subsumed by their <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. Others will feel that it remains outside of their sense of self. Ultimately, I think that we will regard the mental activity of the implants as part of our own <a class="thought" href="entries/thinking_entry.html">thinking</a>. Consider that even without implants, ideas and thoughts are constantly popping into our heads, and we have little idea of where they came from, or how they got there. We nonetheless consider all the mental phenomena that we become aware of as our own thoughts.</p>
<blockquote>So I'll be able to download memories of experiences I've never had?</blockquote>
<p>Yes, but someone has probably had the experience. So why not have the ability to share it?</p>
<blockquote>I suppose for some experiences, it might be safer to just download the memories of it.</blockquote>
<p>Less time-consuming also.</p>
<blockquote>Do you really think that scanning a frozen brain is feasible today?</blockquote>
<p>Sure, just stick your head in my freezer here.</p>
<blockquote>Gee, are you sure this is safe?</blockquote>
<p>Absolutely.</p>
<blockquote>Well, I think I'll wait for FDA approval.</blockquote>
<p>Okay, then you'll have to wait a long time.</p>
<blockquote>Thinking ahead, I still have this sense that we're doomed. I mean, I can understand how a newly instantiated mind, as you put it, will be happy that she was created and will think that she had been me prior to my having been scanned and is still me in a shiny new brain. She'll have no regrets and will be on the "other side." But I don't see how I can get across the human-machine divide. As you pointed out, if I'm scanned, that new me isn't me because I'm still here in my old brain.</blockquote>
<p>Yes, there's a little glitch in this regard. But I'm sure we'll figure how to solve this thorny problem with a little more consideration.</p>
<p>Originally published in <i>The Age of Spiritual Machines</i> (<a class="thought" href="entries/c_entry.html">C</a>)1999 <a class="thought" href="entries/kurzweil_entry.html">Raymond Kurzweil</a>
</p>
</td><td>&#160;</td><td valign="top"><a href="https://web.archive.org/web/20010814212636/http://www.kurzweilai.net/mindx/frame.html?main=post.php?artID%3D19" target="_top">Be the first to comment on this article!</a></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20010814212636im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p class="mindxheader">[<a href="https://web.archive.org/web/20010814212636/http://www.kurzweilai.net/mindx/frame.html?main=post.php?artID%3D19" target="_top">Post New Comment</a>]<p></p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>