<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>Consciousness in Human and Robot Minds</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/meme/memelist.html?m=4">Will Machines Become Conscious?</a> &gt; 
Consciousness in Human and Robot Minds
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20071011164315/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0474.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0474.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/articles/art0474.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">Consciousness in Human and Robot Minds</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0031.html" target="_top">Daniel Dennett</a><br></span></td>
</table>
<br>
<div class="TeaserText">AI skeptics offer several reasons why robots could never become conscious. MITs' humanoid Cog robot project may give them pause.</div>
<br>
<br><i>Originally published May 1997 
            in the book <a href="http://web.archive.org/web/20071011164315/http://www.oup.co.uk/isbn/0-19-852414-5" target="_blank">Cognition, 
            Computation, and Consciousness</a>. Published on KurzweilAI.net on 
            June 6, 2002.</i>
<h2>1. Good and Bad Grounds for Skepticism </h2>
<p>The best <a class="thought" href="entries/reason_entry.html">reason</a> for believing that robots might some day become 
              conscious is that we <a class="thought" href="entries/human_entry.html">human</a> beings are conscious, and we are a <i>sort</i> 
              of <a class="thought" href="entries/robot_entry.html">robot</a> ourselves. That is, we are extraordinarily complex self-controlling, 
              self-sustaining physical mechanisms, designed over the eons by natural 
              selection, and operating according to the same well-understood principles 
              that govern all the other physical processes in living things: digestive 
              and metabolic processes, self-repair and reproductive processes, 
              for <a class="thought" href="entries/instance_entry.html">instance</a>. It may be wildly over-ambitious to suppose that <a class="thought" href="entries/human_entry.html">human</a> 
              artificers can repeat <a class="thought" href="entries/nature_entry.html">Nature</a>'s triumph, with variations in material, 
              form, and design process, but this is not a deep <a class="thought" href="entries/object_entry.html">object</a>ion. It is 
              not as if a conscious <a class="thought" href="entries/machine_entry.html">machine</a> contradicted any fundamental laws 
              of <a class="thought" href="entries/nature_entry.html">nature</a>, the way a perpetual <a class="thought" href="entries/motion_entry.html">motion</a> <a class="thought" href="entries/machine_entry.html">machine</a> does. Still, many 
              skeptics believe -- or in any <a class="thought" href="entries/event_entry.html">event</a> want to believe -- that it will 
              never be done. I wouldn't wager against them, but my <a class="thought" href="entries/reason_entry.html">reason</a>s for 
              skepticism are mundane, economic <a class="thought" href="entries/reason_entry.html">reason</a>s, not theoretical <a class="thought" href="entries/reason_entry.html">reason</a>s. 
            </p>
<p>Conscious robots probably will always simply cost too much to make. 
              Nobody will ever synthesize a gall bladder out of atoms of the requisite 
              <a class="thought" href="entries/element_entry.html">element</a>s, but I think it is uncontroversial that a gall bladder 
              is nevertheless "just" a stupendous assembly of such atoms. 
              Might a conscious <a class="thought" href="entries/robot_entry.html">robot</a> be "just" a stupendous assembly 
              of more <a class="thought" href="entries/element_entry.html">element</a>ary <a class="thought" href="entries/artifact_entry.html">artifact</a>s -- <a class="thought" href="entries/silicon_entry.html">silicon</a> chips, wires, tiny motors 
              and cameras -- or would any such assembly, of whatever size and 
              sophistication, have to leave out some special ingredient that is 
              requisite for <a class="thought" href="entries/consciousness_entry.html">consciousness</a>? </p>
<p>Let us briefly survey a nested series of <a class="thought" href="entries/reason_entry.html">reason</a>s someone might 
              advance for the impossibility of a conscious robot: </p>
<p>
<blockquote>
<p>(1) Robots are purely material things, and <a class="thought" href="entries/consciousness_entry.html">consciousness</a> requires 
                  immaterial <a class="thought" href="entries/mind_entry.html">mind</a>-stuff. (Old-fashioned dualism) </p>
</blockquote>
</p>
<p>It continues to amaze me how attractive this position still is 
              to many people. I would have <a class="thought" href="entries/thought_entry.html">thought</a> a historical perspective alone 
              would make this view seem ludicrous: over the centuries, every <i>other</i>
<a class="thought" href="entries/phenomenon_entry.html">phenomenon</a> of initially "supernatural" mysteriousness 
              has succumbed to an uncontroversial explanation within the commodious 
              folds of physical <a class="thought" href="entries/science_entry.html">science</a>. <a class="thought" href="entries/thales_entry.html">Thales</a>, the Pre-Socratic proto-scientist, 
              <a class="thought" href="entries/thought_entry.html">thought</a> the loadstone had a <a class="thought" href="entries/soul_entry.html">soul</a>, but we now know better; magnetism 
              is one of the best understood of physical phenomena, strange though 
              its manifestations are. The "miracles" of <a class="thought" href="entries/life_entry.html">life</a> itself, 
              and of reproduction, are now analyzed into the well-known intricacies 
              of molecular <a class="thought" href="entries/biology_entry.html">biology</a>. Why should <a class="thought" href="entries/consciousness_entry.html">consciousness</a> be any exception? 
              Why should the <a class="thought" href="entries/brain_entry.html">brain</a> be the only complex physical <a class="thought" href="entries/object_entry.html">object</a> in the 
              <a class="thought" href="entries/universe_entry.html">universe</a> to have an <a class="thought" href="entries/interface_entry.html">interface</a> with another realm of being? Besides, 
              the notorious problems with the supposed transactions at that dualistic 
              <a class="thought" href="entries/interface_entry.html">interface</a> are as good as a <i>reductio ad absurdum</i> of the view. 
              The phenomena of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> are an admittedly dazzling lot, but 
              I suspect that dualism would never be seriously considered if there 
              weren't such a strong undercurrent of desire to protect the <a class="thought" href="entries/mind_entry.html">mind</a> 
              from <a class="thought" href="entries/science_entry.html">science</a>, by supposing it composed of a stuff that is in principle 
              uninvestigatable by the <a class="thought" href="entries/method_entry.html">method</a>s of the physical <a class="thought" href="entries/science_entry.html">science</a>s. </p>
<p>But if you are willing to concede the hopelessness of dualism, 
              and accept some version of <a class="thought" href="entries/materialism_entry.html">materialism</a>, you might still hold: </p>
<p>
<blockquote>
<p>(2) Robots are inorganic (by definition), and <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
                  can exist only in an organic <a class="thought" href="entries/brain_entry.html">brain</a>. </p>
</blockquote>
</p>
<p>Why might this be? Instead of just hooting this view off the stage 
              as an embarrassing throwback to old-fashioned <a class="thought" href="entries/vitalism_entry.html">vitalism</a>, we might 
              pause to note that there is a respectable, if not very interesting, 
              way of defending this claim. <a class="thought" href="entries/vitalism_entry.html">Vitalism</a> is deservedly dead; as biochemistry 
              has shown in matchless detail, the powers of organic compounds are 
              themselves all mechanistically reducible and hence mechanistically 
              reproducible at one scale or another in alternative physical media; 
              but it is conceivable -- if unlikely -- that the sheer speed and 
              compactness of biochemically <a class="thought" href="entries/engine_entry.html">engine</a>ered processes in the <a class="thought" href="entries/brain_entry.html">brain</a> are 
              in fact unreproducible in other physical <a class="thought" href="entries/media_entry.html">media</a> (Dennett, 1987). 
              So there might be straightforward <a class="thought" href="entries/reason_entry.html">reason</a>s of <a class="thought" href="entries/engine_entry.html">engine</a>ering that showed 
              that any <a class="thought" href="entries/robot_entry.html">robot</a> that could not make use of organic tissues of one 
              sort or another within its fabric would be too ungainly to execute 
              some task critical for <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. If making a conscious <a class="thought" href="entries/robot_entry.html">robot</a> 
              were conceived of as a sort of sporting <a class="thought" href="entries/event_entry.html">event</a> -- like the America's 
              Cup -- rather than a scientific endeavor, this could raise a curious 
              conflict over the official rules. Team A wants to use artificially 
              constructed organic polymer "muscles" to move its <a class="thought" href="entries/robot_entry.html">robot</a>'s 
              limbs, because otherwise the motor <a class="thought" href="entries/noise_entry.html">noise</a> wreaks havoc with the <a class="thought" href="entries/robot_entry.html">robot</a>'s 
              artificial ears. Should this be allowed? Is a <a class="thought" href="entries/robot_entry.html">robot</a> with "muscles" 
              instead of motors a <a class="thought" href="entries/robot_entry.html">robot</a> within the meaning of the act? If muscles 
              are allowed, what about lining the <a class="thought" href="entries/robot_entry.html">robot</a>'s artificial <a class="thought" href="entries/retina_entry.html">retina</a>s with 
              genuine organic rods and cones instead of relying on relatively 
              clumsy color-TV <a class="thought" href="entries/technology_entry.html">technology</a>? </p>
<p>I take it that no serious scientific or philosophical thesis links 
              its <a class="thought" href="entries/fate_entry.html">fate</a> to the <a class="thought" href="entries/fate_entry.html">fate</a> of the proposition that a <i><a class="thought" href="entries/protein_entry.html">protein</a>-free</i> 
              conscious <a class="thought" href="entries/robot_entry.html">robot</a> can be made, for example. The standard understanding 
              that a <a class="thought" href="entries/robot_entry.html">robot</a> shall be made of metal, <a class="thought" href="entries/silicon_entry.html">silicon</a> chips, glass, plastic, 
              rubber and such, is an <a class="thought" href="entries/expression_entry.html">expression</a> of the willingness of theorists 
              to bet on a simplification of the issues: their conviction is that 
              the crucial functions of <a class="thought" href="entries/intelligence_entry.html">intelligence</a> can be achieved by one high-level 
              simulation or another, so that it would be no undue hardship to 
              restrict themselves to these materials, the readily available cost-effective 
              ingredients in any case. But if somebody were to invent some sort 
              of cheap artificial <a class="thought" href="entries/neural_network_entry.html">neural network</a> fabric that could usefully be 
              spliced into various tight corners in a <a class="thought" href="entries/robot_entry.html">robot</a>'s control <a class="thought" href="entries/system_entry.html">system</a>, 
              the embarrassing fact that this fabric was made of organic <a class="thought" href="entries/molecule_entry.html">molecule</a>s 
              would not and should not dissuade serious roboticists from using 
              it -- and simply taking on the burden of explaining to the uninitiated 
              why this did not constitute "cheating" in any <a class="thought" href="entries/import_entry.html">import</a>ant 
              <a class="thought" href="entries/sense_entry.html">sense</a>. </p>
<p>I have discovered that some people are attracted by a third <a class="thought" href="entries/reason_entry.html">reason</a> 
              for believing in the impossibility of conscious robots. </p>
<p>
<blockquote>
<p>(3) Robots are <a class="thought" href="entries/artifact_entry.html">artifact</a>s, and <a class="thought" href="entries/consciousness_entry.html">consciousness</a> abhors an <a class="thought" href="entries/artifact_entry.html">artifact</a>; 
                  only something natural, born not manufactured, could exhibit 
                  genuine <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. </p>
</blockquote>
</p>
<p>Once again, it is tempting to dismiss this claim with derision, 
              and in some of its forms, derision is just what it deserves. Consider 
              the general category of creed we might call <i>origin essentialism</i>: 
              only wine made under the direction of the proprietors of Chateau 
              Plonque counts as genuine Chateau Plonque; only a canvas every blotch 
              on which was caused by the hand of Cezanne counts as a genuine Cezanne; 
              only someone "with Cherokee blood" can be a real Cherokee. 
              There are perfectly respectable <a class="thought" href="entries/reason_entry.html">reason</a>s, eminently defensible in 
              a court of law, for maintaining such distinctions, so long as they 
              are understood to be protections of rights growing out of historical 
              processes. If they are interpreted, however, as indicators of "intrinsic 
              properties" that <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> their holders apart from their otherwise 
              indistinguishable counterparts, they are pernicious nonsense. Let 
              us dub <i>origin chauvinism</i> the category of view that holds 
              out for some mystic difference (a difference of value, typically) 
              due <i>simply</i> to such a fact about origin. Perfect imitation 
              Chateau Plonque is exactly as good a wine as the real thing, counterfeit 
              though it is, and the same holds for the fake Cezanne, if it is 
              really indistinguishable by experts. And of course no person is 
              intrinsically better or worse in any regard just for having or not 
              having Cherokee (or Jewish, or African) "blood." </p>
<p>And to take a threadbare philosophical example, an <a class="thought" href="entries/atom_entry.html">atom</a>-for-<a class="thought" href="entries/atom_entry.html">atom</a> 
              duplicate of a <a class="thought" href="entries/human_entry.html">human</a> being, an <a class="thought" href="entries/artifact_entry.html">artifact</a>ual counterfeit of you, let 
              us say, might not <i>legally</i> be you, and hence might not be 
              entitled to your belongings, or deserve your punishments, but the 
              suggestion that such a being would not be a feeling, conscious, 
              alive <i>person</i> as genuine as any born of woman is preposterous 
              nonsense, all the more deserving of our ridicule because if taken 
              seriously it might seem to lend credibility to the racist drivel 
              with which it shares a bogus "intuition". </p>
<p>If <a class="thought" href="entries/consciousness_entry.html">consciousness</a> abhors an <a class="thought" href="entries/artifact_entry.html">artifact</a>, it cannot be because being 
              born gives a complex of cells a property (aside from that historic 
              property itself) that it could not otherwise have "in principle". 
              There might, however, be a question of practicality. We have just 
              seen how, as a <a class="thought" href="entries/matter_entry.html">matter</a> of exigent practicality, it could turn out 
              after all that organic materials were needed to make a conscious 
              <a class="thought" href="entries/robot_entry.html">robot</a>. For similar <a class="thought" href="entries/reason_entry.html">reason</a>s, it could turn out that any conscious 
              <a class="thought" href="entries/robot_entry.html">robot</a> had to be, if not born, at least the beneficiary of a longish 
              period of infancy. Making a fully equipped conscious adult <a class="thought" href="entries/robot_entry.html">robot</a> 
              might just be too much work. It might be vastly easier to make an 
              initially unconscious or nonconscious "infant" <a class="thought" href="entries/robot_entry.html">robot</a> and 
              let it "grow up" into <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, more or less the 
              way we all do. This hunch is not the disreputable claim that a certain 
              sort of historic process puts a mystic stamp of approval on its 
              product, but the more interesting and plausible claim that a certain 
              sort of process is the only practical way of designing all the things 
              that need designing in a conscious being. </p>
<p>Such a claim is entirely <a class="thought" href="entries/reason_entry.html">reason</a>able. Compare it to the claim one 
              might make about the creation of <a class="thought" href="entries/spielberg_entry.html">Steven Spielberg</a>'s film, <i>Schindler's 
              List</i>: it could not have been created entirely by <a class="thought" href="entries/computer_entry.html">computer</a> animation, 
              without the filming of real live actors. This impossibility claim 
              must be false "in principle," since every frame of that 
              film is nothing more than a <a class="thought" href="entries/matrix_entry.html">matrix</a> of gray-scale pixels of the sort 
              that <a class="thought" href="entries/computer_entry.html">computer</a> animation can manifestly create, at any level of detail 
              or "realism" you are willing to pay for. There is nothing 
              mystical, however, about the claim that it would be practically 
              impossible to render the nuances of that film by such a bizarre 
              exercise of <a class="thought" href="entries/technology_entry.html">technology</a>. How much easier it is, practically, to put 
              actors in the relevant circumstances, in a concrete simulation of 
              the scenes one wishes to portray, and let them, via ensemble activity 
              and re-activity, provide the <a class="thought" href="entries/information_entry.html">information</a> to the cameras that will 
              then fill in all the pixels in each frame. This little exercise 
              of the <a class="thought" href="entries/imagination_entry.html">imagination</a> helps to drive home just how much <a class="thought" href="entries/information_entry.html">information</a> 
              there is in a "realistic" film, but even a great film, 
              such as <i>Schindler's List</i>, for all its <a class="thought" href="entries/complexity_entry.html">complexity</a>, is a simple, 
              non-interactive <a class="thought" href="entries/artifact_entry.html">artifact</a> many orders of magnitude less complex than 
              a conscious being. </p>
<p>When <a class="thought" href="entries/robot_entry.html">robot</a>-makers have claimed in the past that in principle they 
              could construct "by hand" a conscious <a class="thought" href="entries/robot_entry.html">robot</a>, this was 
              a hubristic overstatement <a class="thought" href="entries/analog_entry.html">analog</a>ous to what Walt Disney might once 
              have proclaimed: that his studio of animators could create a film 
              so realistic that no one would be able to tell that it was a cartoon, 
              not a "live <a class="thought" href="entries/action_entry.html">action</a>" film. What Disney couldn't do in fact, 
              <a class="thought" href="entries/computer_entry.html">computer</a> animators still cannot do, but perhaps only for the <a class="thought" href="entries/time_entry.html">time</a> 
              being. <a class="thought" href="entries/robot_entry.html">Robot</a> makers, even with the latest high-tech innovations, 
              also fall far short of their hubristic goals, now and for the foreseeable 
              <a class="thought" href="entries/future_entry.html">future</a>. The comparison serves to expose the likely source of the 
              outrage so many skeptics feel when they encounter the manifestos 
              of the Artificial Intelligencia. Anyone who seriously claimed that 
              <i>Schindler's List</i> could in fact have been made by <a class="thought" href="entries/computer_entry.html">computer</a> 
              animation could be seen to betray an obscenely impoverished <a class="thought" href="entries/sense_entry.html">sense</a> 
              of what is conveyed in that film. An <a class="thought" href="entries/import_entry.html">import</a>ant <a class="thought" href="entries/element_entry.html">element</a> of the film's 
              power if the fact that it <i>is</i> a film made by assembling <a class="thought" href="entries/human_entry.html">human</a> 
              actors to portray those events, and that it is not actually the 
              newsreel footage that its black-and-white format reminds you of. 
              When one juxtaposes in one's <a class="thought" href="entries/imagination_entry.html">imagination</a> a <a class="thought" href="entries/sense_entry.html">sense</a> of what the actors 
              must have gone through to make the film with a <a class="thought" href="entries/sense_entry.html">sense</a> of what the 
              people who actually lived the events went through, this reflection 
              sets up reverberations in one's <a class="thought" href="entries/thinking_entry.html">thinking</a> that draw attention to 
              the deeper meanings of the film. Similarly, when <a class="thought" href="entries/robot_entry.html">robot</a> enthusiasts 
              proclaim the likelihood that they can simply <i>construct</i> a 
              conscious <a class="thought" href="entries/robot_entry.html">robot</a>, there is an understandable suspicion that they 
              are simply betraying an infantile grasp of the subtleties of conscious 
              <a class="thought" href="entries/life_entry.html">life</a>. (I hope I have put enough feeling into that condemnation to 
              satisfy the skeptics.) </p>
<p>But however justified that might be in some <a class="thought" href="entries/instance_entry.html">instance</a>s as an <i>ad 
              hominem</i> suspicion, it is simply irrelevant to the <a class="thought" href="entries/import_entry.html">import</a>ant 
              theoretical issues. Perhaps no cartoon could be a great film, but 
              they are certainly real films -- and some are indeed good films; 
              if the best the roboticists can hope for is the creation of some 
              crude, cheesy, second-rate, artificial <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, they still 
              win. Still, it is not a foregone conclusion that even this modest 
              goal is reachable. If you want to have a defensible <a class="thought" href="entries/reason_entry.html">reason</a> for claiming 
              that no conscious <a class="thought" href="entries/robot_entry.html">robot</a> will ever be created, you might want to 
              settle for this: </p>
<p>
<blockquote>
<p>(4) Robots will always just be much too simple to be conscious. 
                </p>
</blockquote>
</p>
<p>After all, a normal <a class="thought" href="entries/human_entry.html">human</a> being is composed of trillions of parts 
              (if we descend to the level of the macromolecules), and many of 
              these rival in <a class="thought" href="entries/complexity_entry.html">complexity</a> and design cunning the fanciest <a class="thought" href="entries/artifact_entry.html">artifact</a>s 
              that have ever been created. We consist of billions of cells, and 
              a single <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/cell_entry.html">cell</a> contains within itself complex "machinery" 
              that is still well beyond the <a class="thought" href="entries/artifact_entry.html">artifact</a>ual powers of <a class="thought" href="entries/engine_entry.html">engine</a>ers. We 
              are composed of thousands of different kinds of cells, including 
              thousands of different <a class="thought" href="entries/species_entry.html">species</a> of symbiont visitors, some of whom 
              might be as <a class="thought" href="entries/import_entry.html">import</a>ant to our <a class="thought" href="entries/consciousness_entry.html">consciousness</a> as others are to our 
              ability to digest our food! If all that <a class="thought" href="entries/complexity_entry.html">complexity</a> were needed for 
              <a class="thought" href="entries/consciousness_entry.html">consciousness</a> to exist, then the task of making a single conscious 
              <a class="thought" href="entries/robot_entry.html">robot</a> would dwarf the entire scientific and <a class="thought" href="entries/engine_entry.html">engine</a>ering resources 
              of the <a class="thought" href="entries/planet_entry.html">planet</a> for millennia. And who would pay for it? </p>
<p>If no other <a class="thought" href="entries/reason_entry.html">reason</a> can be found, this may do to ground your skepticism 
              about conscious robots in your <a class="thought" href="entries/future_entry.html">future</a>, but one shortcoming of this 
              last <a class="thought" href="entries/reason_entry.html">reason</a> is that it is scientifically boring. If this is the 
              only <a class="thought" href="entries/reason_entry.html">reason</a> there won't be conscious robots, then <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
              isn't that special, after all. Another shortcoming with this <a class="thought" href="entries/reason_entry.html">reason</a> 
              is that it is dubious on its face. Everywhere else we have looked, 
              we have found higher-level commonalities of function that permit 
              us to substitute relatively simple bits for fiendishly complicated 
              bits. Artificial heart valves work really very well, but they are 
              orders of magnitude simpler than organic heart valves, heart valves 
              born of woman or sow, you might say. Artificial ears and eyes that 
              will do a serviceable (if crude) job of substituting for lost perceptual 
              organs are visible on the horizon, and anyone who doubts they are 
              possible in principle is simply out of touch. Nobody ever said a 
              prosthetic eye had to see as keenly, or focus as fast, or be as 
              sensitive to color gradations as a normal <a class="thought" href="entries/human_entry.html">human</a> (or other <a class="thought" href="entries/animal_entry.html">animal</a>) 
              eye in <a class="thought" href="entries/order_entry.html">order</a> to "count" as an eye. If an eye, why not 
              an optic <a class="thought" href="entries/nerve_entry.html">nerve</a> (or acceptable substitute thereof), and so forth, 
              all the way in? </p>
<p>Some (Searle, 1992, Mangan, 1993) have supposed, most improbably, 
              that this proposed regress would somewhere run into a non-fungible 
              medium of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, a part of the <a class="thought" href="entries/brain_entry.html">brain</a> that could not be substituted 
              on pain of <a class="thought" href="entries/death_entry.html">death</a> or zombiehood. Once the implications of that view 
              are spelled out (Dennett, 1993a, 1993b), one can see that it is 
              a non-starter. There is no <a class="thought" href="entries/reason_entry.html">reason</a> at all to believe that some one 
              part of the <a class="thought" href="entries/brain_entry.html">brain</a> is utterly irreplaceable by prosthesis, provided 
              we allow that some crudity, some loss of function, is to be expected 
              in most substitutions of the simple for the complex. An artificial 
              <a class="thought" href="entries/brain_entry.html">brain</a> is, on the face of it, as "possible in principle" 
              as an artificial heart, just much, much harder to make and hook 
              up. Of course once we start letting crude forms of prosthetic <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
              -- like crude forms of prosthetic vision or hearing -- pass our 
              litmus tests for <a class="thought" href="entries/consciousness_entry.html">consciousness</a> (whichever tests we favor) the way 
              is open for another boring debate, over whether the phenomena in 
              question are too crude to count. </p>
<h2>2. The <a class="thought" href="entries/cog_entry.html">Cog</a> Project: A <a class="thought" href="entries/humanoid_entry.html">Humanoid</a> <a class="thought" href="entries/robot_entry.html">Robot</a> </h2>
<p>A much more interesting tack to explore, in my opinion, is simply 
              to <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> out to make a <a class="thought" href="entries/robot_entry.html">robot</a> that is theoretically interesting independent 
              of the philosophical conundrum about whether it is conscious. Such 
              a <a class="thought" href="entries/robot_entry.html">robot</a> would have to perform a lot of the feats that we have typically 
              associated with <a class="thought" href="entries/consciousness_entry.html">consciousness</a> in the past, but we would not need 
              to dwell on that issue from the outset. Maybe we could even learn 
              something interesting about what the truly hard problems are without 
              ever settling any of the issues about <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. </p>
<p>Such a project is now underway at MIT. Under the direction of Professors 
              <a class="thought" href="entries/brooks_entry.html">Rodney Brooks</a> and Lynn Andrea Stein of the <a class="thought" href="entries/ai_entry.html">AI</a> Lab, a group of bright, 
              hard-working young graduate students are laboring as I speak to 
              create <a class="thought" href="entries/cog_entry.html">Cog</a>, the most <a class="thought" href="entries/humanoid_entry.html">humanoid</a> <a class="thought" href="entries/robot_entry.html">robot</a> yet attempted, and I am happy 
              to be a part of the <a class="thought" href="entries/cog_entry.html">Cog</a> team. <a class="thought" href="entries/cog_entry.html">Cog</a> is just about <a class="thought" href="entries/life_entry.html">life</a>-size -- that 
              is, about the size of a <a class="thought" href="entries/human_entry.html">human</a> adult. <a class="thought" href="entries/cog_entry.html">Cog</a> has no legs, but lives 
              bolted at the hips, you might say, to its stand. It has two <a class="thought" href="entries/human_entry.html">human</a>-length 
              arms, however, with somewhat simple hands on the wrists. It can 
              bend at the waist and swing its torso, and its head moves with three 
              degrees of <a class="thought" href="entries/freedom_entry.html">freedom</a> just about the way yours does. It has two eyes, 
              each equipped with both a foveal high-resolution vision area and 
              a low-resolution wide-angle parafoveal vision area, and these eyes 
              saccade at almost <a class="thought" href="entries/human_entry.html">human</a> speed. That is, the two eyes can complete 
              approximately three fixations a second, while you and I can manage 
              four or five. Your foveas are at the center of your <a class="thought" href="entries/retina_entry.html">retina</a>s, surrounded 
              by the grainier low-resolution parafoveal areas; for <a class="thought" href="entries/reason_entry.html">reason</a>s of 
              <a class="thought" href="entries/engine_entry.html">engine</a>ering simplicity, <a class="thought" href="entries/cog_entry.html">Cog</a>'s eyes have their foveas mounted above 
              their wide-angle vision areas. </p>
<p>This is typical of the sort of compromise that the <a class="thought" href="entries/cog_entry.html">Cog</a> team is 
              willing to make. It amounts to a wager that a vision <a class="thought" href="entries/system_entry.html">system</a> with 
              the foveas moved out of the middle can still work well enough not 
              to be debilitating, and the problems encountered will not be irrelevant 
              to the problems encountered in normal <a class="thought" href="entries/human_entry.html">human</a> vision. After all, <a class="thought" href="entries/nature_entry.html">nature</a> 
              gives us examples of other eyes with different foveal arrangements. 
              Eagles have three different foveas in each eye, for <a class="thought" href="entries/instance_entry.html">instance</a>, and 
              rabbit eyes are another story all together. <a class="thought" href="entries/cog_entry.html">Cog</a>'s eyes won't give 
              it visual <a class="thought" href="entries/information_entry.html">information</a> exactly like that provided to <a class="thought" href="entries/human_entry.html">human</a> vision 
              by <a class="thought" href="entries/human_entry.html">human</a> eyes (in fact, of course, it will be vastly degraded), 
              but the wager is that this will be plenty to give <a class="thought" href="entries/cog_entry.html">Cog</a> the opportunity 
              to perform impressive feats of hand-eye coordination, identification, 
              and <a class="thought" href="entries/search_entry.html">search</a>. At the outset, <a class="thought" href="entries/cog_entry.html">Cog</a> will not have color vision. </p>
<p>Since its eyes are video cameras mounted on delicate, fast-moving 
              gimbals, it might be disastrous if <a class="thought" href="entries/cog_entry.html">Cog</a> were inadvertently to punch 
              itself in the eye, so part of the hard-wiring that must be provided 
              in advance is an "innate" if rudimentary "pain" 
              or "alarm" <a class="thought" href="entries/system_entry.html">system</a> to serve roughly the same protective 
              functions as the reflex eye-blink and pain-avoidance <a class="thought" href="entries/system_entry.html">system</a>s hard-<a class="thought" href="entries/wired_entry.html">wired</a> 
              into <a class="thought" href="entries/human_entry.html">human</a> infants. </p>
<p><a class="thought" href="entries/cog_entry.html">Cog</a> will not be an adult at first, in spite of its adult size. 
              It is being designed to pass through an extended period of artificial 
              infancy, during which it will have to learn from <a class="thought" href="entries/experience_entry.html">experience</a>, <a class="thought" href="entries/experience_entry.html">experience</a> 
              it will gain in the rough-and-tumble environment of the real world. 
              Like a <a class="thought" href="entries/human_entry.html">human</a> infant, however, it will need a great deal of protection 
              at the outset, in spite of the fact that it will be equipped with 
              many of the most crucial safety-<a class="thought" href="entries/system_entry.html">system</a>s of a living being. It has 
              limit <a class="thought" href="entries/switch_entry.html">switch</a>es, heat sensors, current sensors, strain gauges and 
              alarm signals in all the right places to prevent it from destroying 
              its many motors and joints. It has enormous "funny bones" 
              -- motors sticking out from its elbows in a risky way. These will 
              be protected from harm not by being shielded in heavy armor, but 
              by being equipped with patches of exquisitely sensitive piezo-electric 
              membrane "skin" which will trigger alarms when they make 
              contact with anything. The goal is that <a class="thought" href="entries/cog_entry.html">Cog</a> will quickly "learn" 
              to keep its funny bones from being bumped -- if <a class="thought" href="entries/cog_entry.html">Cog</a> cannot learn 
              this in short <a class="thought" href="entries/order_entry.html">order</a>, it will have to have this high-priority policy 
              hard-<a class="thought" href="entries/wired_entry.html">wired</a> in. The same sensitive membranes will be used on its 
              fingertips and elsewhere, and, like <a class="thought" href="entries/human_entry.html">human</a> tactile nerves, the "meaning" 
              of the signals sent along the attached wires will depend more on 
              what the central control <a class="thought" href="entries/system_entry.html">system</a> "makes of them" than on 
              their "intrinsic" characteristics. A gentle touch, signaling 
              sought-for contact with an <a class="thought" href="entries/object_entry.html">object</a> to be grasped, will not differ, 
              as an <a class="thought" href="entries/information_entry.html">information</a> <a class="thought" href="entries/packet_entry.html">packet</a>, from a sharp pain, signaling a need for 
              rapid countermeasures. It all depends on what the central <a class="thought" href="entries/system_entry.html">system</a> 
              is designed to do with the <a class="thought" href="entries/packet_entry.html">packet</a>, and this design is itself indefinitely 
              revisable -- something that can be adjusted either by <a class="thought" href="entries/cog_entry.html">Cog</a>'s own 
              <a class="thought" href="entries/experience_entry.html">experience</a> or by the tinkering of <a class="thought" href="entries/cog_entry.html">Cog</a>'s artificers. </p>
<p>One of its most interesting "innate" endowments will 
              be <a class="thought" href="entries/software_entry.html">software</a> for visual face recognition. Faces will "pop out" 
              from the background of other <a class="thought" href="entries/object_entry.html">object</a>s as items of special interest 
              to <a class="thought" href="entries/cog_entry.html">Cog</a>. It will further be innately designed to "want" 
              to keep its "mother's" face in view, and to work hard 
              to keep "mother" from turning away. The role of mother 
              has not yet been cast, but several of the graduate students have 
              been tentatively tapped for this role. Unlike a <a class="thought" href="entries/human_entry.html">human</a> infant, of 
              course, there is no <a class="thought" href="entries/reason_entry.html">reason</a> why <a class="thought" href="entries/cog_entry.html">Cog</a> can't have a whole team of mothers, 
              each of whom is innately distinguished by <a class="thought" href="entries/cog_entry.html">Cog</a> as a face to please 
              if possible. Clearly, even if <a class="thought" href="entries/cog_entry.html">Cog</a> really does have a <i>Lebenswelt</i>, 
              it will not be the same as <i>ours</i>. </p>
<p>Decisions have not yet been reached about many of the candidates 
              for hard-wiring or innate features. Anything that can learn must 
              be initially equipped with a great deal of unlearned design. That 
              is no longer an issue; no <i><a class="thought" href="entries/tabula_rasa_entry.html">tabula rasa</a></i> could ever be impressed 
              with <a class="thought" href="entries/knowledge_entry.html">knowledge</a> from <a class="thought" href="entries/experience_entry.html">experience</a>. But it is also not much of an issue 
              which features ought to be innately fixed, for there is a convenient 
              trade-off. I haven't mentioned yet that <a class="thought" href="entries/cog_entry.html">Cog</a> will actually be a multi-generational 
              series of ever improved models (if all goes well!), but of course 
              that is the way any complex <a class="thought" href="entries/artifact_entry.html">artifact</a> gets designed. Any feature 
              that is not innately fixed at the outset, but does get itself designed 
              into <a class="thought" href="entries/cog_entry.html">Cog</a>'s control <a class="thought" href="entries/system_entry.html">system</a> through <a class="thought" href="entries/learning_entry.html">learning</a>, can then be lifted whole 
              into <a class="thought" href="entries/cog_entry.html">Cog</a>-II, as a new <a class="thought" href="entries/bit_entry.html">bit</a> of innate endowment designed by <a class="thought" href="entries/cog_entry.html">Cog</a> itself 
              -- or rather by <a class="thought" href="entries/cog_entry.html">Cog</a>'s <a class="thought" href="entries/history_entry.html">history</a> of interactions with its environment. 
              So even in cases in which we have the best of <a class="thought" href="entries/reason_entry.html">reason</a>s for <a class="thought" href="entries/thinking_entry.html">thinking</a> 
              that <a class="thought" href="entries/human_entry.html">human</a> infants actually come innately equipped with pre-designed 
              gear, we may choose to try to get <a class="thought" href="entries/cog_entry.html">Cog</a> to learn the design in question, 
              rather than be born with it. In some <a class="thought" href="entries/instance_entry.html">instance</a>s, this is laziness 
              or opportunism -- we don't really know what might work well, but 
              maybe <a class="thought" href="entries/cog_entry.html">Cog</a> can train itself up. This insouciance about the putative 
              <a class="thought" href="entries/nature_entry.html">nature</a>/nurture boundary is already a familiar attitude among neural 
              net modelers, of course. Although <a class="thought" href="entries/cog_entry.html">Cog</a> is not specifically intended 
              to demonstrate any particular neural net thesis, it should come 
              as no surprise that <a class="thought" href="entries/cog_entry.html">Cog</a>'s nervous <a class="thought" href="entries/system_entry.html">system</a> is a massively parallel 
              <a class="thought" href="entries/architecture_entry.html">architecture</a> capable of simultaneously training up an indefinite 
              <a class="thought" href="entries/number_entry.html">number</a> of special-purpose <a class="thought" href="entries/network_entry.html">network</a>s or <a class="thought" href="entries/circuit_entry.html">circuit</a>s, under various regimes. 
            </p>
<p>How plausible is the hope that <a class="thought" href="entries/cog_entry.html">Cog</a> can retrace the steps of millions 
              of years of <a class="thought" href="entries/evolution_entry.html">evolution</a> in a few months or years of laboratory exploration? 
              Notice first that what I have just described is a variety of Lamarckian 
              inheritance that no organic lineage has been able to avail itself 
              of. The acquired design innovations of <a class="thought" href="entries/cog_entry.html">Cog</a>-I can be immediately 
              transferred to <a class="thought" href="entries/cog_entry.html">Cog</a>-II, a speed-up of <a class="thought" href="entries/evolution_entry.html">evolution</a> of tremendous, if 
              incalculable, magnitude. Moreover, if you bear in <a class="thought" href="entries/mind_entry.html">mind</a> that, unlike 
              the natural case, there will be a team of overseers ready to make 
              patches whenever obvious shortcomings reveal themselves, and to 
              jog the <a class="thought" href="entries/system_entry.html">system</a>s out of ruts whenever they enter them, it is not 
              so outrageous a hope, in our opinion. But then, we are all rather 
              outrageous people. </p>
<p>One talent that we have hopes of teaching to <a class="thought" href="entries/cog_entry.html">Cog</a> is a rudimentary 
              <a class="thought" href="entries/capacity_entry.html">capacity</a> for <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/language_entry.html">language</a>. And here we run into the fabled innate 
              <a class="thought" href="entries/language_entry.html">language</a> organ or <a class="thought" href="entries/language_entry.html">Language</a> Acquisition <a class="thought" href="entries/device_entry.html">Device</a> made famous by Noam 
              Chomsky. Is there going to be an attempt to build an innate LAD 
              for our Cog? No. We are going to try to get <a class="thought" href="entries/cog_entry.html">Cog</a> to build <a class="thought" href="entries/language_entry.html">language</a> 
              the hard way, the way our ancestors must have done, over thousands 
              of generations. <a class="thought" href="entries/cog_entry.html">Cog</a> has ears (four, because it's easier to get good 
              localization with four microphones than with carefully shaped ears 
              like ours!) and some special-purpose signal-analyzing <a class="thought" href="entries/software_entry.html">software</a> is 
              being developed to give <a class="thought" href="entries/cog_entry.html">Cog</a> a fairly good chance of discriminating 
              <a class="thought" href="entries/human_entry.html">human</a> speech sounds, and probably the <a class="thought" href="entries/capacity_entry.html">capacity</a> to distinguish different 
              <a class="thought" href="entries/human_entry.html">human</a> voices. <a class="thought" href="entries/cog_entry.html">Cog</a> will also have to have speech <a class="thought" href="entries/synthesis_entry.html">synthesis</a> <a class="thought" href="entries/hardware_entry.html">hardware</a> 
              and <a class="thought" href="entries/software_entry.html">software</a>, of course, but decisions have not yet been reached 
              about the details. It is <a class="thought" href="entries/import_entry.html">import</a>ant to have <a class="thought" href="entries/cog_entry.html">Cog</a> as well-equipped 
              as possible for rich and natural interactions with <a class="thought" href="entries/human_entry.html">human</a> beings, 
              for the team intends to take advantage of as much free labor as 
              it can. Untrained people ought to be able to spend <a class="thought" href="entries/time_entry.html">time</a> -- hours 
              if they like, and we rather hope they do -- trying to get <a class="thought" href="entries/cog_entry.html">Cog</a> to 
              learn this or that. Growing into an adult is a long, <a class="thought" href="entries/time_entry.html">time</a>-consuming 
              business, and <a class="thought" href="entries/cog_entry.html">Cog</a> -- and the team that is building <a class="thought" href="entries/cog_entry.html">Cog</a> -- will need 
              all the help it can get. </p>
<p>Obviously this will not work unless the team manages somehow to 
              give <a class="thought" href="entries/cog_entry.html">Cog</a> a motivational <a class="thought" href="entries/structure_entry.html">structure</a> that can be at least dimly recognized, 
              responded to, and exploited by naive observers. In short, <a class="thought" href="entries/cog_entry.html">Cog</a> should 
              be as <a class="thought" href="entries/human_entry.html">human</a> as possible in its wants and fears, likes and dislikes. 
              If those anthropomorphic terms strike you as unwarranted, put them 
              in scare quotes or drop them altogether and replace them with tedious 
              neologisms of your own choosing: <a class="thought" href="entries/cog_entry.html">Cog</a>, you may prefer to say, must 
              have <i>goal-registrations</i> and <i>preference-functions</i> that 
              map in rough isomorphism to <a class="thought" href="entries/human_entry.html">human</a> desires. This is so for many <a class="thought" href="entries/reason_entry.html">reason</a>s, 
              of course. <a class="thought" href="entries/cog_entry.html">Cog</a> won't work at all unless it has its act together 
              in a daunting <a class="thought" href="entries/number_entry.html">number</a> of different regards. It must somehow delight 
              in <a class="thought" href="entries/learning_entry.html">learning</a>, abhor error, strive for novelty, and recognize <a class="thought" href="entries/progress_entry.html">progress</a>. 
              It must be vigilant in some regards, curious in others, and deeply 
              unwilling to engage in self-destructive activity. While we are at 
              it, we might as well try to make it crave <a class="thought" href="entries/human_entry.html">human</a> praise and company, 
              and even exhibit a <a class="thought" href="entries/sense_entry.html">sense</a> of <a class="thought" href="entries/humor_entry.html">humor</a>. </p>
<p>Let me <a class="thought" href="entries/switch_entry.html">switch</a> abruptly from this heavily anthropomorphic <a class="thought" href="entries/language_entry.html">language</a> 
              to a brief description of <a class="thought" href="entries/cog_entry.html">Cog</a>'s initial endowment of <a class="thought" href="entries/information_entry.html">information</a>-processing 
              <a class="thought" href="entries/hardware_entry.html">hardware</a>. The <a class="thought" href="entries/computer_entry.html">computer</a>-complex that has been built to serve as the 
              development <a class="thought" href="entries/platform_entry.html">platform</a> for <a class="thought" href="entries/cog_entry.html">Cog</a>'s artificial nervous <a class="thought" href="entries/system_entry.html">system</a> consists 
              of four backplanes, each with 16 nodes; each <a class="thought" href="entries/node_entry.html">node</a> is basically a 
              Mac-II <a class="thought" href="entries/computer_entry.html">computer</a> -- a 68332 processor with a megabyte of <a class="thought" href="entries/ram_entry.html">RAM</a>. In 
              other words, you can think of <a class="thought" href="entries/cog_entry.html">Cog</a>'s <a class="thought" href="entries/brain_entry.html">brain</a> as roughly equivalent 
              to sixty-four Mac-IIs yoked in a custom parallel <a class="thought" href="entries/architecture_entry.html">architecture</a>. Each 
              <a class="thought" href="entries/node_entry.html">node</a> is itself a multiprocessor, and they all run a special version 
              of parallel <a class="thought" href="entries/lisp_entry.html">Lisp</a> developed by <a class="thought" href="entries/brooks_entry.html">Rodney Brooks</a>, and called, simply, 
              L. Each <a class="thought" href="entries/node_entry.html">node</a> has an interpreter for L in its <a class="thought" href="entries/rom_entry.html">ROM</a>, so it can execute 
              L files independently of every other <a class="thought" href="entries/node_entry.html">node</a>. </p>
<p>Each <a class="thought" href="entries/node_entry.html">node</a> has 6 assignable input-output ports, in addition to the 
              possibility of separate i-o (input-output) to the motor boards directly 
              controlling the various joints, as well as the all-<a class="thought" href="entries/import_entry.html">import</a>ant i-o 
              to the <a class="thought" href="entries/experiment_entry.html">experiment</a>ers' monitoring and control <a class="thought" href="entries/system_entry.html">system</a>, the Front End 
              Processor or FEP (via another unit known as the Interfep). On a 
              bank of separate monitors, one can see the current image in each 
              camera (two foveas, two parafoveas), the activity in each of the 
              many different visual processing areas, or the activities of any 
              other nodes. <a class="thought" href="entries/cog_entry.html">Cog</a> is thus equipped at birth with the equivalent of 
              chronically implanted electrodes for each of its <a class="thought" href="entries/neuron_entry.html">neuron</a>s; all its 
              activities can be monitored in real <a class="thought" href="entries/time_entry.html">time</a>, recorded and debugged. 
              The FEP is itself a Macintosh <a class="thought" href="entries/computer_entry.html">computer</a> in more conventional packaging. 
              At startup, each <a class="thought" href="entries/node_entry.html">node</a> is awakened by a FEP call that commands it 
              to load its appropriate files of L from a file <a class="thought" href="entries/server_entry.html">server</a>. These files 
              configure it for whatever tasks it has currently been designed to 
              execute. Thus the underlying <a class="thought" href="entries/hardware_entry.html">hardware</a> <a class="thought" href="entries/machine_entry.html">machine</a> can be turned into 
              any of a host of different virtual <a class="thought" href="entries/machine_entry.html">machine</a>s, thanks to the <a class="thought" href="entries/capacity_entry.html">capacity</a> 
              of each <a class="thought" href="entries/node_entry.html">node</a> to run its current <a class="thought" href="entries/program_entry.html">program</a>. The nodes do not make further 
              use of disk <a class="thought" href="entries/memory_entry.html">memory</a>, however, during normal <a class="thought" href="entries/operation_entry.html">operation</a>. They keep 
              their <a class="thought" href="entries/transient_entry.html">transient</a> memories locally, in their <a class="thought" href="entries/individual_entry.html">individual</a> megabytes 
              of <a class="thought" href="entries/ram_entry.html">RAM</a>. In other words, <a class="thought" href="entries/cog_entry.html">Cog</a> stores both its genetic endowment (the 
              virtual <a class="thought" href="entries/machine_entry.html">machine</a>) and its long term <a class="thought" href="entries/memory_entry.html">memory</a> on disk when it is shut 
              down, but when it is powered on, it first configures itself and 
              then stores all its short term <a class="thought" href="entries/memory_entry.html">memory</a> distributed one way or another 
              among its 64 nodes. </p>
<p>The <a class="thought" href="entries/space_entry.html">space</a> of possible virtual <a class="thought" href="entries/machine_entry.html">machine</a>s made available and readily 
              explorable by this underlying <a class="thought" href="entries/architecture_entry.html">architecture</a> is huge, of course, and 
              it covers a volume in the <a class="thought" href="entries/space_entry.html">space</a> of all <a class="thought" href="entries/computation_entry.html">computation</a>s that has not 
              yet been seriously explored by <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> <a class="thought" href="entries/research_entry.html">research</a>ers. 
              Moreover, the <a class="thought" href="entries/space_entry.html">space</a> of possibilities it represents is manifestly 
              much more realistic as a <a class="thought" href="entries/space_entry.html">space</a> to build brains in than is the <a class="thought" href="entries/space_entry.html">space</a> 
              heretofore explored, either by the largely serial <a class="thought" href="entries/architecture_entry.html">architecture</a>s 
              of GOFAI ("Good Old Fashioned AI", Haugeland, 1985), or 
              by parallel <a class="thought" href="entries/architecture_entry.html">architecture</a>s simulated by serial <a class="thought" href="entries/machine_entry.html">machine</a>s. Nevertheless, 
              it is arguable that every one of the possible virtual <a class="thought" href="entries/machine_entry.html">machine</a>s executable 
              by <a class="thought" href="entries/cog_entry.html">Cog</a> is minute in comparison to a real <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a>. In short, 
              <a class="thought" href="entries/cog_entry.html">Cog</a> has a tiny <a class="thought" href="entries/brain_entry.html">brain</a>. There is a big wager being made: the parallelism 
              made possible by this arrangement will be sufficient to provide 
              real-<a class="thought" href="entries/time_entry.html">time</a> control of <a class="thought" href="entries/import_entry.html">import</a>antly <a class="thought" href="entries/humanoid_entry.html">humanoid</a> activities occurring on 
              a <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/time_entry.html">time</a> scale. If this proves to be too optimistic by as little 
              as an <a class="thought" href="entries/order_entry.html">order</a> of magnitude, the whole project will be forlorn, for 
              the motivating insight for the project is that by confronting and 
              solving <i>actual</i>, <i>real <a class="thought" href="entries/time_entry.html">time</a></i> problems of self-protection, 
              hand-eye coordination, and interaction with other animate beings, 
              <a class="thought" href="entries/cog_entry.html">Cog</a>'s artificers will discover the <i>sufficient</i> conditions 
              for higher cognitive functions in general-and maybe even for a variety 
              of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> that would satisfy the skeptics. </p>
<p>It is <a class="thought" href="entries/import_entry.html">import</a>ant to recognize that although the theoretical <a class="thought" href="entries/import_entry.html">import</a>ance 
              of having a body has been appreciated ever since <a class="thought" href="entries/turing_entry.html">Alan Turing</a> (1950) 
              drew specific attention to it in his classic paper, "Computing 
              <a class="thought" href="entries/machine_entry.html">Machine</a>s and <a class="thought" href="entries/intelligence_entry.html">Intelligence</a>," within the field of Artificial 
              <a class="thought" href="entries/intelligence_entry.html">Intelligence</a> there has long been a contrary opinion that <a class="thought" href="entries/robotics_entry.html">robotics</a> 
              is largely a waste of <a class="thought" href="entries/time_entry.html">time</a>, money and effort. According to this 
              view, whatever deep principles of organization make cognition possible 
              can be as readily discovered in the more abstract realm of pure 
              simulation, at a fraction of the cost. In many fields, this thrifty 
              attitude has proven to be uncontroversial <a class="thought" href="entries/wisdom_entry.html">wisdom</a>. No economists 
              have asked for the funds to <a class="thought" href="entries/implement_entry.html">implement</a> their <a class="thought" href="entries/computer_entry.html">computer</a> models of markets 
              and industries in tiny robotic Wall Streets or Detroits, and civil 
              <a class="thought" href="entries/engine_entry.html">engine</a>ers have largely replaced their scale models of bridges and 
              tunnels with <a class="thought" href="entries/computer_entry.html">computer</a> models that can do a better job of simulating 
              all the relevant conditions of load, stress and strain. Closer to 
              home, simulations of ingeniously oversimplified imaginary <a class="thought" href="entries/organism_entry.html">organism</a>s 
              foraging in imaginary environments, avoiding imaginary predators 
              and differentially producing imaginary offspring are yielding <a class="thought" href="entries/import_entry.html">import</a>ant 
              insights into the mechanisms of <a class="thought" href="entries/evolution_entry.html">evolution</a> and <a class="thought" href="entries/ecology_entry.html">ecology</a> in the new 
              field of <a class="thought" href="entries/artificial_life_entry.html">Artificial Life</a>. So it is something of a surprise to find 
              this <a class="thought" href="entries/ai_entry.html">AI</a> group conceding, in effect, that there is indeed something 
              to the skeptics' claim (e.g., Dreyfus and Dreyfus, 1986) that genuine 
              embodiment in a real world is crucial to <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. Not, I hasten 
              to add, because genuine embodiment provides some special vital juice 
              that mere virtual-world simulations cannot secrete, but for the 
              more practical <a class="thought" href="entries/reason_entry.html">reason</a>-or hunch-that unless you saddle yourself with 
              all the problems of making a concrete <a class="thought" href="entries/agent_entry.html">agent</a> take care of itself 
              in the real world, you will tend to overlook, underestimate, or 
              misconstrue the deepest problems of design. </p>
<p>Besides, as I have already noted, there is the hope that <a class="thought" href="entries/cog_entry.html">Cog</a> will 
              be able to design itself in large measure, <a class="thought" href="entries/learning_entry.html">learning</a> from infancy, 
              and building its own representation of its world in the terms that 
              it innately understands. Nobody doubts that any <a class="thought" href="entries/agent_entry.html">agent</a> capable of 
              interacting intelligently with a <a class="thought" href="entries/human_entry.html">human</a> being on <a class="thought" href="entries/human_entry.html">human</a> terms must 
              have <a class="thought" href="entries/access_entry.html">access</a> to literally millions if not billions of logically independent 
              items of world <a class="thought" href="entries/knowledge_entry.html">knowledge</a>. Either these must be hand-coded <a class="thought" href="entries/individual_entry.html">individual</a>ly 
              by <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/program_entry.html">program</a>mers -- a tactic being pursued, notoriously, by 
              Douglas Lenat and his <a class="thought" href="entries/cyc_entry.html">CYC</a> team in Dallas-- or some way must be found 
              for the artificial <a class="thought" href="entries/agent_entry.html">agent</a> to learn its world <a class="thought" href="entries/knowledge_entry.html">knowledge</a> from (real) 
              interactions with the (real) world. The potential virtues of this 
              shortcut have long been recognized within <a class="thought" href="entries/ai_entry.html">AI</a> circles (e.g., Waltz, 
              1988). The unanswered question is whether taking on the task of 
              solving the grubby details of real-world <a class="thought" href="entries/robotics_entry.html">robotics</a> will actually 
              permit one to finesse the task of hand-coding the world <a class="thought" href="entries/knowledge_entry.html">knowledge</a>. 
              Brooks, Stein and their team -- myself included -- are gambling 
              that it will. </p>
<p>At this stage of the project, most of the problems being addressed 
              would never arise in the realm of pure, disembodied <a class="thought" href="entries/ai_entry.html">AI</a>. How many 
              separate motors might be used for controlling each hand? They will 
              have to be mounted somehow on the forearms. Will there then be room 
              to mount the motor boards directly on the arms, close to the joints 
              they control, or would they get in the way? How much cabling can 
              each arm carry before weariness or clumsiness overcomes it? The 
              arm joints have been built to be compliant -- springy, like your 
              own joints. This means that if <a class="thought" href="entries/cog_entry.html">Cog</a> wants to do some fine-fingered 
              manipulation, it will have to learn to "burn" some of 
              the degrees of <a class="thought" href="entries/freedom_entry.html">freedom</a> in its arm <a class="thought" href="entries/motion_entry.html">motion</a> by temporarily bracing 
              its elbows or wrists on a table or other convenient landmark, just 
              as you would do. Such compliance is typical of the mixed bag of 
              opportunities and problems created by real <a class="thought" href="entries/robotics_entry.html">robotics</a>. Another is 
              the need for self-calibration or re-calibration in the eyes. If 
              <a class="thought" href="entries/cog_entry.html">Cog</a>'s eyes jiggle away from their preset aim, thanks to the wear 
              and tear of all that sudden saccading, there must be ways for <a class="thought" href="entries/cog_entry.html">Cog</a> 
              to compensate, short of trying continually to adjust its camera-eyes 
              with its fingers. <a class="thought" href="entries/software_entry.html">Software</a> designed to tolerate this probable sloppiness 
              in the first place may well be more robust and versatile in many 
              other ways than <a class="thought" href="entries/software_entry.html">software</a> designed to work in a more "perfect" 
              world. </p>
<p>Earlier I mentioned a <a class="thought" href="entries/reason_entry.html">reason</a> for using artificial muscles, not 
              motors, to control a <a class="thought" href="entries/robot_entry.html">robot</a>'s joints, and the example was not imaginary. 
              Brooks is concerned that the sheer <a class="thought" href="entries/noise_entry.html">noise</a> of <a class="thought" href="entries/cog_entry.html">Cog</a>'s skeletal activities 
              may seriously interfere with the attempt to give <a class="thought" href="entries/cog_entry.html">Cog</a> <a class="thought" href="entries/humanoid_entry.html">humanoid</a> hearing. 
              There is <a class="thought" href="entries/research_entry.html">research</a> underway at the <a class="thought" href="entries/ai_entry.html">AI</a> Lab to develop synthetic electro-mechanical 
              muscle tissues, which would operate silently as well as being more 
              compact, but this will not be available for early incarnations of 
              <a class="thought" href="entries/cog_entry.html">Cog</a>. For an entirely different <a class="thought" href="entries/reason_entry.html">reason</a>, <a class="thought" href="entries/thought_entry.html">thought</a> is being given to 
              the option of designing <a class="thought" href="entries/cog_entry.html">Cog</a>'s visual control <a class="thought" href="entries/software_entry.html">software</a> <i>as if</i> 
              its eyes were moved by muscles, not motors, building in a <a class="thought" href="entries/software_entry.html">software</a>
<a class="thought" href="entries/interface_entry.html">interface</a> that amounts to giving <a class="thought" href="entries/cog_entry.html">Cog</a> a <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of <i>virtual</i> eye-muscles. 
              Why might this extra complication in the <a class="thought" href="entries/interface_entry.html">interface</a> be wise? Because 
              the "opponent-process" control <a class="thought" href="entries/system_entry.html">system</a> exemplified by eye-muscle 
              controls is apparently a deep and ubiquitous feature of nervous 
              <a class="thought" href="entries/system_entry.html">system</a>s, involved in control of attention generally and disrupted 
              in such pathologies as unilateral neglect. If we are going to have 
              such competitive <a class="thought" href="entries/system_entry.html">system</a>s at higher levels of control, it might be 
              wise to build them in "all the way down," concealing the 
              final translation into electric-motor-talk as part of the backstage 
              <a class="thought" href="entries/implement_entry.html">implement</a>ation, not the model. </p>
<p>Other practicalities are more obvious, or at least more immediately 
              evocative to the uninitiated. Three huge red "emergency kill" 
              buttons have already been provided in <a class="thought" href="entries/cog_entry.html">Cog</a>'s environment, to ensure 
              that if <a class="thought" href="entries/cog_entry.html">Cog</a> happens to engage in some activity that could injure 
              or endanger a <a class="thought" href="entries/human_entry.html">human</a> interactor (or itself), there is a way of getting 
              it to stop. But what is the appropriate response for <a class="thought" href="entries/cog_entry.html">Cog</a> to make 
              to the KILL button? If power to <a class="thought" href="entries/cog_entry.html">Cog</a>'s motors is suddenly shut off, 
              <a class="thought" href="entries/cog_entry.html">Cog</a> will slump, and its arms will crash down on whatever is below 
              them. Is this what we want to happen? Do we want <a class="thought" href="entries/cog_entry.html">Cog</a> to drop whatever 
              it is holding? What should "Stop!" <i>mean</i> to Cog? 
              This is a real issue about which there is not yet any consensus. 
            </p>
<p>There are many more details of the current and anticipated design 
              of <a class="thought" href="entries/cog_entry.html">Cog</a> that are of more than passing interest to those in the field, 
              but on this occasion, I want to use the little remaining <a class="thought" href="entries/time_entry.html">time</a> to 
              address some overriding questions that have been much debated by 
              philosophers, and that receive a ready treatment in the environment 
              of <a class="thought" href="entries/thought_entry.html">thought</a> made possible by <a class="thought" href="entries/cog_entry.html">Cog</a>. In other words, let's consider 
              <a class="thought" href="entries/cog_entry.html">Cog</a> merely as a prosthetic aid to philosophical <a class="thought" href="entries/thought_entry.html">thought</a>-<a class="thought" href="entries/experiment_entry.html">experiment</a>s, 
              a modest but by no means negligible role for <a class="thought" href="entries/cog_entry.html">Cog</a> to play. </p>
<h2>3. Some Philosophical Considerations </h2>
<p>A recent criticism of "strong AI" that has received quite 
              a <a class="thought" href="entries/bit_entry.html">bit</a> of attention is the so-called problem of "symbol grounding" 
              (Harnad, 1990). It is all very well for large <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/program_entry.html">program</a>s to have 
              <a class="thought" href="entries/data_structure_entry.html">data structure</a>s that <i>purport</i> to refer to Chicago, milk, or 
              the person to whom I am now talking, but such imaginary reference 
              is not the same as real reference, according to this line of criticism. 
              These internal "symbols" are not properly "grounded" 
              in the world, and the problems thereby eschewed by pure, non-robotic, 
              <a class="thought" href="entries/ai_entry.html">AI</a> are not trivial or peripheral. As one who discussed, and ultimately 
              dismissed, a version of this problem many years ago (Dennett, 1969, 
              p.182ff), I would not want to be interpreted as now abandoning my 
              earlier view. I submit that <a class="thought" href="entries/cog_entry.html">Cog</a> moots the problem of <a class="thought" href="entries/symbol_entry.html">symbol</a> grounding, 
              without having to settle its status as a criticism of "strong 
              AI". Anything in <a class="thought" href="entries/cog_entry.html">Cog</a> that might be a candidate for <a class="thought" href="entries/symbol_entry.html">symbol</a>hood 
              will automatically be "grounded" in <a class="thought" href="entries/cog_entry.html">Cog</a>'s real predicament, 
              as surely as its counterpart in any child, so the issue doesn't 
              arise, except as a practical problem for the <a class="thought" href="entries/cog_entry.html">Cog</a> team, to be solved 
              or not, as fortune dictates. If the day ever comes for <a class="thought" href="entries/cog_entry.html">Cog</a> to comment 
              to anybody about Chicago, the question of whether <a class="thought" href="entries/cog_entry.html">Cog</a> is in any 
              position to do so will arise for exactly the same <a class="thought" href="entries/reason_entry.html">reason</a>s, and be 
              resolvable on the same considerations, as the parallel question 
              about the reference of the word "Chicago" in the idiolect 
              of a young child. </p>
<p>Another claim that has often been advanced, most carefully by Haugeland 
              (1985), is that nothing could properly "matter" to an 
              <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>, and <a class="thought" href="entries/matter_entry.html">matter</a>ing (it is claimed) is crucial 
              to <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. Haugeland restricted his claim to traditional 
              GOFAI <a class="thought" href="entries/system_entry.html">system</a>s, and left robots out of consideration. Would he concede 
              that something could <a class="thought" href="entries/matter_entry.html">matter</a> to Cog? The question, presumably, is 
              how seriously to weigh the <a class="thought" href="entries/import_entry.html">import</a> of the quite deliberate decision 
              by <a class="thought" href="entries/cog_entry.html">Cog</a>'s creators to make <a class="thought" href="entries/cog_entry.html">Cog</a> as much as possible responsible for 
              its own welfare. <a class="thought" href="entries/cog_entry.html">Cog</a> will be equipped with some "innate" 
              but not at all arbitrary preferences, and hence provided of necessity 
              with the concomitant <a class="thought" href="entries/capacity_entry.html">capacity</a> to be "bothered" by the 
              thwarting of those preferences, and "pleased" by the furthering 
              of the ends it was innately designed to seek. Some may want to retort: 
              "This is not <i>real</i> pleasure or pain, but merely a simulacrum." 
              Perhaps, but on what grounds will they defend this claim? <a class="thought" href="entries/cog_entry.html">Cog</a> may 
              be said to have quite crude, simplistic, one-dimensional pleasure 
              and pain, cartoon pleasure and pain if you like, but then the same 
              might also be said of the pleasure and pain of simpler <a class="thought" href="entries/organism_entry.html">organism</a>s 
              -- clams or houseflies, for <a class="thought" href="entries/instance_entry.html">instance</a>. Most, if not all, of the burden 
              of proof is shifted by <a class="thought" href="entries/cog_entry.html">Cog</a>, in my estimation. The <a class="thought" href="entries/reason_entry.html">reason</a>s for saying 
              that something <i>does</i> <a class="thought" href="entries/matter_entry.html">matter</a> to <a class="thought" href="entries/cog_entry.html">Cog</a> are not arbitrary; they 
              are exactly parallel to the <a class="thought" href="entries/reason_entry.html">reason</a>s we give for saying that things 
              <a class="thought" href="entries/matter_entry.html">matter</a> to us and to other creatures. Since we have cut off the dubious 
              retreats to <a class="thought" href="entries/vitalism_entry.html">vitalism</a> or origin chauvinism, it will be interesting 
              to see if the skeptics have any good <a class="thought" href="entries/reason_entry.html">reason</a>s for declaring <a class="thought" href="entries/cog_entry.html">Cog</a>'s 
              pains and pleasures not to <a class="thought" href="entries/matter_entry.html">matter</a> -- at least to it, and for that 
              very <a class="thought" href="entries/reason_entry.html">reason</a>, to us as well. It will come as no surprise, I hope, 
              that more than a few participants in the <a class="thought" href="entries/cog_entry.html">Cog</a> project are already 
              musing about what obligations they might come to have to <a class="thought" href="entries/cog_entry.html">Cog</a>, over 
              and above their obligations to the <a class="thought" href="entries/cog_entry.html">Cog</a> team. </p>
<p>Finally, J.R. Lucas (1994) has raised the claim that if a <a class="thought" href="entries/robot_entry.html">robot</a> 
              were really conscious, we would have to be prepared to believe it 
              about its own internal states. I would like to close by pointing 
              out that this is a rather likely <a class="thought" href="entries/reality_entry.html">reality</a> in the case of <a class="thought" href="entries/cog_entry.html">Cog</a>. Although 
              equipped with an optimal suite of monitoring <a class="thought" href="entries/device_entry.html">device</a>s that will reveal 
              the details of its inner workings to the observing team, <a class="thought" href="entries/cog_entry.html">Cog</a>'s own 
              pronouncements could very well come to be a more trustworthy and 
              informative source of <a class="thought" href="entries/information_entry.html">information</a> on what was really going on inside 
              it. The <a class="thought" href="entries/information_entry.html">information</a> visible on the banks of monitors, or gathered 
              by the gigabyte on <a class="thought" href="entries/hard_disk_entry.html">hard disk</a>s, will be at the outset almost as hard 
              to interpret, even by <a class="thought" href="entries/cog_entry.html">Cog</a>'s own designers, as the <a class="thought" href="entries/information_entry.html">information</a> obtainable 
              by such "third-person" <a class="thought" href="entries/method_entry.html">method</a>s as <a class="thought" href="entries/mri_entry.html">MRI</a> and CT scanning 
              in the <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a>s. As the observers refine their models, and 
              their understanding of their models, their authority as interpreters 
              of the <a class="thought" href="entries/data_entry.html">data</a> may grow, but it may also suffer eclipse. Especially 
              since <a class="thought" href="entries/cog_entry.html">Cog</a> will be designed from the outset to redesign itself as 
              much as possible, there is a high probability that the designers 
              will simply lose the standard hegemony of the artificer ("I 
              made it, so I know what it is supposed to do, and what it is doing 
              now!"). Into this epistemological <a class="thought" href="entries/vacuum_entry.html">vacuum</a> <a class="thought" href="entries/cog_entry.html">Cog</a> may very well 
              thrust itself. In fact, I would gladly defend the conditional prediction: 
              <i>if</i> <a class="thought" href="entries/cog_entry.html">Cog</a> develops to the point where it can conduct what appear 
              to be robust and well-controlled <a class="thought" href="entries/conversation_entry.html">conversation</a>s in something like 
              a <a class="thought" href="entries/natural_language_entry.html">natural language</a>, it will certainly be in a position to rival 
              its own monitors (and the theorists who interpret them) as a source 
              of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> about what it is doing and feeling, and why.</p>
<p></p>
<p>References</p>
<p>Dennett, Daniel <a class="thought" href="entries/c_entry.html">C</a>., 1969, <i><a class="thought" href="entries/content_entry.html">Content</a> and <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i>, London: 
              Routledge &amp; Kegan Paul. </p>
<p>Dennett, Daniel <a class="thought" href="entries/c_entry.html">C</a>., 1987, "Fast <a class="thought" href="entries/thinking_entry.html">Thinking</a>," in Dennett, 
              <i>The Intentional Stance</i>, Cambridge, MA: MIT Press, pp. 323-37. 
            </p>
<p>Dennett, Daniel <a class="thought" href="entries/c_entry.html">C</a>., 1993a, review of <a class="thought" href="entries/searle_entry.html">John Searle</a>, <i>The Rediscovery 
              of the <a class="thought" href="entries/mind_entry.html">Mind</a></i>, in J.Phil. 90, pp.193-205. </p>
<p>Dennett, Daniel <a class="thought" href="entries/c_entry.html">C</a>., 1993b, "Caveat Emptor," <i><a class="thought" href="entries/consciousness_entry.html">Consciousness</a> 
              and Cognition</i>, 2, pp.48-57. </p>
<p>Dreyfus, Hubert &amp; Dreyfus, Stuart, 1986, <i><a class="thought" href="entries/mind_entry.html">Mind</a> Over <a class="thought" href="entries/machine_entry.html">Machine</a></i>, 
              New York: MacMillan. </p>
<p>Harnad, Stevan, 1990, "The <a class="thought" href="entries/symbol_entry.html">Symbol</a> Grounding Problem," 
              Physica D, 42, pp.335-46. </p>
<p>Haugeland, John, 1985, <i><a class="thought" href="entries/ai_entry.html">Artificial Intelligence</a>: The Very Idea</i>, 
              Cambridge MA: MIT Press. </p>
<p>Lucas, J. R., 1994, presentation to the Royal <a class="thought" href="entries/society_entry.html">Society</a>, Conference 
              on <a class="thought" href="entries/ai_entry.html">Artificial Intelligence</a>, April 14, 1994. </p>
<p>Mangan, Bruce, "Dennett, <a class="thought" href="entries/consciousness_entry.html">Consciousness</a>, and the Sorrows of 
              <a class="thought" href="entries/functionalism_entry.html">Functionalism</a>," <i><a class="thought" href="entries/consciousness_entry.html">Consciousness</a> and Cognition</i>, 2, pp-1-17. 
            </p>
<p>Searle, John, 1992, <i>The Rediscovery of the <a class="thought" href="entries/mind_entry.html">Mind</a></i>, Cambridge, 
              MA: MIT Press. </p>
<p>Turing, Alan, 1950, "Computing <a class="thought" href="entries/machine_entry.html">Machine</a>ry and <a class="thought" href="entries/intelligence_entry.html">Intelligence</a>," 
              <i><a class="thought" href="entries/mind_entry.html">Mind</a></i>, 59, pp.433-60. </p>
<p>Waltz, David, 1988, "The Prospects for Building Truly Intelligent 
              <a class="thought" href="entries/machine_entry.html">Machine</a>s," <i>Daedalus</i>, 117, pp.191-222. <br>
</p>
<p>&#160; </p>
<p></p>
<p>From <a href="http://web.archive.org/web/20071011164315/http://www.oup.co.uk/isbn/0-19-852414-5" target="_blank">Cognition, 
              Computation, and Consciousness</a>, Masao Ito, ed., pp. 17-31. &#169; 
              1997 Oxford University Press. Reprinted by permission of <a href="http://web.archive.org/web/20071011164315/http://www.oup.co.uk/" target="_blank">Oxford 
              University Press</a>.</p>
</td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7356" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id7357"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Conscousness, Presence, and AC current<br><span class="mindxheader"><i>posted on 06/07/2002 2:16 PM by england@spatialharmonics.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id7357" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7357" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>It is well known scientifically speaking, that we are physical manifestations of solar energies). The question of consciousness is like looking toward our local source, and like looking at the sun, it is difficult to address such a fundemental question as "what is this energy that moves me - that gives me life?" We all know or should at least have considered the scenario of someone we know dying and leaving the physical body. What we see in the remains of the body - is simply a thing - a concentration of matter and nothing else.  Everything that was that person in the essence of life force, character, personality, - and the pure energy that moved the blood, is gone. So often and how easily it is to mistake the body and the bodies functions as our source.  
<br>
The question of artificial intelligence becoming conscious can only be approached in an accurate way if one specifically defines with concensus, the notion of conciousness. And herein is the dilema for the question at hand. 
<br>
The question I am raising is - are the people engaged in this debate/discussion satisfied with the idea that this unquestionably mysterious energy that literally makes use of and merly uses the physical apperatus we call our body, - is it merely an equivalent (for the question of AI) to plugging in to an electrical socket to power my computer? 
<br>
Are we indeed satisfied with equating this energy with ac current. Until the question of consciousness ventures beyond the realm of merely the functional - that is into the realms of Will and Being, we can only ever be speaking of mechanical replication of mechanical processes.  What I am suggestion is that has nothing to do with Consciousness.  So again, what is understood or assumed about consciousness?  More fundementally, am I content with my assumption that I know my own energetic source and the assumptions that I have with respect to the range of it's influence beyond the functional aspects of my body/machine/brain.   
<br>
<br>
<br>
Wayne England
<br>
Santa Monica, CA.
<br>
<br>
<br>
<br>
<br>
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7695"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Conscousness, Presence, and AC current<br><span class="mindxheader"><i>posted on 06/24/2002 12:05 PM by smile_on@hotmail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id7695" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7695" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>You have some valid points. 
<br>
The problem with your assumptions is that you are comparing human with robots! Robots are well-thought-of entities that are created with some initial goal in mind. And if some scientist initiates such a project in order to end up having a prototype  that would stand in line with Human, I suppose he had missed his two nights sleep! My point is: Robots are built for entire different purposes than we (the Humans) carry out generally.
<br>
....ASIM </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7696"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Conscousness, Presence, and AC current<br><span class="mindxheader"><i>posted on 06/24/2002 12:42 PM by tomaz@techemail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id7696" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7696" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>The kind of view you have, helps people to come through the days - and especially nights.
<br>
<br>
If I'd believe something like that, I couldn't sleep a minute.
<br>
<br>
While I am just a machine (or it's software) .. everything is well, as well as it can be presently. But if I had a 'soul' somewhere attached to God knows what ... I would worry a lot.
<br>
<br>
- Thomas</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7698"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Conscousness, Presence, and AC current<br><span class="mindxheader"><i>posted on 06/24/2002 4:51 PM by grantc4@hotmail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id7698" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7698" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>&gt;The question I am raising is - are the people engaged in this debate/discussion satisfied with the idea that this unquestionably mysterious energy that literally makes use of and merly uses the physical apperatus we call our body, - is it merely an equivalent (for the question of AI) to plugging in to an electrical socket to power my computer? 
<br>
<br>
No more so for us than for any other animal roaming the Earth.  Have you noticed that your dog or cat has a certain amount of intelligence and personality?  Do they not feel pain and sorrow?  Doesn't their blood flow as freely as ours and stop as quickly and finally when they die?  Individual animals have made efforts of will that people have described as heroic.  
<br>
<br>
Whatever this mysterious energy is, we can't say it belongs to us alone.  The only real question is, can we endow our machines with it?  And as the art of building intelligent machines borrows more and more from the life forms doing the building, the harder it will become to tell what is living and what is not.  When the energy sources for nanobots become dependent on things like mitocondria, what will be the difference between where they get it and where we get it? 
<br>
<br>
Right now there is a clear difference between them and us.  But in the days to come, we will as likely build our robots with DNA as with metal tools and power them with the same kind of fuel we use to run our bodies.  Then the primary difference between us will be that instead of having evolved into existence, they will have been engineered.  Their designs will no doubt be cleaner and better suited to the jobs for which they were built.  
<br>
<br>
We, on the other hand, were only created to exist.  We are too general purpose to do as good a job at anything as a well designed robot.  It's that very lack of purpose in design that may be our undoing.  
<br>
<br>
We can, of course, always be redesigned as we go along.  That's what knowing the genetic code and combining it with our knowledge of AI and the creation of new materials can do for us.  We can become borgs with the best features of both man and machine.  That might keep us around for a while.  But who knows what we will look like at that stage?  
<br>
<br>
A body made of materials that never existed before and that will never wear out combined with senses that can detect every frequency of every spectrum in the universe, and a brain that can combine those frequencies of input to examine, in concert with our fellow man and machine, everything the universe has to offer might be worth keeping.  But it might not be recongizable by homo sapiens.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7707"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Conscousness, Presence, and AC current<br><span class="mindxheader"><i>posted on 06/25/2002 4:23 AM by smile_on@hotmail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id7707" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7707" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Yes, as far as the spark of life is concerned, we call it "mysterious"; not because we don't know how to appreciate human life, but because AI as a field of science can't be very useful by itself, if we are to really fathom human existence.
<br>
My second point refers to Artificial Intelligence in general. As a honor year comp.science student, I have come to realize that apart from comparing robots with human always, it will be worthwhile to consider it as a separate entity, that would carry some static parameters ,which may help the entity define its "life". 
<br>
Last point: Our limitations to compare robots with human may result in our consequent inability to solve major deadlocks in AI we face as of today. Please do think over it.
<br>
...ASIM   </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7708"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Conscousness, Presence, and AC current<br><span class="mindxheader"><i>posted on 06/25/2002 4:24 AM by smile_on@hotmail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id7708" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7708" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Yes, as far as the spark of life is concerned, we call it "mysterious"; not because we don't know how to appreciate human life, but because AI as a field of science can't be very useful by itself, if we are to really fathom human existence.
<br>
My second point refers to Artificial Intelligence in general. As a honor year comp.science student, I have come to realize that apart from comparing robots with human always, it will be worthwhile to consider it as a separate entity, that would carry some static parameters ,which may help the entity define its "life". 
<br>
Last point: Our limitations to compare robots with human may result in our consequent inability to solve major deadlocks in AI we face as of today. Please do think over it.
<br>
...ASIM   </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7778"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Conscousness, Presence, and AC current<br><span class="mindxheader"><i>posted on 06/27/2002 6:56 PM by Citizen Blue</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id7778" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7778" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>These postings re-enforce my ideas on the subject.  Thank you. </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id26507"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Conscousness, Presence, and AC current<br><span class="mindxheader"><i>posted on 07/29/2004 10:31 PM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=1326">Incanus</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id26507" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D26507" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Greetings Friend, 
<br>
<br>
I will tell you what this energy is. It is called quintessence.
<br>
<br>
If you begin searching for the meaning of this word, you will learn what this energy is. When I say search for the mean of the word I mean actually come to knowing its meaning through experience (from your words you have already, unconsiously relalised it slightly). 
<br>
<br>
If you wish to know more, or if you wish me to suggest an excellent work based completely on experiments with this "life spark" energy, then please contact me privately. 
<br>
<br>
In LVX
<br>
Ora et lege et Labora. 
<br>
Incanus</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10461"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Consciousness in Human and Robot Minds<br><span class="mindxheader"><i>posted on 10/02/2002 1:20 AM by england@spatialharmonics.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id10461" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10461" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Haven't been hear in a while - but I see there are a few comments now - and would like to just add another thought that follows this questioning of consciousness - and what it is and what it isn't - baring in mind that 'comrehension' is directly linked to the mysterious force/spirit within. (I am not my mind - I am not my body - I am not my emotions) - but I am witness.    
<br>
What is this term consciousness?? Consciousness is not related in any way to the on and off mechanics of mechanical process.  One might as well bounce a thousand balls up and down and claim there could have been some "consciousness" that just happened. (I am refering of course to a microchip with respect to directional motions) There is no ghost in the machine -unless we are speaking of ourselves - and that was the point.  These people who are suggesting I'll be able to download my brain onto a computer some day and live on - are confusing the world of FACT (existentiality - and functions - physical mechanical processes) with the world of VALUE (essential comprehension of meaning - and the experience of BEING) The body is merely an instument that houses what I am more fundementally.   It is a question of LEVELS - there are different levels of consciousness - and different qualities of energy associated with those levels.  For example Miester Eckhart had a different level or quality of energy moving through him - (or he was host to), than say for example, a stubborn person who believes he is right without questioning.  And this is where it gets interesting - because different qualities of energies manifest different kinds of processes  and patternings.  To continue with the example above - Meister Ekhart was known to almost always be in a state of questioning, - a certain openness and application of those aspects within that enable the intelligent sense of creative wonder. It could be argued (as it apparently is by someone) that this kind of patterning of inner relatedness and knowledge could  be "transposed into" algorithms -replicating patternings of relationships and forces in association with sequences of variables etc...  But this can only ever be a surface hollow relication of appearaces  - like a music sampler can can repeat the sound of my voice.  A Robot could never know it was speaking -except to relicate an (appearance) of knowing.
<br>
<br>
This is obvious stuff - but it concerns me that there are people who believe that computers are going to manifest and be host to conscious energy or that i can be alive in a computer? 
<br>
<br>
Again - we don't know what we are talking about collectively when we refer to this term consciousness.  Like so many other words we all have a different take - and have whole sets of assumptions.  This why there is the new Toward a science of Consciousness conference.  Finally for western science the question is up - the problem is most people are simply not up for the question.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10466"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Consciousness in Human and Robot Minds<br><span class="mindxheader"><i>posted on 10/02/2002 3:55 AM by azb0@earthlink.net</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id10466" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10466" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>England,
<br>
<br>
I claim I am conscious.  It certainly feels that way to me.
<br>
<br>
You claim you are conscious.
<br>
<br>
Suppose, in all seriousness, I do not believe you, and believe instead that you are just mechanically and chemically "reacting" to me and your environment, albeit in very complex and "reasonable" ways.
<br>
<br>
What evidence can you present that should convince me that you actually experience the sensation of "consciousness"?
<br>
<br>
I mean, besides, "Well, because its just obvious, duh!"
<br>
<br>
Just curious.
<br>
<br>
Cheers! ____tony b____</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10485"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Consciousness in Human and Robot Minds<br><span class="mindxheader"><i>posted on 10/02/2002 2:00 PM by england@spatialharmonics.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id10485" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10485" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>The proof can only be experienced by you -
<br>
but if you are willing to do an experiment - you will see so clearly for yourself that you will repeat the quote at the end of your posting to yourself.  The problem is - people are not serious about the question of consciousness - that is to say there is an overiding assumption that the consciousness I am familiar with is the extent of the matter, or IT. 
<br>
<br>
If you are serious about the question of consciousness - are you willing for 30 days to try to quietly with intension - and the consciousness you claim you have, to sit still in the morning and simply observe for 30 minutes, what occures in your mind, feelings and body?.  It is precisely the effort of watching and staying with the intension (like a scientist) that will produce a quality of energy in you that will be the "proof" that I am not my functions - that is to say - I am not my mind, body or feelings, but that feelings, thoughts and sensations move through me - and (I can know them and be witness) to them.  The illusion is the assumption that that is how it is anyway - that I am aware of everything that is going on in me... but if I look - for a moment - I see that I am not.  This is a terrible blow to my idea of myself. (Serious stuff) - Because on that level (on my ordinary level) I am like a machine - and the point is a machine can not know itself..  a machine cannot be known to itself...  things just pass through it - it just churns.  The witness in myself is almost always buried beneath the functions (thoughts feelings sensations). Or in other words the witness is there - but is buried by conclusions, assumptions and almost constant distraction - that I give my identity to.  
<br>
<br>
The problem is - that to approach the question of consciousness I need to approach it with an open mind - like a scientist....  - but the unavoidable scenario is that I myself am and can only be - the subject - test and control - if i am to approach the question seriously. The question becomes how intelligent of a scientist am I in relation to the subject of knowing myself?
<br>
Am I just a machine? - just a computer processing data in complex ways?  Is that it?  Can I proove to myself there is nothing more to me? Or is it not quite that simple of a matter?  If it isn't - that can only be good news.  
<br>
<br>
The question lays with the individual when the question is about consciousness - and in that sense there is a reason that it has been avoided by science - I myself need to put all my cherished assumptions and opinions into question - and who wants to do that?  Just as who wants to become (a serious scientific) experiment to their own observation.  - 30 minutes for 30 days.  Suffering enters frame - and I have very little baring on that subject.
<br>
<br>
Words themselves are only symbols for meanings - 
<br>
A computer cannot UNDERSTAND meanings (Values)  - it can only "KNOW" (Facts) The question becomes the differnce between UNDERSTANDING - walking the path - as opposed to KNOWING - talking about the path.
<br>
<br>
Amoong other places...
<br>
It's all in "The MATRIX"  the movie - the masterpice of symbolism.  Is that film not all about me and my scenario.  My problem is I am constantly popping blue pills without knowing it.  
<br>
<br>
ENGLAND.
<br>
<br>
<br>
<br>
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id26530"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Consciousness in Human and Robot Minds<br><span class="mindxheader"><i>posted on 07/30/2004 4:13 PM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=1354">ubermouth</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id26530" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D26530" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>know im many years late but, how exactly are you witness. what exactly does this relation look like?
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id26531"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Consciousness in Human and Robot Minds<br><span class="mindxheader"><i>posted on 07/30/2004 4:17 PM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=1354">ubermouth</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id26531" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D26531" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>secondly, if you are going to say that you are witness to these things via experiencing them, then i must say that you are made of those things ie emotion, body, thought in that you are a mode ie witness ie experiencer, and are indeed made of those things in that experience is consituted of those thing? you cannot not be connect to those things a s a removed observer, you must experience them which entails that you are in a interaction with them, if not in an interactive mode them how do you relate to them?</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id26228"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Consciousness in Human and Robot Minds<br><span class="mindxheader"><i>posted on 07/24/2004 10:56 AM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=1348">jack d</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id26228" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D26228" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Tony,
<br>
<br>
I claim I am a duck. It certainly feels that way to me.
<br>
<br>
You claim you are a duck.
<br>
<br>
Suppose, in all seriousness, I do not believe you, and believe instead that you are just mechanically and chemically "reacting" to me and your environment, albeit in very complex and "reasonable" ways.
<br>
<br>
What evidence can you present that should convince me that you actually are a duck ?
<br>
<br>
I mean, besides, "Well, because its just obvious, duh!"
<br>
<br>
*****
<br>
The answer is that you are confusing the subjective experience of consciousness with its objective characteristics. So for instance there are certain objective characteristics we associate with being a duck.They have beaks, go quack and taste quite nice. So in order to convince you I may be a duck , i would invite you to check my external, objective characteristics for the presence of features normally associated amongst knowledgeable society as a duck. I would not expect you to take my word for it. In order to confirm that I am a duck there needs to be the capacity for you, the observer to interact with me, the duck. This is possible in a very easy way with a duck as a duck is made of matter. ( Nonetheless I may be kidding you as I may not be
<br>
a duck but a heavily disguised finch - my DNA evidence may provide better evidence ).
<br>
<br>
The only objective facts we have about consciousness ( there aren't many ) are that  it's assocated with brains, it appears when we wake up in the morning and disappears when we drink too much or spend too much time hanging around police stations in Iraq. There is little around to objectively measure consciousness. Anaesthetists make a go of it. But it clearly is not as easy for an external observer to verify the existence or not of consciousness in somebody's brain as it is to see whether something is or is not a duck. But nonetheless the fact that saying something is more difficult is not the same thing as saying something is impossible. 
<br>
<br>
Consciousness is a closed phenomena - its EXPERIENCE is only availabel to the person experiencing it. Nonethless its objective existence is available to third parties - fortunately , as otherwise our hospitals wouldn'y function too well is all its anaesthetists weren't able to work on that basis. Similarly, I would suggest , Tony that you exercise that belief ( that others are conscious just like you ) on a daily basis, a bleief as valid as all the other necessary  beliefs, e.g existence of an external world, existence of matter, other human beings, and all that.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id26226"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Consciousness in Human and Robot Minds<br><span class="mindxheader"><i>posted on 07/24/2004 10:35 AM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=1348">jack d</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id26226" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D26226" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Who says that western science cannot 'tackle' the problem of consciousness ? On what basis is this exaggerated claim made ? Consciousness is phenomenological semantic, just like matter and time. It is no more immune to the probing of the scientific method than the reproductive methods of vampire bats. It may be difficult but to state that it is epistemelogically impossible is a philosophical statement that is unsupportable.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10899"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Where is Consciousness?<br><span class="mindxheader"><i>posted on 10/18/2002 1:31 PM by entell</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id10899" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10899" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I think it is quite useless to try to replicate the brain in silicon (or whatever) 
<br>
to find consciousness or make intelligent machines. I believe the brain is simply a tool for intelligence to present itself on. Much like software running on PCs. The PC can do and be many things based on what software it runs. The software is what makes the PC what it is. The hardware is just the platform for 
<br>
the software to run itself on. If researchers are trying to replicate 
<br>
the brain to get to intelligence, I believe they will be very disappointed when they 
<br>
assemble the artificial brain. I can't believe that brain would be the 
<br>
source of intelligence. If so, there is a very interesting question to 
<br>
be asked: what is the difference between a dead person and a living one? Or even better, a 
<br>
normal living person and a person in a coma. The brain is alive and ticking yet there is no consciousness. Therefore consciousness cannot
<br>
possibly be a product of the brain. I have my doubts about if we can ever replicate it in a machine. I know this might sound very unscientific, but what about the role of the soul in all this?  The soul is perhaps not a scientifically proven fact, yet, however, just because it is not proven doesn't mean it does not exist. It is quite possible that there is a higher level "software" (which I refer to as the soul) running on our brains that is the real source of the intelligence that we are trying to replicate in a machine. Once the person dies, there goes the soul (and the software). This explains why it is not enough to keep the brain cells alive to have a conscious person.
<br>
<br>
Apart from consciousness, this thing I refer to as the soul could also be the source of creativity. You know how sometimes you come up with solutions to problems that you didn't know you knew and it just popped up at the least expected time?  Where do those creative thoughts come from? From consciousness? From neurons firing in a completely new pattern (chaos)? 
<br>
<br>
I am also familiar with the concept of genetic programming. In that case, there is yet again no consciousness. It's simply exploring a limited space of solutions to a given problem in a 'brute force' fashion. It is a directed search so it is not completely a dumb process, but still there is no conscious thinking involved. I am a hardware engineer myself and I do quite a bit of creative thinking on a daily basis. Sometimes I wonder if a machine could do my job completely on its own, and if it could, what it would need to be able to accomplish that. For simple things, genetic programming seems good enough, but once the project gets a tiny little bit complicated, I don't think an uncreative process like genetic programming (or any other method) will accomplish much. A creative tool, which doesn't purely depend on just IF-THEN-ELSE statements or 'brute force' searches for the possible best solutions, would be needed. No less will do. 
<br>
<br>
I read quite a bit of the articles on this website, but I was so disappointed because they either re-state known facts, or they are very very focused on "replicating the brain" as if there is a 100% guarantee that doing so will create consciousness. I would think really open-minded scientists would be questioning a lot more before taking on such a difficult task. 
<br>
<br>
I do realize, however, that in simple replication of brain-like behavior, we see some intelligence. When we create artificial neurons, and tie them up the way they are tied up in the brain, we see that they make good speech synthesizers and handwriting recognizers. However, replicating functionality does not equal replicating intelligence or creativity or consciousness. The handwriting recognition hardware did not have the "experience" of doing so. It did not even do so at a conscious level. That's all it is meant to do and it did it because as far as it is concerned, there is nothing else to do. Perhaps we need to be able to communicate with the recognizer to really know if it experienced anything or not.  :)
<br>
<br>
<br>
Anyone with any comments with any of the things I said?  Please let me know. I would like to hear your comments.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10901"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 10/18/2002 2:46 PM by <a href="http://web.archive.org/web/20071011164315/mailto:azb@llnl.gov">tony_b</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id10901" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10901" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>entell,
<br>
<br>
I appreciate your sentiments, but scientific methodology is based upon what can be observed and the efficacy of function.
<br>
<br>
You say that you are conscious.  I claim that I am.  If we were to meet, I would likely be convinced that you are indeed conscious, but my reasoning is not terrible scientific.  It would be a "leap of faith".  It would be silly (statistically) to imaging that I am conscious, and yet all others that "look and act like me" are merely chemical-reactions evolved to present the appearance of consciousness through clever interactions with the environment.
<br>
<br>
But ultimately, consciousness is "what it feels like to be conscious", and that is a subjective measure.  Only the "beholder" can be ultimately convinced.  You say that the comatose person is not conscious, but what criteria are you employing?  They do not respond to you.  So what?  They exhibit no brain waves.   Ok, brain-waves have been show to correlate strongly to certain pattern of thought.  But the lack of brain-waves does not constitute "proof" of loss of internal consciousness.  I will grant you, it probably does, but that is not really "provable".
<br>
<br>
You mentions that genetic algorithms (and other AI techniques) yield the appearance of some intelligence or cleverness in a "limited domain".  True, but as more is learned and these systems are given more general heuristics, that "limited domain" can certainly grow.  There is no a-priori reason it cannot grow to the point that it is (behaves) "more clever" that humans, in a very general sense.  Conscious?  Who really cares.  Behavior is all that matters, functionally.
<br>
<br>
I firmly believe that science (and logic) can never answer whether "soul", as you put it, exists or not.  But from a scientific viewpoint, it can be of no service either way.
<br>
<br>
Science proceeds by (hoping to) delineate what can be made predictable (in the broad sense).  Actions that might originate from a "beyond physics" somewhere cannot be "dealt with", and cannot thus contribute to the functional formulations.
<br>
<br>
I tend not to hold to anything "beyond the physical", because I cannot see how a non-physical can effect the physical.  The "bridge" would need to be one or the other, and then the problem re-emerges at one end of the bridge, a seemingly impossible "non-physical-to-physical" interface.
<br>
<br>
(But, nowhere is it written that the universe must obey logical rules, so I am always open to possibilities, philosophically.)
<br>
<br>
Suppose a very "smart" robot reacts intelligently to your conversations, seems to "care" about you, but after being "struck in the head" its program gets scrambled, and falls into a "stupid loop" (the "program" locks up).  The robot is now "comatose", despite the fact that the processor is still cycling.  So, "mind" is not merely "any processing", but the manifestation of "effective processing".
<br>
<br>
I hope this clarifies (at least) my position.  Look forward to your thoughts!
<br>
<br>
Cheers! ____tony b____ </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10903"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 10/18/2002 4:29 PM by entell</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id10903" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10903" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I agree with you in that consciousness does not have to be created. It is functionally not required for a robot to experience what it is doing, feeling. In fact that might be a bad thing if we are going to continue making the robots do things for us. :)
<br>
<br>
On the other hand, I wonder if simply increasing the speed of processors, and being able to process more and more data in a given time will ever create entities truely intelligent. For example, Deep Blue can beet Gary Kasparov because it can "process" more moves than Gary can in a given amount of time. In my opinion, that does not make Deep Blue intelligent. It makes it very very fast, and it makes it "seem" intelligent. I think this is your point too. As long as a machine can pretend it is intelligent by being fast, then who cares that it does not have a consciousness. 
<br>
<br>
I agree with you except I don't know if it is ever possible to mimick or even surpass human intelligence by simply being fast. In the case of Gary vs Deep Blue, Deep Blue seems to be more intelligent, however, chess is a game where the number of moves are limited. The limited number of moves available is very very large number (practically infinite for humans), however, it is still limited. I can see a computer "seeming" to be more intelligent than a human when the number of possibilities are limited and there is a single solution, like chess, like backgammon, or go, or any other such game.
<br>
<br>
How about when the number of possibilities are infinitely many? How about when there is more than one answer with most of the possible answers being pretty much acceptable based on different trade-offs (like in an engineer project)?  
<br>
<br>
I am sure the computer will figure out the answers much faster than a human and "seem" very intelligent. This is also the game field for genetic programming. It tries to find solutions that match or surpass some criteria. And I am sure it will do a better job as processors get faster, provided that we have a way to describe the problem at hand in terms of chromosomes. Most problems are not very suitable for that except for simple things. In John R. Koza's genetic programming books (more like encyclopedias), there are great many examples of how genetic programming can be applied to real world problems, and he also claims the method re-invented some patented technology. Well I don't call that intelligence simply because trying all (or most) possibilities to figure out the best result does not require much intelligence either from a person or a machine. It is just a more directed search than inventing.
<br>
<br>
Real intelligence is when Enstein comes up with the theory of relativity or when Edison invents the electricity, or Newton figures out how objects behave.. out of the blue.. when no such thing was know to exist. That's what I call intelligence! 
<br>
<br>
Therefore, what I call intelligence is when a computer is NOT told everything, yet it can figure out the missing pieces on its own, and come up with the solution. In the real world, we don't always know everything to solve a problem. I can hear you say genetic programmind does not need everything. Artificial neural networks can also re-construct some information based on what is given, so they are good for handwriting recognition etc.. Very true.. However, consider this: Let's imagine an electrical circuit. Since I am an electrical engineer, I picked that example. If I want my "intelligent" computer to generate me a circuit, I am sure it will do a great job as long as I can explain my problem to it in the way it expects. Assuming all went well, and I told it the problem, and it is ready to start investigating possible solutions (with genetic programming or some artifical neural network setup), there is still one problem. It still has to know what "parts" to use in creating the circuit. I have to give it the basic parts to use from which it might create more complex parts. What if there is yet another basic part that I did not tell it, and it needs that basic part to create the most ultimate best solution? Then what?  It will give me a solution or a few solutions, but they won't be the best, and I probably won't know that they are not the best. The computer did not "create" anything. It simply presented the best fit given the inputs. It still missed the ultimate best answer because it could not create an ungiven input which will result in the bestest solution. This happens a lot in engineering.. For example the transistor was not invented until 1970. Before than computers were impossible. Then came the FETs which are like transistors but better in many ways.. So on and so forth.. I think you get the idea.
<br>
<br>
When the computer can do that kind of "thinking", I will bow in front of it, and accept its intelligence. Please note that this intelligence does not require consciousness unless consciousness is the root of such intelligence. Once again, in the case of Deep Blue, the universe of all possible moves are already known, so it is a matter of time to pick the best move. That does not require the intelligence I mentioned above. Only speed! In the engineering project example I mentioned, the universe of possible solutions is unknown. The computer might have to "invent" something new to reach the best solution. I don't think it will ever be possible to do this with "IF-THEN-ELSE"s, or fast processors, or artifical neural networks where the output is some mathematical function of the input. The output is always limited by what was on the input even though the given inputs could be mixed up to form seemingly new outputs. If the inputs are not large enough to span the entire possible outputs, then our intelligent machine has no luck creating certain outputs.
<br>
<br>
<br>
Lastly, the reason I think it is useless to re-create the brain in silicon is because brain is simply the platform where thoughts and experiences exist. I don't think brain generates "new" ideas. If it did, that would mean that every thought that can ever exist would be already in our brains somewhere. It would mean that the theories that Enstien "discovered" would have existed already in his brain unknown to him, until he thought them into existance... I think it is quite optimistic to imagine that the "new" ideas come from new connections in the brain between neurons for the reason I explained in the previous paragraph. How could neurons cause a completely new thought to appear from nowhere when that thought was not present in the system in the first place?  Well it might happen in the brain, but the computers that we are trying to make intelligent don't work that way. What goes in comes out and what can happen to the input is based on what is known  :)
<br>
<br>
My few cents on the topic. Please feel free to comment on them! </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10904"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 10/18/2002 5:42 PM by Grant</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id10904" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10904" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>A brain surgeon whose book I read recently said words to the effect that consciousness is merely that part of the input and processing that our minds are paying attention to at the moment.  In other words, it's what our minds are focused on.  When AI has the task of dealing with multiple inputs and complex tasks simultaneously to the point that it can't give full attention to more than a few at a time, it will have to pick and choose which require immediate attention and which can run in the background -- in other words, unconsciously.  When the AI mind is divided between this kind of conscious and unconscious processing, it will no doubt be a lot like us.  This does not seem like an impossible thing to reproduce in a complex machine.
<br>
<br>
Grant</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10905"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="80"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="599"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 10/18/2002 5:53 PM by Grant</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id10905" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10905" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>P.S.  Think of an AI built around multiple processors.  One processor handles sight, another handles hand and arm or other types of movement, another handles sound, or other input from inside the machine and the operation therein, and a final one that overrides them all selects between them to decide which requires the AI's immediate attention.  The mind of the AI would be the communication that takes place between all the processors as it acts on the information coming from all of them simultaneously.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10908"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 10/18/2002 8:55 PM by <a href="http://web.archive.org/web/20071011164315/mailto:azb@llnl.gov">tony_b</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id10908" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10908" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>entell,
<br>
<br>
I will be the first to agree that Deep Blue, for all its chess-move "intelligence", in no general intelligence, and nowhere near what we might call an artificial "mind".
<br>
<br>
And I have long expressed reservations about the ability for any algorithmic system to "be a real mind" in the conscious sentient sense to which we are accustomed, because the brain is not merely neurons signalling one another, but also involve subtle EM patterns, chemical pressures, etc.  Moreover, the hyper-fine energy states between "close" neural wave patterns may be a phenomenon that is sensitive to deep QM-indeterminacy, something that a typical transistor-based algorithm support system is specifically designed NOT to be sensitive toward.
<br>
<br>
But having said all of that, I think we need to recognize when qualities attributed to "humans" are really something more, despite our belief that they are.
<br>
<br>
Today (still) the human brain is many magnitudes more complex than any "computer+program" ever built.  The entire internet *may* have capacity, processing power, and complexity rivaling a human brain, but it is nowhere as well "structured", and was not designed to support any centralized sense of operation or agenda.  Simple "speed" will not yield intelligence, even the arificial kind.
<br>
<br>
However, our brain's very complexity leads us to "manage" things for which the "mechanism" is so deeply removed, we often attribute it to support things it may not support, or may not exist at all.  That is, lacking a full understanding or appreciation of its mechanisms, it remains "magic" to us.
<br>
<br>
Creativity is an excellent example.  We get a "novel idea", and assume that it somehow was "created", as if it has a substance, rather than being a pattern or arrangement of previous elements whose new "harmony" causes it to become replayed and embedded into memory.
<br>
<br>
When you need to solve a problem, you do not consciously "search a huge space foolishly", nor do you consciously call upon a "good path-trimming heuristics algorithm" to find a good solution quickly.  That does not mean you are not effectively doing the same thing, however creative or "intuitively-directed" it might feel to you.
<br>
<br>
Deep Blue "could" look through a billion stupid choices to find the best one.  Given the heuristics the programmers gave it, it was able to trim away 99.99% of "really stupid" paths, and apply more attention to those that remain.  If the programmers wanted to, they could have had it (periodically) investigate 1% of the really-stupid paths anyway, since it might learn new gambits on occasion.
<br>
<br>
What if the programmers, instead, gave it the heuristics to experiment with heuristics in general?  Again, seen in isolation at "only that level", it seems like "intelligence in a limited domain - heuristics development", but remember that as it discovers/invents improved heuristics, it is also employing them in (say) chess playing, or who knows what.
<br>
<br>
Now, it is no longer the programmers who are programming the system about good chess playing, and to say that it cannot "output" anything that was not specifically "input" is harder to maintain from a functional viewpoint.  It will have "learned" to play better chess "on its own", viewed from the higher layer of chess-playing.
<br>
<br>
Allow it to expand its domain to "games in general", or "problems in general", along with the ability to interact and absorb the environment (as we do), and the boundaries between "inside and outside" begin to break down completely.  As the "heuristics space" becomes more general, the kinds of behaviors that can manifest are no more limited that humans are limited.
<br>
<br>
The notion that we (individuals) are really separated, and have a real "inside and outside", is a nice conceptual approximation, but may be entirely false.  When you think you have generated a new idea, can you honestly claim that nothing you ever absorbed from the "outside" had any influence in the ability of that idea to come forth?  More esoterically, if we and the universe are really QM-entangled, then anything we build is likewise entangles, and if it is designed to be QM-sensitive, there will be no plausible rationale for claiming it cannot become as "mindful, willful, and creative" as we believe ourselves to be.
<br>
<br>
As much as I enjoy the metaphysical, I am not "convinced" that our mind is anything other than a manifestation of the pure physics.  To claim that we "originate thoughts" is to say that we never absorb outside variety.  We may instead be very good pattern-correlators and good harmonic generators from the complex of inputs we recieve.  If this is the case, then there is no reason "in principle" that a different substrate could not manifest equivalent functionality.
<br>
<br>
Perhaps, as "conscious manifestations", we are all really a single quantum-connected mind-system, and our feelings about "soul" or "self-hood" are really just mis-interpretations of that quality, from individual and limited viewpoints.  But I see the "individual soul thing" as largely a way to try to answer "where do I go when my body ceases, what happens to ME", in the hopes that there is such a "I go".  I do not see other real evidence that "I" is anything different that my current sense-of-the-moment.
<br>
<br>
If we are purely physics, (even if some physics yet not discovered or understood) then we will apply the physics as we discover it.  Why assume otherwise?
<br>
<br>
<br>
Cheers!  ____tony b____</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10911"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="80"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="599"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 10/18/2002 11:09 PM by entell</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id10911" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10911" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>tony_b,
<br>
<br>
<br>
I thank you for sharing your thoughts with me. 
<br>
I think you should write an article or two for this website (perhaps you already have). The ones I read on this website so far has not been as interesting as our dialog.
<br>
<br>
It is interesting that you mention how things are one at a quantum level. I know for a fact that many scientists came up with the same inventions/discoveries simultaneously around the world (even though most of the American scientists were given the tiara by historians). I always thought that that was a weird coincidence until I started reading about quantum theory and how at that level the boundries between the basic particles disappear. Assuming that that is correct, those of us who are sensitive enough to pick up vibes from one another must be "hearing" the others thoughts or something along those lines. We are perhaps one at some level even though at the physical level we live in, we appear to be separate individuals. And perhaps creativity is nothing more than the brain acting as a radio receiver and picking up the transmission from each other and from other places.
<br>
<br>
It is also interesting that if you read biographies of scientists, most admit that it is when they don't consciously think about their problems is when the solution arrives.. Well at least the ones humble enough to admit it.
<br>
Perhaps thought creation is not a conscious activity at all.
<br>
<br>
Looking at the brain for the purpose of finding the roots of thought and creativity would be a good reason I suppose since it does create or bring forth what was created. 
<br>
<br>
Since I make computer systems all day long, and I know how they work, I think it is the toughest thing to get them to do what we can do in terms of creating solutions. Every time I hear a story about some "smart" machine, I read it hoping that someone found the source of thought, or someone got a processor that can do more than jumping from state to state. That's all a processor is by the way even though it seems magical to many people. It moves from state to state based on its current state and the inputs. Each state is a function that it can do which is limited by simple math functions and comparisons and a few basic logic operations. It sometimes amazes me to observe what computers can do today, but when I dig down into it to find the "smartness", all I find is a few digitized inputs that are connected to some comparison functions and some logic operations. Perhaps a few add's and multiply's.. Nothing magical at all.
<br>
<br>
My point is that I think most of us are VERY disappointed with AI today after decades of research because computers can't even separate junk e-mail from good e-mail. I think we had very high expectations in the first place. The computers today simply lack the capability to come up with the "creative" solutions to problems we have. Their hardware is simply not sophisticated enough. For some time, it looked like if we had enough "if-then-else"s and a fast enough machine equiped with some kind of "learning" algorithm, we could conquer the universe. It turns out that's not the case. This scheme dose work well for some limited amount of situations. Dr. Rodney Brooks can get robots to behave like animals having them learn how to walk on their own. We can have computers learn on their own how to read English sentences out loud just like a baby learns how to speak and read. However, it is much tougher to teach a computer which piece of code is a virus, and which other ones are simply trying to re-order the data on the harddrive so that it can be accessed more easily. 
<br>
<br>
Apparently the brain is much better in many ways at these more difficult issues. Apart from being complex, it seem to have connections to something that seems to allow it to be more than its own parts. I do agree with you that most of the time the solutions we find are re-arrangements of previous knowledge we gained consciously and unconsciously, but I can't believe that 100% of all solutions we find to problems are that way. Inventors, scientists and entreprenuers always brag about how they had to "re-invent the process" or "re-invent themselves" to do what they did. In fact, I believe such people are the gifted ones who can "somehow" see things differently than the rest of us. They in fact reject what is inputed to them, and they "create" their own new ways. I am not sure if this rejection is really what is going on in their heads. Perhaps they are indeed re-arranging what is there, and presenting it in a completely new way so it looks all different to us in the end. However, I think it is more likely that they indeed introduce new concepts, thoughts, ideas into the system. I am not sure where they get them, but until we figure out where they get them and how, our computers will be doomed to relay good e-mail together with the junk e-mail. Maybe this "quantum computer" concept will bring some new blood to the field. Yet again I have my doubts. This 1's and 0's business worked out good so far, but I doubt it will suffice to create the thinking machines we want. If binary was the ultimate thing, I am sure we would have seen more of it in nature. 
<br>
<br>
As you said, perhaps there is something  fundamentally unique about these tiny neurons and what happens at the gaps and with all the electro-chemical reactions going on around them. Perhaps they are small enough to be very sensitive to some other "things" that we can't measure or see in the lab yet. The most amazing thing is that they can look at themselves and be curious about themselves and try to figure out how they work. You would think that they would know how they themselves worked!  :)
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id12971"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="100"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="579"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 12/27/2002 5:50 PM by Grant</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id12971" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D12971" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>On the subject of binary coding, nature has been doing it for 3.5 billion years.  DNA is a form of binary code using a chemical medium.  Think of AT as 1 (A and T are always bound to each other) and GC as 0 (also bound together) and you have the equivalent of a Turing tape with 1s and 0s operating a cell/factory to turn out various kinds of products.
<br>
<br>
A cell is little different from a factory that uses software to produce cars or motherboards.  The software is lines of DNA and the hardware is basically proteins and other chemicals.  DNA passes infomation to RNA and RNA uses that information to construct a variety of products which are used by the cell to communicate with other cells, fight off invaders, and reproduce itself.  Some invaders though, such as viruses. use the cells' RNA to reproduce themselves and sometimes destroy the cell in the process, just as a computer virus can destroy the information products used to operate a computer.
<br>
<br>
So nature does use binary code to create and operate all living things.  It always has.
<br>
<br>
Grant</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id12975"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="120"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="559"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 12/27/2002 7:06 PM by <a href="http://web.archive.org/web/20071011164315/mailto:azb0@earthlink.net">tony_b</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id12975" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D12975" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Grant,
<br>
<br>
Actually, you need two bits for each of A, C, G, T, since it matters which side of the helix each pair appears on.
<br>
<br>
That is:
<br>
<br>
. A - A - C - C - T
<br>
. T - T - G - G - A
<br>
<br>
is NOT the same code as
<br>
<br>
. A - T - C - G - T
<br>
. T - A - G - C - A
<br>
<br>
But whether binary, quaternary, or any other n-ary, the REAL issue is unchanged.  By our method of viewing the world, we can break it down into changes between distinct states, or see sequences of items from a distinct "alphabet" of codes.
<br>
<br>
And indeed, the living cell is very much like a state-machine, at that level of description.  AND given a machine that acts on binary code, all "n-ary" codes can be represented, along with the machines to interpret those codes.
<br>
<br>
BUT, as to the topic of consciousness ... it is not entirely clear that merely reproducing the same "logical sequences" in an alien machine will produce the same result (consciousness, or not).
<br>
<br>
Given a completely different set of fundamental forces (say, excluding electric charge) you might (conceptually) invent a family of particles that could form a "chemistry", form the "logical equivalent" of A, C, G, T, and even (thus) produce the equivalent of living cells (and animals, etc).  But if the phenomenon of "consciousness" is (for some peculiar reason) keyed to only "electrical behaviors/manifestations", these would be absent from the new alien "physics".
<br>
<br>
So, the debate rages about the nature of the "quality" of consciousness that we "feel" we possess (experience), and what is required to support it.
<br>
<br>
And all of this, despite any homomorphic logical identity of machines.
<br>
<br>
A silicon brain may well support consciousness ... but only that "brain" will know it.  The rest of us will simply be convinced ... or not.
<br>
<br>
<br>
Cheers! ____tony b____</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id12979"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="140"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="539"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 12/27/2002 11:12 PM by Grant</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id12979" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D12979" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Tony,
<br>
<br>
For an interesting look at the roots of consciousness, you might give this paper a look.  It's a publication of the Congnitive Science department of The University of California at San Diego (UCSD).
<br>
<br>
http://cogsci.ucsd.edu/cogsci/publications/97_05.pdf
<br>
<br>
Grant</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id12981"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="160"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="519"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 12/28/2002 12:54 AM by <a href="http://web.archive.org/web/20071011164315/mailto:azb0@earthlink.net">tony_b</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id12981" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D12981" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Grant,
<br>
<br>
The paper you cite, "Perceiving a New Category:  The Neurological Basis of Perceptual Categorization", is interesting in relating lower-level functioning/perception to higher-level conceptualizations (models and categories).
<br>
<br>
But all of it could be ascribed to many algorithmic processes that we generally believe to be quite "unconscious" in the sense we believe ourselves to "feel conscious".
<br>
<br>
In other words, the paper is good at formalisms, but does not really address "the subjective experience of consciousness" at all.
<br>
<br>
The paper argues that (our) low-level "perceptions" do not merely preceed the latter "conceptualization of categories", but that the very categorization is part and parcel to the effective operation of perception in the first place.  OK, I can buy that.  But we could use this insight to develop a better automatic garage-door opener, and never come to believe that the device "experiences consciousness".
<br>
<br>
I tend to the view that consciousness is a necessarily subjective experience, and that the only one who "knows" it is present is "the beholder".  Everyone else will either be convinced, or not.
<br>
<br>
Can consciousness manifest in an alien substrate?  I don't SEE why not.
<br>
<br>
Will understanding the "formal" mechanics and organization of data-flows in a biological brain AID in producing systems that behave as-if conscious?  Sure, it could only help.
<br>
<br>
Will any amount of such theorizing and engineering produce a PROOF that the consciously-behaving product actually EXPERIENCES consciousness, as we feel we do?  I don't see that as possible.  I believe that only "that entity" will know, beyond a doubt, whether it is a "waking awareness".
<br>
<br>
And we will have to trust it, or not, when it behaves well enough to challenge us with the very question.
<br>
<br>
Cheers! ____tony b____ 
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id12987"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="180"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="499"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 12/28/2002 10:11 AM by Grant</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id12987" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D12987" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Tony,
<br>
<br>
You may be trying to make more out of consciousness than is really there.  I think what we call consciousness is just the brain function we are paying attention to at any moment.  All of our senses and all of our internal brain functions are working all the time.  But when we pick one out to pay attention to, such as moving a finger or identifying a sound, we become conscious of that experience at that time.  I believe consciousness is the act of paying attention.  Of focusing that portion of the brain which coordinates the activities of mind and body on specific tasks to concentrate those activities on a specific goal.  Someone throws a ball and we coordinate eye and hand and awareness of time and distance to catch it.  We are always engaged in something, even when sitting still.  What the mind is engaged in is consciousness.  What it is not specifically engaged in we call the unconscious.  The brain processes all of the sights and sounds and smells, tastes and feelings including the memories triggered by those inputs and we continue to process the data about these things in the background, but we only remember what we were paying attention to.  What we remember is what we were conscious of.  And that's consciousness.  IMHO.
<br>
<br>
Grant
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id13001"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="200"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="479"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 12/28/2002 10:18 PM by <a href="http://web.archive.org/web/20071011164315/mailto:azb0@earthlink.net">tony_b</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id13001" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D13001" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Grant,
<br>
<br>
You are absolutely right about that.  Yes, that which we are conscious of is the activity to which we are "paying attention".
<br>
<br>
But what defines "paying attention"?
<br>
<br>
Consider the robot Aibo, (or any of its kin).  It has numerous processors taking care of "mundane, housekeeping", while some few of them are attempting to manage the "main task", which might be to track the motion of a ball in order to kick it in a given direction.  Lower order processors help maintain balance and orientation, while the main processors "pay attention" to the ball.
<br>
<br>
So is Aibo conscious?  Maybe.  The mere fact that Aibo does not (likely) think "why am I chasing this silly ball" certainly makes him "seem" less than conscious, but that may be just a human chauvinism.
<br>
<br>
Your PC may have only one physical processor, but it is timesharing many tasks, one of which is just to keep that little display clock on the correct time, another is to manage which process is using what portion of memory so they do not step on each other.  But it pays its HIGHEST attention to the GUI, for it must respond to your typing and mouse-clicks immediately.  In a sense, it is "paying attention" to you (via the interface.)
<br>
<br>
So, is your PC "conscious"?
<br>
<br>
My bottom line is, the sensation that I have of being conscious, what it "feels like" to me, is something I can only surmise is similar for you, and would have no idea at all whether even the most "paying attention" robot actually "felt" as I do as a consciousness.  It might, and it might not.
<br>
<br>
I say, you would have to "be it", to know for certain.
<br>
<br>
Cheers! ____tony b____</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id12965"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 12/27/2002 12:55 PM by stevenm@highwire.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id12965" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D12965" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I don't get the logic of your last paragraph...  You say that the brain does not generate new ideas because it would mean that all ideas must preexist in the brain.  I take 'generate' to mean creating something that did not exist before.  To 'discover' on the other hand would mean to identify a pre-existant fact... I know this could just be semantics but if I switch the words to conform to my understanding of them, it means that the human brain generates new ideas all the time.  Ideas that conform with varying degrees to perceived reality and live or die based on a lot of factors, but hopefully greatest of these factors is how well they model reality.
<br>
<br>
Can a silicon brain achieve creativity?  I've found at least one source that suggests that they can.  See http://www.imagination-engines.com/
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id11575"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 11/13/2002 5:13 AM by <a href="http://web.archive.org/web/20071011164315/mailto:ankit_narang@da-iict.org">Ankit Narang</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id11575" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D11575" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Hello
<br>
I am Ankit from India. I am really short of time right now. I am doing B.Tech in Information and communication technology from DA-IICT Gandhinagar (www.da-iict.org) and we guys have to submit a project for a course called Intruduction to design. My topic for the design is "Computer procerssor Vs. Human brain". And I have to come up with a product (concrete). And I donno why am I mailing you. The point I wanted to emphasise is that it would be shit on our part saying that we can't replicate human brain. I think and belive that we can and shall.
<br>
Goodbye
<br>
Ankit Narang
<br>
India</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id17883"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 06/11/2003 5:26 PM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=404">metaphysics</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id17883" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D17883" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>yes the possibility to replicate the actual functioning of a human brain is plausible but the brain has aspects to it that seem to demonstrate that their is another component such as instincts, that seem to be beyond the simple physical elements of the brain. We may replicate the physical elements of the brain but the pattern of its functioning is just so complex as even now we hardly know what abilities the brain has</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id17885"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Where is Consciousness?<br><span class="mindxheader"><i>posted on 06/11/2003 5:52 PM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=21">/:setAI</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id17885" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D17885" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>this notion that unconscious processes like intuition and epiphany must be "other" than neurofunction is based on poor reasoning and examination of the evidence- [Penrose makes this error]
<br>
<br>
all that "hidden" unconscious processes like intuition imply is that the structures responsible for generating the "idea" are simply not WHOLLY interconnected with the modular hierarchical process of consciousness- basically- their are regions in the brain- particularly the ancient/emotional areas like the limbic system- that operate in a different way than the rich interconectedness of the cortexes- these primitive strucures were adapted by survival pressures in less-conscious animals- thus they are more "automatic" when certain signals are sent to their inputs- their sub-modules are relatively isolated from the networks of consciousness- so the conclusions and commands they output seem as if they have no known source! "the idea came from nowhere" but it DIDN'T- only the processes which formulate these intuitions and epiphanies are hidden- 
<br>
<br>
but why are they hidden? because much of these processes involve direct reactions and hard-wired survival/planning functions which wouldn't make very much sense in a conscious memory-web comparation process- it is no coincidence that intuitions/epiphanies arrise out of activity in the primitive regions of the brain where the rules are more automatic</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16398"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Dennett's Dopey Idea<br><span class="mindxheader"><i>posted on 04/15/2003 5:13 PM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=221">Clifford</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id16398" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16398" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>  When I read that Steven Rose (the "British Carl Sagan" and a man who literally WROTE THE BOOK on Darwin's theory of natural selection) says Darwin's books state NOTHING about consciousness, I was puzzled.
<br>
<br>
  But then Noam Chomsky and physicist Michio Kaku both told me that Dennett's assertion that Charles Darwin proved strong AI is a contention that just plain BLOWS.
<br>
<br>
  Aside from Dennett's science-fiction riff on the Darwin legend, there's some question as to why Chuck got buried next to Issaac Newton. The British Crown knew Darwin was one of history's MAJOR PLAYERS, but someone forgot to tell the lab biologists- you know, the people who actually DO things instead of WRITE things. Lab biologists make NO use of Darwin's theory. His book just sits on their shelf next to Aristotle's "Physics" and everybody rests easier knowing that the universe has been EXPLAINED.
<br>
<br>
  But if you're the type who's into UFOs and channeling, you might dare take a peek at MENSA science writer Richard Milton's book, "Shattering the Myths of Darwinism". Oxford gasbag Richard Dawkins threatened to have Milton's ass hauled off to a Psychiatric "hospital".
<br>
<br>
  What Dennett, Dawkins and Francis Crick REALLY should do is pack into the Evangelical Atheism Mystery Tour Bus and let everybody in on the painfulTRUTH. Maybe they could hook up with G. Gordon Liddy and slap around ideas about life in another mail-order video debate.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16399"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Dennett's Dopey Idea<br><span class="mindxheader"><i>posted on 04/15/2003 5:57 PM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=2">subtillioN</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id16399" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16399" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p> <center><p class="mindxquote"> Lab biologists make NO use of Darwin's theory.  </p></center>
<br>
Lab biology doesn't take place on evolutionary time scales.  Nevertheless the small scale details of evolution has been witnessed in the laboratory.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id26115"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Dennett's Dopey Idea<br><span class="mindxheader"><i>posted on 07/18/2004 6:28 AM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=1332">nomade</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id26115" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D26115" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>very amusing and enjoyable post exposing the tendency of Dennett &amp; Co. to interpret science in order to justify a particular metaphysic- a procedure based on an unscientific attitude.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id26168"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Dennett's Dopey Idea<br><span class="mindxheader"><i>posted on 07/20/2004 2:57 AM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=1338">keithprosser</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id26168" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D26168" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>After a few thousand years of kicking round the same ideas, I think it's time we tried to find out why every philosopher since Aristotle has gone around in circles regarding consciousness.
<br>
<br>
The idea that consciousness is 'something' is based on the observation (call it that) that one is conscious or 'has consciousness'.  We know better than that for everything else.  Perception of X does not mean X exists.  It only means X is 'neural representated', so suppose we say that consciousness is also just that - the neural (mis)representation of mechanistic brain action?
<br>
<br>
The brain does interpret neural representations - that is its job.  If it represents its own function (which is in reality just a deterministic, if complex, process)as something strange and mysterious then we will perceive 'consciousness' as strange and mysterious.  But that does not mean there is anything strange and mysterious going on - we only perceive that there is.
<br>
<br>
The brain (or a machine) does not need to implement 'subjective consciousness' to account for self-perception of that strange phenomenon.  (And there is only evidence of it being self-perceived, and none for its actual existence).  
<br>
<br>
All the brain has to do is neurally (mis) represent its own function and be able to interpret such neural represenations, both of which are (almost!) indisputably basic actions of the brain, and presumably this would be much easier to implement artificially than real 'subjective consciousness', which I deny the human brain really does/has.
<br>
<br>
<br>
<br>
<br>
<br>
<br>
Does this help?
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id29052"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Consciousness in Human and Robot Minds<br><span class="mindxheader"><i>posted on 11/15/2004 11:30 AM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=1542">faiz_is_studying</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id29052" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D29052" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Of course it is theoretically possible for a robot to obtain a conscious.  This whole essay is trying to prove the obvious.  Dennett has carefully manoeuvred his wording so that he is only required to prove that robots can acquire a conscious if there was an enormous amount of funding and time available.  Money can buy just about everything.  It is obvious that these 'economic reasons' can theoretically make it possible for programmers to give robots a consciousness.  
<br>
<br>
Although I do believe it is possible for a robot to have a conscious, it will not be happening any time in the near or distant future.  I believe that the four arguments made against the possibility of a robot cognisant were manipulated by Dennett to appear unintelligent.  In fact, they are logical arguments and I feel as if it is only fair to defend them in more detail.  
<br>
<br>
'(1) Robots are purely material things, and consciousness requires immaterial mind-stuff.'
<br>
<br>
This statement does not even use proper grammar.  In addition, the grammar that is used sounds like a second grade child wrote it.  Readers should not be fooled by Dennett's manipulative wordings to believe what he writes. 
<br>
<br>
'(2) Robots are inorganic (by definition), and consciousness can exist only in an organic brain.'
<br>
<br>
All life as known to mankind is organic and as such our brains can only measure that which we know.  As a result, this argument may be true since we have only experienced evidence of consciousness within organic beings.  Thus, there is no proof that inorganic robots can develop a conscious.
<br>
<br>
'(3) Robots are artefacts, and consciousness abhors an artifact; only something natural, born not manufactured, could exhibit genuine consciousness.'
<br>
<br>
Consciousness that is genuine cannot be interpreted using a mathematical formula developed by a computer scientist.  A genuine consciousness can never be copied, as it is unique to every person.  Although the Cog uses experience as a learning basis, there are too many actions that can occur which will affect the Cog's lifetime.  
<br>
<br>
Furthermore, a machine cannot experience the same things that real humans can.  A machine does not know the feeling of eating food, drinking water, or even getting angry.  In addition, sometimes a genuine consciousness would like to forget about its worries in life and become intoxicated with alcohol.  A machine would have major problems obtaining a real and genuine consciousness.  
<br>
<br>
<br>
<br>
'(4) Robots will always just be much too simple to be conscious.'
<br>
<br>
Not enough explanation was given to support this statement.  The human mind is extremely complex and is dependent on actions that occur surrounding one's life.  These external actions that occur are countless.  There are way too many for a computer scientist to keep a track of.  
<br>
<br>
Human feelings are like an extensive series of webs interlinked and weaved together.  There can be random feelings going on at any given moment in the human mind mixed with other random feelings.  Once again, it would be very difficult to nearly impossible for a computer scientist to program something this complex.  There are simply too many feelings that can go on in one's mind.  
<br>
<br>
One extremely difficult component of the human mind to create is affection.  One can become affectionate with other individuals for different reasons.  I do not believe it is necessarily experience in life that can decide whom you become affectionate with.  Some things are always left to be totally unexpected.
<br>
<br>
Personally, from a computer scientist's point of view, I feel as if it is a very difficult task to give a robot a conscious.  Just by allowing a robot to learn things by itself from experience will not work alone.  There will need to be billions of static lines of code to make a robotic consciousness become genuine.  Maintaining this code would be just about close to impossible.  However, given the brightest resources to work on this task, I am sure that in five hundred years it could happen.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id29057"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Consciousness in Human and Robot Minds<br><span class="mindxheader"><i>posted on 11/15/2004 2:06 PM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=35">grantcc</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id29057" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D29057" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>A couple of points your argument overlooks.  
<br>
<br>
One, you imply that a robot cannot be organic.  Once we learn to use the DNA and proteomic code there seems to me to be no limit to how we can combine metal and organic substances to produce robotic beings.  We just have to stop thinking of robots as tin men who can only do what they are preprogrammed to do.
<br>
<br>
Two, you imply that programming will only be done in a linear fashion as it is being done right now.  What is to keep us from developing robots that program themselves the same way we program ourselves?  The brain is a complex adaptive system that uses experience and evolutionary (in the sense of adapting itself to survive in whatever environment it finds itself) adjustments to program itself.  
<br>
<br>
If a few thousand brain cells from a mouse can control an airplane, what is to keep a few billion brain cells from controlling a robot?  By "control" here I mean "self control" rather than control by an external entity.  We could just give a robot an assignment and expect it to carry it out with a pre-program that consists of learning and practice rather than stuffing ones and zeros into its head.  The airplane that flies with the aid of mouse brain cells is as much a robot as a Japanese toy that can walk and dance.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id30347"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Consciousness in Human and Robot Minds<br><span class="mindxheader"><i>posted on 01/12/2005 10:46 AM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=1513">anyguy</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id30347" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D30347" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I think conciousness is something that comes with your ability to control your environment. Toolmaking or  technology. Put some more order to your environment (R. Kurzweil, Law of Time and Chaos) and soonly you will reach a perception of time. Because you have control on the sequence of events.
<br>
<br>
Conciousness is an inevitable phenomenon simply because at certain point you have so much control over and intervention with the physical world around that you suddenly find your self to be 'I', the very subject(1). Since you have the capacity to act like one.
<br>
<br>
 Counciousness may be defined as constructing a conceptual interaction among self, universe and time. Time comes with conciousness, when you have so much control over the universe (or in a way your self,)- lets say, being able to mate, eat anytime you want, either because you have better tools or intellect to hunt or collect and keep-; then a different or more meaningful sequence of events comes to your perception.  Simply because you have at some degree, control over it, enough to make it a sequence, in other words create information.   
<br>
<br>
(1) Gottlob Frege, the great logician of the early 20th century, made the obvious but crucial observation that a first-person subject has to be the subject of something. In which case we can ask, what kind of something is up to doing the job? What kind of thing is of sufficient metaphysical weight to supply the experiential substrate of a self ' or, at any rate, a self worth having '
<br>
<br>
R.Kurzweil's 
<br>
<br>
Law of Accelerating Returns As order exponentially increases, time exponentially speeds up (i.e., the time interval between salient events grows shorter as time passes).
<br>
Law of Increasing Chaos As chaos exponentially increases, time exponentially slows down (i.e., the time interval between salient events grows longer as time passes).
<br>
Law of Time and Chaos In a process, the time interval between salient events (i.e., events that change the nature of the process, or significantly affect the future of the process) expands or contracts along with the amount of chaos.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id82690"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Consciousness in Human and Robot Minds<br><span class="mindxheader"><i>posted on 07/25/2007 1:24 AM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=4607">undercovers</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id82690" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D82690" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Well, obviously, consciousness will have to be re-defined if we are to include robots within our current terminology!  Are we saying that consciousness as the ability to learn and adapt?  Is there more to it?  Humans and robots are incredibly different, and if we change our ideas of what both are and consolidate them together, then we will have to change our philosophy as well.  Are we just as programmed as the robots that we create, or is there something more to it?
<br>
<br>
I guess what I'm saying is, humans make decisions based on past experiences and how they have previously seen others act in certain situations.  If robots are doing the exact same thing, what is the difference?  I feel that there is much more, but I don't want to assume too much and get a big head about my species!!
<br>
<br>
"Robots are well-thought-of entities that are created with some initial goal in mind...My point is: Robots are built for entire different purposes than we (the Humans) carry out generally."</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id82701"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Consciousness in Human and Robot Minds<br><span class="mindxheader"><i>posted on 07/25/2007 6:23 AM by <a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/profile.php?id=2395">doojie</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7356%23id82701" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011164315/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D82701" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Humans do not have such well thought out goals because there is a need for adaptation to circumstance.
<br>
<br>
 Since humans are embedded ina genetic system that codes similiarly to other genetic systems, we tend to enter into competition among systems, so that intelligence amnd consciousness is also embedded within those systems.
<br>
<br>
 The falw in consciousness is when we assume that we take the "software" of our symbol system and extend it in such a way that it transcends the physical substrate in which we are embedded.
<br>
<br>
 Religion and government follow this process, extending a symbol system over the "neurons" of the people themselves, and expect the symbol system to expand, but the result is a crash, in the form of revolution or speciation of systems.
<br>
<br>
 Essentially what we recognize as consciousness reacts to this process of crash and re-crash, and we adapt to that system using our own symbol system at a more individual level.
<br>
<br>
 But there is always a tendency toward rapid growth in some systems, and we select those traits that foster even greater growth(war, authority, tyranny, which are usually mechanical processes geared to an ideal and created to be resistant to change.
<br>
<br>
 Robots are programmed with these "ideals" in mechanical fashion, and are not embedded in a greater genetic or symbolic system.
<br>
<br>
 The problem with conscious robots is that consciousness operates at so many levels, even transcending the group and forcing us to react in adaptive processes. How to do that with robots?</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011164315im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>