<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>The Age of Intelligent Machines: Can Machines Think?</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/meme/memelist.html?m=7">Visions of the Future</a> &gt; 
<a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/meme/memelist.html?m=12">The Age of Intelligent Machines</a> &gt; 
The Age of Intelligent Machines: Can Machines Think?
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20090527091226/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0099.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0099.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/articles/art0099.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">The Age of Intelligent Machines: Can Machines Think?</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0031.html" target="_top">Daniel Dennett</a><br></span></td>
</table>
<br>
<div class="TeaserText">The "inner light, that private way that it is with you that nobody else can share ... is forever outside the bounds of computer science," argues philosopher Dennett. From Ray Kurzweil's revolutionary book The Age of Intelligent Machines, published in 1990.</div>
<br>
<br><span class="AuthorAffiliation">Distinguished Arts and <a class="thought" href="entries/science_entry.html">Science</a>s Professor; Director, The Center for Cognitive Studies, Tufts University.</span>
<br>
<br>
<span class="DatePublished">Originally Published 1990</span>
<br>
<br>
<p>Can <a class="thought" href="entries/machine_entry.html">machine</a>s think? This has been a conundrum for philosophers for years, but in their fascination with the pure conceptual issues they have for the most part overlooked the real social importance of the answer.</p>
<p>It is of more than academic importance that we learn to think clearly about the actual cognitive powers of <a class="thought" href="entries/computer_entry.html">computer</a>s, for they are now being introduced into a variety of sensitive social roles where their powers will be put to the ultimate test: in a wide variety of areas, we are on the verge of making ourselves dependent upon their cognitive powers. The cast of overestimating them could be enormous.</p>
<p>One of the principal inventors of the <a class="thought" href="entries/computer_entry.html">computer</a> was the great British mathematician <a class="thought" href="entries/turing_entry.html">Alan Turing</a>. It was he who first figured out, in highly abstract terms, how to design a <a class="thought" href="entries/program_entry.html">program</a>mable computing <a class="thought" href="entries/device_entry.html">device</a>, what we now call a universal <a class="thought" href="entries/turing_machine_entry.html">Turing machine</a>.</p>
<p>All <a class="thought" href="entries/program_entry.html">program</a>mable <a class="thought" href="entries/computer_entry.html">computer</a>s in use today are in essence <a class="thought" href="entries/turing_machine_entry.html">Turing machine</a>s. About forty years ago, at the dawn of the <a class="thought" href="entries/computer_entry.html">computer</a> age, Turing began a classic article "Computing <a class="thought" href="entries/machine_entry.html">Machine</a>ry and <a class="thought" href="entries/intelligence_entry.html">Intelligence</a>" with the words "I propose to consider the question, 'Can <a class="thought" href="entries/machine_entry.html">machine</a>s think?'" but he then went on to say that this was a bad question, a question that leads only to sterile debate and haggling over definitions, a question, as he put it, "too meaningless to deserve discussion."<sup>1</sup>
</p>
<p>In its place he substituted what he took to be a much better question, a question that would be crisply answerable and intuitively satisfying--in every way an acceptable substitute for the philosophic puzzler with which he began.</p>
<p>First he described a parlor game of sorts, the imitation game, to be played by a man, a woman, and a judge (of either gender). The man and woman are hidden from the judge's view but are able to communicate with the judge by teletype; the judge's task is to guess, after a period of questioning each contestant, which interlocutor is the man and which the woman.</p>
<p>The man tries to convince the judge he is the woman, and the woman tries to convince the judge of the truth. The man wins the judge makes the wrong identification. A little reflection will convince you, I am sure, that aside from lucky breaks, it would take a clever man to convince the judge that he was the woman--on the assumption that the judge is clever too, of course.</p>
<p>Now suppose, Turing said, we replace the man or woman with a <a class="thought" href="entries/computer_entry.html">computer</a> and give the judge the task of determining which is the <a class="thought" href="entries/human_entry.html">human</a> being and which is the <a class="thought" href="entries/computer_entry.html">computer</a>. Turing proposed that any <a class="thought" href="entries/computer_entry.html">computer</a> that can regularly or often foal a discerning judge in this game would be intelligent, a <a class="thought" href="entries/computer_entry.html">computer</a> that thinks, <i>beyond any <a class="thought" href="entries/reason_entry.html">reason</a>able doubt.</i>
</p>
<p>Now, it is important to realize that failing this test is not supposed to be a sign of lack of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. Many intelligent people, after all, might not be willing or able to play the imitation game, and we should allow <a class="thought" href="entries/computer_entry.html">computer</a>s the same opportunity to decline to prove themselves. This is, then, a one-way test; failing it proves nothing.</p>
<p>Furthermore, Turing was not committing himself to the view (although it is easy to see how one might think he was) that to think is to think just like a <a class="thought" href="entries/human_entry.html">human</a> being--any more than he was committing himself to the view that for a man to think, he must think exactly like a woman. Men, women, and <a class="thought" href="entries/computer_entry.html">computer</a>s may all have different ways of <a class="thought" href="entries/thinking_entry.html">thinking</a>.</p>
<p>But surely, he <a class="thought" href="entries/thought_entry.html">thought</a>, one can think in one's own peculiar style well enough to imitate a <a class="thought" href="entries/thinking_entry.html">thinking</a> man or woman, one can think well, indeed. This imagined exercise has come to be known as the <a class="thought" href="entries/turing_test_entry.html">Turing test</a>.</p>
<p>It is a sad irony that Turing's proposal has had exactly the opposite effect on the discussion of what he intended. Turing didn't design the test as a useful tool in scientific <a class="thought" href="entries/psychology_entry.html">psychology</a>, a method of confirming or disconfirming scientific theories or evaluating particular models of mental function; he designed it to be nothing more than a philosophical conversation stopper.</p>
<p>He proposed, in the <a class="thought" href="entries/spirit_entry.html">spirit</a> of "Put up or shut up!", a simple test for <a class="thought" href="entries/thinking_entry.html">thinking</a> that is <i>surely</i> strong enough to satisfy the sternest skeptic (or so he <a class="thought" href="entries/thought_entry.html">thought</a>). He was saying, in effect, that instead of arguing interminably about the ultimate <a class="thought" href="entries/nature_entry.html">nature</a> and essence of <a class="thought" href="entries/thinking_entry.html">thinking</a>, we should all agree that whatever that <a class="thought" href="entries/nature_entry.html">nature</a> is, anything that could pass this test would surely have it; then we could turn to asking how or whether some <a class="thought" href="entries/machine_entry.html">machine</a> could be designed and built that might pass the test fair and square.</p>
<p>Alas, philosophers, amateur and professional, have instead taken Turing's proposal as the pretext for just the sort of definitional haggling and interminable arguing about imaginary counter-examples that he was hoping to squelch.</p>
<p>This forty-year preoccupation with the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> has been all the more regrettable because it has focused attention on the wrong issues. There are <i>real world</i> problems that are revealed by considering the strengths and weaknesses of the <a class="thought" href="entries/turing_test_entry.html">Turing test</a>, but these have been concealed behind a smoke screen of misguided criticisms. A failure to think imaginatively about the test actually proposed by Turing has led many to underestimate its severity and to confuse it with much less interesting proposals.</p>
<p>So first I want to show that the <a class="thought" href="entries/turing_test_entry.html">Turing test</a>, conceived as he conceived it, is (as he <a class="thought" href="entries/thought_entry.html">thought</a>) quite strong enough as a test of <a class="thought" href="entries/thinking_entry.html">thinking</a>. I defy anyone to improve upon it. But here is the point almost universally overlooked by the literature: there is a common <i>misapplication</i> of the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> that often leads to drastic overestimation of the powers of actually existing <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/system_entry.html">system</a>s. The follies of this familiar sort of <a class="thought" href="entries/thinking_entry.html">thinking</a> about <a class="thought" href="entries/computer_entry.html">computer</a>s can best be brought out by a reconsideration of the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> itself.</p>
<p>The insight underlying the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> is the same insight that inspires the new practice among symphony orchestras of conducting auditions with an opaque screen between the jury and the musician. What <a class="thought" href="entries/matter_entry.html">matter</a>s in a musician is, obviously, musical ability and only musical ability; such features as <a class="thought" href="entries/sex_entry.html">sex</a>, hair length, skin color, and weight are strictly irrelevant. Since juries might be biased even innocently and unawares by these irrelevant features, they are carefully screened off so only the essential feature, musicianship, can be examined.</p>
<p>Turing recognized that people might be similarly biased in their judgments of <a class="thought" href="entries/intelligence_entry.html">intelligence</a> by whether the contestant had soft skin, warm blood, facial features, hands, and eyes--which are obviously not themselves essential <a class="thought" href="entries/component_entry.html">component</a>s of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. So he devised a screen that would let through only a sample of what really <a class="thought" href="entries/matter_entry.html">matter</a>ed: the capacity to understand, and think cleverly about, challenging problems.</p>
<p>Perhaps he was inspired by Descartes, who in his <i>Discourse on Method</i> (1637) plausibly argued that there was no more demanding test of <a class="thought" href="entries/human_entry.html">human</a> mentality than the capacity to hold an intelligent conversation: "It is indeed conceivable that a <a class="thought" href="entries/machine_entry.html">machine</a> could be so made that it would utter words, and even words appropriate to the presence of physical acts or objects which cause some change in its organs; as, for example, it was touched in some so spot that it would ask what you wanted to say to it; in another, that it would cry that it was hurt, and so on for similar things. But it could never modify its phrases to reply to the <a class="thought" href="entries/sense_entry.html">sense</a> of whatever was said in its presence, as even the most stupid men can do."<sup>2</sup>
</p>
<p>This seemed obvious to Descartes in the seventeenth century, but of course, the fanciest <a class="thought" href="entries/machine_entry.html">machine</a>s he knew were elaborate clockwork figures, not <a class="thought" href="entries/electronic_entry.html">electronic</a> <a class="thought" href="entries/computer_entry.html">computer</a>s. Today it is far from obvious that such <a class="thought" href="entries/machine_entry.html">machine</a>s are impossible, but Descartes' hunch that ordinary conversation would put as severe a strain on <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> as any other test was shared by Turing. Of course, there is nothing sacred about the particular conversational game chosen by Turing for his test; it is just a cannily chosen test of more general <a class="thought" href="entries/intelligence_entry.html">intelligence</a>.</p>
<p>The assumption Turing was prepared to make was this: Nothing could possibly pass the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> by winning the imitation game without being able to perform indefinitely many other clearly intelligent <a class="thought" href="entries/action_entry.html">action</a>s. Let us call that assumption the quick-probe assumption.</p>
<p>Turing realized, as anyone would, that there are hundreds and thousands of telling signs of intelligent <a class="thought" href="entries/thinking_entry.html">thinking</a> to be observed in our fellow creatures, and one could, one wanted, compile a vast battery of different tests to assay the capacity for intelligent <a class="thought" href="entries/thought_entry.html">thought</a>. But success on his chosen test, he <a class="thought" href="entries/thought_entry.html">thought</a>, would be highly predictive of success on many other intuitively acceptable tests of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>.</p>
<p>Remember, failure on the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> does not predict failure on those others, but success would surely predict success. His test was so severe, he <a class="thought" href="entries/thought_entry.html">thought</a>, that nothing that could pass it fair and square would disappoint us in other quarters. Maybe it wouldn't do everything we hoped--maybe it wouldn't appreciate ballet, understand quantum <a class="thought" href="entries/physics_entry.html">physics</a>, or have a good plan far world peace, but we'd all see that it was surely one of the intelligent, <a class="thought" href="entries/thinking_entry.html">thinking</a> entities in the neighborhood.</p>
<p>Is this high opinion of the <a class="thought" href="entries/turing_test_entry.html">Turing test</a>s severity misguided? Certainly many have <a class="thought" href="entries/thought_entry.html">thought</a> so, but usually because they have not imagined the test in sufficient detail, and hence have underestimated it. Trying to forestall this skepticism, Turing imagined several lines of questioning that a judge might employ in this game that would be taxing indeed--lines about writing <a class="thought" href="entries/poetry_entry.html">poetry</a> or playing <a class="thought" href="entries/chess_entry.html">chess</a>. But with thirty years' experience with the actual talents and foibles of <a class="thought" href="entries/computer_entry.html">computer</a>s behind us, perhaps we can add a few more tough lines of questioning.</p>
<p>Terry Winograd, a leader in <a class="thought" href="entries/ai_entry.html">AI</a> efforts to produce conversational ability in a <a class="thought" href="entries/computer_entry.html">computer</a>, draws our attention to a pair of sentences.<sup>3</sup> They differ in only one word. The first sentence is this: "The committee denied the group a parade permit because they advocated violence." Here's the second sentence: "The committee denied the group a parade permit because they feared violence."</p>
<p>The difference is just in the verb--"advocated" or "feared." As Winograd points out, the pronoun "they" in each sentence is officially ambiguous. Both readings of the pronoun are always legal. Thus, we can imagine a world in which <a class="thought" href="entries/government_entry.html">government</a>al committees in charge of parade permits advocate violence in the streets and, for some strange <a class="thought" href="entries/reason_entry.html">reason</a>, use this as their pretext for denying a parade permit. But the natural, <a class="thought" href="entries/reason_entry.html">reason</a>able, intelligent reading of the first sentence is that it's the group that advocated violence, and of the second, that it's the committee that feared the violence.</p>
<p>Now sentences like this are embedded in a conversation, the <a class="thought" href="entries/computer_entry.html">computer</a> must figure out which reading of the pronoun is meant, it is to respond intelligently. But mere rules of grammar or vocabulary will not fix the right reading. What fixes the right reading for us is <a class="thought" href="entries/knowledge_entry.html">knowledge</a> about <a class="thought" href="entries/politics_entry.html">politics</a>, social circumstances, committees and their attitudes, groups that want to parade, how they tend to behave, and the like. One must know about the world, in short, to make <a class="thought" href="entries/sense_entry.html">sense</a> of such a sentence.</p>
<p>In the jargon of <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>, a conversational <a class="thought" href="entries/computer_entry.html">computer</a> needs lots of world <a class="thought" href="entries/knowledge_entry.html">knowledge</a> to do its jab. But, it seems, it is somehow endowed with that world <a class="thought" href="entries/knowledge_entry.html">knowledge</a> on many topics, it should be able to do much more with that world <a class="thought" href="entries/knowledge_entry.html">knowledge</a> than merely make <a class="thought" href="entries/sense_entry.html">sense</a> of a conversation containing just that sentence.</p>
<p>The only way, it appears, for a <a class="thought" href="entries/computer_entry.html">computer</a> to disambiguate that sentence and keep up its end of a conversation that uses that sentence would be for it to have a much more general ability to respond intelligently to <a class="thought" href="entries/information_entry.html">information</a> about social and political circumstances and many other topics. Thus, such sentences, by putting a demand on such abilities, are good quick probes. That is, they test for a wider competence.</p>
<p>People typically ignore the prospect of having the judge ask off-the-wall questions in the <a class="thought" href="entries/turing_test_entry.html">Turing test</a>, and hence they underestimate the competence a <a class="thought" href="entries/computer_entry.html">computer</a> would have to have to pass the test. But remember, the rules of the imitation game as Turing presented it permit the judge to ask any question that could be asked of a <a class="thought" href="entries/human_entry.html">human</a> being--no holds barred. Suppose, then, we give a contestant in the game this question: An Irishman found a genie in a bottle who offered him two wishes.</p>
<p>"First I'll have a pint of Guinness," said the Irishman, and when it appeared, he took several long drinks from it and was delighted to see that the glass filled itself magically as he drank. "What about your second wish?" asked the genie. "Oh well, that's easy," said the Irishman. "I'll have another one of these!" Please explain this story to me, and tell me there is anything funny or sad about it.</p>
<p>Now even a child could express, even not eloquently, the understanding that is required to get this joke. But think of how much one has to know and understand about <a class="thought" href="entries/human_entry.html">human</a> culture, to put it pompously, to be able to give any account of the point of this joke.</p>
<p>I am not supposing that the <a class="thought" href="entries/computer_entry.html">computer</a> would have to laugh at, or be amused by, the joke. But it wants to win the imitation game--and that's the test, after all--it had better know enough in its own alien, humorless way about <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/psychology_entry.html">psychology</a> and culture to be able to pretend effectively that it was amused and explain why.</p>
<p>It may seem to you that we could devise a better test. Let's compare the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> with some other candidates.</p><h2>Candidate 1</h2><p>A <a class="thought" href="entries/computer_entry.html">computer</a> is intelligent; it wins the World <a class="thought" href="entries/chess_entry.html">Chess</a> Championship.</p>
<p>That's not a good test, it turns out. <a class="thought" href="entries/chess_entry.html">Chess</a> prowess has proven to be an isolatable talent. There are <a class="thought" href="entries/program_entry.html">program</a>s today that can play fine <a class="thought" href="entries/chess_entry.html">chess</a> but do nothing else. So the quick-probe assumption is false far the test of playing winning <a class="thought" href="entries/chess_entry.html">chess</a>.</p><h2>Candidate 2</h2><p>The <a class="thought" href="entries/computer_entry.html">computer</a> is intelligent; it solves the Arab-Israeli conflict.</p>
<p>This is surely a more severe test than Turing's. But it has some detects: passed once, it is unrepeatable; it is slow, no doubt; and it is not crisply clear what would count as passing it. Here's another prospect, then:</p><h2>Candidate 3</h2><p>A <a class="thought" href="entries/computer_entry.html">computer</a> is intelligent; it succeeds in stealing the British crown jewels without the use of force or violence.</p>
<p>Now this is better. First, it could be repeated again and again, though of course each repeat test would presumably be harder, but this is a feature it shares with the <a class="thought" href="entries/turing_test_entry.html">Turing test</a>. Second, the mark of success is clear: either you've got the jewels to show for your efforts or you don't. But it is expensive and slow, a socially dubious caper at best, and no doubt luck would play too great a role.</p>
<p>With ingenuity and effort one might be able to came up with other candidates that would equal the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> in severity, fairness, and efficiency, but I think these few examples should suffice to convince us that it would be hard to improve on Turing's original proposal.</p>
<p>But still, you may protest, something might pass the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> and still not be intelligent, not be a thinker. What does <i>might</i> mean here? what you have in mind is that by cosmic accident, by a supernatural coincidence, a stupid person or a stupid <a class="thought" href="entries/computer_entry.html">computer</a> <i>might</i> fool a clever judge repeatedly, well, yes, but so what? The same frivolous possibility "in principle" holds for any test whatever.</p>
<p>A playful <a class="thought" href="entries/god_entry.html">god</a> or evil demon, let us agree, could fool the world's scientific community about the presence of H20 in the Pacific Ocean. But still, the tests they rely on to establish that there is H20 in the Pacific Ocean are quite beyond <a class="thought" href="entries/reason_entry.html">reason</a>able criticism. The <a class="thought" href="entries/turing_test_entry.html">Turing test</a> for <a class="thought" href="entries/thinking_entry.html">thinking</a> is no worse than any well-established scientific test, we can <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> skepticism aside and go back to serious <a class="thought" href="entries/matter_entry.html">matter</a>s. Is there any more likelihood of a false positive result on the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> than on, say, the tests currently used for the presence of iron in an ore sample?</p>
<p>This question is often obscured by a move called operationalism that philosophers have sometimes made. Turing and those who think well of his test are often accused of being operationalists. Operationalism is the tactic of <i>defining</i> the presence of some property, <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, for instance, as being established once and for all by the passing of some test. Let's illustrate this with a different example.</p>
<p>Suppose I offer the following test--we'll call it the Dennett test--for being a great city. A great city is one in which, on a randomly chosen day, one can do all three of the following: hear a symphony orchestra, see a Rembrandt <i>and</i> a professional athletic contest, and eat <i>quenelles de brothel</i> a <i>la Nantua</i> for lunch. To make the operationalist move would 6e to declare that any city that passes the Dennett test is by <i>definition</i> a great city. What being a great city <i>amounts to is</i> just passing the Dennett test.</p>
<p>Well then, if the Chamber of Commerce of Great Falls, Montana, wanted, and I can't imagine why--to get their hometown on my list of great cities, they could accomplish this by the relatively inexpensive route of hiring full <a class="thought" href="entries/time_entry.html">time</a> about ten basketball players, forty musicians, and a quick-<a class="thought" href="entries/order_entry.html">order</a> <i>quenelle</i> chef and renting a cheap Rembrandt from some museum. An idiotic operationalist would then be stuck admitting that Great Falls, Montana, was in fact a great city, since all he or she cares about in great cities is that they pass the Dennett test.</p>
<p>Sane operationalists (who far that very <a class="thought" href="entries/reason_entry.html">reason</a> are perhaps not operationalists at all, since "operationalist" seems to be a dirty word) would cling confidently to their test, but only because they have what they consider to be very good <a class="thought" href="entries/reason_entry.html">reason</a>s for <a class="thought" href="entries/thinking_entry.html">thinking</a> the odds astronomical against a false positive result, like the imagined Chamber of Commerce caper. I devised the Dennett test, of course, with the realization that no one would be both stupid and rich enough to go to such preposterous lengths to foil the test.</p>
<p>In the actual world, wherever you find symphony orchestras, <i>quenelles,</i> Rembrandts, and professional sports, you also find daily newspapers, parks, repertory theaters, libraries, fine <a class="thought" href="entries/architecture_entry.html">architecture</a>, and all the other things that go to make a city great. My test was simply devised to locate a <i>telling</i> sample that could not help but be representative of the rest of the city's treasures. I would cheerfully run the minuscule risk of having my bluff called. Obviously, the test items are not all that I care about in a city.</p>
<p>In fact, some of them I don't care about at all. I just think they would be cheap and easy ways of assuring myself that the subtle things I do care about in cities are present. Similarly, I think it would be entirely unreasonable to suppose that <a class="thought" href="entries/turing_entry.html">Alan Turing</a> had an inordinate fondness for party games or put too high a value on party game prowess in his test. In both the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> and the Dennett test a very unrisky gamble is being taken: the gamble that the quick-probe assumption is in general safe.</p>
<p>But two can play this game of playing the odds. Suppose some <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/program_entry.html">program</a>mer happens to be, for whatever strange <a class="thought" href="entries/reason_entry.html">reason</a>, dead <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> on tricking me into judging an <a class="thought" href="entries/entity_entry.html">entity</a> to be a <a class="thought" href="entries/thinking_entry.html">thinking</a>, intelligent thing when it is not. Such a trickster could rely as well as 1 can on unlikelihood and take a few gambles. Thus, the <a class="thought" href="entries/program_entry.html">program</a>mer can expect that it is not remotely likely that 1, as the judge, will bring up the topic of children's birthday parties, or baseball, or moon rocks, then he or she can avoid the trouble of building world <a class="thought" href="entries/knowledge_entry.html">knowledge</a> on those topics into the <a class="thought" href="entries/data_entry.html">data</a> base.</p>
<p>Whereas I do improbably raise these issues, the <a class="thought" href="entries/system_entry.html">system</a> will draw a blank, and I will unmask the pretender easily. But with all the topics and words that I might raise, such a saving would no doubt be negligible. Turn the idea inside out, however, and the trickster will have a fighting chance.</p>
<p>Suppose the <a class="thought" href="entries/program_entry.html">program</a>mer has <a class="thought" href="entries/reason_entry.html">reason</a> to believe that I will ask only about children's birthday parties or baseball or moon rocks--all other topics being, for one <a class="thought" href="entries/reason_entry.html">reason</a> or another, out of bounds. Not only does the task shrink dramatically, but there already exist <a class="thought" href="entries/system_entry.html">system</a>s or preliminary sketches of <a class="thought" href="entries/system_entry.html">system</a>s in <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> that can do a whiz-bang job of responding with apparent <a class="thought" href="entries/intelligence_entry.html">intelligence</a> an just those specialized topics.</p>
<p>William Wood's LUNAR <a class="thought" href="entries/program_entry.html">program</a>, to take what is perhaps the best example, answers scientists' questions--posed in ordinary English--about moon rocks. In one test it answered correctly and appropriately something like 90 percent of the questions that geologists and other experts <a class="thought" href="entries/thought_entry.html">thought</a> of asking it about moon rocks. (In 12 percent of those correct responses there were trivial, correctable defects.)</p>
<p>Of course, Wood's motive in creating LUNAR was not to trick unwary geologists into <a class="thought" href="entries/thinking_entry.html">thinking</a> they were conversing with an intelligent being. And that had been his motive, his project would still be a long way from success.</p>
<p>For it is easy enough to unmask LUNAR without ever straying from the prescribed topic of moon rocks. Put LUNAR in one room and a moon rocks specializt in another, and then ask them both their opinion of the social value of the moon-rock-gathering expeditions, for instance. Or ask the contestants their opinion of the suitability of moon rocks as ashtrays, or whether people who have touched moon rocks are ineligible for the draft. Any intelligent person knows a lot more about moon rocks than their geology. Although it might be unfair to demand this extra <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of a <a class="thought" href="entries/computer_entry.html">computer</a> moon-rock specialist, it would be an easy way to get it to fail the <a class="thought" href="entries/turing_test_entry.html">Turing test</a>.</p>
<p>But just suppose that someone could extend LUNAR to cover itself plausibly on such probes, so long as the topic was still, however indirectly, moon rocks. We might come to think it was a lot more like the <a class="thought" href="entries/human_entry.html">human</a> moon-rock specialist than it really was. The moral we should draw is that as Turing-test judges we should resist all limitations and waterings-down of the <a class="thought" href="entries/turing_test_entry.html">Turing test</a>. They make the game too easy--vastly easier than the original test. Hence, they lead us into the risk of overestimating the actual comprehension of the <a class="thought" href="entries/system_entry.html">system</a> being tested.</p>
<p>Consider a different limitation on the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> that should strike a suspicious chord in us as soon as we hear it. This is a variation on a theme developed in a recent article by Ned Block.<sup>4</sup> Suppose someone were to propose to restrict the judge to a vocabulary of, say, the 850 words of <a class="thought" href="entries/basic_entry.html">Basic</a> English, and to single-sentence probes--that is, "moves"--of no more than four words.</p>
<p>Moreover, contestants must respond to these probes with no more than four words per move, and a test may involve no more than forty questions Is this an innocent variation on Turing's original test? These restrictions would make the imitation game clearly finite.</p>
<p>That is, the total number of all possible permissible games is a large but finite number. One might suspect that such a limitation would permit the trickster simply to store, in alphabetical <a class="thought" href="entries/order_entry.html">order</a>, all the possible good conversations within the limits and fool the judge with nothing more sophisticated than a <a class="thought" href="entries/system_entry.html">system</a> of table lookup. In fact, that isn't in the cards.</p>
<p>Even with these severe, improbable, and suspicious restrictions imposed upon the imitation game, the number of legal games, though finite, is mind-bogglingly large. I haven't bothered trying to calculate it but it surely astronomically exceeds the number of possible <a class="thought" href="entries/chess_entry.html">chess</a> games with no more than forty moves, and that number has been calculated. John Haugeland says it's in the neighborhood of 10<sup>120</sup>. For comparison, Haugeland suggests there have only been 10<sup>18</sup> seconds since the beginning of the <a class="thought" href="entries/universe_entry.html">universe</a>.<sup>5</sup>
</p>
<p>Of course, the number of good, sensible conversations under these limits is a tiny fraction, maybe 1 in 10<sup>15</sup>, of the number of merely grammatically well-formed conversations. So let's say, to be very conservative, that there are only 10<sup>15</sup> different smart conversations such a <a class="thought" href="entries/computer_entry.html">computer</a> would have to store. Well, the task shouldn't take more than a few trillion years--with generous federal support. Finite numbers can be very large.</p>
<p>So though we needn't worry that this particular trick of storing all the smart conversations would work, we can appreciate that there are lots of ways of making the task easier that may appear innocent at first. We also get a reassuring measure of just how severe the unrestricted <a class="thought" href="entries/turing_test_entry.html">Turing test</a> is by reflecting on the more than astronomical size of even that severely restricted version of it.</p>
<p>Block's imagined--and utterly impossible--<a class="thought" href="entries/program_entry.html">program</a> exhibits the dreaded feature known in <a class="thought" href="entries/computer_entry.html">computer</a>-<a class="thought" href="entries/science_entry.html">science</a> circles as <a class="thought" href="entries/combinatorial_explosion_entry.html">combinatorial explosion</a>. No conceivable <a class="thought" href="entries/computer_entry.html">computer</a> could overpower a <a class="thought" href="entries/combinatorial_explosion_entry.html">combinatorial explosion</a> with sheer speed and size. Since the problem areas addressed by <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> are veritable minefields of <a class="thought" href="entries/combinatorial_explosion_entry.html">combinatorial explosion</a>, and since it has often proved difficult to find <i>any</i> solution to a problem that avoids them, there is considerable plausibility in Newell and Simon's proposal that avoiding <a class="thought" href="entries/combinatorial_explosion_entry.html">combinatorial explosion</a> (by any means at all) be viewed as one of the hallmarks of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>.</p>
<p>Our brains are millions of times bigger than the brains of gnats, but they are still--for all their vast <a class="thought" href="entries/complexity_entry.html">complexity</a>--compact, efficient, timely organs that somehow or other manage to perform all their tasks while avoiding <a class="thought" href="entries/combinatorial_explosion_entry.html">combinatorial explosion</a>. A <a class="thought" href="entries/computer_entry.html">computer</a> a million times bigger or faster than a <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> might not look like the <a class="thought" href="entries/brain_entry.html">brain</a> of a <a class="thought" href="entries/human_entry.html">human</a> being, or even be internally organized like the <a class="thought" href="entries/brain_entry.html">brain</a> of a <a class="thought" href="entries/human_entry.html">human</a> being but, far all its differences, it somehow managed to control a wise and timely <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of activities, it would have to be the beneficiary of a very special design that avoided <a class="thought" href="entries/combinatorial_explosion_entry.html">combinatorial explosion</a>. And whatever that design was, would we not be right to consider the <a class="thought" href="entries/entity_entry.html">entity</a> intelligent?</p>
<p>Turing's test was designed to allow for this possibility. His point was that we should not be <a class="thought" href="entries/species_entry.html">species</a>-chauvinistic, or anthropocentric, about the insides of an intelligent being, for there might be inhuman ways of being intelligent.</p>
<p>To my <a class="thought" href="entries/knowledge_entry.html">knowledge</a> the only serious and interesting attempt by any <a class="thought" href="entries/program_entry.html">program</a> designer to win even a severely modified <a class="thought" href="entries/turing_test_entry.html">Turing test</a> has been Kenneth Colby's. Colby is a psychiatrist and <a class="thought" href="entries/intelligence_entry.html">intelligence</a> artificer at UCLA. He has a <a class="thought" href="entries/program_entry.html">program</a> called PARRY, which is a <a class="thought" href="entries/computer_entry.html">computer</a> simulation of a paranoid patient who has delusions about the Mafia being out to get him.</p>
<p>As you do with other conversational <a class="thought" href="entries/program_entry.html">program</a>s, you interact with it by sitting at a terminal and typing questions and answers back and forth. A number of years ago, Colby put PARRY to a very restricted test. He had genuine psychiatrists interview PARRY. He did not suggest to them that they might be talking or typing to a <a class="thought" href="entries/computer_entry.html">computer</a>; rather, he made up some plausible story about why they were communicating with a real, live patient by teletype.</p>
<p>He also had the psychiatrists interview real, <a class="thought" href="entries/human_entry.html">human</a> paranoids via teletype. Then he took a PARRY transcript, inserted it in a group of teletype transcripts from real patients, gave them to another group of experts--more psychiatrists--and said, "One of these was a conversation with a <a class="thought" href="entries/computer_entry.html">computer</a>. Can you figure out which one it was?" They couldn't. They didn't do better than chance.</p>
<p>Colby presented this with some huzzah, but critics scoffed at the suggestion that this was a legitimate <a class="thought" href="entries/turing_test_entry.html">Turing test</a>. My favorite commentary on it was Joseph Weizenbaum's; in a letter to <i>the <a class="thought" href="entries/communication_entry.html">Communication</a>s of the Association of Computing <a class="thought" href="entries/machine_entry.html">Machine</a>ry</i>, he said that, inspired by Colby, he had designed an even better <a class="thought" href="entries/program_entry.html">program</a>, which passed the same test.<sup>6</sup> His also had the virtue of being a very inexpensive <a class="thought" href="entries/program_entry.html">program</a>, in these times of tight money. In fact you didn't even need a <a class="thought" href="entries/computer_entry.html">computer</a> for it. All you needed was an electric typewriter. His <a class="thought" href="entries/program_entry.html">program</a> modeled infantile autism.</p>
<p>And the transcripts--you type in your questions, and the thing just sits there and hums--cannot be distinguished by experts from transcripts of real conversations with infantile autistic patients. What was wrong with Colby's test, of course, was that the unsuspecting interviewers had no motivation at all to try out any of the sorts of questions that easily would have unmasked PARRY.</p>
<p>Colby was undaunted, and after his team had improved PARRY, he put it to a much more severe test--a surprisingly severe test. This <a class="thought" href="entries/time_entry.html">time</a>, the interviewers--again psychiatrists, <i>were</i> given the task at the outset of telling the <a class="thought" href="entries/computer_entry.html">computer</a> from the real patient. They were <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> up in a classic <a class="thought" href="entries/turing_machine_entry.html">Turing machine</a> test: the patient in one room, the <a class="thought" href="entries/computer_entry.html">computer</a> PARRY in the other room, with the judges conducting interviews with both of them (on successive days). The judges' task was to find out which one was the <a class="thought" href="entries/computer_entry.html">computer</a> and which one was the real patient. Amazingly, they didn't do much better, which leads some people to say, "Well, that just confirms my impression of the <a class="thought" href="entries/intelligence_entry.html">intelligence</a> of psychiatrists!"</p>
<p>But more seriously now, was this an honest-to-goodness <a class="thought" href="entries/turing_test_entry.html">Turing test</a>? Were there tacit restrictions on the lines of questioning of the judges? Like the geologists interacting with LUNAR, the psychiatrists' professional preoccupations and habits kept them from asking the sorts of unlikely questions that would have easily unmasked PARRY. After all, they realized that since one of the contestants was a real, live paranoid person, medical <a class="thought" href="entries/ethics_entry.html">ethics</a> virtually forbade them from toying with, upsetting, or attempting to confuse their interlocutors.</p>
<p>Moreover, they also knew that this was a test of a model of paranoia, so there were certain questions that wouldn't be deemed to be relevant to testing the model as a <i>model of paranoia</i>. So they asked just the sort of questions that therapists typically ask of such patients, and of course PARRY had been ingeniously and laboriously prepared to deal with just that sort of question.</p>
<p>One of the psychiatrist judges did, in fact, make a rather half-hearted attempt to break out of the mold and ask some telling questions: "Maybe you've heard the saying 'Don't cry over spilled milk.' What does that mean to you?" PARRY answered, "Maybe you have to watch out for the Mafia."</p>
<p>When then asked "Okay, now you were in a movie theater watching a movie and smelled something like burning wood or rubber, what would you do?" PARRY replied, "You know, they know me." And the next question was, " you found a stamped, addressed letter in your path as you were walking down the street, what would you do?" PARRY replied, "What else do you want to know?"<sup>7</sup>
</p>
<p>Clearly, PARRY was, you might say, parrying these questions, which were incomprehensible to it, with more or less stock paranoid formulas. We see a <a class="thought" href="entries/bit_entry.html">bit</a> of a dodge that is apt to work, apt to seem plausible to the judge, only because the "contestant" is <i>supposed</i> to be a paranoid, and such people are expected to respond uncooperatively on such occasions. These unimpressive responses didn't particularly arouse the suspicions of the judge, as a <a class="thought" href="entries/matter_entry.html">matter</a> of fact, though they probably should have.</p>
<p>PARRY, like all other large <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/program_entry.html">program</a>s, is dramatically hound by limitations of cost-effectiveness. What was important to Colby and his crew was simulating his model of paranoia. This was a massive effort. PARRY has a thesaurus or dictionary of about 4,500 words and 700 idioms and the grammatical competence to use it-a <i><a class="thought" href="entries/parser_entry.html">parser</a></i>, in the jargon of <a class="thought" href="entries/computation_entry.html">computation</a>al <a class="thought" href="entries/linguistics_entry.html">linguistics</a>.</p>
<p>The entire PARRY <a class="thought" href="entries/program_entry.html">program</a> takes up about 200,000 words of <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/memory_entry.html">memory</a>, all laboriously installed by the <a class="thought" href="entries/program_entry.html">program</a>ming team. Now once all the effort had gone into devising the model of paranoid <a class="thought" href="entries/thought_entry.html">thought</a> processes and linguistic ability, there was little <a class="thought" href="entries/time_entry.html">time</a>, <a class="thought" href="entries/energy_entry.html">energy</a>, money, and interest left over to build in huge amounts of world <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of the sort that any actual paranoid would, of course, have. (Not that anyone yet knows haw to build in world <a class="thought" href="entries/knowledge_entry.html">knowledge</a> in the first place.)</p>
<p>Even one could do it, building in the world <a class="thought" href="entries/knowledge_entry.html">knowledge</a> would no doubt have made PARRY orders of magnitude larger and slower. And what would have been the point, given Colby's theoretical aims?</p>
<p>PARRY is a theoretician's model of a psychological phenomenon: paranoia. It is not intended to have practical applications. But in recent years there has appeared a branch of <a class="thought" href="entries/ai_entry.html">AI</a> (<a class="thought" href="entries/knowledge_engineering_entry.html">knowledge engineering</a>) that develops what are now called <a class="thought" href="entries/expert_system_entry.html">expert system</a>s. <a class="thought" href="entries/expert_system_entry.html">Expert system</a>s are designed to be practical. They are typically <a class="thought" href="entries/software_entry.html">software</a> super specializt consultants that can be asked to diagnose medical problems, analyze geological <a class="thought" href="entries/data_entry.html">data</a>, analyze the results of scientific experiments, and the like. Some of them are very impressive.</p>
<p><a class="thought" href="entries/sri_entry.html">SRI</a> in California announced a few years ago that <a class="thought" href="entries/prospector_entry.html">PROSPECTOR</a>, an <a class="thought" href="entries/sri_entry.html">SRI</a>-developed <a class="thought" href="entries/expert_system_entry.html">expert system</a> in geology, had correctly predicted the existence of a large, important mineral deposit that had been entirely unanticipated by the <a class="thought" href="entries/human_entry.html">human</a> geologists who had fed it its <a class="thought" href="entries/data_entry.html">data</a>. <a class="thought" href="entries/mycin_entry.html">MYCIN</a>, perhaps the most famous of these <a class="thought" href="entries/expert_system_entry.html">expert system</a>s, diagnoses infections of the blood, and it does probably as well as, maybe better than, any <a class="thought" href="entries/human_entry.html">human</a> consultants. And many other <a class="thought" href="entries/expert_system_entry.html">expert system</a>s are on the way.</p>
<p>All <a class="thought" href="entries/expert_system_entry.html">expert system</a>s, like all other large <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/program_entry.html">program</a>s, are what you might call Potemkin villages. That is, they are cleverly constructed facades, like cinema sets. The actual filling-in of details of <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/program_entry.html">program</a>s is <a class="thought" href="entries/time_entry.html">time</a>-consuming, costly work, so economy dictates that only those surfaces of the phenomenon that are likely to be probed or observed are represented.</p>
<p>Consider, for example, the CYRUS <a class="thought" href="entries/program_entry.html">program</a> developed 6y Janet Kalodner in Roger Schenk's <a class="thought" href="entries/ai_entry.html">AI</a> group at Yale a few years ago.<sup>8</sup> CYRUS stands (we are told) for "<a class="thought" href="entries/computer_entry.html">Computer</a>ized Yale Retrieval and Updating <a class="thought" href="entries/system_entry.html">System</a>," but surely it is no accident that CYRUS modeled the <a class="thought" href="entries/memory_entry.html">memory</a> of Cyrus Vance, who was then secretary of state in the Carter administration.</p>
<p>The paint of the CYRUS project was to devise and test some plausible ideas about how people organize their memories of the events they participate in. Hence, it was meant to be a "pure- <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>, a scientific model, not an <a class="thought" href="entries/expert_system_entry.html">expert system</a> intended for any practical purpose. CYRUS was updated daily by being fed all UPI wire-service news stories that mentioned Vance, and it was fed them directly with no doctoring and no <a class="thought" href="entries/human_entry.html">human</a> intervention.</p>
<p>With an ingenious news-reading <a class="thought" href="entries/program_entry.html">program</a> called FRUMP, it could take any story just as it came in on the wire and could digest it and use it to update its <a class="thought" href="entries/database_entry.html">database</a> so that it could answer more questions. You could address questions to CYRUS in English by typing at a terminal. You addressed CYRUS in the second person, as you were talking with Cyrus Vance himself. The results looked like this:</p>
<p>
<i>Question:</i> Last <a class="thought" href="entries/time_entry.html">time</a> you went to Saudi Arabia, where did you stay?</p>
<p>
<i>Answer:</i> In a palace in Saudi Arabia on September 23, 1978.</p>
<p>
<i>Question:</i> Did you go sightseeing there?</p>
<p>
<i>Answer:</i> Yes, at an oilfield in Dharan on September 23, 1978.</p>
<p>
<i>Question:</i> Has your we ever met Mrs. Begin?</p>
<p>
<i>Answer:</i> Yes, most recently at a state dinner in Israel in January 1980.</p>
<p>CYRUS could correctly answer thousands of questions, almost any fair question one could think of asking it. But one actually <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> out to explore the boundaries of its facade and find the questions that overshot the mark, one could soon find them. "Have you ever met a <a class="thought" href="entries/female_entry.html">female</a> head of state?" was a question I asked it wondering CYRUS knew that Indira Ghandi and Margaret Thatcher were women.</p>
<p>But for some <a class="thought" href="entries/reason_entry.html">reason</a> the connection could not be drawn, and CYRUS failed to answer either yes or no. I had stumped it, in spite of the fact that CYRUS could handle a host of what you might call neighboring questions flawlessly. One soon learns from this sort of probing exercise that it is very hard to extrapolate accurately from a sample performance to the <a class="thought" href="entries/system_entry.html">system</a>'s total competence. It's also very hard to keep from extrapolating much too generously.</p>
<p>While I was visiting Schenk's laboratory in the spring of 1980, something revealing happened. The real Cyrus Vance suddenly resigned. The effect on the <a class="thought" href="entries/program_entry.html">program</a> CYRUS was chaotic. It was utterly unable to cape with the flood of "unusual" news about Cyrus Vance. The only sorts of episodes CYRUS could understand at all were diplomatic meetings, flights, press conferences, state dinners, and the like--less than two dozen general sorts of activities (the kinds that are newsworthy and typical of secretaries of state). It had no provision for sudden resignation.</p>
<p>It was as if the UPI had reported that a wicked witch had turned Vance into a frog. It is distinctly possible that CYRUS would have taken that report more in stride than the actual news. One can imagine the conversation</p>
<p>
<i>Question:</i> Hello, Mr. Vance, what's new?</p>
<p>
<i>Answer:</i> I was turned into a frog yesterday.</p>
<p>But, of course, it wouldn't know enough about what it had just written to be puzzled, startled, or embarrassed. The <a class="thought" href="entries/reason_entry.html">reason</a> is obvious. When you look inside CYRUS, you find that it has skeletal definitions of thousands of words, but these definitions are minimal. They contain as little as the <a class="thought" href="entries/system_entry.html">system</a> designers think that they can get away with.</p>
<p>Thus, perhaps, "lawyer" would be defined as synonymous with "attorney" and "legal counsel," but aside from that, all one would discover about lawyers is that they are adult <a class="thought" href="entries/human_entry.html">human</a> beings and that they perform various functions in legal areas. you then traced out the path to "<a class="thought" href="entries/human_entry.html">human</a> being," you'd find out various obvious things CYRUS "knew" about <a class="thought" href="entries/human_entry.html">human</a> beings (hence about lawyers/, but that is not a lot.</p>
<p>That lawyers are university graduates, that they are better paid than chambermaids, that they know how to tie their shoes, that they are unlikely to be found in the company of lumberjacks--these trivial, weird, facts about lawyers would not be explicit or implicit anywhere in this <a class="thought" href="entries/system_entry.html">system</a>.</p>
<p>In other words, a very thin stereotype of a lawyer would 6e incorporated into the <a class="thought" href="entries/system_entry.html">system</a>, so that almost nothing you could tell it about a lawyer would surprise it. So long as surprising things don't happen, so long as Mr. Vance, for instance, leads a typical diplomat's le, attending state dinners, giving speeches, flying from Cairo to Rome, and so forth, this <a class="thought" href="entries/system_entry.html">system</a> works very well.</p>
<p>But as soon as his path is crossed by an important anomaly, the <a class="thought" href="entries/system_entry.html">system</a> is unable to cape and unable to recover without fairly massive <a class="thought" href="entries/human_entry.html">human</a> intervention. In the case of the sudden resignation, Kolodner and her associates soon had CYRUS up and running again with a new talent--answering questions about Edmund Muskie, Vance's successor. But it was no less vulnerable to unexpected events. Not that it <a class="thought" href="entries/matter_entry.html">matter</a>ed particularly, since CYRUS was a theoretical model, not a practical <a class="thought" href="entries/system_entry.html">system</a>.</p>
<p>There are a host of ways of improving the performance of such <a class="thought" href="entries/system_entry.html">system</a>s, and, of course, some <a class="thought" href="entries/system_entry.html">system</a>s are much better than others. But all <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/program_entry.html">program</a>s in one way or another have this fa&#231;ade-like quality, simply for <a class="thought" href="entries/reason_entry.html">reason</a>s of economy. For instance, most <a class="thought" href="entries/expert_system_entry.html">expert system</a>s in medical diagnosis developed so far operate with statistical <a class="thought" href="entries/information_entry.html">information</a>. They have no deep or even shallow <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of the underlying causal mechanisms of the phenomena that they are diagnosing.</p>
<p>To take an imaginary example, an <a class="thought" href="entries/expert_system_entry.html">expert system</a> asked to diagnose an abdominal pain would be oblivious to the potential import of the fact that the patient had recently been employed as a sparring partner by Mohammed Ali: there being no statistical <a class="thought" href="entries/data_entry.html">data</a> available to it on the rate of kidney stones among athlete's assistants. That's a fanciful case no doubt--too obvious, perhaps, to lead to an actual failure of diagnosis and practice. But more subtle and hard-to-detect limits to comprehension are always present, and even experts, even the <a class="thought" href="entries/system_entry.html">system</a>'s designers, can be uncertain of where and how these limits will interfere with the desired operation of the <a class="thought" href="entries/system_entry.html">system</a>.</p>
<p>Again, steps can be taken and are being taken to correct these flaws. For instance, my former colleague at Tufts, Benjamin Kuipers, is currently working on an <a class="thought" href="entries/expert_system_entry.html">expert system</a> in nephrology for diagnosing kidney ailments that will be based on an elaborate <a class="thought" href="entries/system_entry.html">system</a> of causal <a class="thought" href="entries/reason_entry.html">reason</a>ing about the phenomena being diagnosed. But this is a very ambitious, long-range project of considerable theoretical difficulty. And even all the <a class="thought" href="entries/reason_entry.html">reason</a>able, cost-effective steps are taken to minimize the superficiality of <a class="thought" href="entries/expert_system_entry.html">expert system</a>s, they will still be facades, just somewhat thicker or wider facades.</p>
<p>When we were considering the fantastic case of the crazy Chamber of Commerce of Great Falls, Montana, we couldn't imagine a plausible motive for anyone going to any sort of trouble to trick the Dennett test. The quick-probe assumption for the Dennett test looked quite secure. But when we look at <a class="thought" href="entries/expert_system_entry.html">expert system</a>s, we see that, however innocently, their designers do have motivation for doing exactly the sort of trick that would fool an unsuspicious <a class="thought" href="entries/turing_test_entry.html">Turing test</a>er.</p>
<p>First, since <a class="thought" href="entries/expert_system_entry.html">expert system</a>s are all superspecializts that are only supposed to know about some narrow subject, users of such <a class="thought" href="entries/system_entry.html">system</a>s, not having much <a class="thought" href="entries/time_entry.html">time</a> to kill, do not bother probing them at the boundaries at all. They don't bother asking "silly" or irrelevant questions. Instead, they concentrate, not unreasonably, on exploiting the <a class="thought" href="entries/system_entry.html">system</a>'s strengths. But shouldn't they try to obtain a clear vision of such a <a class="thought" href="entries/system_entry.html">system</a>'s weaknesses as well? The normal habit of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/thought_entry.html">thought</a> when we converse with one another is to assume general comprehension, to assume rationality, to assume, moreover, that the quick-probe assumption is, in general, sound.</p>
<p>This amiable habit of <a class="thought" href="entries/thought_entry.html">thought</a> almost irresistibly leads to putting too much faith in <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/system_entry.html">system</a>s, especially user-friendly <a class="thought" href="entries/system_entry.html">system</a>s that present themselves in a very anthropomorphic manner.</p>
<p>Part of the solution to this problem is to teach all users of <a class="thought" href="entries/computer_entry.html">computer</a>s, especially users of <a class="thought" href="entries/expert_system_entry.html">expert system</a>s, how to probe their <a class="thought" href="entries/system_entry.html">system</a>s before they rely on them, how to <a class="thought" href="entries/search_entry.html">search</a> out and explore the boundaries of the facade. This is an exercise that calls for not only <a class="thought" href="entries/intelligence_entry.html">intelligence</a> and imagination but also for a <a class="thought" href="entries/bit_entry.html">bit</a> of special understanding about the limitations and actual structure of <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/program_entry.html">program</a>s. It would help, of course, if we had standards of truth in advertising, in effect, for <a class="thought" href="entries/expert_system_entry.html">expert system</a>s.</p>
<p>For instance, each such <a class="thought" href="entries/system_entry.html">system</a> should come with a special demonstration routine that exhibits the sorts of shortcomings and failures that the designer knows the <a class="thought" href="entries/system_entry.html">system</a> to have. This would not be a substitute, however, for an attitude of cautious, almost obsessive, skepticism on the part of users, for designers are often, not always, unaware of the subtler flaws in the products they produce. That is inevitable and natural because of the way <a class="thought" href="entries/system_entry.html">system</a> designers must think. They are trained to think positively--constructively, one might say--about the designs that they are constructing.</p>
<p>I come, then, to my conclusions. First, a philosophical or theoretical conclusion: The <a class="thought" href="entries/turing_test_entry.html">Turing test</a>, in unadulterated, unrestricted form as Turing presented it, is plenty strong well used. I am confident that no <a class="thought" href="entries/computer_entry.html">computer</a> in the next twenty years in going to pass the unrestricted <a class="thought" href="entries/turing_test_entry.html">Turing test</a>. They may well win the World <a class="thought" href="entries/chess_entry.html">Chess</a> Championship or even a Nobel Prize in <a class="thought" href="entries/physics_entry.html">physics</a>, but they won't pass the unrestricted <a class="thought" href="entries/turing_test_entry.html">Turing test</a>.</p>
<p>Nevertheless, it is not, I think, impossible in principle for a <a class="thought" href="entries/computer_entry.html">computer</a> to pass the test fair and square. I'm not giving one of those a priori "<a class="thought" href="entries/computer_entry.html">computer</a>s can't think" arguments. I stand unabashedly ready, moreover, to declare that any <a class="thought" href="entries/computer_entry.html">computer</a> that actually passes the unrestricted <a class="thought" href="entries/turing_test_entry.html">Turing test</a> will be, in every theoretically interesting <a class="thought" href="entries/sense_entry.html">sense</a>, a <a class="thought" href="entries/thinking_entry.html">thinking</a> thing.</p>
<p>But remembering how very strong the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> is, we must also recognize that there may also be interesting varieties of <a class="thought" href="entries/thinking_entry.html">thinking</a> or <a class="thought" href="entries/intelligence_entry.html">intelligence</a> that are not well poised to play and win the imitation game. That no nonhuman <a class="thought" href="entries/turing_test_entry.html">Turing test</a> winners are yet visible on the horizon does not mean that there aren't <a class="thought" href="entries/machine_entry.html">machine</a>s that already exhibit some of the important features of <a class="thought" href="entries/thought_entry.html">thought</a>.</p>
<p>About them it is probably futile to ask my title question, Do they think? Do they <i>really</i> think? In some regards they do, and in some regards they don't. Only a detailed look at what they do and how they are structured will reveal what is interesting about them.</p>
<p>The <a class="thought" href="entries/turing_test_entry.html">Turing test</a>, not being a scientific test, is of scant help on that task, but there are plenty of other ways to examine such <a class="thought" href="entries/system_entry.html">system</a>s. Verdicts on their <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, capacity for <a class="thought" href="entries/thought_entry.html">thought</a>, or <a class="thought" href="entries/consciousness_entry.html">consciousness</a> will be only as informative and persuasive as the theories of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, <a class="thought" href="entries/thought_entry.html">thought</a>, or <a class="thought" href="entries/consciousness_entry.html">consciousness</a> the verdicts were based on, and since our task is to create such theories, we should get on with it and leave the Big Verdict for another occasion. In the meantime, should anyone want a surefire test of <a class="thought" href="entries/thinking_entry.html">thinking</a> by a <a class="thought" href="entries/computer_entry.html">computer</a> that is almost guaranteed to be fail-safe, the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> will do very nicely.</p>
<p>My second conclusion is more practical and hence in one clear <a class="thought" href="entries/sense_entry.html">sense</a> more important. Cheapened versions of the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> are everywhere in the air. Turing's test is not just effective, it is entirely natural; this is, after all, the way we assay the <a class="thought" href="entries/intelligence_entry.html">intelligence</a> of each other every day.</p>
<p>And since incautious use of such judgments and such tests is the norm, we are in some considerable danger of extrapolating too easily and judging too generously about the understanding of the <a class="thought" href="entries/system_entry.html">system</a>s we are using. The problem of overestimating cognitive prowess, comprehension, and <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is not, then, just a philosophical problem. It is a real social problem, and we should alert ourselves to it and take steps to avert it.</p><h1>Postscript: Eyes, Ears, Hands, and <a class="thought" href="entries/history_entry.html">History</a></h1><p>My philosophical conclusion in this paper is that any <a class="thought" href="entries/computer_entry.html">computer</a> that actually passed the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> would be a thinker in every theoretically interesting <a class="thought" href="entries/sense_entry.html">sense</a>. This conclusion seems to some people to fly in the face of what I have myself argued on other occasions. Peter Bieri, commenting on this paper at Boston University, noted that I have often claimed to show the importance to genuine understanding of a rich and intimate perceptual interconnection between an <a class="thought" href="entries/entity_entry.html">entity</a> and its surrounding world--the need for something like eyes and ears--and a similarly complex active engagement with <a class="thought" href="entries/element_entry.html">element</a>s in that world--the need for something like hands with which to do things in that world. Moreover,</p>
<p>I have often held that only a biography of sorts--a <a class="thought" href="entries/history_entry.html">history</a> of actual projects, <a class="thought" href="entries/learning_entry.html">learning</a> experiences, and other bouts with reality--could produce the sorts of complexities (both external, or behavioral, and internal) that are needed to ground a principled interpretation of an <a class="thought" href="entries/entity_entry.html">entity</a> as a thinker, an <a class="thought" href="entries/entity_entry.html">entity</a> with beliefs, desires, intentions, and other mental attitudes.</p>
<p>But the opaque screen in the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> discounts or dismisses these factors altogether, it seems, by focusing attention on only the contemporaneous capacity to engage in one very limited sort of activity: verbal <a class="thought" href="entries/communication_entry.html">communication</a>. (I have even coined a pejorative label for such purely <a class="thought" href="entries/language_entry.html">language</a>-using <a class="thought" href="entries/system_entry.html">system</a>s: "bedridden.")</p>
<p>Am I going back on my earlier claims? Not at all. I am merely pointing out that the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> is so powerful that it will indirectly ensure that these conditions, they are truly necessary, are met by any successful contestant.</p>
<p>"You may well be right," Turing could say, "that eyes, ears, hands, and a <a class="thought" href="entries/history_entry.html">history</a> are necessary conditions for <a class="thought" href="entries/thinking_entry.html">thinking</a>. so, then I submit that nothing could pass the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> that didn't have eyes, ears, hands, and a <a class="thought" href="entries/history_entry.html">history</a>. That is an empirical claim, which we can someday hope to test. you suggest that these are not just practically or physically necessary but conceptually necessary conditions for <a class="thought" href="entries/thinking_entry.html">thinking</a>, you make a philosophical claim that I for one would not know how, or care, to assess. Isn't it more interesting and important in the end to discover whether or not it is true that no bedridden <a class="thought" href="entries/system_entry.html">system</a> could pass a demanding <a class="thought" href="entries/turing_test_entry.html">Turing test</a>?"</p>
<p>Suppose we put to Turing the suggestion that he add another <a class="thought" href="entries/component_entry.html">component</a> to his test: Not only must an <a class="thought" href="entries/entity_entry.html">entity</a> win the imitation game; it must also be able to identify--using whatever sensory apparatus it has available to it--a variety of familiar objects placed in its room: a tennis racket, a potted palm, a bucket of yellow paint, a live dog. This would ensure that somehow or other the <a class="thought" href="entries/entity_entry.html">entity</a> was capable of moving around and distinguishing things in the world.</p>
<p>Turing could reply, I assert, that this is an utterly unnecessary addition to his test, making it no more demanding than it already was. A suitably probing conversation would surely establish beyond a shadow of a doubt that the contestant knew its way around in the real world. The imagined alternative of somehow "prestocking" a bedridden, blind <a class="thought" href="entries/computer_entry.html">computer</a> with enough <a class="thought" href="entries/information_entry.html">information</a> and a clever enough <a class="thought" href="entries/program_entry.html">program</a> to trick the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> is <a class="thought" href="entries/science_fiction_entry.html">science fiction</a> of the worst kind: possible "in principle" but not remotely possible in fact in view of the <a class="thought" href="entries/combinatorial_explosion_entry.html">combinatorial explosion</a> of possible variation such a <a class="thought" href="entries/system_entry.html">system</a> would have to cope with.</p>
<p>"But suppose you're wrong. What would you say of an <a class="thought" href="entries/entity_entry.html">entity</a> that was created all at once (by some <a class="thought" href="entries/program_entry.html">program</a>mers, perhaps), an instant individual with all the conversational talents of an embodied, experienced <a class="thought" href="entries/human_entry.html">human</a> being?" This is like the question, Would you call a hunk of H20 that was as hard as steel at room temperature ice? I do not know what Turing would say, of course, so I will speak for myself.</p>
<p>Faced with such an improbable violation of what 1 take to be the laws of <a class="thought" href="entries/nature_entry.html">nature</a>, I would probably be speechless. The least of my worries would 6e about which lexicographical leap to take, whether to say, "it turns out, to my amazement, that something can think without having had the benefit of eyes, ears, hands, and a <a class="thought" href="entries/history_entry.html">history</a>" or "it turns out, to my amazement, that something can pass the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> without <a class="thought" href="entries/thinking_entry.html">thinking</a>." Choosing between these ways of expressing my astonishment would be asking myself a question too meaningless to deserve discussion.</p><h1>Discussion</h1><p>
<i>Question:</i> Why was Turing interested in differentiating a man from a woman in his famous test?</p>
<p>
<i>Answer:</i> That was just an example. He described a parlor game in which a man would try to fool the judge by answering questions as a woman would answer. l suppose that Turing was playing on the idea that maybe, just maybe, there is a big difference between the way men think and the way women think. But of course they're both thinkers. He wanted to use that fact to make us realize that, even there were clear differences between the way a <a class="thought" href="entries/computer_entry.html">computer</a> and a person <a class="thought" href="entries/thought_entry.html">thought</a>, they'd both still be <a class="thought" href="entries/thinking_entry.html">thinking</a>.</p>
<p>
<i>Question:</i> Why does it seem that some people are upset by <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a>? Does <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a> threaten our self-esteem?</p>
<p>
<i>Answer:</i> I think Herb Simon has already given the canniest diagnosis of that. For many people the mind is the last refuge of mystery against the encroaching spread of <a class="thought" href="entries/science_entry.html">science</a>, and they don't like the idea of <a class="thought" href="entries/science_entry.html">science</a> engulfing the last hit of <i>terra incognito</i>. This means that they are threatened, I think irrationally, by the prospect that <a class="thought" href="entries/research_entry.html">research</a>ers in <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> may come to understand the <a class="thought" href="entries/human_entry.html">human</a> mind as well as biologists understand the genetic <a class="thought" href="entries/code_entry.html">code</a> and physicists understand electricity and magnetism. This could lead to the "evil scientist" (to take a stock character from <a class="thought" href="entries/science_fiction_entry.html">science fiction</a>) who can control you because he or she has a deep understanding of what's going on in your mind.</p>
<p>This seems to me to be a totally valueless fear, one that you can <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> aside for the simple <a class="thought" href="entries/reason_entry.html">reason</a> that the <a class="thought" href="entries/human_entry.html">human</a> mind is full of an extraordinary amount of detailed <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, as Roger Schenk, for example, has been pointing out. As long as the scientist who is attempting to manipulate you does not share all your <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, his or her chances of manipulating you are minimal. People can always hit you over the head. They can do that now. We don't need <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> to manipulate people by putting them in chains or torturing them. But someone tries to manipulate you by controlling your <a class="thought" href="entries/thought_entry.html">thought</a>s and ideas, that person will have to know what you know and more. The best way to keep yourself safe from that kind of manipulation is to be well informed.</p>
<p>
<i>Question:</i> Do you think we will be able to <a class="thought" href="entries/program_entry.html">program</a> self-<a class="thought" href="entries/consciousness_entry.html">consciousness</a> into a <a class="thought" href="entries/computer_entry.html">computer</a>?</p>
<p>
<i>Answer:</i> Yes, I do think that it's possible to <a class="thought" href="entries/program_entry.html">program</a> self-<a class="thought" href="entries/consciousness_entry.html">consciousness</a> into a <a class="thought" href="entries/computer_entry.html">computer</a>. "Self-<a class="thought" href="entries/consciousness_entry.html">consciousness</a>" can mean many things. you take the simplest, crudest notion of self-<a class="thought" href="entries/consciousness_entry.html">consciousness</a>, I suppose that would be the sort of self-<a class="thought" href="entries/consciousness_entry.html">consciousness</a> that a lobster has: When it's hungry, it eats something, but it never eats itself. It has some way of distinguishing between itself and the rest of the world, and it has a rather special regard for itself. The lowly lobster is, in one regard, self-conscious.</p>
<p>You want to know whether or not you can create that on the <a class="thought" href="entries/computer_entry.html">computer</a>, the answer is yes. It's no trouble at all. The <a class="thought" href="entries/computer_entry.html">computer</a> is already a self-watching, self-monitoring sort of thing. That is an established part of the <a class="thought" href="entries/technology_entry.html">technology</a>. But, of course, most people have something more in mind when they speak of self-<a class="thought" href="entries/consciousness_entry.html">consciousness</a>. It is that special inner <a class="thought" href="entries/light_entry.html">light</a>, that private way that it is with you that nobody else can share, something that is forever outside the bounds of <a class="thought" href="entries/computer_science_entry.html">computer science</a>.</p>
<p>How could a <a class="thought" href="entries/computer_entry.html">computer</a> ever be conscious in this sense? That belief, that very gripping, powerful <a class="thought" href="entries/intuition_entry.html">intuition</a>, is in the end, I think, simply an illusion of <a class="thought" href="entries/common_sense_entry.html">common sense</a>. It is as gripping as the commonsense illusion that the <a class="thought" href="entries/earth_entry.html">earth</a> stands still and the sun goes around the <a class="thought" href="entries/earth_entry.html">earth</a>. But the only way that those of us who do not believe in the illusion will ever convince the general public that it is an illusion is by gradually unfolding a very difficult and fascinating story about just what is going on in our minds.</p>
<p>In the interim, people like me, philosophers who have to live by our wits and tell a lot of stories use what I call <a class="thought" href="entries/intuition_entry.html">intuition</a> pumps, little examples that help to free up the imagination. I simply want to draw your attention to one fact.</p>
<p>You look at a <a class="thought" href="entries/computer_entry.html">computer</a>, I don't care whether it's a giant Cray or a <a class="thought" href="entries/personal_computer_entry.html">personal computer</a>, you open up the box and look inside and see those chips, you say, "No way could that be conscious. No way could that be self-conscious." But the same thing is true if you take the top off somebody's skull and look at the gray <a class="thought" href="entries/matter_entry.html">matter</a> pulsing away in there. You think, "That is conscious? No way could that lump of stuff be conscious." Of course, it makes no difference whether you look at it with a microscope or with the naked eye.</p>
<p>At no level of inspection does a <a class="thought" href="entries/brain_entry.html">brain</a> look like the seat of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. Therefore, don't expect a <a class="thought" href="entries/computer_entry.html">computer</a> to look like the seat of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. You want to get a grasp of how a <a class="thought" href="entries/computer_entry.html">computer</a> could be conscious, it's no more difficult in the end than getting a grasp of how a <a class="thought" href="entries/brain_entry.html">brain</a> could be conscious. When we develop good accounts of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, it will no longer seem so obvious to everyone that the idea of a self-conscious <a class="thought" href="entries/computer_entry.html">computer</a> is a contradiction in terms. At the same <a class="thought" href="entries/time_entry.html">time</a>, I doubt that there will ever be self-conscious robots, but for boring <a class="thought" href="entries/reason_entry.html">reason</a>s. There won't be any point in making them.</p>
<p>Theoretically, could we make a gall bladder out of atoms? In principle, we could. A gall bladder is just a collection of atoms, but manufacturing one would cost the moon. It would be more expensive than every project <a class="thought" href="entries/nasa_entry.html">NASA</a> has ever dreamed of, and there would be no scientific payoff. We wouldn't learn anything new about how gall bladders work.</p>
<p>For the same <a class="thought" href="entries/reason_entry.html">reason</a> I don't think we're going to see really <a class="thought" href="entries/humanoid_entry.html">humanoid</a> robots, because practical, cost-effective robots don't need to be very <a class="thought" href="entries/humanoid_entry.html">humanoid</a> at all. They need to be like the robots you can already see at General Motors, or like boxy little <a class="thought" href="entries/computer_entry.html">computer</a>s that do special-purpose things.</p>
<p>The theoretical issues will be studied by <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a>ers looking at models that, to the layman, will show very little sign of humanity at all, and it will be only by rather indirect arguments that anyone will be able to appreciate that these models cast <a class="thought" href="entries/light_entry.html">light</a> on the deep theoretical question of how the mind is organized.</p><h1>Footnotes</h1><a name="r1"></a>
<p class="Reference">1. Alan M. Turing, "Computing <a class="thought" href="entries/machine_entry.html">Machine</a>ry and <a class="thought" href="entries/intelligence_entry.html">Intelligence</a>," <i>Mind 59</i> (1950).</p>
<a name="r2"></a>
<p class="Reference">2. Rene Descartes, <i>Discourse on</i> <i>Method (1637</i>), trans. Lawrence LaFleur (New York: Bobbs-Merrill,1960).</p>
<a name="r3"></a>
<p class="Reference">3. Terry Winograd, <i>Understanding </i><a class="thought" href="entries/natural_language_entry.html">Natural Language</a> (New York: Academic Press, 1972).</p>
<a name="r4"></a>
<p class="Reference">4. Ned Block, "Psychologism and Behaviorism, <i>Philosophical Review</i>, 1982.</p>
<a name="r5"></a>
<p class="Reference">5. John Haugeland, <i>Mind Design</i> (Cambridge, Mass.: MIT Press, 1981), p. 16.</p>
<a name="r6"></a>
<p class="Reference">6. Joseph Weizenbaum, CACM17, no. 9 (September 1974): 543.</p>
<a name="r7"></a>
<p class="Reference">7. I thank Kenneth Colby for providing me with the complete transcripts (including the judges' commentaries and reactions) from which these exchanges are quoted. The first published account of the experiment is Jon F. Raiser, Kenneth Mark Colby, William S. Faught, and Roger <a class="thought" href="entries/c_entry.html">C</a>. Parkinson, "Can Psychiatrists Distinguish a <a class="thought" href="entries/computer_entry.html">Computer</a> Simulation of Paranoia from the Real Thing? The Limitations of Turing-like Tests as Measures of the Adequacy of Simulations," in <i>Journal of Psychiatric <a class="thought" href="entries/research_entry.html">Research</a></i> 15<i>,</i> no. 3 (1980):149-162. Colby discusses PARRY and its implications in "Modeling a Paranoid Mind," in <i>Behavioral and </i><a class="thought" href="entries/brain_entry.html">Brain</a><i> <a class="thought" href="entries/science_entry.html">Science</a>s</i> 4, no. 4 (1981): 515-560.</p>
<a name="r8"></a>
<p class="Reference">8. Janet L. Kolodner, "Retrieval and Organization Strategies in Conceptual <a class="thought" href="entries/memory_entry.html">Memory</a>: A <a class="thought" href="entries/computer_entry.html">Computer</a> Model" (Ph.D. disc., <a class="thought" href="entries/research_entry.html">Research</a> Report no. 187, Dept. of <a class="thought" href="entries/computer_science_entry.html">Computer Science</a>, Yale University; Janet L. Kolodner, "Maintaining Organization in a Dynamic Long-Term <a class="thought" href="entries/memory_entry.html">Memory</a>," <i>Cognitive </i><a class="thought" href="entries/science_entry.html">Science</a> 7 (1983):243-280; Janet L Kolodner, "Reconstructive <a class="thought" href="entries/memory_entry.html">Memory</a>: A <a class="thought" href="entries/computer_entry.html">Computer</a> Model," <i>Cognitive </i><a class="thought" href="entries/science_entry.html">Science</a> 7 (1983): 281-328.</p>
</td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p><br>
<img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/articles/images/aimdennett01.jpg" vspace="10"><br>
<span class="PhotoCredit">Courtesy of Tufts University</span>
<br>
<span class="Caption">Daniel Dennett is Distinguished Arts and Science Professor and Director of the Center for Cognitive Studies at Tufts University.  He is the author or editor of a number of books on cognitive science and the philosophy of mind, including The Mind's I, coedited with Douglans Hofstadter (1981); Elbow Room (1984); and The Intentiional Stance (1987).</span>
<br>
<br>
<br></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D4970" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id4971"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>i am the first<br><span class="mindxheader"><i>posted on 01/22/2002 12:05 AM by zorgalina@hotmail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D4970%23id4971" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D4971" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>i am the first</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id120198"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: The Age of Intelligent Machines: Can Machines Think?<br><span class="mindxheader"><i>posted on 05/13/2008 3:19 PM by <a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/mindx/profile.php?id=6107">jsalvatore</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D4970%23id120198" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D120198" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Though you make a sound argument of which I agree completely regarding the validity of a true turing test, I am skeptical as to the possibility of any man-programmed computer passing it legitimately. I beleive it would require more than just a deep understanding of how components of the brain interact in order to function. A human is able to think and experience the phenomenological components of consciousness as a result of more than just the electrical circuitry of the nervous system; it envolves the real interaction of organic chemicals at the atomic level, the understanding of which we as humans are severely underinformed. I don't think that we can pretend that any purely electrical system will be able to successfully model our organic, chemical, physical, and electrical systems any time in the near future. I may be wrong but my current belief is that artificial intelligence needs to begin a more biological approach to understanding consciousness in order to fully realize all of the components necessary to begin modelling it. </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id120199"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: The Age of Intelligent Machines: Can Machines Think?<br><span class="mindxheader"><i>posted on 05/13/2008 3:33 PM by <a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/mindx/profile.php?id=4884">PredictionBoy</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D4970%23id120199" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D120199" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>way to save a thread, isalvatore</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id120211"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: The Age of Intelligent Machines: Can Machines Think?<br><span class="mindxheader"><i>posted on 05/13/2008 5:03 PM by <a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/mindx/profile.php?id=3090">NanoStuff</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D4970%23id120211" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090527091226/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D120211" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Woah Marty, what the hell is going on!</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090527091226im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>