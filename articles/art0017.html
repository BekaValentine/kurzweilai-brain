<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>Letter from Hans Moravec</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20071011041509/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20071011041509/http://www.kurzweilai.net/meme/memelist.html?m=4">Will Machines Become Conscious?</a> &gt; 
Letter from Hans Moravec
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20071011041509/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0017.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0017.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20071011041509/http://www.kurzweilai.net/articles/art0017.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">Letter from Hans Moravec</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20071011041509/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0012.html" target="_top">Hans Moravec</a><br></span></td>
</table>
<br>
<div class="TeaserText">In this March 25, 1999 Letter to New York Review of Books, Carnegie Mellon University Professor Hans Moravec counters John Searle's "Chinese Room" argument, which attempts to show that machines cannot be conscious.</div>
<br>
<br><span class="AuthorAffiliation"><a class="thought" href="entries/moravec_entry.html">Hans Moravec</a>&#160;Robotics Institute&#160;Carnegie Mellon University&#160;Pittsburgh, PA 15213</span>
<br>
<br>
<p>Originally published March 25, 1999 at <a href="http://web.archive.org/web/20071011041509/http://www.nybooks.com/" target="_new">The New York Review of Books</a>. Published on KurzweilAI.net February 22, 2001.</p>
<p>To the Editor:</p>
<p>In the April 8 NYRB review of <a class="thought" href="entries/kurzweil_entry.html">Raymond Kurzweil</a>'s new book, <a class="thought" href="entries/searle_entry.html">John Searle</a> once again trots out his hoary "<a class="thought" href="entries/chinese_room_entry.html">Chinese Room</a>" argument. So doing, he illuminates a chasm between certain <a class="thought" href="entries/intuition_entry.html">intuition</a>s in traditional western <a class="thought" href="entries/philosophy_entry.html">Philosophy</a> of Mind and conflicting understandings emerging from the new <a class="thought" href="entries/science_entry.html">Science</a>s of Mind.</p>
<p>Searle's argument imagines a <a class="thought" href="entries/human_entry.html">human</a> who blindly follows cleverly contrived rote rules to conduct an intelligent conversation without actually understanding a word of it. To Searle the scenario illustrates <a class="thought" href="entries/machine_entry.html">machine</a> that exhibits understanding without actually having it. To <a class="thought" href="entries/computer_entry.html">computer</a> scientists the argument merely shows Searle is looking for understanding in the wrong places. It would take a <a class="thought" href="entries/human_entry.html">human</a> maybe 50,000 years of rote work and billions of scratch notes to generate each second of genuinely intelligent conversation by this means, working as a <a class="thought" href="entries/cog_entry.html">cog</a> in a vast paper <a class="thought" href="entries/machine_entry.html">machine</a>. The understanding the <a class="thought" href="entries/machine_entry.html">machine</a> exhibits would obviously not be encoded in the usual places in the <a class="thought" href="entries/human_entry.html">human</a>'s <a class="thought" href="entries/brain_entry.html">brain</a>, as Searle would have it, but rather in the changing pattern of symbols in that paper mountain.</p>
<p>Searle seemingly cannot accept that real meaning can exist in mere patterns. But such attributions are essential to <a class="thought" href="entries/computer_entry.html">computer</a> scientists and mathematicians, who daily work with mappings between different physical and symbolic structures. One day a <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/memory_entry.html">memory</a> pattern means a number, another it is a string of text or a snippet of sound or a patch of picture. When running a weather simulation it may be a pressure or a humidity, and in a <a class="thought" href="entries/robot_entry.html">robot</a> <a class="thought" href="entries/program_entry.html">program</a> it may be a belief, a goal, a feeling or a state of alertness. Cognitive biologists, too, think this way as they accumulate evidence that sensations, feelings, beliefs, <a class="thought" href="entries/thought_entry.html">thought</a>s and other <a class="thought" href="entries/element_entry.html">element</a>s of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> are encoded as distributed patterns of activity in the nervous <a class="thought" href="entries/system_entry.html">system</a>. Scientifically-oriented philosophers like <a class="thought" href="entries/dennett_entry.html">Daniel Dennet</a>t have built plausible theories of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> on the approach.</p>
<p>Searle is partway there in his discussion of extrinsic and intrinsic qualities, but fails to take a few additional steps that would make the situation much clearer, but reverse his conclusion. It is true that any <a class="thought" href="entries/machine_entry.html">machine</a> can be viewed in a "mechanical" way, in terms of the interaction of its <a class="thought" href="entries/component_entry.html">component</a> parts. But also, as <a class="thought" href="entries/turing_entry.html">Alan Turing</a> proposed and Searle acknowledges, a <a class="thought" href="entries/machine_entry.html">machine</a> able to conduct an insightful conversation, or otherwise interact in a genuinely humanlike fashion, can usefully be viewed in a "psychological" way, wherein an observer <a class="thought" href="entries/attribute_entry.html">attribute</a>s <a class="thought" href="entries/thought_entry.html">thought</a>s, feelings, understanding and <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. Searle claims such attributions to a <a class="thought" href="entries/machine_entry.html">machine</a> are merely extrinsic, and not also intrinsic as in <a class="thought" href="entries/human_entry.html">human</a> beings, and suggests idiosyncratically that intrinsic feelings exude in some mysterious and undefined way from the unique physical substance of <a class="thought" href="entries/human_entry.html">human</a> brains.</p>
<p>Consider an alternative explanation for intrinsic experience. Among the psychological <a class="thought" href="entries/attribute_entry.html">attribute</a>s we extrinsically <a class="thought" href="entries/attribute_entry.html">attribute</a> to people is the ability to make attributions. But with the ability to make attributions, an <a class="thought" href="entries/entity_entry.html">entity</a> can <a class="thought" href="entries/attribute_entry.html">attribute</a> beliefs, feelings and <a class="thought" href="entries/consciousness_entry.html">consciousness</a> to itself, independent of outside observers' attributions! Self-attribution is the crowning flourish gives properly constituted cognitive mechanisms, <a class="thought" href="entries/biological_entry.html">biological</a> or <a class="thought" href="entries/electronic_entry.html">electronic</a>, an intrinsic <a class="thought" href="entries/life_entry.html">life</a> in their own mind's eyes. So abstract a cause for intrinsic experience may be unpalatable to classically materialist thinkers like Searle, but it feels quite natural to <a class="thought" href="entries/computer_entry.html">computer</a> scientists. It is also supported by <a class="thought" href="entries/biological_entry.html">biological</a> observations linking particular patterns of <a class="thought" href="entries/brain_entry.html">brain</a> activity with subjective mental states, and is a part of Dennett's and others' theories of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>.</p>
<p>Elsewhere Hilary Putnam and Searle independently offered another kind of objection. If real <a class="thought" href="entries/thought_entry.html">thought</a>s, feelings, meaning and <a class="thought" href="entries/consciousness_entry.html">consciousness</a> are found in special interpretations of the activity patterns of <a class="thought" href="entries/human_entry.html">human</a> or <a class="thought" href="entries/robot_entry.html">robot</a> brains, wouldn't there also be interpretations that find <a class="thought" href="entries/consciousness_entry.html">consciousness</a> in less traditional places, for instance (to use their examples), in the patterns of <a class="thought" href="entries/particle_entry.html">particle</a> motion of arbitrary rocks or blackboards? Putnam, once a champion of the interpretive position, found this implication impossibly counterintuitive, and turned his back on the whole logical chain. To Searle, it simply bolsters his preexisting opinion. But counterintuitive implications do not refute an idea. The interpretations required in Putnam's and Searle's examples are too complex for us to actually muster, putting the implied beings out of our interpretive reach, thus unable to affect our everyday experience. The last chapter of my recent book <a class="thought" href="entries/robot_entry.html">Robot</a><i>: Mere </i><a class="thought" href="entries/machine_entry.html">Machine</a><i> to Transcendent Mind</i> explores further implications, and uncovers no self-contradictions nor contradictions with reality as we know it. Rather, the interpretive position sheds <a class="thought" href="entries/light_entry.html">light</a> on mysteries like the unexpected simplicity of <a class="thought" href="entries/basic_entry.html">basic</a> physical law. It does predict many surprises beyond our immediate observational horizons, and offends common metaphysical assumptions. But today, when millions of 3D videogame players immerse themselves in increasingly expansive and populated worlds found in very special interpretations of the <a class="thought" href="entries/particle_entry.html">particle</a> motions of a few unimpressive-looking <a class="thought" href="entries/silicon_entry.html">silicon</a> chips, is the idea of whole worlds hidden in unexpected places still beyond the pale?</p>
</td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20071011041509/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D2111" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id2112"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>The paradox of conciousness<br><span class="mindxheader"><i>posted on 08/18/2001 2:33 PM by jsmarr@stanford.edu</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011041509/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2111%23id2112" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011041509/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D2112" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Great article by Moravec, he really shows the way to what Dennett thinks of as a central paradox in explaining subjective conciousness, which is really at the core of Searle's argument--the difference between performing intelligent transactions and "being" inetlligent. The paradox is that to explain conciousness, one always feels the need to think of the "guy inside experiencing things", yet any TRUE explanation of conciousness must be at the level of individual unconcious components, because otherwise the argument has just been pushed back. Searle and others can't accept such an explanation, but clearly computers and AI are getting more and more "intelligent" without changing their underlying structure, and eventually I believe they will look as intelligent as us, without having answered any of the "deep" conciousness questions. So now is the last time philosophers have the luxury to conjecture on the necessary means for conciousness, because soon it will be a moot point.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011041509im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>