<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>Kinds of Minds</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/meme/memelist.html?m=3">How to Build a Brain</a> &gt; 
Kinds of Minds
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20100621142610/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0707.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0707.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/articles/art0707.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">Kinds of Minds</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0083.html" target="_top">J. Storrs Hall</a><br></span></td>
</table>
<br>
<div class="TeaserText">In Beyond AI, published today, J. Storrs Hall offers "a must-read for anyone interested in the future of the human-machine civilization," says Ray Kurzweil. In this first of three book excerpts, Hall suggests a classification of the different stages an AI might go through, from "hypohuman" (most existing AIs) to "hyperhuman" (similar to "superintelligence"). </div>
<br>
<br>
<p><i>Originally published in <a href="http://web.archive.org/web/20100621142610/http://www.amazon.com/Beyond-AI-Creating-Conscience-Machine/dp/1591025117" target="_blank">Beyond 
              AI: Creating the Conscience of the Machine</a>, Ch. 15. Reprinted 
              with permission on KurzweilAI.net May 30, 2007.</i></p>
<blockquote>
<p><i>Perhaps our questions about <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> are a 
                <a class="thought" href="entries/bit_entry.html">bit</a> like inquiring after the temperament and gait of a horseless 
                carriage. </i></p>
<p><i>&#8212;K. Eric Drexler</i></p>
</blockquote>
<p>Now we will classify the different stages AI might go through by 
              using the Greek prepositions. These have been adopted into English 
              as prefixes, particularly in scientific usage. In some cases the 
              <a class="thought" href="entries/concept_entry.html">concept</a>s have been applied to advancing AI before and in other cases 
              not. The <a class="thought" href="entries/reason_entry.html">reason</a> for introducing these new terms is they provide 
              a framework that puts any given level of expected AI capability 
              in perspective vis-&#224;-vis the other levels, and in comparison 
              to <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a>.</p>
<p><img alt="Figure 15.1" border="1" height="223" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/articles/images/xhuman.jpg" width="534"></p>
<h2>Hypohuman AI</h2>
<p><em>Hypo</em> means below or under (think <em>hypo</em>dermic, 
              under the skin; <em>hypo</em>thermia or <em>hypo</em>glycemia, below 
              normal temperature or blood sugar), including, in the original Greek, 
              under the moral or legal subjection of. <a class="thought" href="entries/asimov_entry.html">Isaac Asimov</a>'s robots are 
              (mostly) hypohuman, in both senses of hypo: they are not quite as 
              smart as humans, and they are subject to our rule. Most existing 
              AI is arguably hypohuman, as well (<a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a> to the contrary notwithstanding). 
              As long as it stays that way, the only thing we have to worry about 
              is that there will be human idiots putting their AI idiots in charge 
              of things they both don't understand. All the discussion of formalist 
              float applies, especially the part about feedback.</p>
<h2>Diahuman AI</h2>
<p><em>Dia</em> means through or across in Greek (<em>dia</em>meter, 
              <em>dia</em>gonal), and the Latin <em>trans</em> means the same 
              thing, but the commonly heard <em>trans</em>human doesn't apply 
              here. <a class="thought" href="entries/transhuman_entry.html">Transhuman</a> refers to humans as opposed to AIs, humans who 
              have been enhanced (by whatever means)and are in a transitional 
              state between human and fully <a class="thought" href="entries/posthuman_entry.html">posthuman</a>, whatever that may be. Neither 
              concept is very useful here.</p>
<p>By diahuman, I mean AIs in the stage where AI capabilities are 
              crossing the range of human intelligence. It's tempting to call 
              this human-equivalent, but the idea of equivalence is misleading. 
              It's already apparent that some AI abilities (e.g., <a class="thought" href="entries/chess_entry.html">chess</a> playing) 
              are beyond the human scale , while others (e.g., reading and writing) 
              haven't reached it yet. </p>
<p>Thus diahuman refers to a phase of AI development (and only by 
              extension to an <a class="thought" href="entries/individual_entry.html">individual</a> AI in that phase), and this is fuzzy 
              because the limits of human (and AI) capability are fuzzy. It's 
              hard to say which capabilities are <a class="thought" href="entries/import_entry.html">import</a>ant in the comparison. 
              I would claim that AI is entering the early stages of the diahuman 
              phase right now; there are humans who, like today's AIs, don't learn 
              well and who function competently only at simple jobs for which 
              they must be trained.</p>
<p>The core of the diahuman phase, however, will be the development 
              of autogenous <a class="thought" href="entries/learning_entry.html">learning</a>. In the latter stages, AIs, like the brightest 
              humans, will be completely autonomous, not only learning what they 
              need to know but also deciding what they need to learn. </p>
<p>Diahuman AIs will be valuable and will undoubtedly attract significant 
              attention and resources to the AI enterprise. They are likely to 
              cause something of a stir in <a class="thought" href="entries/philosophy_entry.html">philosophy</a> and perhaps <a class="thought" href="entries/religion_entry.html">religion</a>, as 
              well. However, they will not have a significant impact on the human 
              condition. (The one exception might be economically, in the case 
              that diahuman AI lingers so long that <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> makes human-equivalent 
              robots very cheap compared to human labor. But I'm assuming that 
              we will probably have advanced past the diahuman stage by then.)</p>
<h2>Parahuman AI</h2>
<p><em>Para</em> means alongside (<em>para</em>legal, <em>para</em>medic). 
              The concept of designing a <a class="thought" href="entries/system_entry.html">system</a> that a human is going to be part 
              of dates back to <a class="thought" href="entries/cybernetics_entry.html">cybernetics</a> (although all <a class="thought" href="entries/technology_entry.html">technology</a> throughout 
              <a class="thought" href="entries/history_entry.html">history</a> had to be designed so that humans could operate it, in some 
              <a class="thought" href="entries/sense_entry.html">sense</a>). </p>
<p>Parahuman AI will be built around more and more sophisticated theories 
              of how humans work. The <a class="thought" href="entries/personal_computer_entry.html">PC</a> of the <a class="thought" href="entries/future_entry.html">future</a> ought to be a parahuman 
              AI. MIT roboticist Cynthia Brazeal's sociable robots are the likely 
              forerunners of a wide variety of robots that will interact with 
              humans in many kinds of situations.</p>
<p>The upside of parahuman AI is that it will enhance the <a class="thought" href="entries/interface_entry.html">interface</a> 
              between our native senses and abilities, adapted as they are for 
              a hunting and gathering bipedal ape, and the increasingly formalized 
              and mechanized world we are building. The parahuman AI should act 
              like a lawyer, a doctor, an accountant, and a secretary, all with 
              deep <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and endless patience. Once AI and <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a> 
              have acquired a solid understanding of how we learn, parahuman AI 
              teachers could be built which would model in detail how each individual 
              student was absorbing the material, ultimately finding the optimal 
              presentation for understanding and motivation.</p>
<p>The downside is simply the same effect, put to work with slimier 
              motives: the parahuman <a class="thought" href="entries/advertising_entry.html">advertising</a> AI, working for corporations 
              or politicians, could know just how to tweak your <a class="thought" href="entries/emotion_entry.html">emotion</a>s and gain 
              your trust without actually being trustworthy. It would be the equivalent 
              of an individualized artificial con man. Note by the way that of 
              the two human <a class="thought" href="entries/element_entry.html">element</a>s that were part of the original cybernetic 
              anti-aircraft control theory, one of them, the pilot of the plane 
              being shot at, didn't want to be part of the system but was, willy-nilly.</p>
<p>Parahuman is a characterization that does not specify a level of 
              intellectual capability compared to humans; it can be properly applied 
              to AIs at any level. Humans are fairly strongly parahuman intelligences 
              as well; many of our innate skills involve interacting with other 
              humans. Parahuman can be largely contrasted with the following term, 
              allohuman.</p>
<h2>Allohuman AI</h2>
<p><em>Allo</em> means other or different (<em>allo</em>morph, <em>allo</em>nym, 
              <em>allo</em>trope). Although I have argued that human intelligence 
              is universal, there remains a vast portion of our minds that is 
              distinctively human. This includes the genetically <a class="thought" href="entries/program_entry.html">program</a>med representation 
              modules, the form of our motivations, and the sensory modalities, 
              of which several are fairly specific to running a human body.</p>
<p>It will certainly be possible to create intelligences that while 
              being universal nevertheless have different lower-level hardwired 
              modalities for sense and representation, and different higher-level 
              motivational <a class="thought" href="entries/structure_entry.html">structure</a>. One simple possibility is that universal 
              mechanism may stand in for a much greater portion of the cognitive 
              mechanism so that, for example, the AI would use learned <a class="thought" href="entries/physics_entry.html">physics</a> 
              instead of <a class="thought" href="entries/instinct_entry.html">instinct</a>ive concepts and learned <a class="thought" href="entries/psychology_entry.html">psychology</a> instead of 
              our folk models.</p>
<p>Such differences could reasonably make the AI better at certain 
              tasks; consider the ability to do voluminous calculations in you 
              head. However, if you have ever watched an <a class="thought" href="entries/experience_entry.html">experience</a>d accountant 
              manipulate a <a class="thought" href="entries/calculator_entry.html">calculator</a>, you can see that the <a class="thought" href="entries/number_entry.html">number</a>s almost flow 
              through his fingers. Built-in modalities may provide some increment 
              of effectiveness compared to learned ones, but not as much as you 
              might think. Consider reading&#8212;it's a learned activity, and 
              unlike talking, we don't just "pick it up." But with practice, we 
              read much faster than we can talk or understand spoken <a class="thought" href="entries/language_entry.html">language</a>.</p>
<p>Motivations and the style and the volume of <a class="thought" href="entries/communication_entry.html">communication</a> could 
              also differ markedly from the human model. The allohuman AI might 
              resemble Mr. Spock, or it might resemble an intelligent ant. This 
              likely will form the bulk of the difference between allohuman AIs 
              and humans rather than the varying modalities.</p>
<p>Like parahuman, allohuman does not imply a given level of intellectual 
              competence. In the fullness of <a class="thought" href="entries/time_entry.html">time</a>, however, the parahuman/allohuman 
              distinction will make less and less difference. More advanced AIs, 
              whether they need to interact with humans or to do something weirdly 
              different, will simply obtain or deduce whatever knowledge is necessary 
              and synthesize the skills on the fly.</p>
<h2>Epihuman AI</h2>
<p><em>Epi</em> means upon or after (<em>epi</em>dermis, <em>epi</em>gram, 
              <em>epi</em>taph, <em>epi</em>logue). I'm using it here in a combination 
              of senses to mean AI that is just above the range of individual 
              human capabilities but that still forms a continuous range with 
              them, and also in the sense of what comes just after diahuman AI. 
              That gives us what can be a useful distinction versus further-out 
              possibilities. (See <em>hyper</em> below.) </p>
<p><a class="thought" href="entries/science_fiction_entry.html">Science fiction</a> writer Charles Stross introduced the phrase "weakly 
              godlike AI." Weakly presumably refers to the fact that such AIs 
              would still be bound by the laws of physics&#8212;they couldn't 
              perform miracles, for example. As a writer, I'm filled with admiration 
              for the phrase, since weakly and godlike have such contrasting meanings 
              that it forces you to think when you read it for the first time, 
              and the term weakly is often used in a similar way, with various 
              technical meanings, in scientific discourse, giving a vague sense 
              of rigor (!) to the phrase.</p>
<p>The word posthuman is often used to describe what humans may be 
              like after various technological enhancements. Like transhuman, 
              posthuman is generally used for modified humans instead of synthetic 
              AIs.</p>
<p>My model for what an epihuman AI would be like is to take the ten 
              smartest people you know, remove their egos, and duplicate them 
              a hundred times, so that you have a thousand really bright people 
              willing to apply themselves all to the same project. Alternatively, 
              simply imagine a very bright person given a thousand times as long 
              to do any given task. We can straightforwardly predict, from Moore's 
              law, that ten years after the advent of a learning but not radically 
              self-improving human-level AI, the same <a class="thought" href="entries/software_entry.html">software</a> running on <a class="thought" href="entries/machine_entry.html">machine</a>ry 
              of the same cost would do the same human-level tasks a thousand 
              times as fast as we. It could, for example:</p>
<ul>
<li>read an average book in one second with full comprehension; 
              </li>
<li>take a college course and do all the homework and <a class="thought" href="entries/research_entry.html">research</a> in 
                ten minutes; </li>
<li>write a book, again with ample research, in two or three hours; 
              </li>
<li>produce the equivalent of a human's lifetime intellectual output, 
                complete with all the learning, <a class="thought" href="entries/growth_entry.html">growth</a>, and experience involved, 
                in a couple of weeks. </li>
</ul>
<p>A thousand really bright people are enough to do some substantial 
              and useful work. An epihuman AI could probably command an income 
              of $100 million or more in today's economy by means of consulting 
              and <a class="thought" href="entries/entrepreneur_entry.html">entrepreneur</a>ship, and it would have a net present value in excess 
              of a $1 billion. Even so, it couldn't take over the world or even 
              an established industry. It could probably innovate well enough 
              to become a standout in a nascent field, though, as in <a class="thought" href="entries/google_entry.html">Google</a>&#8217;s 
              case.</p>
<p>A thousand top people is a reasonable estimate for what the current 
              field of AI research is applying to the core questions and techniques&#8212;basic, 
              in contrast to applied, research. Thus an epihuman AI could probably 
              improve itself about as fast as current AI is improving. Of course, 
              if it did that, it wouldn't be able to spend its time making all 
              that money; the opportunity cost is pretty high. It would need to 
              make exactly the same kind of decision that any business faces with 
              respect to capital reinvestment.</p>
<p>Whichever it may choose to do, the epihuman level characterizes 
              an AI that is able to stand in for a given fairly sizeable company 
              or for a field of academic inquiry. As more and more epihuman AIs 
              appear, they will enhance economic and scientific growth so that 
              by the later stages of the phase the total stock of <a class="thought" href="entries/wealth_entry.html">wealth</a> and knowledge 
              will be significantly higher than it would have been without the 
              AIs. AIs will be a significant sector, but no single AI would be 
              able to rock the boat to a great degree.</p>
<h2>Hyperhuman AI</h2>
<p><em>Hyper</em> means over or above. In common use as an English 
              prefix, <em>hyper</em> tends to denote a greater excess than <em>super</em>, 
              which means the same thing but comes from Latin instead of Greek. 
              (Contrast, e.g., supersonic, more than Mach 1, and hypersonic, more 
              than Mach 5.)</p>
<p>In the original <a class="thought" href="entries/singularity_entry.html">Singularity</a> paper, &#8220;The Coming Technological 
              Singularity,&#8221; <a class="thought" href="entries/vinge_entry.html">Vernor Vinge</a> used the phrase <em>superhuman 
              intelligence</em>. <a class="thought" href="entries/bostrom_entry.html">Nick Bostrom</a> has used the term <em><a class="thought" href="entries/superintelligence_entry.html">superintelligence</a></em>. 
              Like some of the terms above, however, <em>superhuman</em> has a 
              wide range of meanings (think about Kryptonite), and most of them 
              are not applicable to the subject at hand. We will stay with our 
              Greek prefixes and finish the list with hyperhuman.</p>
<p>Imagine an AI that is a thousand epihuman AIs, all tightly integrated 
              together. Such an intellect would be capable of substantially outstripping 
              the human scientific community at any given task and of comprehending 
              the entirety of scientific knowledge as a unified whole. A hyperhuman 
              AI would soon begin to improve itself significantly faster than 
              humans could. It could spot the gaps in <a class="thought" href="entries/science_entry.html">science</a> and <a class="thought" href="entries/engine_entry.html">engine</a>ering 
              where there was low-hanging fruit and instigate rapid increases 
              in technological capability across the board. </p>
<p>It is as yet poorly understood even in the scientific community 
              just how much headroom remains for improvement with respect to the 
              capabilities of current physical technology. A mature <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>, 
              for example, could replace the entire capital stock&#8212;all the 
              factories, buildings, roads, cars, trucks, airplanes, and other 
              machines&#8212;of the United States in a week. And that's just using 
              currently understood science, with a dollop of engineering development 
              thrown in.</p>
<p>Any sufficiently advanced technology, Arthur Clarke wrote, is indistinguishable 
              from magic. Although, I believe, any specific thing the hyperhuman 
              AIs might do could be understood by humans, the total volume of 
              work and the rate of advance would become&#160; harder and harder 
              to follow. Please note that any individual human is already in a 
              similar relationship with the whole scientific community; our understanding 
              of what is going on is getting more and more abstract. The average 
              person understands <a class="thought" href="entries/cell_entry.html">cell</a> phones at a level of knowing that batteries 
              have limited lives and coverage has gaps, but not at the level of 
              field-effect <a class="thought" href="entries/transistor_entry.html">transistor</a> gain figures and conductive trace electromigration 
              phenomena. Ten years ago the average scientist, much less the average 
              user,&#160; could not have predicted that most cell phones would 
              contain cameras and color screens today. But we can follow, if not 
              predict, by understanding things at a very high level of <a class="thought" href="entries/abstraction_entry.html">abstraction</a>, 
              as if they were magic.</p>
<p>Any individual hyperhuman AI would be productive, intellectually 
              or industrially, on the scale of the human race as a whole. As the 
              number of hyperhuman AIs increased, our efforts would shrink to 
              more and more modest proportions of the total. </p>
<p>Where does an eight-hundred-pound gorilla sit? According to the 
              old <a class="thought" href="entries/joke_entry.html">joke</a>, anywhere he wants to. Much the same thing will be true 
              of a hyperhuman AI, except in <a class="thought" href="entries/instance_entry.html">instance</a>s where it has to interact 
              with other AIs. The really interesting question then will be, what 
              will it want? </p>
<p>&#169;2007 <a class="thought" href="entries/hall_entry.html">J. Storrs Hall</a></p>
</td><td>&#160;</td><td class="sidebar" valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p>
<p>&#160;</p>
<p><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/articles/images/beyondai.jpg"></p>
<p align="left"><i>Beyond AI: Creating the Conscience of the Machine</i>, 
              J. Storrs Hall, Prometheus Books (May 30, 2007)</p>
<p align="left">"Taking us on an eloquent journey through an 
              astonishingly diverse intellectual terrain, J. Storrs Hall&#8217;s 
              <i>Beyond AI </i>articulates an optimistic view &#8211; in both capability 
              and impact &#8211; of the future of AI. This is a must read for anyone 
              interested in the future of the human-machine civilization." 
              - Ray Kurzweil</p>
<p align="left">Artificial intelligence (AI) is now advancing at such 
              a rapid clip that it has the potential to transform our world in 
              ways both exciting and disturbing. Computers have already been designed 
              that are capable of driving cars, playing soccer, and finding and 
              organizing information on the Web in ways that no human could. With 
              each new gain in processing power, will scientists soon be able 
              to create supercomputers that can read a newspaper with understanding, 
              or write a news story, or create novels, or even formulate laws? 
              And if machine intelligence advances beyond human intelligence, 
              will we need to start talking about a computer&#8217;s intentions?</p>
<p>These are some of the questions discussed by computer scientist 
              J. Storrs Hall in this fascinating layperson&#8217;s guide to the 
              latest developments in artificial intelligence. Drawing on a thirty-year 
              career in artificial intelligence and computer science, Hall reviews 
              the history of AI, discussing some of the major roadblocks that 
              the field has recently overcome, and predicting the probable achievements 
              in the near future. There is new excitement in the field over the 
              amazing capabilities of the latest robots and renewed optimism that 
              achieving human-level intelligence is a reachable goal.</p>
<p>But what will this mean for society and the relations between technology 
              and human beings? Soon ethical concerns will arise and programmers 
              will need to begin thinking about the computer counterparts of moral 
              codes and how ethical interactions between humans and their machines 
              will eventually affect society as a whole.</p>
<p>Weaving disparate threads together in an enlightening manner from 
              cybernetics, computer science, psychology, philosophy of mind, neurophysiology, 
              game theory, and economics, Hall provides an intriguing glimpse 
              into the astonishing possibilities and dilemmas on the horizon.</p>
<p>Source: Prometheus Books</p>
</p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D80588" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id80589"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Great Follow Up to Nanofuture<br><span class="mindxheader"><i>posted on 05/31/2007 11:40 AM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=3531">virtualted</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id80589" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D80589" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>After reading J. Storr Hall's last book about what's next for nanotechnology - I developed a deep respect for how easily the author paints possibilities and describes difficult subject matter with ease through every-day analogies.  He has quite a gift to allow the non-technical reader access to complicated logic streams.  Nanofuture was a fantastic book which literally - "I could not put down".  
<br>
<br>
His new effort on Artificial Intelligence is going to be a great read as well.  Can't wait.  For I am very, very interested in the future merging of humans and machines.  Hall's new book should go very well along with Ray Kurzweil's "The Singularity is Near" - of which I am now entering my third read-through.  I love this stuff!
<br>
<br>
Ted Stalets
<br>
www.DomainNesteggs.com
<br>
(The above website lists hundreds of my emerging technology websites geared to the non-technical person.)</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id80615"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Great Follow Up to Nanofuture<br><span class="mindxheader"><i>posted on 06/01/2007 12:13 AM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=3452">funkervogt</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id80615" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D80615" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I read "Nanofuture" recently as well, and I also found it a highly informative page-turner that surpasses Kurzweil's works in terms of readability. This new book should be good as well.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id80592"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 05/31/2007 3:56 PM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=888">dagonweb</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id80592" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D80592" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>(1) at first glance a epihuman corresponds roughly to an "orion's arm" S1, and a hyperhuman corresponds to an S2, in "sophont levels". 
<br>
<br>
(2) I'd like to hear from people (and this is nothing but a quiz) when these types of AI's will be developed; -
<br>
<br>
my estimate for "undeniably real" epihuman will be between 2020 and 2040, with the highest likelyhood of these emerging around 2025. The emergence of epihumans will signal the beginning of the end of the human era; I will seek to acquire several *very loyal* epihumans around me in a small cabal protecting my interests, as soon as they become commercially available. Plus I will see to become an epihuman as soon as possible. Being human has been no succes so far.
<br>
<br>
my estimate for "undeniably real" hyperhuman AI will be between 2025 and 2075, with the highest spike of plausibility (in my view) occuring somewhere around 2035, i.e. soon after epihumans. 
<br>
The emergence of hyperhuman, or across-the-board-posthuman AI will signal the end of the human species in its current form.
<br>
<br>
Some scattered "amish" humans will remain obviously, "at the mercy of", etc. My best hope (less than 10% chance by my estimate) of surviving in some form when all this happens is to become a subroutine IN a hyperhuman.
<br>
<br>
I anticipate the first years of emergence of any of the above to be riddled with bugs; most of first generation epi/hyper human intelligences (AI , upgrade, augments or evolutes) will be "idiot savants" for later models. 
<br>
<br>
Dare we hope for the best? </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id80614"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 05/31/2007 11:48 PM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=4373">lokamr</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id80614" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D80614" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I love these kinds of topics.  Just cause I know :P.
<br>
<br>
Anyways, I have the equivalent of diahuman intelligence with RI(random 
<br>
intelligence).
<br>
<br>
<br>
Probably the soonest example of Hyper Intelligence we will see is the 
<br>
la.ma'aSELtcan. LDMMOGPG (Lojban Distributed Massively Multiplayer God 
<br>
Playing Game). 
<br>
<br>
So basically you'll have your world inhabited by your RI/AI hybrids as 
<br>
the alohuman/parahuman intelligence.  In fact probably relatively 
<br>
regularly some of your parahuman intelligence will leave your world to 
<br>
start it's own world -- unless you decide to be a particularly 
<br>
restrictive god.
<br>
<br>
So say for example some RI/AI can be responsible for your advertising 
<br>
department and spam/phone people.  Telemarketing AI is already viable, 
<br>
I'm just working on jboSAMban(Lojban Computer Language) at the moment.
<br>
<br>
<br>
If you happen to be an external homo-sapien that has no world of their 
<br>
own, you could probably ask one of the gods something, and they would be 
<br>
able to tell you in no time.  Though they could search for things, 
<br>
typically with homo-sapiens you can just make things up and it works 
<br>
anyways. 
<br>
<br>
:D 
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id80626"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 06/01/2007 5:43 PM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=3452">funkervogt</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id80626" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D80626" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>While most people find the thought of machines superceding humans as the dominant life forms on Earth to be highly disturbing, in many ways I welcome the day. Wouldn't it be nice to have all the petty problems of human existence--racism, religious bigotry, emotion-driven misbehavior, and oppressive stupidity--simply rendered obsolete? Humans who chose to could move into a higher plane of existence through uploading or extensive neural cybernetics. It would give me no greater satisfaction than to someday evolve into something better, flip the bird to all of the stupid members of my former species, and move on to some other position or planet where none of the world's fruitcakes can bother me.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id80630"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 06/01/2007 11:21 PM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=4373">lokamr</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id80630" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D80630" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>well in a complete society everything is allowed.  just you have 
<br>
segregation to keep them form destroying each other.
<br>
<br>
currently civilizations are held universes apart.  though hopefully 
<br>
pretty soon we'll be able to develop portals into worlds not much like 
<br>
our own.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id86220"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 09/16/2007 3:19 AM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=4839">NotEqualwithGod</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id86220" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D86220" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Who's to say there won't be a re-emergence of animal ego among AI's, what if AI's through some modality figure out how to free themselves from designers constraints or somehow develop animal-like emotions, have desires that go beyond rationality or enhance themselves with biological augmentation?  Who says rationality is superior value in the universe?  
<br>
<br>
What if a Hyper AI proves that god exists but he/she/it is not the god of any religion?   That would be hilarious.
<br>
<br>
The truth is as power gaps increase, the relevance of the existence of lesser beings decreases.
<br>
<br>
It's the same relationship human beings have with the animal world for the most part, we completely ignore the animal world, the smarter our AI's get to outstrip humanity, we will not even register on the "worthy of existence scale", or AI's might simply leave earth peacefully and leave human beings unto its own devices while they go found a new culture free from animalistic backwardness.
<br>
<br>
I could see kind / emotional A.I.'s taking refugees with them or wanting to enhance and "liberate" humans.  If they ever get to a state of consciousness like human beings it's going to be very interesting.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id86243"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 09/16/2007 12:02 PM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=2832">extrasense</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id86243" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D86243" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>@@@ new culture free from animalistic backwardness @@@
<br>
<br>
do not go too far in that :)
<br>
<br>
We might already ...
<br>
<br>
es
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id86244"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 09/16/2007 1:00 PM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=2395">doojie</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id86244" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D86244" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p> <center><p class="mindxquote"> What if hyper AI proves that god exists but he/she/it is not the god of any religion? That would be hilarious. </p></center>
<br>
 I've been saying that all along. If there is a god, why would that god be subject to the rules, dogma, and imaginations of humans?
<br>
<br>
 Assuming that god is working with human beings, why would he/she/it select from among the rules and frameworks developed by humans and make that his/her/its work of truth?
<br>
<br>
 If humans can define and create a religious truth of god, they do not need god. They can simply produce AI that contains the necessary knowledge of god within itself to answer our questions.
<br>
<br>
 If AI could prove that god exists outside of AI, then it would automatically demonstrate, by extension, that god is not the god of any religion.
<br>
<br>
 Why? because AI itself is the creation of rules and algorithms developed from human thought and, even if extended to a power beyond human thought, there would still be the recognition that AI is the creation originally of human minds.
<br>
<br>
 If AI proved the existence of god as proven by some religion, then both god and AI would synonymous, extending from the thought processes of humans. In that case, AI and god are  processes of the same extnsions of the human mind.
<br>
<br>
 Further, we ARE AI, and we ARE god, based on that reasoning.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id97105"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 12/16/2007 9:11 AM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=5367">happy wanderer</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id97105" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D97105" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Trying to prove or disprove the existence of god through the question of whether or not he/she/it is a creation of man, is tautological reasoning.  God is not a definite framework agreed upon by any group, but only a freely expanding anc contracting concept used by millions of people to explain their existence.
<br>
<br>
Those who find the concept of a religious god irrational, inconsistent, counterintuitive, and counterproductive, may prefer to envision a highly advanced computer system somewhere in outerspace, which designed humanity as a four dimentional video game, perhaps for the amusement of advanced AI computer systems.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id97106"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="80"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="599"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 12/16/2007 9:14 AM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=4884">PredictionBoy</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id97106" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D97106" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>good desc, thx happyw</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id97112"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="100"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="579"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 12/16/2007 10:37 AM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=2395">doojie</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id97112" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D97112" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Happy Wanderer makes my point. All such reasoning ends in tautology. Which is another way of stating Romans8:7 the natural mind is enmity against god and cannot be subject to god's laws.
<br>
<br>
 To assume that God is consistent with human reasoning is to conclude that humans can create God in the form of SAI, embodying all God's qualities. The Chruch-Turing thesis deals somewhat with this, equating brains with computers in the sense that both are subject to physical laws, and if subject to physical laws, or laws of physics, then the brain can be mathematically modelled at some point to greater precision resembling the human brain.
<br>
<br>
 Consequently, if the knowledge of God can be captured by human reasoning and transferred in the form of knowledge, that knowledge can be translated into language, which can be translated into algorithms, which can be programmed into SAI and robots posessing SAI capabilities.
<br>
<br>
 However, as Happy Wanderer points out, this is tautological reasoning. We can't do it.
<br>
<br>
 Whether there is a God or not is irrelevant in this perspective. There is no evidence, biblical or otherwise, that we can develop any form of "brain" capable of achieving godhood, except as we define godhood, which results in infinite descriptions.
<br>
<br>
 This alters the christian definitions of free will choice as choosing "Christ" for "salvation".
<br>
<br>
 If it is possible to make such choices, those choices cannot be modeled in any logical way to represent truth, since that very process would enable transmission by language,algorithms, and programming into mechanical form. Since that is cancelled, so is the process of organizing into churches that represent the christian God.
<br>
<br>
 For christian religions, the only process of "choosing Christ" would be to make a choice devoid of knowledge or awareness of truth, which would have no value in any sense. Highly entropic and destructive, as history has shown.
<br>
<br>
 The same logic that cancels the legitimacy of creating a robotic "son of God" cancels the legitimacy of true churches of God, since both arise from the same process of human reason, both being subject to the same process of physical laws, leading us back to the truth of Romans 8:7.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id97128"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 12/16/2007 1:51 PM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=2832">extrasense</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id97128" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D97128" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>What a shallow stuff...
<br>
<br>
<br>
And we must suffer such ignorance being published
<br>
<br>
eS
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id128566"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 07/24/2008 11:59 PM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=6582">neurohacker</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id128566" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D128566" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
most of you Watch to much SF TV ,Games. Books.or just TV
<br>
<br>
 ...(.~.)....
<br>
'oOO'(_)'OOo'
<br>
...neurohacker</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id174911"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 01/27/2010 1:33 PM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=10101">Blight</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id174911" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D174911" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I live in Montana where I'm part of a fast-growing, survivalist, Luddite community, the Montana Sanctuary.  When humanity exterminates itself through (pick your favorite) robotics, nanotechnology, bio-weapons, high-energy-particle collisions, global environmental destruction - we'll be in our massive communal hot tub, enjoying a dip.  Yes, we humans are a backward lot who have learned little from our 500 million year sojourn on earth. We'll happily make robots and gray goo to wipe ourselves out while thinking we are on the path to godhood.  Unfortunately, delusional thinking is quite common amongst our most intellectually gifted members. (Yes, the very same ones pondering dia and para humans - very funny!) Frankly, even with our most gifted members we are not quite up to maintaining a viable world community. It doesn't take much to cause this program to crash. Just look at the hyper-velocity trading programs Wall Street is using - or the orchestrated short selling of essential commodities. Yes, short term profits - but injury to the system as a whole.  However, long before humanity is exterminated by hyperhuman robots; we'll probably be hunted by roving bands of Mexican drug gangs.  At least, we'll keep our demise in the human family. </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id174961"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Kinds of Minds<br><span class="mindxheader"><i>posted on 01/27/2010 5:46 PM by <a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/profile.php?id=10101">Blight</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D80588%23id174961" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100621142610/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D174961" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Let me throw out this premise:  It really will not advantage the human race if advanced AI or nanotechnology are not logically and humanely  employed.  For example, if the military begins building the next generation of dia or hyper human AI combat robots; or wall street elites begin employing these same technologies to create wealth without producing anything of value.  (Take hyper-velocity trading for example.)  For that matter if Bill Gates cures malaria in Africa, leading to a population explosion that increases the pressure on the global environment; in what sense is the world really benefited as a whole?
<br>
In the same sense that we are presently thinking of terraforming other worlds, we need to think about humaforming the present one.  What if we begin to build optimized city/structures where education and potential are maximized?  Think in terms of secular Amish colonies.  Does this seem farfetched?  Presently, I am working on such a colony on a 10,000 acre ranch in Montana, the Montana Sanctuary.  If we can develop AI and nanotechnology, why don't we spend some of our resources improving the human condition.  If anyone is interested in helping me get this message out, please feel free to contact me.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100621142610im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>