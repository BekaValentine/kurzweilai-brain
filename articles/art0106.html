<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>Embrace, Don't Relinquish, the Future</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/meme/memelist.html?m=2">Dangerous Futures</a> &gt; 
Embrace, Don't Relinquish, the Future
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20090303113422/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0106.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0106.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/articles/art0106.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">Embrace, Don't Relinquish, the Future</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0006.html" target="_top">Max More</a><br></span></td>
</table>
<br>
<div class="TeaserText">Extropy Institute head Max More finds Bill Joy's Wired essay uninformed, unworkable, and even unethical because it will slow down progress in medicine and other vital areas, he believes.</div>
<br>
<br><p>Originally published May 7, 2000 at <a href="http://web.archive.org/web/20090303113422/http://www.extropy.org/maxview.htm" target="_new">Extropy.org</a>. Published on KurzweilAI.net February 26, 2001. Read Ray Kurzweil's response to <a class="thought" href="entries/joy_entry.html">Bill Joy</a> <a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/articles/art0156.html" target="_self">here</a>.</p>
<p>When a scientist publishes a paper, her peers expect to see evidence that she has read prior work relevant to her topic. They expect the scientist to have studied the field thoroughly before contributing a paper, especially in a controversial field. <a class="thought" href="entries/joy_entry.html">Bill Joy</a>, as Chief Scientist at <a class="thought" href="entries/sun_microsystems_entry.html">Sun Microsystems</a>, should understand this. In reading his essay "<a href="http://web.archive.org/web/20090303113422/http://www.wired.com/wired/archive/8.04/joy.html" target="_new">Why the Future Doesn't Need Us</a>" I am struck by his public show of ignorance of <a class="thought" href="entries/thinking_entry.html">thinking</a> about <a class="thought" href="entries/future_entry.html">future</a> technologies, his unrealistic <a class="thought" href="entries/thought_entry.html">thought</a>s about "<a class="thought" href="entries/relinquishment_entry.html">relinquishment</a>", and his slighting of those who have considered these issues deeply as lacking in <a class="thought" href="entries/common_sense_entry.html">common sense</a>. At the same <a class="thought" href="entries/time_entry.html">time</a>, I appreciate his courage in publicly laying out his fears.</p>
<p>As a philosopher, I find his comments about losing our humanity to be frustratingly offhand. I will address this issue in a separate response. Here I wish to focus on Joy's call for <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> of the technologies of genetic <a class="thought" href="entries/engine_entry.html">engine</a>ering, molecular <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>, and <a class="thought" href="entries/robotics_entry.html">robotics</a> (and all associated fields). As someone who has <a class="thought" href="entries/thought_entry.html">thought</a> about these issues for many years, I wish to challenge Joy's <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> policy on two grounds: First, it's unworkable. Second, it's ethically appalling. (A third <a class="thought" href="entries/reason_entry.html">reason</a>--that in practice it would result in authoritarian control while still failing to achieve its purpose--I will leave for a separate response.)</p>
<p>According to Joy's extensive essay, his apocalyptic <a class="thought" href="entries/thinking_entry.html">thinking</a> was <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> off by hearing a conversation between Ray Kurzweil and <a class="thought" href="entries/moravec_entry.html">Hans Moravec</a>. Apart from attending a <a class="thought" href="entries/foresight_institute_entry.html">Foresight Institute</a> conference back in 1989, Joy shows no sign of having read any of the writings or listening to any of the talks of those who have devoted themselves to the issues he raises. Despite the brilliant clarity of Kurzweil's writing, Joy still isn't clear whether we are supposed to "become robots or fuse with robots or something like that." He gives no credit to the years of work by the <a class="thought" href="entries/foresight_institute_entry.html">Foresight Institute</a> not only in promoting the idea of <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> but in planning for its potential dangers by considering both technical and <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and policy-based approaches. Certainly we here at <a class="thought" href="entries/extropy_entry.html">Extropy</a> Institute--a multi-disciplinary think tank and <a class="thought" href="entries/education_entry.html">education</a>al organization devoted to the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/future_entry.html">future</a>--never heard from Joy before he released his missive to the masses.</p>
<p>Someone in Joy's influential position has a responsibility to delve into prior <a class="thought" href="entries/thinking_entry.html">thinking</a> on these issues before scaring a public already unreasonably afraid of some advanced technologies, including genetic <a class="thought" href="entries/engine_entry.html">engine</a>ering. I find it incredible that Joy cites Carl Sagan, one of my intellectual inspirations in the course of criticizing we leading advocates of 21<sup>st</sup> century technologies as lacking in <a class="thought" href="entries/common_sense_entry.html">common sense</a>. Those who advocate obviously unrealistic policies such as global <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> should not make accusations about <a class="thought" href="entries/common_sense_entry.html">common sense</a>. This would be less galling if Joy had actually bothered to find out what we advocates for the <a class="thought" href="entries/future_entry.html">future</a> had to say over the last twelve years. (In 1988, a year before the Foresight conference that Joy attended, we founded <i><a class="thought" href="entries/extropy_entry.html">Extropy</a></i> magazine which evolved into <a class="thought" href="entries/extropy_entry.html">Extropy</a> Institute--a <a class="thought" href="entries/transhuman_entry.html">transhuman</a>ist organization devoted to "Incubating Better <a class="thought" href="entries/future_entry.html">Future</a>s".) Joy also accuses us of lacking humility while in an interview he draws a (misleading) parallel between himself and Einstein's 1939 letter to President Roosevelt.</p>
<p>While acknowledging the tremendously beneficial possibilities of emerging technologies, <a class="thought" href="entries/joy_entry.html">Bill Joy</a> judges them too dangerous for us to handle. The only acceptable course in his view is <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a>. He wants everyone in the world "to limit development of the technologies that are too dangerous, by limiting our pursuit of certain kinds of <a class="thought" href="entries/knowledge_entry.html">knowledge</a>". Joy joins the centuries-old procession of theocrats, autocrats, and technocrats in attacking our pursuit of unlimited <a class="thought" href="entries/knowledge_entry.html">knowledge</a>. He mentions the myth of Pandora's box. He might have thrown in the anti-humanistic and anti-<a class="thought" href="entries/transhuman_entry.html">transhuman</a>istic myths of the Garden of Eden, the Tower of Babel, and the demise of Icarus. Moving from myth to reality, he should have been explicit in describing the necessary means deployed throughout <a class="thought" href="entries/history_entry.html">history</a>: burning books, proscribing the reading of dangerous ideas, state control of <a class="thought" href="entries/science_entry.html">science</a>.</p><h1>PART 1: <a class="thought" href="entries/relinquishment_entry.html">RELINQUISHMENT</a> CANNOT WORK</h1><p>The first of my objections to <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> has already been well made by Ray Kurzweil. Joy's fantasies about <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> ride on the assumption that "we could agree, as a <a class="thought" href="entries/species_entry.html">species</a>" to hold back from developing the "<a class="thought" href="entries/gnr_entry.html">GNR</a>" technologies (genetic <a class="thought" href="entries/engine_entry.html">engine</a>ering, <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>, and <a class="thought" href="entries/robotics_entry.html">robotics</a>) and presumably any enabling or related technologies. Perhaps Joy's experience in having a staff of <a class="thought" href="entries/engine_entry.html">engine</a>ers to do his bidding have blinded him to the incredibly obvious fact that the six billion humans on this <a class="thought" href="entries/planet_entry.html">planet</a> do not and will not agree to relinquish technologies that offer massive benefits as well as defensive and offensive <a class="thought" href="entries/military_entry.html">military</a> capabilities.</p>
<p>We have failed to prevent the spread of nuclear weapons <a class="thought" href="entries/technology_entry.html">technology</a>, despite its terrifying <a class="thought" href="entries/nature_entry.html">nature</a> and relative ease in detection. How are we to prevent all companies, all <a class="thought" href="entries/government_entry.html">government</a>s, all hidden groups in the world from working on these technologies? Bill, all six billion of these people--many desperately in need of the material and medical benefits offered by these technologies--will not read the Dalai Lama and go along with your master plan. <a class="thought" href="entries/relinquishment_entry.html">Relinquishment</a> is a <a class="thought" href="entries/utopian_entry.html">utopian</a> fantasy worthy of the most blinkered hippies of the '60s. Adding coercive enforcement to the mix moves the idea from <a class="thought" href="entries/utopian_entry.html">utopian</a> fantasy to frightening dystopia.</p>
<p>Ray Kurzweil points to a fine-grained <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> that can at least reduce the dangers of runaway technologies among those willing to play this game. <a class="thought" href="entries/nanotechnology_entry.html">Nanotechnology</a> pioneer Eric Drexler has long recommended designing nanomachines that will quickly cease functioning if not fed some essential and naturally uncommon ingredient. Ralph Merkle's broadcast <a class="thought" href="entries/architecture_entry.html">architecture</a> offers another way to develop nanomachines under control. These and other proposals can reduce the hazards of accidental <a class="thought" href="entries/nanotechnology_entry.html">nanotech</a>nological disasters.</p>
<p>However, we can pursue intelligent design, ethical guidelines, and oversight only piecemeal, not universally. Less cautious or less benevolent developers will refuse even this fine-grained <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a>. That fact makes it imperative to <i>accelerate</i> the development of advanced technologies in open societies. Only by possessing the most advanced technological <a class="thought" href="entries/knowledge_entry.html">knowledge</a> can we hope to defend ourselves against the attacks and accidents from outside our sphere of influence. We should be pushing for better understanding of <a class="thought" href="entries/nanotechnology_entry.html">nanotech</a> defenses, accelerated decoding and deactivation of genetically-<a class="thought" href="entries/engine_entry.html">engine</a>ered <a class="thought" href="entries/pathogen_entry.html">pathogen</a>s, and putting more <a class="thought" href="entries/thought_entry.html">thought</a> into means of limiting runaway independent superintelligent <a class="thought" href="entries/ai_entry.html">AI</a>.</p>
<p>I will not address genetic <a class="thought" href="entries/engine_entry.html">engine</a>ering since I regard this as an insignificant danger compared to those of <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> and runaway <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> (<a class="thought" href="entries/ai_entry.html">AI</a>). The dangers of runaway artificial <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a> have received less attention than those of <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>. Perhaps this is because the prospect of <a class="thought" href="entries/ai_entry.html">AI</a> seems to move further away every <a class="thought" href="entries/time_entry.html">time</a> we take a step forward. <a class="thought" href="entries/joy_entry.html">Bill Joy</a> cites only <a class="thought" href="entries/moravec_entry.html">Hans Moravec</a> on this issue, perhaps because Moravec's view is the most frightening available. In Moravec's view of the <a class="thought" href="entries/future_entry.html">future</a>, superintelligent <a class="thought" href="entries/machine_entry.html">machine</a>s, initially harnessed for <a class="thought" href="entries/human_entry.html">human</a> benefit, soon leave us behind. In the most pessimistic <i><a class="thought" href="entries/terminator_entry.html">Terminator</a></i>-like scenario, they might remove us from the scene as an annoyance. Oddly, despite having read Kurzweil's book, Joy never discusses Ray's thoroughly different (and more plausible) scenario. In Ray's <a class="thought" href="entries/future_entry.html">future</a> projections, we gradually augment ourselves with <a class="thought" href="entries/computer_entry.html">computer</a> and robotic <a class="thought" href="entries/technology_entry.html">technology</a>, becoming superhumanly intelligent. Moravec's apartheid of <a class="thought" href="entries/human_entry.html">human</a> and <a class="thought" href="entries/machine_entry.html">machine</a> is replaced with the integration of <a class="thought" href="entries/biology_entry.html">biology</a> and <a class="thought" href="entries/technology_entry.html">technology</a>.</p>
<p>While a little <a class="thought" href="entries/research_entry.html">research</a> would have shown Joy that <a class="thought" href="entries/extropian_entry.html">extropian</a> and other <a class="thought" href="entries/transhuman_entry.html">transhuman</a>ist thinkers have indeed addressed the danger of explosively evolving, unfriendly <a class="thought" href="entries/ai_entry.html">AI</a>, I grant that we must continue to address this issue. Again, global <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> is not an option. Rather than a futile effort to prevent <a class="thought" href="entries/ai_entry.html">AI</a> development, we should concentrate on warding off dangers within our circle of influence and developing preventative measures against rogue AIs.</p>
<p><a class="thought" href="entries/human_entry.html">Human</a> beings are the dominant <a class="thought" href="entries/species_entry.html">species</a> on this <a class="thought" href="entries/planet_entry.html">planet</a>. Joy wants to protect our dominance by blocking the development of smarter and more powerful beings. I find it odd that Joy, working at a company like <a class="thought" href="entries/sun_microsystems_entry.html">Sun Microsystems</a>, can think only of the old <a class="thought" href="entries/corporate_entry.html">corporate</a> strategy where dominant companies attempted to suppress disruptive innovations. Perhaps he should take a look at <a class="thought" href="entries/cisco_entry.html">Cisco</a> <a class="thought" href="entries/system_entry.html">System</a>s, or <a class="thought" href="entries/microsoft_entry.html">Microsoft</a>, both of which have adopted a different strategy: Embrace and extend. Humanity would do well to borrow from the new business strategists' approach. Realistically, we cannot prevent the rise of non-<a class="thought" href="entries/biological_entry.html">biological</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. We can embrace it and extend ourselves to incorporate it. The more quickly and continuously we absorb <a class="thought" href="entries/computation_entry.html">computation</a>al advances, the easier it will be and the less risk of a <a class="thought" href="entries/technology_entry.html">technology</a> runway. Absorption and integration will include economic interweaving of these emerging technologies with our organizations as well as directly interfacing our <a class="thought" href="entries/biology_entry.html">biology</a> with sensors, displays, <a class="thought" href="entries/computer_entry.html">computer</a>s, and other <a class="thought" href="entries/device_entry.html">device</a>s. This way we avoid an us-versus-them situation. <i>They</i> become part of <i>us</i>.</p><h1>PART 2: <a class="thought" href="entries/relinquishment_entry.html">RELINQUISHMENT</a> IS UNETHICAL</h1><p>Some people reach ethical conclusions by consulting an ultimate authority. Their authority gives them answers that are received and applied without questioning. For those of us who prefer a more rational approach to ethical <a class="thought" href="entries/thought_entry.html">thought</a>, reaching a conclusion involves consulting our <a class="thought" href="entries/basic_entry.html">basic</a> values then carefully deciding which of the available paths ahead will best reflect those values. Our factual beliefs about how the world works will therefore profoundly affect our moral <a class="thought" href="entries/reason_entry.html">reason</a>ing. Two individuals may share values but reach differing conclusions due to divergent factual beliefs. I suspect that my ethical disagreement with Joy over <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> results both from differing beliefs about the facts and differing <a class="thought" href="entries/basic_entry.html">basic</a> values.</p>
<p>Joy assigns a high probability to the <a class="thought" href="entries/extinction_entry.html">extinction</a> of humanity if we do not relinquish certain emerging technologies. Joy's implicit <a class="thought" href="entries/calculus_entry.html">calculus</a> reminds me of Pascal's Wager. Finding no rational basis for accepting or rejecting belief in a <a class="thought" href="entries/god_entry.html">God</a>, Pascal claimed that belief was the best bet. Choosing not to believe had minimal benefits and the possibility of an infinitely high cost (eternal damnation). Choosing to believe carried small costs and offered potentially infinite rewards (eternity in Heaven). Now, the <a class="thought" href="entries/extinction_entry.html">extinction</a> of the <a class="thought" href="entries/human_entry.html">human</a> race is not as bad as eternity in Hell, but most of us would agree that it's a utterly rotten result. If <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> can drastically reduce the odds of such a large loss, while costing us little, then <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> is the rational and moral choice. A clear, simple, easy answer. Alas, Joy, like Pascal, loads the dice to produce his desired result.</p>
<p>I view the chances of success for global <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> as practically zero. Worse, I believe that partial <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> will frighteningly increase the chances of disaster by disarming the responsible while leaving powerful abilities in the hands of those full of hatred, resentment, and authoritarian ambition. We may find a place for the fine-grained voluntary <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> of inherently dangerous means where safer technological paths are available. But unilateral <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> means unilateral disarmament. I can only hope that <a class="thought" href="entries/joy_entry.html">Bill Joy</a> never becomes a successful Neville Chamberlain of 21<sup>st</sup> century technologies. In place of <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a>, we would do better to accelerate our development of these technologies, while focusing on developing protections against and responses to their destructive uses.</p>
<p>My assessment of the costs of <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> differ from Joy's for another <a class="thought" href="entries/reason_entry.html">reason</a>. Billions of people continue to suffer illness, damage, starvation, and all the plethora of woes humanity has had to endure through the ages. The emerging technologies of genetic <a class="thought" href="entries/engine_entry.html">engine</a>ering, molecular <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>, and <a class="thought" href="entries/biological_entry.html">biological</a>-technological <a class="thought" href="entries/interface_entry.html">interface</a>s offer solutions to these problems. Joy would stop <a class="thought" href="entries/progress_entry.html">progress</a> in <a class="thought" href="entries/robotics_entry.html">robotics</a>, <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>, and related fields. Too bad for those now regaining hearing and sight thanks to implants. Too bad for the billions who will continue to die of numerous diseases that could be dispatched through genetic and <a class="thought" href="entries/nanotechnology_entry.html">nanotech</a>nological solutions. I cannot reconcile the deliberate indulgence of continued suffering with any plausible ethical perspective.</p>
<p>Like Joy, I too worry about the <a class="thought" href="entries/extinction_entry.html">extinction</a> of <a class="thought" href="entries/human_entry.html">human</a> beings. I see it happening everyday, one by one. We call this serial <a class="thought" href="entries/extinction_entry.html">extinction</a> of humanity "aging and <a class="thought" href="entries/death_entry.html">death</a>". Because aging and <a class="thought" href="entries/death_entry.html">death</a> have always been with us and have seemed inevitable, we often rationalize this serial <a class="thought" href="entries/extinction_entry.html">extinction</a> as natural and even desirable. We cry out against the sudden <a class="thought" href="entries/death_entry.html">death</a> of large numbers of humans. But, unless it touches someone close, we rarely concern ourselves with the drip, drip, drip of individual lives decaying and disintegrating into nothingness. Some day, not too far in the <a class="thought" href="entries/future_entry.html">future</a>, people will look back on our complacency and rationalizations with horror and disgust. They will wonder why people gathered in crowds to protest genetic modification of crops yet never demonstrated in favor of accelerating anti-aging <a class="thought" href="entries/research_entry.html">research</a>. Holding back from developing the technologies targeted by Joy will not only shift power into the hands of the destroyers, it will mean an unforgivable lassitude and complicity in the face of <a class="thought" href="entries/entropy_entry.html">entropy</a> and <a class="thought" href="entries/death_entry.html">death</a>.</p>
<p>Joy's concerns about technological dangers may seem responsible. But his unbalanced fear-mongering and lack on emphasis of the enormous benefits can only put a drag on <a class="thought" href="entries/progress_entry.html">progress</a>. We are already seeing fear, ignorance, and various hidden agendas spurring resistance to genetic <a class="thought" href="entries/research_entry.html">research</a> and <a class="thought" href="entries/biotechnology_entry.html">biotechnology</a>. Of course we must take care in how we develop these technologies. But we must also recognize how they can tackle <a class="thought" href="entries/cancer_entry.html">cancer</a>, heart disease, birth defects, crippling accidents, <a class="thought" href="javascript:loadBrain('Parkinson\'s Disease')">Parkinson's disease</a>, schizophrenia, depression, chronic pain, aging and <a class="thought" href="entries/death_entry.html">death</a>.</p>
<p>On the basis of Joy's recent writing and speaking, I have to assume that we disagree not only about the facts but also in our <a class="thought" href="entries/basic_entry.html">basic</a> values. Joy seems to value safety, stability, and caution above all. I value relief of humanity's historical ills, challenge, and the drive to transcend our existing limitations, whether <a class="thought" href="entries/biological_entry.html">biological</a>, intellectual, <a class="thought" href="entries/emotion_entry.html">emotion</a>al, or <a class="thought" href="entries/spirit_entry.html">spirit</a>ual.</p>
<p>Joy quotes the fragmented yet brilliant figure of Friedrich Nietzsche to support his call for an abandonment of the unfettered pursuit of <a class="thought" href="entries/knowledge_entry.html">knowledge</a>. Nietzsche is telling the reader that our trust in <a class="thought" href="entries/science_entry.html">science</a> "cannot owe its origin to a <a class="thought" href="entries/calculus_entry.html">calculus</a> of utility; it must have originated <i>in spite of</i> the fact that the disutility and dangerousness of the 'will to truth', or 'truth at any price' is proved to it constantly." Joy has understood Nietzsche so poorly that he thinks Nietzsche here is supporting his call for relinquishing the unchained quest for <a class="thought" href="entries/knowledge_entry.html">knowledge</a> in favor of safety and comfort. Nietzsche was no friend to "utility". He despised the English Utilitarian philosophers for their enthroning pleasure or happiness as the ultimate value. Even a cursory reading of Nietzsche should make it obvious that he valued not comfort, ease, or certainty. Nietzsche <i>liked</i> the dangerousness of the will to truth. He liked that the <a class="thought" href="entries/search_entry.html">search</a> for <a class="thought" href="entries/knowledge_entry.html">knowledge</a> endangered dogma and the comforts and delusions of dogma.</p>
<p>Nietzsche's Zarathustra says: "The most cautious people ask today: 'How may man still be preserved?'" He might have been talking of <a class="thought" href="entries/joy_entry.html">Bill Joy</a> when he continues: "Zarathustra, however, asks as the sole and first one to do so: `How shall man be <i>overcome</i>?"... "Overcome for me these masters of the present, o my brothers--these petty people: <i>they</i> are the overman's greatest danger!" If we interpret Nietzsche's inchoate notion of the overman as the <a class="thought" href="entries/transhuman_entry.html">transhuman</a>s who will emerge from the integration of <a class="thought" href="entries/biology_entry.html">biology</a> and the technologies feared by Joy, we can see with whom Nietzsche would likely side. I will limit myself to one more quotation from Nietzsche:</p>
<p>And <a class="thought" href="entries/life_entry.html">life</a> itself confided this secret to me: "Behold," it said, "I am that which must always overcome itself. Indeed, you call it a will to procreate or a drive to an end, to something higher, farther, more manifold: but all this is one... Rather would I perish than forswear this; and verily, where there is perishing... there <a class="thought" href="entries/life_entry.html">life</a> sacrifices itself--for [more] power... Whatever I create and however much I live it--soon I must oppose it and my life; ... 'will to existence': that will does not exist... not will to <a class="thought" href="entries/life_entry.html">life</a> but... will to power. There is much that <a class="thought" href="entries/life_entry.html">life</a> esteems more highly than <a class="thought" href="entries/life_entry.html">life</a> itself.&#160;Zarathustra II 12 (K: 248)</p>
<p>Like Nietzsche, I find mere survival ethically and <a class="thought" href="entries/spirit_entry.html">spirit</a>ually inadequate. Even if, contrary to my view, <a class="thought" href="entries/relinquishment_entry.html">relinquishment</a> improved our odds of survival, that would not make it the most ethical choice if we value the unfettered <a class="thought" href="entries/search_entry.html">search</a> for <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and intellectual, <a class="thought" href="entries/emotion_entry.html">emotion</a>al, and <a class="thought" href="entries/spirit_entry.html">spirit</a>ual <a class="thought" href="entries/progress_entry.html">progress</a>. Does that mean doing nothing while <a class="thought" href="entries/technology_entry.html">technology</a> surges ahead? No. We can minimize the dangers, ease the cultural transition, and accelerate the arrival of benefits in two ways: We can develop a sophisticated philosophical perspective on the issues. And we can seek to use new technologies to enhance <a class="thought" href="entries/emotion_entry.html">emotion</a>al and psychological health, freeing ourselves from the irrationalities and destructiveness built into the genes of our <a class="thought" href="entries/species_entry.html">species</a>.</p>
<p>We should be spurring understanding of <a class="thought" href="entries/emotion_entry.html">emotion</a>s and the neural basis of feeling and motivation. I've seen some good work in this area (such as Joseph LeDoux's <i>The <a class="thought" href="entries/emotion_entry.html">Emotion</a>al </i><a class="thought" href="entries/brain_entry.html">Brain</a>), but until very recently <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a> has ignored <a class="thought" href="entries/emotion_entry.html">emotion</a>s. If we are to flourish in the presence of incredible new technological abilities, we would do well to focus on using them to debug <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/nature_entry.html">nature</a>. Power can corrupt, but <a class="thought" href="entries/knowledge_entry.html">knowledge</a> that brings the power to self-modify so as to refine our <a class="thought" href="entries/psychology_entry.html">psychology</a> can ward off corruption and destruction. I have spoken on this topic more than I have yet publicly written, but I would stress the importance of advancing our abilities for refinement of our own <a class="thought" href="entries/emotion_entry.html">emotion</a>s.</p>
<p>Improving philosophical understanding will speed the absorption and integration of new technologies. If we continue to approach rapid and profound technological change with philosophical worldviews rooted in old myths and pre-scientific story-making, we will needlessly fear change, miss out on potential advances, and be caught unprepared. When the announcement came from Scotland proclaiming the first successful <a class="thought" href="entries/mammal_entry.html">mammal</a>ian cloning, the Catholic Pope issued a statement opposing cloning on grounds that made no <a class="thought" href="entries/sense_entry.html">sense</a>. (His vague objection would apply equally to identical twins.) President Clinton and other leaders also automatically moved to ban <a class="thought" href="entries/human_entry.html">human</a> cloning, with no indication of clear <a class="thought" href="entries/thinking_entry.html">thinking</a> based in <a class="thought" href="entries/science_entry.html">science</a> and <a class="thought" href="entries/philosophy_entry.html">philosophy</a>.</p>
<p><a class="thought" href="entries/extropian_entry.html">Extropian</a>s and other <a class="thought" href="entries/transhuman_entry.html">transhuman</a>ists have been developing philosophical <a class="thought" href="entries/thinking_entry.html">thinking</a> fitting to these powerful emerging technologies. In our books, essays, talks, and email forums, we have explored a vast range of philosophical issues in depth. Just last year in August 1999, I chaired <a class="thought" href="entries/extropy_entry.html">Extropy</a> Institute's fourth conference: Biotech <a class="thought" href="entries/future_entry.html">Future</a>s: Challenges and Choices of <a class="thought" href="entries/life_extension_entry.html">Life Extension</a> and Genetic <a class="thought" href="entries/engine_entry.html">Engine</a>ering. The conference laid out the likely path of emerging technologies and dissected issues raised. In my own talk, I analyzed implicit philosophical mistakes that engender fear and resistance to the changes we anticipate. I summarized our own goals in a letter to Mother <a class="thought" href="entries/nature_entry.html">Nature</a>, and have laid out some guiding values in The <a class="thought" href="entries/extropian_entry.html">Extropian</a> Principles.</p>
<p><a class="thought" href="entries/joy_entry.html">Bill Joy</a>'s essay and subsequent talks may feed the public's fear and misunderstanding of our potential <a class="thought" href="entries/future_entry.html">future</a>. On the other hand, perhaps his <a class="thought" href="entries/thought_entry.html">thought</a>s will raise interest in the philosophical, ethical, and policy issues in a productive way. As a philosopher committed to incubating better <a class="thought" href="entries/future_entry.html">future</a>s, I along with my colleagues in <a class="thought" href="entries/extropy_entry.html">Extropy</a> Institute welcome constructive input from Joy in this continuing <a class="thought" href="entries/learning_entry.html">learning</a> process. Humanity is on the edge of a grand <a class="thought" href="entries/evolution_entry.html">evolution</a>ary leap. Let's not pull back from the edge, but by all means let's check our flight equipment as we prepare for takeoff.</p>
<a href="http://web.archive.org/web/20090303113422/http://www.extropy.org/maxview.htm" target="_new">Original article at Extropy.org</a>
</td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D2253" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id2254"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>What ethics?<br><span class="mindxheader"><i>posted on 08/25/2001 1:04 PM by jpjolly@aon.at</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id2254" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D2254" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Max More is right to say that Bill Joy's plea for "relinquishment" is nonsense. The new developments of the past few decades are genies that won't go back into their bottles. However, figuring out what to do with them is going to require a lot of attention by all of us. The reason that so many people have trouble articulating clear ethical positions regarding new technologies is that some new technological developments challenge the validity of our ethical values.
<br>
<br>
Like all the other commentators who cite "ethics" as the basis for their arguments, More ignores the fact that our ethical concepts reflected a world in which certain facts of life - death, illness, suffering - were assumed to be immutable. Against this background, it is easy to recognize long life and health as universal values, and to view caring for the sick as an exemplary exercise of these values. Yet in this context, caring for the sick means taking time from from our other endeavors to give them whatever attention and comfort we can. But has the work of Edward Jenner or Christian Barnaard contributed to society's ability to fulfill this ideal? In today's world of "granny dumping" and industrial-style hospital care, I tend to think that we have moved further from it than ever. (It would be interesting to find out how many of the top people in bio-engineering have ever spent  an afternoon holding the hand of a sick friend or relative.) 
<br>
<br>
More calls himself a philosopher, but a good philospher would define his terms first. And by doing so, he would forced to admit that the ethics he is talking about are those of a bygone era, ill-equipped to deal with playing God on the scale to which we now seem capable.
<br>
<br>
Advocates of genetic engineering for medical purposes take the position that their research is ethically "good" because it may, for example, some day eradicate those diseases which take the greatest toll in terms of human lives. Yet they conveniently ignore the fact that such a development would change the basic parameters of human existence at least as  fundamentally as, say, the development of agriculture. Using mere biological intelligence, and employing only the concepts of the previous millenium, it is possible to envision some of the unbalancing effects this might have on humanity, such as the implications of new horizons in overpopulation. What form all this might take is, of course, subject to speculation. But whatever happens, it is an insult to our intelligence when lobbyists tell us that everything will be the same, only we won't have to worry about cancer any more. 
<br>
<br>
Or try this: What is cloning? Cloning uses a cell from a living organism to make a biologically identical copy of the original organism. And what is its purpose?  Is it for procreation? Society possesses a wealth of moral thought on reproduction, but the idea of cloning does not appear in any of this. Is it for research? In the debate on stem cell research, advocates place the possible knowledge to be gained above the sanctity of innocent human life. Yet this is an certainly an alien concept in existing ethics. 
<br>
<br>
At the level of events which represent paradigm shifts in human history, once we  step back from existing cultural positions, we have few concepts that are useful in judging what happens. If a technological development provides overwhelming competitive advantages to those who use it, there is ultimately no way to stop its development. But it is important to remember that changes in the parameters of existence do not take place in an orderly manner. Eventually, the effects of sci-fi technologies change our lives much more drastically than the ability to order pizza via Internet has done. Although Bill Joy's call for researchers to relinquish development of "threatening" technologies is naive and futile, there can be no sensible philosophical discussion of the future of technology without a reconsideration of ethical concepts. The public and scientific debate on these topics will have to go beyond the mentalities of mere fundraising on the one hand and wishing it would all go away on the other. Those who consider themselves to be on the cutting edge would provide a much more valuable service by thinking hard about how technology will redfine our ethical categories, and help the rest of us to understand it better.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id2257"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: What ethics?<br><span class="mindxheader"><i>posted on 08/25/2001 6:07 PM by grantc4@hotmail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id2257" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D2257" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Whose ethics are we talking about?  Are we to be guided by the ethics of the Taliban or the Southern Baptists or the Catholics, Buddhists or Hindus?  All of them have different ideas about what kind of conduct can be called ethical.  Or do we have to create a new universal cannon of ethics that applies to a people who would verge on being gods to the people who wrote the original books on the subject?  </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id2265"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: What ethics?<br><span class="mindxheader"><i>posted on 08/26/2001 10:25 AM by jpjolly@aon.at</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id2265" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D2265" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>It's not a matter of merely choosing from existing ethical systems, nor of throwing them all out to worship new tech, but of trying to find some rudimentary consensus about what humanity is we want technology to do for us. Otherwise, the Trekkies should just admit that their faith in technology is a religion in its own right. Bill Joy quotes George Dyson (from "Darwin Among the Machines"): "In the game of life and evolution there are three players at the table: human beings, nature, and machines. I am firmly on the side of nature. But nature, I suspect, is on the side of the machines." One of our new religions is Darwinism. But does that mean we want to dedicate ourselves fully to its principles?
<br>
<br>
If we are still talking about More's text, then the question is whether we can even talk about these things in moral terms when the conditions that gave rise to our moral concepts are no longer adequate. In case you think that's an exaggeration, consider how difficult it is for people today to go even a short time without their cars, phones, and microwaves. Can you or anyone you know make fire without a match? How much more difficult will it then be for us to live without our computers, once we have integrated them into our individual brain circuits? 
<br>
<br>
The debate, such as it is, is being carried out between two extreme groups. On the one hand, there are those who tell us that the technology they are about to invent will be like the Shmoo's from the Li'l Abner comics, curing all ills, solving all problems with a smiling face. On the other, we have the wild-eyed prophets trudging in from the desert to warn us of impending doom. In this climate, and in the context of traditional ethical systems, can anyone claim to know whether there is even a grain of value in radical new technologies?  When day-to-day survival is the problem, anything that makes that survival easier looks "good". But is prolonging human life good in and of itself if basic survival in "conventional" terms has never been easier? What I am saying is that the talented, ethically res'ponsible scientists working on the forefornt of technological breakthroughs should have the honesty to recognize that when they re-draw the demarcations lines of the possible, they automatically cast doubt on their ethical mandate for further research. And those people who still think that it is possible to "undiscover" earth-shaking new technologies need to overcome their reservations, inform themselves, and take part in the discussion, even the Taliban.
<br>
<br>
Once again, it seems to me that there is very little serious critical thought going on here, whether among technophiles or among Luddites. </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id2266"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: What ethics?<br><span class="mindxheader"><i>posted on 08/26/2001 3:58 PM by tomaz@techemail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id2266" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D2266" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>&gt; the technology they are about to invent will be like the Shmoo's from the Li'l Abner comics, curing all ills, solving all problems with a smiling face
<br>
<br>
Exactly. A political correctness, that the 'technology cannot solve all problems' - or some theatrical considerations which drives Holywood movies  - are totally irrelevant.
<br>
<br>
&gt; curing all ills, solving all problems with a smiling face
<br>
<br>
YES!
<br>
<br>
<br>
- Thomas Kristan</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id4946"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="80"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="599"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Singularity cult amounts to blind worship of gray goo in Schmoo form?<br><span class="mindxheader"><i>posted on 01/20/2002 10:54 AM by craighubleyus@yahoo.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id4946" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D4946" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>If you really believe that the most dangerous thing that can arise from nanotech is the Schmoos, you're pathetic and likely insane.
<br>
<br>
But at least we know what you worship now.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id2273"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: The ethics of a moving target<br><span class="mindxheader"><i>posted on 08/26/2001 10:02 PM by jrichard@empire.net</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id2273" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D2273" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>One of the great challenges of accelerating technology is that it introduces ethical issues faster than the human community can absorb and focus on.
<br>
<br>
In a way, the neo-Luddite movement can be seen as an attempt to slow the whole process down so that the old ethics (whatever it may be) can still function in a world that resembles its source.
<br>
<br>
As each technical possibility emerges, one way to view the ethical aspect is to ask who will want this technology and what harm will there be if they get it.
<br>
<br>
One might ask what are the ethics in situations where a large minority would want something that the majority would consider harmful because it changes their world in a way they don't want.
<br>
<br>
For example, if a large minority chose to be cyborgs with greatly enhanced intelligence, should the rest of humanity accept a world in which they would gradually become second-class citizens?
<br>
<br>
The importance of coming to grips with all this suggests that we should be funding Ethics and Technology centers in all the major universities.
<br>
This would give us a significant pool of people who could frame all the ethical considerations before decisions were made on allowing certain technologies to proceed.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id4947"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>uncritical promotion of technology is itself a violation of ethics.<br><span class="mindxheader"><i>posted on 01/20/2002 10:57 AM by craighubleyus@yahoo.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id4947" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D4947" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>My own experience is that the Luddites are asking the right questions.
<br>
<br>
The techno-philes are still promoting the technology mindlessly, as in nuclear age.
<br>
Given history and current events, uncritical promotion of technology is itself a violation of ethics.
<br>
<br>
"But is prolonging human life good in and of itself if basic survival in "conventional" terms has never been easier? "
<br>
<br>
No.  Because a bunch of two-hundred-year-old vampires spouting the same propaganda from their childhood and demanding organ transplants from children is not a sane ruling class.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id4949"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>how likely is an intelligent species to become a "god" not commit suicide?<br><span class="mindxheader"><i>posted on 01/20/2002 10:59 AM by craighubleyus@yahoo.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id4949" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D4949" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>"do we have to create a new universal canon of ethics that applies to a people who would verge on being gods to the people who wrote the
<br>
 original books on the subject?"
<br>
<br>
Likely, yes.  If time is cyclic this is easy but necessary.  If time is linear this is hard but could be avoided in favor of a dumb bet on blind luck.  Think about it.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id4940"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Max More knows nothing about ethics - he is a self-serving cultist<br><span class="mindxheader"><i>posted on 01/20/2002 7:11 AM by craighubleyus@yahoo.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id4940" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D4940" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>http://www.tikkun.org/magazine/index.cfm/action/tikkun/issue/tik0111/article/011111a.html
<br>
<br>
"In the memorable phrase of Father Thomas Berry, our current economic and technological
<br>
                 system has turned all of nature from a community of subjects into a collection of objects. To
<br>
                 restore relationship and begin healing we must again treat the living kingdom as a community of
<br>
                 subjects, each with its own meaning and destiny, none as merely exploitable objects or means
<br>
                 of production. Moving towards this new moral community involves nothing less than replacing
<br>
                 the infrastructure of cold evil with technologies and human systems which are responsive to our
<br>
                 physical and spiritual needs and the needs of the rest of the biotic community. This means
<br>
                 evolving a means of production and social organization for which we can take true
<br>
                 responsibility. It is a daunting, almost overwhelming task, but the alternative is to continue to live
<br>
                 in state of cold evil, complicit in the current system's crimes and distanced from relationship and
<br>
                 healing. This we can no longer do."
<br>
<br>
More is provably wrong.  Joy is morally right.  But of course if you ignore proofs from both history and science, and have no morality, of course you may follow More to doomsday.
<br>
<br>
If you want to play with this stuff off my (and Bill Joy's) planet, we probably can't stop you.
<br>
<br>
But destroying all of it, and all of its creators, we find inside our gravity well, is a reasonable precaution.
<br>
<br>
Craig Hubley</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id4943"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Max More knows nothing about ethics - he is a self-serving cultist<br><span class="mindxheader"><i>posted on 01/20/2002 9:46 AM by grantc4@hotmail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id4943" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D4943" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Isn't it wonderful!  Now that we're gods, everyone wants to take over and direct the course of evolution.  The only problem is, we're all pulling in different directions.  How is that going to be any different from the random selection we have now?
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id4945"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>ethics is a matter of constraining yourself to needs of others<br><span class="mindxheader"><i>posted on 01/20/2002 10:42 AM by craighubleyus@yahoo.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id4945" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D4945" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Damn good point.  There is no difference between a bunch of pseudo-gods pulling in random directions and simple randommness.
<br>
<br>
And random evolution has given us some pretty disastrous events, e.g. cyanophytes chewing up the whole methane atmosphere a billion years ago.
<br>
<br>
Now, that was fun for us, but if a bunch of robotic critters decide to put it *back*... hmm
<br>
<br>
Big ugly disasters, dieoffs, etc..
<br>
<br>
If Max More is going to call Bill Joy unethical, he should look into the process of ethics itself:
<br>
it usually requires modifying your own behavior to deal with the constraints imposed on it by others.
<br>
<br>
Time will tell...</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id13740"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: ethics is a matter of constraining yourself to needs of others<br><span class="mindxheader"><i>posted on 01/21/2003 9:02 PM by Jeremy</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id13740" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D13740" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Time will tell...
<br>
<br>
and when it does its work, it may be too late.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id21429"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Just some thoughts...<br><span class="mindxheader"><i>posted on 11/05/2003 12:13 PM by <a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/profile.php?id=775">techno</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id21429" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D21429" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Max More argues that relinquishment, as suggested by Bill Joy, will not work based on two principle grounds (its unworkable and its unethical).  I completely agree with the fact that relinquishment will be unsuccessful on the grounds that it is unworkable.  How many times have we seen the entire world come to a consensus on a global issue?  Most people cannot reach a consensus on issues within their own homes.  Even if we can get a consensus, how do we enforce it? If the potential exists, someone will carry on the research somewhere in the world where enforcement is not very strong.  I don't agree with the concept of 'fine-grained' relinquishment either.  Max More mentions that 'Eric Drexler has long recommended designing nanomachines that will quickly cease functioning if not fed some essential and naturally uncommon ingredient.'  If it was this easy to control these nanomachines, then why would people be opposed to such technology?  Responsible developers might take these types of precautions, but what about individuals who might use the technology for other purposes?  Max More mentions that accelerating development of advanced research in open societies will help us defend ourselves against rouge developers.  Although this makes sense if we are trying to stay ahead of everyone else who might use the technology for unintended purposes, it somewhat contradicts the notion of putting more thought into intelligent design and ethical guidelines.  I believe that intelligent design and ethical considerations requires us to slow down the process of development so that we can really understand where we are and where we should go next. As Ray Kurzweil mentions, we cannot look at the advance of technology from a linear perspective because the growth is exponential.  Accelerating the speed at which we develop advanced technology then only seems to decrease the amount of time we have to critically assess our progress.
<br>
On the grounds that relinquishment is unethical, I have mixed feeling about this.  I do believe that it is unethical to completely stop research in areas that will help eliminate suffering and disease and will allow us to live much longer lives.  On the other hand, if the destructive power of the technology becomes greater than the constructive power, then is it really worth it?   I am not exactly sure where I stand on the ethics issue.  I don't agree with Max Mores' view of aging and death as a serial extinction of humanity.  We live in a world of cycles.  Human life as well as technology follows this cyclic pattern of rise and fall.  What is birth without death?  Technology one day might allow us to live until we are 200 years old or more, but we will eventually die.  The rationalization of aging and death as natural and possibly even desirable will always remain, even when we can live hundreds of years.  If he believes that technology will somehow solve this, I think he is a little too optimistic about the greatness of the future.
<br>
<br>
thx.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id21537"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Just some thoughts...<br><span class="mindxheader"><i>posted on 11/09/2003 9:51 PM by <a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/profile.php?id=819">Naomi8</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id21537" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D21537" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Max More protests that Bill Joy's "Why the Future Doesn't Need Us" Wired essay was prematurely publicized without adequate consideration of possible ramifications.  More insists that 'someone in Joy's influential position has a responsibility to delve into prior thinking on these issues before scaring a public already unreasonably afraid of some advanced technologies.'  However, individuals like Joy bring meaning to Luddism and spark awareness to a possible future that I have never even imagined.  Intelligent people should register Joy's arguments as professional opinion and do extensive research to discover evidence supporting or contradicting his beliefs, and ultimately make up their own minds on what to believe.  More lazy-minded people can rely on the popular trilogy 'The Matrix' to shape the fundamentals of their beliefs.  At times it may be difficult to distinguish fact from fiction, hence the message 'The Matrix' portrays could more deeply penetrate the general population's minds, than could More's attempt of persuasion in the Wired essay.  Should the co-directing Wachowski brothers also be condemned for 'scaring' a public on the consequences of advanced technologies and gearing our perspectives toward a bleak future?
<br>
<br>
The objection that Joy's call for mandatory relinquishment is unworkable does seem accurate in reality, now.  The commentary above argues through the rhetorical question: 'how many times have we seen the entire world come to a consensus on a global issue?'  The obvious answer being almost never.  However, there are significant exceptions to the answer hinted at.  Worldwide consensus can be reached on key issues.  An example of this being that countries considered hostile are prohibited of owning weapons of mass destruction.  If a strong enough voice is heard than I am confidant that the world will listen.  A snowball effect could be initiated through individual minds like Bill Joy's, through to the U.S. senate, through to United Nations, through to the world.  However, before we can reach consensus, More is correct in that more explicit means and measures need to be described on how to enforce relinquishment worldwide of dangerous technologies.  Joy's essay should not be treated as an ultimatum to either enact relinquishment or accept the inevitable terrors to come.  He is simply one of the pioneering voices of Luddism in our time, and with sufficient attention and consideration, relinquishment could be workable and successful if deemed a necessary means for preventing destructive uses of technologies.
<br>
<br>
The above commentary claims that 'intelligent design and ethical considerations requires us to slow down the process of development so that we can really understand where we are and where we should go next.'  This may not be necessary if a genuine attempt was made to bring a pool of experts up-to-speed with what possible consequences could follow from our advanced technologies, deemed dangerous or not.  Often organizations conduct control reviews to identify the risks and weaknesses in a project.  The Leader of Opposition role in the government is a prime example of the type of experts needed to question and analyze advances in 'GNR' technologies.  Although all issues may not be identified, these experts could prepare humankind for what is to come in our future.  With scientists and contingency experts moving in tandem, there could be legislation passed and valuable lessons learned to equip us all for the unexpected.
<br>
<br>
I offer unwavering support that relinquishment could mean 'deliberate indulgence of continued suffering' of humankind.  There is strength in More's rebuttal on ethical grounds that relinquishing 'GNR' technologies could mean continued suffering of 'illness, damage, starvation, and all the plethora of woes humanity has had to endure through the ages.'  General moral imperatives to 'contribute to society and human well-being' and 'avoid harm to others' (ACM Code of Ethics) are directly applicable in the short-term, and potentially in the long-term.  With our 'Leader of Opposition GNR experts' in place, we can only hope that continual advancement of 'GNR' technologies with complete awareness of the consequences can bring us to the 'utopian fantasy' we all dream of.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id40088"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Embrace, Don't Relinquish, the Future<br><span class="mindxheader"><i>posted on 06/12/2005 3:50 AM by <a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/profile.php?id=1973">Jake Witmer</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id40088" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D40088" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I strongly agree.  Embrace, don't relinquish the future.
<br>
<br>
I could never design, with my own flesh and limited life-span, a computer replete with all of its peripheral devices, (not to mention the internet or its protocols) that I am using to commuicate with this discussion group.  I don't have the math ability for it.  I suspect strongly that the same is true of the Luddites in our midst.  But I differ from them in that I appreciate the efforts of the technologists who gave me this wonderful ability to communicate effectively with vast numbers of my fellow humans.
<br>
<br>
To quote Petr Beckmann, author of "A History of Pi":
<br>
<center><p class="mindxquote">
<br>
"It has again become fashionable to blame science and technology for the ills of society.  I have some sympathies for the Luddites who were uneducated, miserable, and desperate.  I have none for the college-educated illiterates who drivel about 'too much science and technology' because they want to conserve their lifestyle by denying it to everyone else."  </p></center>
<br>
So why do the new fascist 'left' and 'right' believe that force is the answer to all of life's problems?  -Because it's too hard for them to imagine the truth: that the technologists value life, when they themselves do not.
<br>
<br>
It has forever been the aim of well-meaning technologists to decentralize power through the peaceful and voluntary market.  It has been the goal of the left to go to the strongest bully, and beg them to do the impossible: make us all safe.  The result of this action, (when the bully looks around and realizes that the vast ocean of idiots begging for safety is much stronger than he alone is) is that the bully happily accepts the responsibility.  "Sure thing, Mr. Luddite, I'll keep you safe!"  And in turn, the brutalizer only asks that the luddite pseudo-intellectuals gain the confidence of the rest of the mindless herd, from which he draws his real brute-strength.
<br>
<br>
The only reason why the luddites here in America have not already turned this country into a complete dictatorship is that the technologists have defended the most important human right:  The right of self-defense.  The second amendment gaurantees that we cannot be subjected to Stalinism, even if that's exactly what the Luddites among us want.
<br>
<br>
There is a saying in the gun culture that "Gun control isn't about guns, it's about control".  This statement's truth is proven more likely with every luddite argument on these boards.  The luddites value 'control' and 'stability' over the lives of a family that is cowering behind their door for fear of the thought police.
<br>
<br>
Ultimately, what the luddites want is for there to be no strong individuals among us (for all of those individuals to be targeted for destruction by the collective).  They then would control everything, because they recognize that they would not ever be given the responsibility of leadership from an informed collective, but an uninformed collective might well grant them the crown.  Luckily for them, the collective wishes to avoid the responsibility of thinking.
<br>
<br>
It is in the hands of the few then, the technologists, that the responsiblity of decentralizing power falls.
<br>
<br>
If the power becomes concentrated in government hands, then the Luddites will control (or limit) its deployment.
<br>
<br>
This would be a tragedy.  As relatively free individuals, we can already see what government does to individual rights when it is given the choice -it declares individual rights null and void.  This is the nature of government, and more basically of collective rule.
<br>
<br>
There is no valid reason to strip people from their families and put them in prisons, because they owned certain kinds of drugs or small arms.  -But the fearmongers do it anyway, and they have a lot of political support from the rest of the uneducated masses.
<br>
<br>
This shows that the majority of unimaginitive people cannot imagine a positive use for something that has a potential negative use (ie: illegal drugs, illegal small-arms).  Everyone in the new-tech community should be painfully aware of this fact.
<br>
<br>
We must also be aware that there are people who do not value life among us.  These are not the machine gun owners who stand prepared to defend against a democide (as the technology banners would have us believe).  These are the Luddites who say "We love life so much that we want to get rid of all machine guns, so that they can never kill again".
<br>
<br>
This then leaves the machine guns in the hands of only the government.  Whatever ignorant luddite then whispers in that government's ear then gets to point the machine guns at his enemies.
<br>
<br>
The Weimar Republic required universal gun registration as a supposed means of denying gun registration (and thus gun ownership) to gypsies (a minority that the majority of ignorant citizens unreasonably feared and hated).  Their stated goal was to collectively reduce violence.  The result of their goal was to allow Hitler to remove guns from the hands of his regime's political enemies (in 1938), and then cart the Jews (and gypsies) off to concentration camps, without a shot fired.  There have been similar defensive technology restrictions in every major genocide/democide.  A very recent example of this was in Rwanda.  The Tutsis were not allowed, by law, to own weapons of self-defense.  Had they been able to, they would not have allowed goons to bash their heads in with machetes.
<br>
<br>
The political norm of luddite anti-technology meant that one option for saving the Tutsis was never considered:  "Why not arm them equally, quickly?"  Why not ask the western world to contribute money to buy them guns?  Seems crazy, to people who have been trained not to think about the nature of self defense, and the nature of human collectivism.  But it would have saved the Tutsis -they would have returned fire, rather than be massacred.
<br>
<br>
In the absence or loss of a democratic election process, universal gun ownership is the only thing that can prevent a democide/genocide.  See:
<br>
<br>
<a href="http://web.archive.org/web/20090303113422/http://www.hawaii.edu/powerkills" target="_blank">http://www.hawaii.edu/powerkills</a>
<br>
<a href="http://web.archive.org/web/20090303113422/http://www.jpfo.org/" target="_blank">http://www.jpfo.org</a>
<br>
<br>
Consider how these basic rules of defensive technology and collective rule apply to a defensive technology like military nanotechnology.  We haven't outgrown the collective rule by thugs yet, and there is no indication that the majority of the populace even wishes this to happen.  But our technology is getting much better.
<br>
<br>
If we wish to maintain our human dignity, then there must be some free individual who has the private ability to manufacture advanced military nanotechnology, and distribute this, as a defensive technology, to a willing populace of current libertarians/gun-owners.
<br>
<br>
This is not an assertion that self-described libertarians are the answer, but rather those who currently act as libertarians on the balance of power in society.  A gun-owning 'Democratic/Republican Party' voter who believes in human dignity and equality under the law is vastly more 'libertarian' than a Libertarian Party member in New York City who's given up his guns and does nothing to ensure that his rights are defended.
<br>
<br>
The statements I've made here are some of the few political statements that do not violate the natural laws that govern human politics.
<br>
<br>
Rather than relinquish technological advancement, I suggest that pioneers of defensive technologies pursue and distribute their work as far and wide as possible.  How should it be distributed?  It should be distributed to as many of those who have a proven past ability to responsibly control defensive technology, as possible.
<br>
<br>
I would recommend that for instance, a past reliable manufacturer of 50 caliber rifles, would be a better person to trust with this technology than would any higher-up in the department of defense.  Someone who was registered as a Libertarian Party member in 1975 or 1984-90 (the low points of the party's popularity) would be another good choice.  As would nearly anyone smart enough to build the technology itself  (which is the primary reason that this debate will likely be pointless: those smart enough to make the advancements will just advance faster than the rest of us, whether anyone likes it or not).
<br>
<br>
These individuals are the minority that has forsaken power to advance the ideological cause of "Live and Let Live".
<br>
<br>
The very worst thing to do?  Let nature take its course, trusting the "leading force" government to do the right thing.
<br>
<br>
The leadership of the current "Leading Force" (George Bush/USA) sees nothing wrong with the provisions in the "Patriot Act" that deny trial by jury to those accused of being vaguely defined as "terrorists".  So much for the "due process" of a science court chosen by government or military leaders.  Mainstream politicians also see nothing wrong with granting validity to ideas as technologically backwards and demented as the Pope's.
<br>
<br>
By what right does any of this aggregate of irrational humanity make a demand on any rational being that he/she stop working on anything?
<br>
<br>
The technologists need to stop assuming that their antagonists have any valid or legitimate motives.
<br>
<br>
Ayn Rand was one of the first people to note that the anti-technology forces seem to be rebelling against human creativity and production more than anything else.  The probable reasons?  Occam's razor gives them to us: 1) It is easier to destroy than build, and if people give you status for destroying, why not pursue it? 2) Advocating destruction will allocate the power of the producer to you personally, through the misdirection, appropriation, and theft by authoritarian might and 3) If you haven't seen the beauty and complexity that life is capable of, and haven't prepared for, then the level of jealousy you must feel towards those who have must be pretty large -so why should they have more money, reproductive opportunity, comfort, and status than you do?  You want what they have, but there's no reason why you should have it, since you didn't work/think to attain it.  Why not?  Either A) You're not smart enough, B) Nobody helped you in the right direction when you were young (and you didn't overcome being sent in the wrong direction on your own) or C) The productivity is itself a bad thing, and everyone else is wrong for desiring it.
<br>
<br>
The reasons why most Luddites choose option "C" to rationalize their actions is described quite well by Ayn Rand and her legacy here:
<br>
<br>
<a href="http://web.archive.org/web/20090303113422/http://www.aynrand.org/site/PageServer?pagename=media_topic_environmentalism_and_animal_rights" target="_blank">http://www.aynrand.org/site/PageServer?pagename=me  dia_topic_environmentalism_and_animal_rights</a>
<br>
<br>
I wish that most technologists would recognize that politics cannot be avoided through a lack of addressing it.  The luddite masses will not go away, and they are used to solving their problems with force.
<br>
<br>
Please, familiarize yourself with the Libertarian Party Platform, and support Libertarian candidates when they defend your right to innovate.  To do less is to be philosophically divided, and thus easy pickings for the ignorant collective.
<br>
<br>
On the other hand, if the technologists all united around the Libertarian Platform, they would have enough grey matter directed at any election to win it. 
<br>
<a href="http://web.archive.org/web/20090303113422/http://www.lp.org/issues/platform_all.shtml" target="_blank">http://www.lp.org/issues/platform_all.shtml</a>
<br>
Even a cursory attempt to study elections and then win them, on bahalf of libertarian candidates, would pay DRAMATIC dividends to the technology movement.
<br>
<br>
The Luddites have grasped the fact that, since the public is willing to used force, they should control that force if they want to get their way.
<br>
<br>
The Libertarians offer the chance to render that force of collective ignorance impotent in its ability to destroy.
<br>
<br>
Keep in mind that this is not an argument for destroying the Luddites (even though they've proven they'd happily destroy us).  This is an argument in favor of disarming their offensive against us (organized anti-technology government forces), while allowing them to keep their defensive weaponry (their own small arms/equal nanotech/equal AI augmentation).
<br>
<br>
Causing dramatic Libertarian/educational victories in the political arena would likely prevent mass defensive/offensive bloodshed later.
<br>
<br>
Why?
<br>
<br>
Because tolerance of different paths is central to the enjoyment of life for all.
<br>
<br>
The luddites assume that something that lives forever and is vastly intelligent is a threat.  Why?  No threat has been implied by this statement.  A vast intelligence would likely repair in us that which breaks, rather than break it.
<br>
<br>
It seems vastly more likely that the artilects will treat unmodified humans like we treat dogs.  We give them what they want, treat them with kindness, take them to the vet and cure their illnesses.  Extend their lives as long as possible.  The extent to which they suffer is the extent to which we fail to control our own world.  The artilects would likely be less limited in their graces than are we.
<br>
<br>
That might be better than what we have now.
<br>
<br>
Infinitely better than what we have now would be for us to advance with the artilects themselves, exchanging value for value the whole way.
<br>
<br>
The more uncoerced good choices we have, the better.
<br>
<br>
Obviously.
<br>
<br>
-Jake</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id40100"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Embrace, Don't Relinquish, the Future<br><span class="mindxheader"><i>posted on 06/12/2005 4:25 PM by <a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/profile.php?id=471">eldras</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id40100" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D40100" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>but whatever the psychological reason for 'ludditism' we need to look at the enormous power of coming technologoes, especially computing and and deal with detailed ways to make it safe.
<br>
<br>
<br>
It's no good waking up one morning and billions of pc's have gone awol and dug themselves into the earth somewhere in australia refusing to negotiate with us :)
<br>
<br>
<br>
I think Bill Joy and Steve Hawking  and others are right to urge a public safety debate on A.I.
<br>
<br>
<br>
There is a real issue of genocidal consequences here and parliaments shpuld be lobbied to draft safety legislation WITHOUR impeding prgress.
<br>
<br>
<br>
Eldras</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id40247"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Embrace, Don't Ruin, the Future<br><span class="mindxheader"><i>posted on 06/15/2005 1:34 PM by <a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/profile.php?id=1973">Jake Witmer</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id40247" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D40247" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p> <center><p class="mindxquote"> There is a real issue of genocidal consequences here and parliaments should be lobbied to draft safety legislation WITHOUT impeding prgress.  </p></center>
<br>
Of course, if they draft safety legislation, it will impede progress, whether you like it or not.
<br>
<br>
There's ALWAYS the chance of democide resulting from the actions of government though.  Nanotechnology is just as (or more) likely to decrease the odds of  democide as it is to increase them.  Also, the potential benefit of millions of people living longer lives is the most reasonable use of nanotechnology, with or without government intervention.  (I use the more accurate word democide for "mass murder by government, during peacetime" rather than genocide which indicates that the killing has to be guided along race lines -see RJ Rummel's website, "The Democratic Peace" at <a href="http://web.archive.org/web/20090303113422/http://www.hawaii.edu/powerkills" target="_blank">http://www.hawaii.edu/powerkills</a> )
<br>
<br>
We are more likely to be killed by a government that can easily manipulate a mass of poor, unhealthy, stupid opposing mobs, than we are by a post-singularity government that has healthier and wealthier citizens.
<br>
<br>
Our government is also currently encouraging an inflationary crash of our money system, through deficit spending.  See <a href="http://web.archive.org/web/20090303113422/http://www.harrybrowne.com/" target="_blank">http://www.harrybrowne.com</a> or read "The Coming Collapse of the Dollar and How You Can Profit From It" by Turk and Rubino.  This dramatically increases the likelihood of mass murder/dictatorship during peacetime.
<br>
<br>
Our citizenry has already turned their backs on nearly every limitation on government power that was originally built into our system.  Jury nullification of law, free speech, etc...  But most people blindly think government is just a way for them to get what they want.
<br>
<br>
How, pray tell, will Congress or Parliament, being lobbied by the ignorant masses, use their only tool (brute force or its threat) to forestall supposedly unconstructive developement of nanotechnology?  They can't.  First, they themselves are probably dumber than a boot, and hence decided to enter a career of "deciding how to steal and spend money that isn't theirs, in order to coerce people to act against their wishes (which often line up perfectly with everyone's best interest)".  Second, it won't even be someone as smart as Kurweil (or even the Unabomber for that matter) whose advice they'll be taking --it'll be advice from a mob full of lowest-common-denominators.  Third, even if the advice was good (which it won't be), the legislators couldn't do a damn thing but shift the research money being spent to illegal channels, adding the cost of leaving the US to the already great cost of doing business.  Fourth, the language of the bill will then have to be interpreted by a horde of lawyers who know exactly how to prey on the stupidity of (judge and prosecution) hand-picked jurors (and sometimes by regulatory prosecutors who don't even need to worry about jurors, because the threat of a regulatory "civil" fine can force an out-of-court extortion settlement if they want to).
<br>
<br>
Put simply:  If you aren't smart enough to build nanotechnology yourself, don't go screwing things up for those who are, unless you're damned sure that they're working for Al Qaeda.  (And if that's the case, there are already a million laws already on the books that are adequate to deal with the threat.)  The only thing that government ever does is slow everything down, get in the way, and push formerly honest citizens into new black markets.  (Of course, existing criminals also take advantage of new black markets created by govenment intervention - I was oversimplifying.)
<br>
<br>
The single greatest non-natural threat to humans is government intervention or its threat (if you include the cost of regulation).
<br>
<a href="http://web.archive.org/web/20090303113422/http://www.hawaii.edu/powerkills/VIS.TEARS.ALL.AROUND.HTM" target="_blank">http://www.hawaii.edu/powerkills/VIS.TEARS.ALL.ARO  UND.HTM</a>
<br>
<br>
If Kurzweil really wants to move technology forward, he should run for President as a Libertarian.  (Actually, with the web traffic he gets here, and what <a href="http://web.archive.org/web/20090303113422/http://www.lp.org/" target="_blank">http://www.lp.org</a> gets during a presidential year, that would probably be a mutually beneficial thing... he'd likely sell at least another 100,000 books.  Of course, there are only vague hints as to what his politics are - although he uses a differently-weighted version of Ayn Rand's comment on death and taxes in his 'Fantastic Voyage' book)
<br>
<br>
We'd already be living to 500 if it wasn't for the taxes, AMA, and FDA.  Before you shrug this idea off, imagine if the wealth of the nation was nearly doubled (no IRS or regulatory licenses, etc...), and any health invention could be instantly introduced to the market, without regulatory cost.  Keep in mind the thousands of heart patients killed by the FDA ban on propranalol alone (prior to its approval).  See:
<br>
<a href="http://web.archive.org/web/20090303113422/http://www.fdareview.org/incentives.shtml" target="_blank">http://www.FDAReview.org/incentives.shtml</a>
<br>
<a href="http://web.archive.org/web/20090303113422/http://www.fdareview.org/harm.shtml" target="_blank">http://www.FDAReview.org/harm.shtml</a>
<br>
<br>
The above isn't proof, but its a good first step towards taking adequate responsiblity for your vote.  (The more responsiblity one takes for their vote, the further they generally move from believing that government force is a good way to solve problems  -unless they're evil.)
<br>
<br>
PostScript...  Nanotechnologists: consider relocating to Costa Rica (or Alaska if you don't want to leave the States).  Cost Rica just elected 10% of their parlaiment as Libertarian.  <a href="http://web.archive.org/web/20090303113422/http://www.libertario.org/" target="_blank">http://www.libertario.org</a>  -With even a little bit of extra help, they could create a better version of the USA there.  Consider this: If 3/4 of their congress and their president are libertarian, then it will be more capitalist than Hong Kong was, and it will be a mecca for new industry.  If you have money, and you want to eliminate government obstacles to freedom, they've got a credit card contribution page on their website.  They'd be a good example to use here regarding what could and should be.  They also know what they're doing, because they accomplished their previous electoral victories with nearly no outside money.
<br>
<br>
The reason I included AK as an alternative is because there is a large unincorporated area here that pays no taxes.  Also, there are lots of libertarians here, even if they are too underfunded to win big political races.  Plus, it's be better to introduce your single vote into a State that only has ~600,000 voters rather than 3,000,000+ voters, and you only need to live here during the summer and own property to vote here (Although technically they can't legally disenfranchise the homeless if you're willing to make that claim for voting purposes).
<br>
<br>
-Jake</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id40289"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Embrace, Don't Ruin, the Future<br><span class="mindxheader"><i>posted on 06/16/2005 11:06 AM by <a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/profile.php?id=1090">FarmerGene</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id40289" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D40289" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>
<br>
"We'd already be living to 500 if it wasn't for the taxes, AMA, and FDA. Before you shrug this idea off, imagine if the wealth of the nation was nearly doubled (no IRS or regulatory licenses, etc...),"
<br>
<br>
Most people are not capable of conceiving of how much better off they would be with little or no government. 
<br>
<br>
After reading Rummel's 'Death by Government' I wondered if someone would write a book encompassing democide, the destruction of property through wars, the losses occurring because of taxes and regulations (taxes should be subtracted from GDP), and deaths from wars. It boggles the mind to understand how anti-life and anti-progress government really is.
<br>
<br>
"Cost Rica just elected 10% of their parlaiment as Libertarian. <a href="http://web.archive.org/web/20090303113422/http://www.libertario.org/" target="_blank">http://www.libertario.org</a> "
<br>
<br>
Costa Rica, the Switzerland of Central America. Beautiful country. Is the Limon Project still going?</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id40293"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="80"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="599"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Embrace, Don't Ruin, the Future<br><span class="mindxheader"><i>posted on 06/16/2005 11:47 AM by <a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/profile.php?id=1090">FarmerGene</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id40293" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D40293" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>
<br>
Jake, could you write that book?
<br>
<br>
Joe</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id40319"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="100"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="579"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Embrace, Don't Ruin, the Future<br><span class="mindxheader"><i>posted on 06/16/2005 3:18 PM by <a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/profile.php?id=1973">Jake Witmer</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id40319" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D40319" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Thanks for the positive feedback.  To be honest, I was bracing myself to find out that most of the big-brains here on the board are socialist/communist/collectivist, or some such.  -Perhaps they are, and I'm in for a letdown.
<br>
<br>
I'm writing a book about what I know right now, and there may well be a chapter that notes how destructive government is, from several sources.  Unfortunately, there is little I could do to expand on the immense body of work that's already been written on the subject of the costs of government.  Rummel's website is the best one I know, because he reduces outside debate to just the things everyone can agree on, ie: enforced starvation and mass murder in the streets is a BAD THING.  Even here, he loses "earnest" green party supporters and die-hard collectivists who refuse to see the obvious.
<br>
<br>
The Cato Institute doesn't assume individual rights as obvious, and tries to find pragmatic justifications for defending freedom.  They try to put a "friendly face" on freedom.  The trouble is: That this is what is necessary in America today.
<br>
<br>
The Americans of today are not the strong-willed people who created this country.  They have a hard time understanding why they should assume responsibility for something as basic as their personal self-defense.  Much less why free trade, open immigration, and other 'abstract concepts' are worth defending.
<br>
<br>
The point of all of this is to say that my efforts could be better spent actually organizing towards individual freedom in Alaska and other potential freedom hot-spots.  My book will be about the realities of organizing a local pro-freedom movement in an unfree area (which Alaska is, even though it is much better than the lower 49).
<br>
<br>
Unfortunately I likely won't be able to respond to these posts again until late July, as I will be trying the local approach in certain areas of Arizona and won't have much time.  If you really want to discuss ways that one can be more effective in moving towards freedom, it's not a book that cannot talk and answer individual objections that people have.  Everyone has a reason why freedom won't or can't work, or a "way of pursuing freedom" that is ineffective and doesn't require much personal effort.  If you want to help me move the cause of freedom forward, email me, and I will email you my phone number. jcwitmer at hotmail.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id41797"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="120"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="559"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Embrace, Don't Ruin, the Future<br><span class="mindxheader"><i>posted on 06/30/2005 12:30 AM by <a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/profile.php?id=471">eldras</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id41797" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D41797" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>july's good.
<br>
<br>
I find knwoledge exhange great and it will reduce to perfect/near perfect laws like physics.
<br>
<br>
I think finance is a phase humans are going through but it wont last post singularity</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id47719"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="140"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="539"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Embrace, Don't Ruin, the Future<br><span class="mindxheader"><i>posted on 09/19/2005 1:58 AM by <a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/profile.php?id=1973">Jake Witmer</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D2253%23id47719" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090303113422/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D47719" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Sorry: It's a little past July, and I'm on a shared computer, traveling.
<br>
<br>
I think there'll be finance post-singularity, it just won't usually be 'life or death'.  There will always be more intelligent, creative, attractive, etc... people/things/robots.  People will still strive for different things, and they'll still want to be with things they can't take to the more-malleable frontier, wherever that is.
<br>
<br>
-J</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090303113422im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>