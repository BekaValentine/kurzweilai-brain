<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>How Long Before Superintelligence?</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20080512152111im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20080512152111im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20080512152111im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20080512152111im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20080512152111im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20080512152111im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20080512152111/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20080512152111/http://www.kurzweilai.net/meme/memelist.html?m=4">Will Machines Become Conscious?</a> &gt; 
How Long Before Superintelligence?
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20080512152111/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0168.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0168.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20080512152111/http://www.kurzweilai.net/articles/art0168.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20080512152111im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">How Long Before Superintelligence?</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20080512152111/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0051.html" target="_top">Nick Bostrom</a><br></span></td>
</table>
<br>
<div class="TeaserText">This paper outlines the case for believing that we will have superhuman artificial intelligence within this century. It looks at different estimates of the processing power of the human brain; how long it will take until computer hardware achieve a similar performance; ways of creating the software through bottom-up approaches like the one used by biological brains; how difficult it will be neuroscience figure out enough about how brains work to make this approach work; and how fast we can expect superintelligence to be developed once there is human-level artificial intelligence.</div>
<br>
<br><span class="AuthorAffiliation">Department of <a class="thought" href="entries/philosophy_entry.html">Philosophy</a>, <a class="thought" href="entries/logic_entry.html">Logic</a> and Scientific Method, London School of <a class="thought" href="entries/economics_entry.html">Economics</a></span>
<br>
<br>
<p>Originally published 1997. Version with revision <a class="thought" href="entries/history_entry.html">history</a> can be found <a href="http://web.archive.org/web/20080512152111/http://www.nickbostrom.com/superintelligence.html" target="_new">here</a>. Published on KurzweilAI.net April 30, 2001.</p><h1><b>Definition of "<a class="thought" href="entries/superintelligence_entry.html">superintelligence</a>"</b></h1><p>By a "<a class="thought" href="entries/superintelligence_entry.html">superintelligence</a>" we mean an intellect that is much smarter than the best <a class="thought" href="entries/human_entry.html">human</a> brains in practically every field, including scientific <a class="thought" href="entries/creativity_entry.html">creativity</a>, general <a class="thought" href="entries/wisdom_entry.html">wisdom</a> and social skills. This definition leaves open how the <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a> is implemented: it could be a <a class="thought" href="entries/digital_entry.html">digital</a> <a class="thought" href="entries/computer_entry.html">computer</a>, an ensemble of <a class="thought" href="entries/network_entry.html">network</a>ed <a class="thought" href="entries/computer_entry.html">computer</a>s, cultured cortical tissue or what have you. It also leaves open whether the <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a> is conscious and has <a class="thought" href="entries/subjective_experience_entry.html">subjective experience</a>s.</p>
<p>Entities such as companies or the scientific community are not <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a>s according to this definition. Although they can perform a number of tasks of which no individual <a class="thought" href="entries/human_entry.html">human</a> is capable, they are not intellects and there are many fields in which they perform much worse than a <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> - for example, you can't have real-<a class="thought" href="entries/time_entry.html">time</a> conversation with "the scientific community".</p><h1><a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a><b> and present <a class="thought" href="entries/supercomputer_entry.html">supercomputer</a>s</b></h1><p><a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> states that processor speed doubles every eighteen months. The doubling <a class="thought" href="entries/time_entry.html">time</a> used to be two years, but that changed about fifteen years ago. The most recent <a class="thought" href="entries/data_entry.html">data</a> points indicate a doubling <a class="thought" href="entries/time_entry.html">time</a> as short as twelve months. This would mean that there will be a thousand-fold increase in <a class="thought" href="entries/computation_entry.html">computation</a>al power in ten years. <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> is what <a class="thought" href="entries/chip_entry.html">chip</a> manufacturers rely on when they decide what sort of <a class="thought" href="entries/chip_entry.html">chip</a> to develop in <a class="thought" href="entries/order_entry.html">order</a> to remain competitive.</p>
<p>If we estimate the <a class="thought" href="entries/computation_entry.html">computation</a>al capacity of the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a>, and allow ourselves to extrapolate available processor speed according to <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> (whether doing so is permissible will be discussed shortly), we can calculate how long it will take before <a class="thought" href="entries/computer_entry.html">computer</a>s have sufficient raw power to match a <a class="thought" href="entries/human_entry.html">human</a> intellect.</p>
<p>The fastest <a class="thought" href="entries/supercomputer_entry.html">supercomputer</a> today (December 1997) is 1.5 Terraops, 1.5*10<sup>12</sup> ops. There is a project that aims to extract 10 Terraops from the <a class="thought" href="entries/internet_entry.html">Internet</a> by having a hundred thousand volunteers install a <a class="thought" href="entries/screen_saver_entry.html">screen saver</a> on their <a class="thought" href="entries/computer_entry.html">computer</a>s that would allow a central <a class="thought" href="entries/computer_entry.html">computer</a> to delegate some <a class="thought" href="entries/computation_entry.html">computation</a>al tasks to them. This (so-called metacomputing) approach works best for tasks that are very easy to parallelize, such as doing an exhaustive journey though <a class="thought" href="entries/search_entry.html">search</a> <a class="thought" href="entries/space_entry.html">space</a> in attempting to break a <a class="thought" href="entries/code_entry.html">code</a>. With better <a class="thought" href="entries/bandwidth_entry.html">bandwidth</a> connections in the <a class="thought" href="entries/future_entry.html">future</a> (e.g. optical fibers), large-scale metacomputing will work even better than today. <a class="thought" href="entries/brain_entry.html">Brain</a> simulations should by their <a class="thought" href="entries/nature_entry.html">nature</a> be relatively easy to parallelize, so maybe huge <a class="thought" href="entries/brain_entry.html">brain</a> simulations distributed over the <a class="thought" href="entries/internet_entry.html">Internet</a> could be a feasible alternative in the <a class="thought" href="entries/future_entry.html">future</a>. We shall however disregard this possibility for present purposes and regard the 1.5 Tops <a class="thought" href="entries/machine_entry.html">machine</a> as the best we can do today. The potential of metacomputing can be factored into our prognosis by viewing it as an additional <a class="thought" href="entries/reason_entry.html">reason</a> to believe that available computing power will continue to grow as <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> predicts.</p>
<p>Even without any <a class="thought" href="entries/technology_entry.html">technology</a> improvement we can do somewhat better than, for example by doubling the number of chips that we put in the box. A 3 Tops <a class="thought" href="entries/computer_entry.html">computer</a> has been ordered by the US <a class="thought" href="entries/government_entry.html">government</a> to be used in testing and developing the nation's stock pile of nuclear weapons. However, considering that the cost of this <a class="thought" href="entries/machine_entry.html">machine</a> is $94,000,000, it is clear that even massive extra funding would only yield a very modest increase in computing power in the short term.</p>
<p>How good grounds are there to believe that <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> will continue to hold in the <a class="thought" href="entries/future_entry.html">future</a>? It is clear that sooner or later it must fail. There are physical limitations on the density with which <a class="thought" href="entries/matter_entry.html">matter</a> can store and process <a class="thought" href="entries/information_entry.html">information</a>. The Bekenstein bound gives an upper limit on the amount of <a class="thought" href="entries/information_entry.html">information</a> that can be contained within any given volume using a given amount of <a class="thought" href="entries/energy_entry.html">energy</a>. Since <a class="thought" href="entries/space_entry.html">space</a> colonization would allow at most a polynomial (~t<sup>3</sup>) expansion rate (assuming expansion rate is bounded by the speed of <a class="thought" href="entries/light_entry.html">light</a>), the exponential increase of available <a class="thought" href="entries/computation_entry.html">computation</a>al power cannot be continued indefinitely, unless new <a class="thought" href="entries/physics_entry.html">physics</a> is forthcoming.</p>
<p>In my opinion, <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> loses its credibility long before we reach absolute physical limits. It probably hasn't got much predictive power beyond, say, the next fifteen years. That is not to say that processor speed will not continue to double every twelve or eighteen months after 2012; only that we cannot use <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> to argue that it will. Instead, if we want to make predictions beyond that date, we will have to look directly at what is physically feasible. That will presumably also mean that we have to contend ourselves with a greater uncertainty interval along the <a class="thought" href="entries/time_entry.html">time</a> axis. Physical feasibility studies tell us, at best, what will happen given that people want it to happen; but even if we assume that the demand is there, it will still not tell us when it will happen.</p>
<p>In about the year 2007 we will have reached the physical limit of present <a class="thought" href="entries/silicon_entry.html">silicon</a> <a class="thought" href="entries/technology_entry.html">technology</a>. <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a>, however, has survived several technological phase transitions before, from relays to <a class="thought" href="entries/vacuum_tube_entry.html">vacuum tube</a>s to <a class="thought" href="entries/transistor_entry.html">transistor</a>s to <a class="thought" href="entries/integrated_circuit_entry.html">integrated circuit</a>s to Very Large Scale <a class="thought" href="entries/integrated_circuit_entry.html">Integrated circuit</a>s (<a class="thought" href="entries/vlsi_entry.html">VLSI</a>). There is no <a class="thought" href="entries/reason_entry.html">reason</a> why present <a class="thought" href="entries/vlsi_entry.html">VLSI</a> designs on two-dimensional <a class="thought" href="entries/silicon_entry.html">silicon</a> wafers should be the last word in <a class="thought" href="entries/chip_entry.html">chip</a> <a class="thought" href="entries/technology_entry.html">technology</a>. Several ways to overcome the limits of the present <a class="thought" href="entries/technology_entry.html">technology</a> have been proposed and are being developed.</p>
<p>In the near <a class="thought" href="entries/future_entry.html">future</a>, it might for example be possible to use phase shift masks to push the minimum <a class="thought" href="entries/circuit_entry.html">circuit</a>-line width on a microchip down to as little as 0.13 micrometer, even while remaining in the optical range with the lithographic irradiation. Leaving the optical range, we could use x-rays or at least extreme ultraviolet ("EUV", also called "soft x-rays") to attain still finer precision. Failing this, it should be feasible to use <a class="thought" href="entries/electron_entry.html">electron</a> bean writing, although this production method would be slow and hence expensive. A compromise would be to write some of the gates with an <a class="thought" href="entries/electron_entry.html">electron</a> beam, especially at bottlenecks where speed is absolutely crucial, and use optical or EUV to write the other <a class="thought" href="entries/element_entry.html">element</a>s of the <a class="thought" href="entries/chip_entry.html">chip</a>.</p>
<p>We can also increase the power of a <a class="thought" href="entries/chip_entry.html">chip</a> by using more layers, a technique that has only recently been mastered, and by making bigger wafers (up to 300 mm should not be a problem). Drastically bigger chips could be manufactured if there were some error tolerance. Tolerance to error could be obtained by using evolvable <a class="thought" href="entries/hardware_entry.html">hardware</a>.</p>
<p>It is also possible to push the physical limits on how small the <a class="thought" href="entries/transistor_entry.html">transistor</a>s can be made by <a class="thought" href="entries/switch_entry.html">switch</a>ing to new materials, such as Gallium Arsenide. Quantum <a class="thought" href="entries/transistor_entry.html">transistor</a>s are presently being developed, promising a major step forward for <a class="thought" href="entries/circuit_entry.html">circuit</a>ry where high <a class="thought" href="entries/switch_entry.html">switch</a>ing speed or low <a class="thought" href="entries/energy_entry.html">energy</a> consumption is essential.</p>
<p>Because of the highly parallel <a class="thought" href="entries/nature_entry.html">nature</a> of <a class="thought" href="entries/brain_entry.html">brain</a>-like <a class="thought" href="entries/computation_entry.html">computation</a>s, it should also be possible to use a highly parallel <a class="thought" href="entries/architecture_entry.html">architecture</a>, in which case it will suffice to produce a great number of moderately fast processors, and have then have them connected. You could either put them in the same box which would give you a bus-based multiprocessor (which are quite popular today) or you could link them up to a high-<a class="thought" href="entries/bandwidth_entry.html">bandwidth</a> local-area <a class="thought" href="entries/network_entry.html">network</a> (an option that will be increasingly attractive as the performance of standard <a class="thought" href="entries/network_entry.html">network</a>ing <a class="thought" href="entries/technology_entry.html">technology</a> improves). &lt;B&gt;</p>
<p>These are all things that are being developed today. Massive funding is pumped into these technologies &lt;C&gt;. Although the difficulties can appear staggering to a person working in the field, who is constantly focused on the immediate problems, it is fair to say that there is widespread <a class="thought" href="entries/optimism_entry.html">optimism</a> among the experts that the prospects are good that <a class="thought" href="entries/computer_entry.html">computer</a>s will continue to grow more powerful for the foreseeable <a class="thought" href="entries/future_entry.html">future</a>.</p><h1>Notes</h1><p>&lt;A&gt; It is not clear what, exactly, <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> says. The law derives its name from <a class="thought" href="entries/moore_entry.html">Gordon Moore</a>, co-founder of Intel Corp., who back in 1965 noted that microchips were doubling in <a class="thought" href="entries/circuit_entry.html">circuit</a> density every year. In 1975 he made the prediction that from then on, the doubling <a class="thought" href="entries/time_entry.html">time</a> would be two years. The actual doubling <a class="thought" href="entries/time_entry.html">time</a> has fluctuated a <a class="thought" href="entries/bit_entry.html">bit</a>, starting at one year, going up to two years, and is now back to approximately one year again. So one ambiguity in citing <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> is that it is unclear whether the <a class="thought" href="entries/time_entry.html">time</a> constant is supposed to be one year, two years, or whether it is supposed to be whatever the most recent <a class="thought" href="entries/data_entry.html">data</a> points indicate. A second ambiguity resides in the fact that the initial statement was phrased in terms of the number on <a class="thought" href="entries/transistor_entry.html">transistor</a>s that could be fitted into an area unit, rather than in terms of the speed of the resulting <a class="thought" href="entries/chip_entry.html">chip</a>. Until now, this distinction hasn't <a class="thought" href="entries/matter_entry.html">matter</a>ed much, because <a class="thought" href="entries/circuit_entry.html">circuit</a>ry density and speed have been highly correlated. When we look to the <a class="thought" href="entries/future_entry.html">future</a>, however, it is possible that we will achieve increased computing power by other means than by making <a class="thought" href="entries/transistor_entry.html">transistor</a>s smaller. It therefore makes <a class="thought" href="entries/sense_entry.html">sense</a> to reformulate <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> into a statement asserting an <a class="thought" href="entries/exponential_growth_entry.html">exponential growth</a> in computing power (per <a class="thought" href="entries/inflation_entry.html">inflation</a>-adjusted dollar) rather than <a class="thought" href="entries/chip_entry.html">chip</a> density. It is better to apply the label "<a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a>" to this slightly modified hypothesis than to invent a new term for what is basically the same idea.</p>
<p>&lt;B&gt; In the longer term, we also have to consider molecular <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> and maybe <a class="thought" href="entries/quantum_computing_entry.html">quantum computing</a>.</p>
<p>&lt;C&gt; It nowadays takes about 400 <a class="thought" href="entries/engine_entry.html">engine</a>ers to produce a new <a class="thought" href="entries/chip_entry.html">chip</a>. A modern <a class="thought" href="entries/chip_entry.html">chip</a> factory may cost over $2 billion. About $20 to $30 billion is spent on microchip R&amp;D every years. These figures have grown over the years, so it should be pointed out that one factor that could slow the pace of development would be if funding begins to level out, as it sooner or later will.</p><h1><a class="thought" href="entries/hardware_entry.html">Hardware</a><b> requirements</b></h1><p>The <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> contains about 10<sup>11</sup> <a class="thought" href="entries/neuron_entry.html">neuron</a>s. Each <a class="thought" href="entries/neuron_entry.html">neuron</a> has about 5*10<sup>3</sup> <a class="thought" href="entries/synapse_entry.html">synapse</a>s, and signals are transmitted along these <a class="thought" href="entries/synapse_entry.html">synapse</a>s at an average frequency of about 10<sup>2</sup> Hz. Each signal contains, say, 5 bits. This equals 10<sup>17</sup> ops.&lt;A&gt;</p>
<p>The true value cannot be much higher than this, but it might be much lower. There seems to be great redundancy in the brain; synchronous firing of large pools of <a class="thought" href="entries/neuron_entry.html">neuron</a>s is often required if the signal is not to drown in the general <a class="thought" href="entries/noise_entry.html">noise</a>. An alternative way of calculating the total capacity is to consider some part of the cortex that performs a function that we know how to replicate on <a class="thought" href="entries/digital_entry.html">digital</a> <a class="thought" href="entries/computer_entry.html">computer</a>s. We calculate the average <a class="thought" href="entries/computer_entry.html">computer</a>-equivalent processing capacity of a single <a class="thought" href="entries/neuron_entry.html">neuron</a> in that cortical area, and multiply this value with the number of <a class="thought" href="entries/neuron_entry.html">neuron</a>s in the <a class="thought" href="entries/brain_entry.html">brain</a>. <a class="thought" href="entries/moravec_entry.html">Hans Moravec</a> has done this calculation using <a class="thought" href="entries/data_entry.html">data</a> about the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/retina_entry.html">retina</a> (<a href="http://web.archive.org/web/20080512152111/http://www.frc.ri.cmu.edu/~hpm/book97/ch3/retina.comment.html" target="_new">Moravec 1997</a>) and compared it with known <a class="thought" href="entries/computation_entry.html">computation</a>al demands of edge extraction in <a class="thought" href="entries/robot_entry.html">robot</a> vision. He got the value 10<sup>14</sup> ops for the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> as a whole. That is three orders of magnitude less than the upper bound calculated by assuming that there is no redundancy.</p>
<p>It is hard to see any <a class="thought" href="entries/reason_entry.html">reason</a> to suppose that the redundancy in the <a class="thought" href="entries/retina_entry.html">retina</a> should be greater than in the cortex. If anything, one would rather expect it to be the other way around, since edge extraction is more low-level task than higher cognitive processes and therefore presumably more optimized (by <a class="thought" href="entries/evolution_entry.html">evolution</a> and individual <a class="thought" href="entries/learning_entry.html">learning</a>).</p>
<p>If we need 100 Tops to simulate the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> then the required <a class="thought" href="entries/computation_entry.html">computation</a>al power will be reached sometime between 2004 and 2008, depending on whether we assume a doubling <a class="thought" href="entries/time_entry.html">time</a> of 12 or 18 months. This would be the best experimental <a class="thought" href="entries/supercomputer_entry.html">supercomputer</a>s in the world, not necessarily the <a class="thought" href="entries/computer_entry.html">computer</a>s available to <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a>ers. Depending on how much funding is forthcoming, it might take up to an additional decade before <a class="thought" href="entries/research_entry.html">research</a>ers experimenting with general <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> have <a class="thought" href="entries/access_entry.html">access</a> to <a class="thought" href="entries/machine_entry.html">machine</a>s with this capacity.</p>
<p>This is if we take the <a class="thought" href="entries/retina_entry.html">retina</a> simulation as a model. As the present, however, not enough is known about the neocortex to allow us to simulate it in such an optimized way. But the <a class="thought" href="entries/knowledge_entry.html">knowledge</a> might be available by 2004 to 2008 (as we shall see in the next section). What is required, if we are to get <a class="thought" href="entries/human_entry.html">human</a>-level <a class="thought" href="entries/ai_entry.html">AI</a> with <a class="thought" href="entries/hardware_entry.html">hardware</a> power at this lower bound, is the ability to simulate 1000-<a class="thought" href="entries/neuron_entry.html">neuron</a> aggregates in a highly efficient way.</p>
<p>The extreme alternative, which is what we assumed in the derivation of the upper bound, is to simulate each <a class="thought" href="entries/neuron_entry.html">neuron</a> individually. The number of clock cycles that neuroscientists can expend simulating the processes of a single <a class="thought" href="entries/neuron_entry.html">neuron</a> knows of no limits, but that is because their aim is to model the detailed chemical and electrodynamic processes in the <a class="thought" href="entries/nerve_entry.html">nerve</a> <a class="thought" href="entries/cell_entry.html">cell</a> rather than to just do the minimal amount of <a class="thought" href="entries/computation_entry.html">computation</a> necessary to replicate those features of its response function which are relevant for the total performance of the neural net. It is not known how much of the detail that is contingent and inessential and how much needs to be preserved in <a class="thought" href="entries/order_entry.html">order</a> for the simulation to replicate the performance of the whole. It seems like a good bet though, at least to the author, that the nodes could be strongly simplified and replaced with simple standardized <a class="thought" href="entries/element_entry.html">element</a>s. It appears perfectly feasible to have an intelligent <a class="thought" href="entries/neural_network_entry.html">neural network</a> with any of a large variety of <a class="thought" href="entries/neuron_entry.html">neuron</a>al output functions and <a class="thought" href="entries/time_entry.html">time</a> delays.</p>
<p>It does look plausible, however, that by the <a class="thought" href="entries/time_entry.html">time</a> when we know how to simulate an idealized <a class="thought" href="entries/neuron_entry.html">neuron</a> and know enough about the <a class="thought" href="entries/brain_entry.html">brain</a>'s synaptic structure that we can put the artificial <a class="thought" href="entries/neuron_entry.html">neuron</a>s together in a way that functionally mirrors how it is done in the <a class="thought" href="entries/brain_entry.html">brain</a>, then we will also be able to replace whole 1000-<a class="thought" href="entries/neuron_entry.html">neuron</a> modules with something that requires less <a class="thought" href="entries/computation_entry.html">computation</a>al power to simulate than it does to simulate all the <a class="thought" href="entries/neuron_entry.html">neuron</a> in the module individually. We might well get all the way down to a mere 1000 instructions per <a class="thought" href="entries/neuron_entry.html">neuron</a> and second, as is implied by Moravec's estimate (10<sup>14</sup> ops / 10<sup>11</sup> <a class="thought" href="entries/neuron_entry.html">neuron</a>s = 1000 operations per second and <a class="thought" href="entries/neuron_entry.html">neuron</a>). But unless we can build these modules without first building a whole <a class="thought" href="entries/brain_entry.html">brain</a> then this optimization will only be possible after we have already developed <a class="thought" href="entries/human_entry.html">human</a>-equivalent <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>.</p>
<p>If we assume the upper bound on the <a class="thought" href="entries/computation_entry.html">computation</a>al power needed to simulate the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a>, i.e. if we assume enough power to simulate each <a class="thought" href="entries/neuron_entry.html">neuron</a> individually (10<sup>17</sup> ops), then <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> says that we will have to wait until about 2015 or 2024 (for doubling times of 12 and 18 months, respectively) before <a class="thought" href="entries/supercomputer_entry.html">supercomputer</a>s with the requisite performance are at hand. But if by then we know how to do the simulation on the level of individual <a class="thought" href="entries/neuron_entry.html">neuron</a>s, we will presumably also have figured out how to make at least some optimizations, so we could probably adjust these upper bounds a <a class="thought" href="entries/bit_entry.html">bit</a> downwards.</p>
<p>So far I have been talking only of processor speed, but <a class="thought" href="entries/computer_entry.html">computer</a>s need a great deal of <a class="thought" href="entries/memory_entry.html">memory</a> too if they are to replicate the <a class="thought" href="entries/brain_entry.html">brain</a>'s performance. Throughout the <a class="thought" href="entries/history_entry.html">history</a> of <a class="thought" href="entries/computer_entry.html">computer</a>s, the ratio between <a class="thought" href="entries/memory_entry.html">memory</a> and speed has remained more or less constant at about 1 <a class="thought" href="entries/byte_entry.html">byte</a>/ops. Since a signal is transmitted along a <a class="thought" href="entries/synapse_entry.html">synapse</a>, on average, with a frequency of about 100 Hz and since its <a class="thought" href="entries/memory_entry.html">memory</a> capacity is probably less than 100 bytes (1 <a class="thought" href="entries/byte_entry.html">byte</a> looks like a more <a class="thought" href="entries/reason_entry.html">reason</a>able estimate), it seems that speed rather than <a class="thought" href="entries/memory_entry.html">memory</a> would be the bottleneck in <a class="thought" href="entries/brain_entry.html">brain</a> simulations on the <a class="thought" href="entries/neuron_entry.html">neuron</a>al level. (If we instead assume that we can achieve a thousand-fold leverage in our simulation speed as assumed in Moravec's estimate, then that would bring the requirement of speed down, perhaps, one <a class="thought" href="entries/order_entry.html">order</a> of magnitude below the <a class="thought" href="entries/memory_entry.html">memory</a> requirement. But if we can optimize away three orders of magnitude on speed by simulating 1000-<a class="thought" href="entries/neuron_entry.html">neuron</a> aggregates, we will probably be able to cut away at least one <a class="thought" href="entries/order_entry.html">order</a> of magnitude of the <a class="thought" href="entries/memory_entry.html">memory</a> requirement. Thus the difficulty of building enough <a class="thought" href="entries/memory_entry.html">memory</a> may be significantly smaller, and is almost certainly not significantly greater, than the difficulty of building a processor that is fast enough. We can therefore focus on speed as the critical parameter on the <a class="thought" href="entries/hardware_entry.html">hardware</a> front.)</p>
<p>This paper does not discuss the possibility that quantum phenomena are irreducibly involved in <a class="thought" href="entries/human_entry.html">human</a> cognition. <a href="http://web.archive.org/web/20080512152111/http://psyche.cs.monash.edu.au/psyche-index-v2.html" target="_new">Hameroff and Penrose</a> and others have suggested that coherent quantum states may exist in the microtubules, and that the <a class="thought" href="entries/brain_entry.html">brain</a> utilizes these phenomena to perform high-level cognitive feats. The author's opinion is that this is implausible. The controversy surrounding this issue won't be entered into here; it will simply be assumed, throughout this paper, that quantum phenomena are not functionally relevant to high-level <a class="thought" href="entries/brain_entry.html">brain</a> modeling.</p>
<p>In conclusion we can say that the <a class="thought" href="entries/hardware_entry.html">hardware</a> capacity for <a class="thought" href="entries/human_entry.html">human</a>-equivalent <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> will likely exist before the end of the first quater of the next century, and may be reached as early as 2004. A corresponding capacity should be available to leading <a class="thought" href="entries/ai_entry.html">AI</a> labs within ten years thereafter (or sooner if the potential of <a class="thought" href="entries/human_entry.html">human</a>-level <a class="thought" href="entries/ai_entry.html">AI</a> and <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a> is by then better appreciated by funding agencies).</p><h1>Notes</h1><p>&lt;A&gt; It is possible to nit-pick on this estimate. For example, there is some evidence that some limited amount of <a class="thought" href="entries/communication_entry.html">communication</a> between <a class="thought" href="entries/nerve_entry.html">nerve</a> cells is possible without synaptic transmission. And we have the regulatory mechanisms consisting <a class="thought" href="entries/neurotransmitter_entry.html">neurotransmitter</a>s and their sources, receptors and re-uptake channels. While <a class="thought" href="entries/neurotransmitter_entry.html">neurotransmitter</a> balances are crucially important for the proper functioning of the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a>, they have an insignificant <a class="thought" href="entries/information_entry.html">information</a> <a class="thought" href="entries/content_entry.html">content</a> compared to the synaptic structure. Perhaps a more serious point is that that <a class="thought" href="entries/neuron_entry.html">neuron</a>s often have rather complex <a class="thought" href="entries/time_entry.html">time</a>-integration properties (Koch 1997). Whether a specific <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of synaptic inputs result in the firing of a <a class="thought" href="entries/neuron_entry.html">neuron</a> depends on their exact timing. The authors' opinion is that except possibly for a small number of special applications such as auditory stereo perception, the temporal properties of the <a class="thought" href="entries/neuron_entry.html">neuron</a>s can easily be accommodated with a <a class="thought" href="entries/time_entry.html">time</a> resolution of the simulation on the <a class="thought" href="entries/order_entry.html">order</a> of 1 ms. In an unoptimized simulation this would add an <a class="thought" href="entries/order_entry.html">order</a> of magnitude to the estimate given above, where we assumed a temporal resolution of 10 ms, corresponding to an average firing rate of 100 Hz. However, the other values on which the estimate was based appear to be too high rather than too low, so we should not change the estimate much to allow for possible fine-grained <a class="thought" href="entries/time_entry.html">time</a>-integration effects in a <a class="thought" href="entries/neuron_entry.html">neuron</a>'s dendritic tree. (Note that even if we were to adjust our estimate upward by an <a class="thought" href="entries/order_entry.html">order</a> of magnitude, this would merely add three to five years to the predicted upper bound on when <a class="thought" href="entries/human_entry.html">human</a>-equivalent <a class="thought" href="entries/hardware_entry.html">hardware</a> arrives. The lower bound, which is based on Moravec's estimate, would remain unchanged.)</p><h1><a class="thought" href="entries/software_entry.html">Software</a><b> via the bottom-up approach</b></h1><p><a class="thought" href="entries/superintelligence_entry.html">Superintelligence</a> requires <a class="thought" href="entries/software_entry.html">software</a> as well as <a class="thought" href="entries/hardware_entry.html">hardware</a>. There are several approaches to the <a class="thought" href="entries/software_entry.html">software</a> problem, varying in the amount of top-down direction they require. At the one extreme we have <a class="thought" href="entries/system_entry.html">system</a>s like <a class="thought" href="entries/cyc_entry.html">CYC</a> which is a very large encyclopedia-like <a class="thought" href="entries/knowledge_entry.html">knowledge</a>-base and inference-<a class="thought" href="entries/engine_entry.html">engine</a>. It has been spoon-fed facts, rules of thumb and <a class="thought" href="entries/heuristic_entry.html">heuristic</a>s for over a decade by a team of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/knowledge_entry.html">knowledge</a> enterers. While <a class="thought" href="entries/system_entry.html">system</a>s like <a class="thought" href="entries/cyc_entry.html">CYC</a> might be good for certain practical tasks, this hardly seems like an approach that will convince <a class="thought" href="entries/ai_entry.html">AI</a>-skeptics that <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a> might well happen in the foreseeable <a class="thought" href="entries/future_entry.html">future</a>. We have to look at <a class="thought" href="entries/paradigm_entry.html">paradigm</a>s that require less <a class="thought" href="entries/human_entry.html">human</a> input, ones that make more use of bottom-up methods.</p>
<p>Given sufficient <a class="thought" href="entries/hardware_entry.html">hardware</a> and the right sort of <a class="thought" href="entries/program_entry.html">program</a>ming, we could make the <a class="thought" href="entries/machine_entry.html">machine</a>s learn in the same way a child does, i.e. by interacting with <a class="thought" href="entries/human_entry.html">human</a> adults and other objects in the environment. The <a class="thought" href="entries/learning_entry.html">learning</a> mechanisms used by the <a class="thought" href="entries/brain_entry.html">brain</a> are currently not completely understood. Artificial <a class="thought" href="entries/neural_network_entry.html">neural network</a>s in real-world applications today are usually trained through some variant of the Backpropagation <a class="thought" href="entries/algorithm_entry.html">algorithm</a> (which is known to be <a class="thought" href="entries/biological_entry.html">biological</a>ly unrealistic). The Backpropagation <a class="thought" href="entries/algorithm_entry.html">algorithm</a> works fine for smallish <a class="thought" href="entries/network_entry.html">network</a>s (of up to a few thousand <a class="thought" href="entries/neuron_entry.html">neuron</a>s) but it doesn't scale well. The <a class="thought" href="entries/time_entry.html">time</a> it takes to train a <a class="thought" href="entries/network_entry.html">network</a> tends to increase dramatically with the number of <a class="thought" href="entries/neuron_entry.html">neuron</a>s it contains. Another limitation of backpropagation is that it is a form of supervised <a class="thought" href="entries/learning_entry.html">learning</a>, requiring that signed error terms for each output <a class="thought" href="entries/neuron_entry.html">neuron</a> are specified during <a class="thought" href="entries/learning_entry.html">learning</a>. It's not clear how such detailed performance feedback on the level of individual <a class="thought" href="entries/neuron_entry.html">neuron</a>s could be provided in real-world situations except for certain well-defined specialized tasks.</p>
<p>A <a class="thought" href="entries/biological_entry.html">biological</a>ly more realistic <a class="thought" href="entries/learning_entry.html">learning</a> mode is the Hebbian <a class="thought" href="entries/algorithm_entry.html">algorithm</a>. Hebbian <a class="thought" href="entries/learning_entry.html">learning</a> is unsupervised and it might also have better scaling properties than Backpropagation. However, it has yet to be explained how Hebbian <a class="thought" href="entries/learning_entry.html">learning</a> by itself could produce all the forms of <a class="thought" href="entries/learning_entry.html">learning</a> and adaptation of which the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> is capable (such the storage of structured representation in long-term <a class="thought" href="entries/memory_entry.html">memory</a>). Presumably, Hebb's rule would at least need to be supplemented with reward-induced <a class="thought" href="entries/learning_entry.html">learning</a> (Morillo 1992) and maybe with other <a class="thought" href="entries/learning_entry.html">learning</a> modes that are yet to be discovered. It does seems plausible, though, to assume that only a very limited <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of different <a class="thought" href="entries/learning_entry.html">learning</a> rules (maybe as few as two or three) are operating in the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a>. And we are not very far from knowing what these rules are.</p>
<p>Creating <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a> through imitating the functioning of the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> requires two more things in addition to appropriate <a class="thought" href="entries/learning_entry.html">learning</a> rules (and sufficiently powerful <a class="thought" href="entries/hardware_entry.html">hardware</a>): it requires having an adequate initial <a class="thought" href="entries/architecture_entry.html">architecture</a> and providing a rich flux of sensory input.</p>
<p>The latter prerequisite is easily provided even with present <a class="thought" href="entries/technology_entry.html">technology</a>. Using video cameras, microphones and tactile sensors, it is possible to ensure a steady flow of real-world <a class="thought" href="entries/information_entry.html">information</a> to the artificial <a class="thought" href="entries/neural_network_entry.html">neural network</a>. An interactive <a class="thought" href="entries/element_entry.html">element</a> could be arranged by connecting the <a class="thought" href="entries/system_entry.html">system</a> to <a class="thought" href="entries/robot_entry.html">robot</a> limbs and a speaker.</p>
<p>Developing an adequate initial <a class="thought" href="entries/network_entry.html">network</a> structure is a more serious problem. It might turn out to be necessary to do a considerable amount of hand-coding in <a class="thought" href="entries/order_entry.html">order</a> to get the cortical <a class="thought" href="entries/architecture_entry.html">architecture</a> right. In <a class="thought" href="entries/biological_entry.html">biological</a> organisms, the <a class="thought" href="entries/brain_entry.html">brain</a> does not start out at birth as a homogenous tabula rasa; it has an initial structure that is coded genetically. <a class="thought" href="entries/neuroscience_entry.html">Neuroscience</a> cannot, at its present stage, say exactly what this structure is or how much of it needs be preserved in a simulation that is eventually to match the cognitive competencies of a <a class="thought" href="entries/human_entry.html">human</a> adult. One way for it to be unexpectedly difficult to achieve <a class="thought" href="entries/human_entry.html">human</a>-level <a class="thought" href="entries/ai_entry.html">AI</a> through the <a class="thought" href="entries/neural_network_entry.html">neural network</a> approach would be if it turned out that the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> relies on a colossal amount of genetic hardwiring, so that each cognitive function depends on a unique and hopelessly complicated inborn <a class="thought" href="entries/architecture_entry.html">architecture</a>, acquired over aeons in the <a class="thought" href="entries/evolution_entry.html">evolution</a>ary <a class="thought" href="entries/learning_entry.html">learning</a> process of our <a class="thought" href="entries/species_entry.html">species</a>.</p>
<p>Is this the case? A number of considerations that suggest otherwise. We have to contend ourselves with a very brief review here. For a more comprehensive discussion, the reader may consult Phillips &amp; Singer (1997).</p>
<p>Quartz &amp; Sejnowski (1997) argue from recent neurobiological <a class="thought" href="entries/data_entry.html">data</a> that the developing <a class="thought" href="entries/human_entry.html">human</a> cortex is largely free of domain-specific structures. The representational properties of the specialized <a class="thought" href="entries/circuit_entry.html">circuit</a>s that we find in the mature cortex are not generally genetically prespecified. Rather, they are developed through interaction with the problem domains on which the <a class="thought" href="entries/circuit_entry.html">circuit</a>s operate. There are genetically coded tendencies for certain <a class="thought" href="entries/brain_entry.html">brain</a> areas to specialize on certain tasks (for example primary visual processing is usually performed in the primary visual cortex) but this does not mean that other cortical areas couldn't have learnt to perform the same function. In fact, the <a class="thought" href="entries/human_entry.html">human</a> neocortex seems to start out as a fairly flexible and general-purpose mechanism; specific modules arise later through self-organizing and through interacting with the environment.</p>
<p>Strongly supporting this view is the fact that cortical lesions, even sizeable ones, can often be compensated for if they occur at an early age. Other cortical areas take over the functions that would normally have been developed in the destroyed region. In one study, sensitivity to visual features was developed in the auditory cortex of neonatal ferrets, after that region's normal auditory input channel had been replaced by visual projections (<a class="thought" href="entries/sur_entry.html">Sur</a> et al. 1988). Similarly, it has been shown that the visual cortex can take over functions normally performed by the somatosensory cortex (Schlaggar &amp; O'Leary 1991). A recent experiment (Cohen et al. 1997) showed that people who have been blind from an early age can use their visual cortex to process tactile stimulation when reading Braille.</p>
<p>There are some more primitive regions of the <a class="thought" href="entries/brain_entry.html">brain</a> whose functions cannot be taken over by any other area. For example, people who have their hippocampus removed, lose their ability to learn new episodic or semantic facts. But the neocortex tends to be highly plastic and that is where most of the high-level processing is executed that makes us intellectually superior to other <a class="thought" href="entries/animal_entry.html">animal</a>s. (It would be interesting to examine in more detail to what extent this holds true for all of neocortex. Are there small neocortical regions such that, if excised at birth, the subject will never obtain certain high-level competencies, not even to a limited degree?)</p>
<p>Another consideration that seems to indicate that innate architectural differentiation plays a relatively small part in accounting for the performance of the mature <a class="thought" href="entries/brain_entry.html">brain</a> is the that neocortical <a class="thought" href="entries/architecture_entry.html">architecture</a>, especially in infants, is remarkably homogeneous over different cortical regions and even over different <a class="thought" href="entries/species_entry.html">species</a>:</p>
<p>Laminations and vertical connections between lamina are hallmarks of all cortical <a class="thought" href="entries/system_entry.html">system</a>s, the morphological and physiological characteristics of cortical <a class="thought" href="entries/neuron_entry.html">neuron</a>s are equivalent in different <a class="thought" href="entries/species_entry.html">species</a>, as are the kinds of synaptic interactions involving cortical <a class="thought" href="entries/neuron_entry.html">neuron</a>s. This similarity in the organization of the <a class="thought" href="entries/cerebral_cortex_entry.html">cerebral cortex</a> extends even to the specific details of cortical <a class="thought" href="entries/circuit_entry.html">circuit</a>ry. (White 1989, p. 179).</p>
<p>One might object that at this point that cetaceans have much bigger corticies than humans and yet they don't have <a class="thought" href="entries/human_entry.html">human</a>-level abstract understanding and <a class="thought" href="entries/language_entry.html">language</a> &lt;A&gt;. A large cortex, apparently, is not sufficient for <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. However, one can easily imagine that some very simple difference between <a class="thought" href="entries/human_entry.html">human</a> and cetacean brains can account for why we have abstract <a class="thought" href="entries/language_entry.html">language</a> and understanding that they lack. It could be something as trivial as that our cortex is provided with a low-level "drive" to learn about abstract relationships whereas dolphins and whales are <a class="thought" href="entries/program_entry.html">program</a>med not to care about or pay much attention to such things (which might be totally irrelevant to them in their natural environment). More likely, there are some structural developments in the <a class="thought" href="entries/human_entry.html">human</a> cortex that other <a class="thought" href="entries/animal_entry.html">animal</a>s lack and that are necessary for advanced abstract <a class="thought" href="entries/thinking_entry.html">thinking</a>. But these uniquely <a class="thought" href="entries/human_entry.html">human</a> developments may well be the result of relatively simple changes in just a few <a class="thought" href="entries/basic_entry.html">basic</a> parameters. They do not require a large amount of genetic hardwiring. Indeed, given that <a class="thought" href="entries/brain_entry.html">brain</a> <a class="thought" href="entries/evolution_entry.html">evolution</a> that allowed <a class="thought" href="entries/homo_sapiens_entry.html">Homo Sapiens</a> to intellectually outclass other <a class="thought" href="entries/animal_entry.html">animal</a>s took place under a relatively brief period of <a class="thought" href="entries/time_entry.html">time</a>, <a class="thought" href="entries/evolution_entry.html">evolution</a> cannot have embedded very much <a class="thought" href="entries/content_entry.html">content</a>-specific <a class="thought" href="entries/information_entry.html">information</a> in these additional cortical structures that give us our intellectual edge over our <a class="thought" href="entries/humanoid_entry.html">humanoid</a> or ape-like ancestors.</p>
<p>These considerations (especially the one of cortical plasticity) suggest that the amount of neuroscientific <a class="thought" href="entries/information_entry.html">information</a> needed for the bottom-up approach to succeed may be very limited. (Notice that they do not argue against the modularization of adult <a class="thought" href="entries/human_entry.html">human</a> brains. They only indicate that the greatest part of the <a class="thought" href="entries/information_entry.html">information</a> that goes into the modularization results from <a class="thought" href="entries/self_organizing_entry.html">self-organization</a> and perceptual input rather than from an immensely complicated genetic look-up table.)</p>
<p>Further advances in <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a> are probably needed before we can construct a <a class="thought" href="entries/human_entry.html">human</a>-level (or even higher <a class="thought" href="entries/animal_entry.html">animal</a>-level) <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> by means of this radically bottom-up approach. While it is true that <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a> has advanced very rapidly in recent years, it is difficult to estimate how long it will take before enough is known about the <a class="thought" href="entries/brain_entry.html">brain</a>'s <a class="thought" href="entries/neuron_entry.html">neuron</a>al <a class="thought" href="entries/architecture_entry.html">architecture</a> and its <a class="thought" href="entries/learning_entry.html">learning</a> <a class="thought" href="entries/algorithm_entry.html">algorithm</a>s to make it possible to replicate these in a <a class="thought" href="entries/computer_entry.html">computer</a> of sufficient <a class="thought" href="entries/computation_entry.html">computation</a>al power. A wild guess: something like fifteen years. This is not a prediction about how far we are from a complete understanding of all important phenomena in the <a class="thought" href="entries/brain_entry.html">brain</a>. The estimate refers to the <a class="thought" href="entries/time_entry.html">time</a> when we might be expected to know enough about the <a class="thought" href="entries/basic_entry.html">basic</a> principles of how the <a class="thought" href="entries/brain_entry.html">brain</a> works to be able to implement these <a class="thought" href="entries/computation_entry.html">computation</a>al <a class="thought" href="entries/paradigm_entry.html">paradigm</a>s on a <a class="thought" href="entries/computer_entry.html">computer</a>, without necessarily modeling the <a class="thought" href="entries/brain_entry.html">brain</a> in any <a class="thought" href="entries/biological_entry.html">biological</a>ly realistic way.</p>
<p>The estimate might seem to some to underestimate the difficulties, and perhaps it does. But consider how much has happened in the past fifteen years. The discipline of <a class="thought" href="entries/computation_entry.html">computation</a>al <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a> did hardly even exist back in 1982. And <a class="thought" href="entries/future_entry.html">future</a> <a class="thought" href="entries/progress_entry.html">progress</a> will occur not only because <a class="thought" href="entries/research_entry.html">research</a> with today's <a class="thought" href="entries/instrument_entry.html">instrument</a>ation will continue to produce illuminating findings, but also because new experimental tools and techniques become available. Large-scale multi-electrode recordings should be feasible within the near <a class="thought" href="entries/future_entry.html">future</a>. Neuro/<a class="thought" href="entries/chip_entry.html">chip</a> <a class="thought" href="entries/interface_entry.html">interface</a>s are in development. More powerful <a class="thought" href="entries/hardware_entry.html">hardware</a> is being made available to neuroscientists to do <a class="thought" href="entries/computation_entry.html">computation</a>-intensive simulations. Neuropharmacologists design drugs with higher specificity, allowing <a class="thought" href="entries/research_entry.html">research</a>es to selectively target given receptor subtypes. Present scanning techniques are improved and new ones are under development. The list could be continued. All these innovations will give neuroscientists very powerful new tools that will facilitate their <a class="thought" href="entries/research_entry.html">research</a>.</p>
<p>This section has discussed the <a class="thought" href="entries/software_entry.html">software</a> problem. It was argued that it can be solved through a bottom-up approach by using present equipment to supply the input and output channels, and by continuing to study the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> in <a class="thought" href="entries/order_entry.html">order</a> to find out about what <a class="thought" href="entries/learning_entry.html">learning</a> <a class="thought" href="entries/algorithm_entry.html">algorithm</a> it uses and about the initial <a class="thought" href="entries/neuron_entry.html">neuron</a>al structure in new-born infants. Considering how large strides <a class="thought" href="entries/computation_entry.html">computation</a>al <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a> has taken in the last decade, and the new experimental <a class="thought" href="entries/instrument_entry.html">instrument</a>ation that is under development, it seems <a class="thought" href="entries/reason_entry.html">reason</a>able to suppose that the required neuroscientific <a class="thought" href="entries/knowledge_entry.html">knowledge</a> might be obtained in perhaps fifteen years from now, i.e. by year 2012.</p><h1>Notes</h1><p>&lt;A&gt; That dolphins don't have abstract <a class="thought" href="entries/language_entry.html">language</a> was recently established in a very elegant experiment. A pool is divided into two halves by a net. Dolphin A is released into one end of the pool where there is a mechanism. After a while, the dolphin figures out how to operate the mechanism which causes dead fish to be released into both ends of the pool. Then A is transferred to the other end of the pool and a dolphin B is released into the end of the pool that has the mechanism. The idea is that if the dolphins had a <a class="thought" href="entries/language_entry.html">language</a>, then A would tell B to operate the mechanism. However, it was found that the average <a class="thought" href="entries/time_entry.html">time</a> for B to operate the mechanism was the same as for A.</p><h1><b>Why the past failure of </b><a class="thought" href="entries/ai_entry.html">AI</a><b> is no argument against its </b><a class="thought" href="entries/future_entry.html">future</a><b> success</b></h1><p>In the seventies and eighties the <a class="thought" href="entries/ai_entry.html">AI</a> field suffered some stagnation as the exaggerated expectations from the early heydays failed to materialize and <a class="thought" href="entries/progress_entry.html">progress</a> nearly ground to a halt. The lesson to draw from this episode is not that <a class="thought" href="entries/strong_ai_entry.html">strong AI</a> is dead and that superintelligent <a class="thought" href="entries/machine_entry.html">machine</a>s will never be built. It shows that <a class="thought" href="entries/ai_entry.html">AI</a> is more difficult than some of the early pioneers might have <a class="thought" href="entries/thought_entry.html">thought</a>, but it goes no way toward showing that <a class="thought" href="entries/ai_entry.html">AI</a> will forever remain unfeasible.</p>
<p>In retrospect we know that the <a class="thought" href="entries/ai_entry.html">AI</a> project couldn't possibly have succeeded at that stage. The <a class="thought" href="entries/hardware_entry.html">hardware</a> was simply not powerful enough. It seems that at least about 100 Tops is required for <a class="thought" href="entries/human_entry.html">human</a>-like performance, and possibly as much as 10<sup>17</sup> ops is needed. The <a class="thought" href="entries/computer_entry.html">computer</a>s in the seventies had a computing power comparable to that of <a class="thought" href="entries/insect_entry.html">insect</a>s. They also achieved approximately <a class="thought" href="entries/insect_entry.html">insect</a>-level <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. Now, on the other hand, we can foresee the arrival of <a class="thought" href="entries/human_entry.html">human</a>-equivalent <a class="thought" href="entries/hardware_entry.html">hardware</a>, so the cause of <a class="thought" href="entries/ai_entry.html">AI</a>'s past failure will then no longer be present.</p>
<p>There is also an explanation for the relative absence even of noticeable <a class="thought" href="entries/progress_entry.html">progress</a> during this period. As <a class="thought" href="entries/moravec_entry.html">Hans Moravec</a> points out:</p>
<blockquote>For several decades the computing power found in advanced <a class="thought" href="entries/ai_entry.html">Artificial Intelligence</a> and <a class="thought" href="entries/robotics_entry.html">Robotics</a> <a class="thought" href="entries/system_entry.html">system</a>s has been stuck at <a class="thought" href="entries/insect_entry.html">insect</a> <a class="thought" href="entries/brain_entry.html">brain</a> power of 1 <a class="thought" href="entries/mips_entry.html">MIPS</a>. While <a class="thought" href="entries/computer_entry.html">computer</a> power per dollar fell [should be: rose] rapidly during this period, the money available fell just as fast. The earliest days of <a class="thought" href="entries/ai_entry.html">AI</a>, in the mid 1960s, were fuelled by lavish post-<a class="thought" href="entries/sputnik_entry.html">Sputnik</a> defense funding, which gave <a class="thought" href="entries/access_entry.html">access</a> to $10,000,000 <a class="thought" href="entries/supercomputer_entry.html">supercomputer</a>s of the <a class="thought" href="entries/time_entry.html">time</a>. In the post Vietnam war days of the 1970s, funding declined and only $1,000,000 <a class="thought" href="entries/machine_entry.html">machine</a>s were available. By the early 1980s, <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a> had to settle for $100,000 <a class="thought" href="entries/minicomputer_entry.html">minicomputer</a>s. In the late 1980s, the available <a class="thought" href="entries/machine_entry.html">machine</a>s were $10,000 workstations. By the 1990s, much work was done on <a class="thought" href="entries/personal_computer_entry.html">personal computer</a>s costing only a few thousand dollars. Since then <a class="thought" href="entries/ai_entry.html">AI</a> and <a class="thought" href="entries/robot_entry.html">robot</a> <a class="thought" href="entries/brain_entry.html">brain</a> power has risen with improvements in <a class="thought" href="entries/computer_entry.html">computer</a> efficiency. By 1993 <a class="thought" href="entries/personal_computer_entry.html">personal computer</a>s provided 10 <a class="thought" href="entries/mips_entry.html">MIPS</a>, by 1995 it was 30 <a class="thought" href="entries/mips_entry.html">MIPS</a>, and in 1997 it is over 100 <a class="thought" href="entries/mips_entry.html">MIPS</a>. Suddenly <a class="thought" href="entries/machine_entry.html">machine</a>s are reading text, recognizing speech, and robots are driving themselves cross country. (<a href="http://web.archive.org/web/20080512152111/http://www.frc.ri.cmu.edu/~hpm/book97/index.html" target="_new">Moravec 1997</a>)</blockquote>
<p>In general, there seems to be a new-found <a class="thought" href="entries/sense_entry.html">sense</a> of <a class="thought" href="entries/optimism_entry.html">optimism</a> and excitement among people working in <a class="thought" href="entries/ai_entry.html">AI</a>, especially among those taking a bottom-up approach, such as <a class="thought" href="entries/research_entry.html">research</a>ers in <a class="thought" href="entries/genetic_algorithm_entry.html">genetic algorithm</a>s, neuromorphic <a class="thought" href="entries/engine_entry.html">engine</a>ering and in <a class="thought" href="entries/neural_network_entry.html">neural network</a>s <a class="thought" href="entries/hardware_entry.html">hardware</a> implementations. Many experts who have been around, though, are wary not again to underestimate the difficulties ahead.</p><h1><b>Once there is <a class="thought" href="entries/human_entry.html">human</a>-level </b><a class="thought" href="entries/ai_entry.html">AI</a><b> there will soon be <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a></b></h1><p>Once <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> reaches <a class="thought" href="entries/human_entry.html">human</a> level, there will be a positive feedback loop that will give the development a further boost. AIs would help constructing better AIs, which in turn would help building better AIs, and so forth.</p>
<p>Even if no further <a class="thought" href="entries/software_entry.html">software</a> development took place and the AIs did not accumulate new skills through self-<a class="thought" href="entries/learning_entry.html">learning</a>, the AIs would still get smarter if processor speed continued to increase. If after 18 months the <a class="thought" href="entries/hardware_entry.html">hardware</a> were upgraded to double the speed, we would have an <a class="thought" href="entries/ai_entry.html">AI</a> that could think twice as fast as its original implementation. After a few more doublings this would directly lead to what has been called "weak <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a>", i.e. an intellect that has about the same abilities as a <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> but is much faster.</p>
<p>Also, the marginal utility of improvements in <a class="thought" href="entries/ai_entry.html">AI</a> when <a class="thought" href="entries/ai_entry.html">AI</a> reaches <a class="thought" href="entries/human_entry.html">human</a>-level would also seem to skyrocket, causing funding to increase. We can therefore make the prediction that once there is <a class="thought" href="entries/human_entry.html">human</a>-level <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> then it will not be long before <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a> is technologically feasible.</p>
<p>A further point can be made in support of this prediction. In contrast to what's possible for <a class="thought" href="entries/biological_entry.html">biological</a> intellects, it might be possible to copy skills or cognitive modules from one artificial intellect to another. If one <a class="thought" href="entries/ai_entry.html">AI</a> has achieved eminence in some field, then subsequent AIs can upload the pioneer's <a class="thought" href="entries/program_entry.html">program</a> or synaptic weight-<a class="thought" href="entries/matrix_entry.html">matrix</a> and immediately achieve the same level of performance. It would not be necessary to again go through the training process. Whether it will also be possible to copy the best parts of several AIs and combine them into one will depend on details of implementation and the degree to which the AIs are modularized in a standardized fashion. But as a general rule, the intellectual achievements of artificial intellects are additive in a way that <a class="thought" href="entries/human_entry.html">human</a> achievements are not, or only to a much less degree.</p><h1><b>The demand for <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a></b></h1><p>Given that <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a> will one day be technologically feasible, will people choose to develop it? This question can pretty confidently be answered in the affirmative. Associated with every step along the road to <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a> are enormous economic payoffs. The <a class="thought" href="entries/computer_entry.html">computer</a> industry invests huge sums in the next generation of <a class="thought" href="entries/hardware_entry.html">hardware</a> and <a class="thought" href="entries/software_entry.html">software</a>, and it will continue doing so as long as there is a competitive pressure and profits to be made. People want better <a class="thought" href="entries/computer_entry.html">computer</a>s and smarter <a class="thought" href="entries/software_entry.html">software</a>, and they want the benefits these <a class="thought" href="entries/machine_entry.html">machine</a>s can help produce. Better medical drugs; relief for humans from the need to perform boring or dangerous jobs; entertainment--there is no end to the list of consumer-benefits. There is also a strong <a class="thought" href="entries/military_entry.html">military</a> motive to develop <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>. And nowhere on the path is there any natural stopping point where technofobics could plausibly argue "hither but not further".</p>
<p>It therefore seems that up to <a class="thought" href="entries/human_entry.html">human</a>-equivalence, the driving-forces behind improvements in <a class="thought" href="entries/ai_entry.html">AI</a> will easily overpower whatever resistance might be present. When the question is about <a class="thought" href="entries/human_entry.html">human</a>-level or greater <a class="thought" href="entries/intelligence_entry.html">intelligence</a> then it is conceivable that there might be strong political forces opposing further development. <a class="thought" href="entries/superintelligence_entry.html">Superintelligence</a> might be seen to pose a threat to the supremacy, and even to the survival, of the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/species_entry.html">species</a>. Whether by suitable <a class="thought" href="entries/program_entry.html">program</a>ming we can arrange the motivation <a class="thought" href="entries/system_entry.html">system</a>s of the <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a>s in such a way as to guarantee perpetual obedience and subservience, or at least non-harmfulness, to humans is a <a class="thought" href="entries/content_entry.html">content</a>ious topic. If <a class="thought" href="entries/future_entry.html">future</a> policy-makers can be sure that AIs would not endanger <a class="thought" href="entries/human_entry.html">human</a> interests then the development of <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> will continue. If they can't be sure that there would be no danger, then the development might well continue anyway, either because people don't regard the gradual displacement of <a class="thought" href="entries/biological_entry.html">biological</a> humans with <a class="thought" href="entries/machine_entry.html">machine</a>s as necessarily a bad outcome, or because such <a class="thought" href="entries/strong_force_entry.html">strong force</a>s (motivated by short-term profit, curiosity, ideology, or desire for the capabilities that <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a>s might bring to its creators) are active that a collective decision to ban new <a class="thought" href="entries/research_entry.html">research</a> in this field can not be reached and successfully implemented.</p><h1><b>Conclusion</b></h1><p>Depending on degree of optimization assumed, <a class="thought" href="entries/human_entry.html">human</a>-level <a class="thought" href="entries/intelligence_entry.html">intelligence</a> probably requires between 10<sup>14</sup> and 10<sup>17</sup> ops. It seems quite possible that very advanced optimization could reduce this figure further, but the entrance level would probably not be less than about 10<sup>14</sup> ops. If <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> continues to hold then the lower bound will be reached sometime between 2004 and 2008, and the upper bound between 2015 and 2024. The past success of <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> gives some inductive <a class="thought" href="entries/reason_entry.html">reason</a> to believe that it will hold another ten, fifteen years or so; and this prediction is supported by the fact that there are many promising new technologies currently under development which hold great potential to increase procurable computing power. There is no direct <a class="thought" href="entries/reason_entry.html">reason</a> to suppose that <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> will not hold longer than 15 years. It thus seems likely that the requisite <a class="thought" href="entries/hardware_entry.html">hardware</a> for <a class="thought" href="entries/human_entry.html">human</a>-level <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> will be assembled in the first quarter of the next century, possibly within the first few years.</p>
<p>There are several approaches to developing the <a class="thought" href="entries/software_entry.html">software</a>. One is to emulate the <a class="thought" href="entries/basic_entry.html">basic</a> principles of <a class="thought" href="entries/biological_entry.html">biological</a> brains. It is not implausible to suppose that these principles will be well enough known within 15 years for this approach to succeed, given adequate <a class="thought" href="entries/hardware_entry.html">hardware</a>.</p>
<p>The stagnation of <a class="thought" href="entries/ai_entry.html">AI</a> during the seventies and eighties does not have much bearing on the likelihood of <a class="thought" href="entries/ai_entry.html">AI</a> to succeed in the <a class="thought" href="entries/future_entry.html">future</a> since we know that the cause responsible for the stagnation (namely, that the <a class="thought" href="entries/hardware_entry.html">hardware</a> available to <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a>ers was stuck at about 10<sup>6</sup> ops) is no longer present.</p>
<p>There will be a strong and increasing pressure to improve <a class="thought" href="entries/ai_entry.html">AI</a> up to <a class="thought" href="entries/human_entry.html">human</a>-level. If there is a way of guaranteeing that superior artificial intellects will never harm <a class="thought" href="entries/human_entry.html">human</a> beings then such intellects will be created. If there is no way to have such a guarantee then they will probably be created nevertheless.</p><h1>Postscript I</h1><p>(25 October, 1998)</p>
<p>The U.S. Department of <a class="thought" href="entries/energy_entry.html">Energy</a> has ordered a new <a class="thought" href="entries/supercomputer_entry.html">supercomputer</a> from <a class="thought" href="entries/ibm_entry.html">IBM</a>, to be installed in the Lawrence Livermore National Laboratory in the <a class="thought" href="entries/y2k_entry.html">year 2000</a>. It will cost $85 million and will perform 10 Tops. This development is in accordance with <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a>, or possibly slightly more rapid than an extrapolation would have predicted.</p>
<p>Many steps forward that have been taken during the past year. An especially nifty one is the new <a class="thought" href="entries/chip_entry.html">chip</a>-making techniques being developed at <a class="thought" href="entries/irvine_sensors_entry.html">Irvine Sensors Corporation</a> (ISC). They have found a way to stack chips directly on top of each other in a way that will not only save <a class="thought" href="entries/space_entry.html">space</a> but, more importantly, allow a larger number of interconnections between neigboring chips. Since the number of interconnections have been a bottleneck in <a class="thought" href="entries/neural_network_entry.html">neural network</a> <a class="thought" href="entries/hardware_entry.html">hardware</a> implementations, this breakthrough could prove very important. In principle, it should allow you to have an arbitrarily large cube of <a class="thought" href="entries/neural_network_entry.html">neural network</a> modules with high local connectivity and moderate non-local connectivity.</p><h1>Postscript II</h1><p>(28 August, 2000)</p>
<p>Is <a class="thought" href="entries/progress_entry.html">progress</a> still on schedule? - In fact, things seem to be moving somewhat faster than expected, at least on the <a class="thought" href="entries/hardware_entry.html">hardware</a> front. (<a class="thought" href="entries/software_entry.html">Software</a> <a class="thought" href="entries/progress_entry.html">progress</a> is more difficult to quantify.) <a class="thought" href="entries/ibm_entry.html">IBM</a> is currently working on a next-generation <a class="thought" href="entries/supercomputer_entry.html">supercomputer</a>, Blue Gene, which will perform over 10<sup>15</sup> ops. This <a class="thought" href="entries/computer_entry.html">computer</a>, which is designed to tackle the <a class="thought" href="entries/protein_entry.html">protein</a> folding problem, is expected to be ready around 2005. It will achieve its enormous power through massive parallelism rather than through dramatically faster processors. Considering the increasing emphasis on parallel computing, and the steadily increasing <a class="thought" href="entries/internet_entry.html">Internet</a> <a class="thought" href="entries/bandwidth_entry.html">bandwidth</a>, it becomes important to interpret <a class="thought" href="javascript:loadBrain('Moore\'s Law')">Moore's law</a> as a statement about how much computing power can be bought for a given sum of (<a class="thought" href="entries/inflation_entry.html">inflation</a> adjusted) money. This measure has historically been growing at the same pace as processor speed or <a class="thought" href="entries/chip_entry.html">chip</a> density, but the measures may come apart in the <a class="thought" href="entries/future_entry.html">future</a>. It is how much computing power that can be bought for, say, 100 million dollars that is relevant when we are trying to guess when <a class="thought" href="entries/superintelligence_entry.html">superintelligence</a> will be developed, rather than how fast individual processors are.</p><h1><b>Acknowledgments</b></h1><p>The author would like to thank all those who have contributed comments on earlier versions of this paper. The very helpful suggestions by <a class="thought" href="entries/hal_entry.html">Hal</a> Finney, Robin Hanson, Carl Feynman, Anders Sandberg, and Peter McCluskey were especially appreciated.</p><h1><b>References</b></h1><a name="r1"></a>
<p class="Reference">Bostrom N. 1996. "Cortical Integration: Possible Solutions to the Binding and Linking Problems in Perception, <a class="thought" href="entries/reason_entry.html">Reason</a>ing and Long Term <a class="thought" href="entries/memory_entry.html">Memory</a>".</p>
<a name="r2"></a>
<p class="Reference">Cohen L., G. et al. 1997. "Functional relevance of cross-modal plasticity in blind humans". <a class="thought" href="entries/nature_entry.html">Nature</a> 389: 180-83. de Garis, H. 1997.</p>
<a name="r3"></a>
<p class="Reference">Hameroff &amp; Penrose <a href="http://web.archive.org/web/20080512152111/http://psyche.cs.monash.edu.au/psyche-index-v2.html" target="_new">http://psyche.cs.monash.edu.au/psyche-index-v2.html</a>
</p>
<a name="r4"></a>
<p class="Reference">Koch, <a class="thought" href="entries/c_entry.html">C</a>. 1997. "<a class="thought" href="entries/computation_entry.html">Computation</a> and the single <a class="thought" href="entries/neuron_entry.html">neuron</a>". <a class="thought" href="entries/nature_entry.html">Nature</a> 385: 207-10.</p>
<a name="r5"></a>
<p class="Reference">Moravec, H. 1998. "When will <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/hardware_entry.html">hardware</a> match the <a class="thought" href="entries/human_entry.html">human</a> brain?" Journal of <a class="thought" href="entries/transhuman_entry.html">Transhuman</a>ism, vol. 1. At <a href="http://web.archive.org/web/20080512152111/http://www.transhumanist.com/" target="_new">http://www.transhumanist.com/</a>
</p>
<a name="r6"></a>
<p class="Reference">Moravec, H. 1997. <a href="http://web.archive.org/web/20080512152111/http://www.frc.ri.cmu.edu/~hpm/book97/ch3/retina.comment.html" target="_new">http://www.frc.ri.cmu.edu/~hpm/book97/ch3/retina.comment.html</a>
</p>
<a name="r7"></a>
<p class="Reference">Morillo, <a class="thought" href="entries/c_entry.html">C</a>., R. 1992. "Reward <a class="thought" href="entries/event_entry.html">event</a> <a class="thought" href="entries/system_entry.html">system</a>s: reconceptualizing the explanatory roles of motivation, desire and pleasure". Phil. Psych. Vol. 5, No. 1, pp. 7-32.</p>
<a name="r8"></a>
<p class="Reference">Phillips W. A. &amp; Singer W. 1997. "In <a class="thought" href="entries/search_entry.html">Search</a> of Common Foundations for Cortical <a class="thought" href="entries/computation_entry.html">Computation</a>s". Behavioural and <a class="thought" href="entries/brain_entry.html">Brain</a> <a class="thought" href="entries/science_entry.html">Science</a>s, 20, 657-722.</p>
<a name="r9"></a>
<p class="Reference">Quartz S. R. &amp; Sejnowski T. J. 1997. "The neural basis of cognitive development: A constructivist manifesto". Behavioural and <a class="thought" href="entries/brain_entry.html">Brain</a> <a class="thought" href="entries/science_entry.html">Science</a>s, 20, 537-596.</p>
<a name="r10"></a>
<p class="Reference">Schlaggar, B. L. &amp; O'Leary, D. D. M. 1991. "Potential of visual cortex to develop an array of functional units unique to somatosensory cortex". <a class="thought" href="entries/science_entry.html">Science</a> 252: 1556-60.</p>
<a name="r11"></a>
<p class="Reference"><a class="thought" href="entries/sur_entry.html">Sur</a>, M. et al. 1988. "Experimentally induced visual projections into auditory thalamus and cortex". <a class="thought" href="entries/science_entry.html">Science</a> 242: 1437-41</p>
<a name="r12"></a>
<p class="Reference">White, E. L. 1989. Cortical <a class="thought" href="entries/circuit_entry.html">Circuit</a>s: Synaptic Organization of the <a class="thought" href="entries/cerebral_cortex_entry.html">Cerebral Cortex</a>. Structure, Function and Theory.</p>
<a name="r13"></a>
<p class="Reference">(1997) Copyright <a class="thought" href="entries/bostrom_entry.html">Nick Bostrom</a></p>
<a name="r14"></a>
<p class="Reference">[Revised 25 October, 1998, and provided with a postscript]</p>
<a name="r15"></a>
<p class="Reference">[A second postscript added 28 August, 2000]</p>
</td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20080512152111im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20080512152111/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D6892" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id6893"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20080512152111im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20080512152111im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080512152111im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Moor's Law<br><span class="mindxheader"><i>posted on 05/17/2002 1:47 PM by Citizen Blue</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20080512152111/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6892%23id6893" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20080512152111/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D6893" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080512152111im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Evolution would seem 
</p></td></tr></table></td></tr></table></td></tr></table></body></html>