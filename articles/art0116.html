<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>Chapter 11: The Engines of Destruction</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/meme/memelist.html?m=18">Nanotechnology</a> &gt; 
<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/meme/memelist.html?m=8">Engines of Creation</a> &gt; 
Chapter 11: The Engines of Destruction
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20100614011813/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0116.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0116.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/articles/art0116.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">Chapter 11: The Engines of Destruction</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0014.html" target="_top">K. Eric Drexler</a><br></span></td>
</table>
<br>
<div class="TeaserText"></div>
<br>
<br><blockquote>Nor do I doubt if the most formidable armies ever heere upon <a class="thought" href="entries/earth_entry.html">earth</a> is a sort of soldiers who for their smallness are not visible.</blockquote>
<blockquote>- Sir WILLIAM PERRY, on microbes, 1640</blockquote>
<p>REPLICATING <a class="thought" href="entries/assembler_entry.html">assembler</a>s and <a class="thought" href="entries/thinking_entry.html">thinking</a> <a class="thought" href="entries/machine_entry.html">machine</a>s pose <a class="thought" href="entries/basic_entry.html">basic</a> threats to people and to <a class="thought" href="entries/life_entry.html">life</a> on <a class="thought" href="entries/earth_entry.html">Earth</a>. Today's organisms have abilities far from the limits of the possible, and our <a class="thought" href="entries/machine_entry.html">machine</a>s are evolving faster than we are. Within a few decades they seem likely to surpass us. Unless we learn to live with them in safety, our <a class="thought" href="entries/future_entry.html">future</a> will likely be both exciting and short. We cannot hope to foresee all the problems ahead, yet by paying attention to the big, <a class="thought" href="entries/basic_entry.html">basic</a> issues, we can perhaps foresee the greatest challenges and get some idea of how to deal with them.</p>
<p>&#160;Entire books will no doubt be written on the coming social upheavals: What will happen to the global <a class="thought" href="entries/order_entry.html">order</a> when <a class="thought" href="entries/assembler_entry.html">assembler</a>s and automated <a class="thought" href="entries/engine_entry.html">engine</a>ering eliminate the need for most international trade? How will society change when individuals can live indefinitely? What will we do when replicating <a class="thought" href="entries/assembler_entry.html">assembler</a>s can make almost anything without <a class="thought" href="entries/human_entry.html">human</a> labor? What will we do when <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s can think faster than humans? (And before they jump to the conclusion that people will despair of doing or creating anything, the authors may consider how runners regard cars, or how painters regard cameras.)</p>
<p>&#160;In fact, authors have already foreseen and discussed several of these issues. Each is a <a class="thought" href="entries/matter_entry.html">matter</a> of uncommon importance, but more fundamental than any of them is the survival of <a class="thought" href="entries/life_entry.html">life</a> and liberty. After all, if <a class="thought" href="entries/life_entry.html">life</a> or liberty is obliterated, then our ideas about social problems will no longer <a class="thought" href="entries/matter_entry.html">matter</a>.</p><h1>The Threat from the <a class="thought" href="entries/machine_entry.html">Machine</a>s</h1><p>In Chapter 4, I described some of what replicating <a class="thought" href="entries/assembler_entry.html">assembler</a>s will do for us if we handle them properly. Powered by fuels or sunlight, they will be able to make almost anything (including more of themselves) from common materials.</p>
<p>&#160;Living organisms are also powered by fuels or sunlight, and also make more of themselves from ordinary materials. But unlike <a class="thought" href="entries/assembler_entry.html">assembler</a>-based <a class="thought" href="entries/system_entry.html">system</a>s, they cannot make "almost anything".</p>
<p>&#160;Genetic <a class="thought" href="entries/evolution_entry.html">evolution</a> has limited <a class="thought" href="entries/life_entry.html">life</a> to a <a class="thought" href="entries/system_entry.html">system</a> based on <a class="thought" href="entries/dna_entry.html">DNA</a>, <a class="thought" href="entries/rna_entry.html">RNA</a>, and ribosomes, but memetic <a class="thought" href="entries/evolution_entry.html">evolution</a> will bring <a class="thought" href="entries/life_entry.html">life</a>-like <a class="thought" href="entries/machine_entry.html">machine</a>s based on nanocomputers and <a class="thought" href="entries/assembler_entry.html">assembler</a>s. I have already described how <a class="thought" href="entries/assembler_entry.html">assembler</a>-built molecular <a class="thought" href="entries/machine_entry.html">machine</a>s will differ from the ribosome-built <a class="thought" href="entries/machine_entry.html">machine</a>ry of <a class="thought" href="entries/life_entry.html">life</a>. <a class="thought" href="entries/assembler_entry.html">Assembler</a>s will be able to build all that ribosomes can, and more; <a class="thought" href="entries/assembler_entry.html">assembler</a>-based replicators will therefore be able to do all that <a class="thought" href="entries/life_entry.html">life</a> can, and more. From an <a class="thought" href="entries/evolution_entry.html">evolution</a>ary point of view, this poses an obvious threat to otters, people, cacti, and ferns - to the rich fabric of the biosphere and all that we prize.</p>
<p>&#160;The early <a class="thought" href="entries/transistor_entry.html">transistor</a>ized <a class="thought" href="entries/computer_entry.html">computer</a>s soon beat the most advanced <a class="thought" href="entries/vacuum_entry.html">vacuum</a>-tube <a class="thought" href="entries/computer_entry.html">computer</a>s because they were based on superior <a class="thought" href="entries/device_entry.html">device</a>s. For the same <a class="thought" href="entries/reason_entry.html">reason</a>, early <a class="thought" href="entries/assembler_entry.html">assembler</a>-based replicators could beat the most advanced modern organisms. "Plants" with "leaves" no more efficient than today's solar cells could out-compete real plants, crowding the biosphere with an inedible foliage. Tough, omnivorous "<a class="thought" href="entries/bacteria_entry.html">bacteria</a>" could out-compete real <a class="thought" href="entries/bacteria_entry.html">bacteria</a>: they could spread like blowing pollen, replicate swiftly, and reduce the biosphere to dust in a <a class="thought" href="entries/matter_entry.html">matter</a> of days. Dangerous replicators could easily be too tough, small, and rapidly spreading to stop - at least if we made no preparation. We have trouble enough controlling viruses and fruit flies.</p>
<p>&#160;Among the cognoscenti of <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>, this threat has become known as the "gray goo problem." Though masses of uncontrolled replicators need not be gray or gooey, the term "gray goo" emphasizes that replicators able to obliterate <a class="thought" href="entries/life_entry.html">life</a> might be less inspiring than a single <a class="thought" href="entries/species_entry.html">species</a> of crabgrass. They might be "superior" in an <a class="thought" href="entries/evolution_entry.html">evolution</a>ary <a class="thought" href="entries/sense_entry.html">sense</a>, but this need not make them valuable. We have evolved to <a class="thought" href="entries/love_entry.html">love</a> a world rich in living things, ideas, and <a class="thought" href="entries/diversity_entry.html">diversity</a>, so there is no <a class="thought" href="entries/reason_entry.html">reason</a> to value gray goo merely because it could spread. Indeed, if we prevent it we will thereby prove <i>our</i> <a class="thought" href="entries/evolution_entry.html">evolution</a>ary superiority.</p>
<p>&#160;The gray goo threat makes one thing perfectly clear: we cannot afford certain kinds of accidents with replicating <a class="thought" href="entries/assembler_entry.html">assembler</a>s.</p>
<p>&#160;In Chapter 5, I described some of what advanced <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s will do for us, if we handle them properly. Ultimately, they will embody the patterns of <a class="thought" href="entries/thought_entry.html">thought</a> and make them flow at a pace no <a class="thought" href="entries/mammal_entry.html">mammal</a>'s <a class="thought" href="entries/brain_entry.html">brain</a> can match. <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s that work together as people do will be able to out-think not just individuals, but whole societies. Again, the <a class="thought" href="entries/evolution_entry.html">evolution</a> of genes has left <a class="thought" href="entries/life_entry.html">life</a> stuck. Again, the <a class="thought" href="entries/evolution_entry.html">evolution</a> of memes by <a class="thought" href="entries/human_entry.html">human</a> beings - and eventually by <a class="thought" href="entries/machine_entry.html">machine</a>s - will advance our <a class="thought" href="entries/hardware_entry.html">hardware</a> far beyond the limits of <a class="thought" href="entries/life_entry.html">life</a>. And again, from an <a class="thought" href="entries/evolution_entry.html">evolution</a>ary point of view this poses an obvious threat.</p>
<p>&#160;Knowledge can bring power, and power can bring <a class="thought" href="entries/knowledge_entry.html">knowledge</a>. Depending on their <a class="thought" href="entries/nature_entry.html">nature</a>s and their goals, advanced <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s might accumulate enough <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and power to displace us, if we don't prepare properly. And as with replicators, mere <a class="thought" href="entries/evolution_entry.html">evolution</a>ary "superiority" need not make the victors better than the vanquished by any standard but brute competitive ability.</p>
<p>&#160;This threat makes one thing perfectly clear: we need to find ways to live with <a class="thought" href="entries/thinking_entry.html">thinking</a> <a class="thought" href="entries/machine_entry.html">machine</a>s, to make them law-abiding citizens.</p><h1><a class="thought" href="entries/engine_entry.html">Engine</a>s of Power</h1><p>Certain kinds of replicators and <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s may confront us with forms of <a class="thought" href="entries/hardware_entry.html">hardware</a> capable of swift, effective, independent <a class="thought" href="entries/action_entry.html">action</a>. But the novelty of this threat - coming from the <a class="thought" href="entries/machine_entry.html">machine</a>s themselves - must not blind us to a more traditional danger. Replicators and <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s can also serve as great <a class="thought" href="entries/engine_entry.html">engine</a>s of power, if wielded freely by sovereign states.</p>
<p>&#160;Throughout <a class="thought" href="entries/history_entry.html">history</a>, states have developed technologies to extend their <a class="thought" href="entries/military_entry.html">military</a> power, and states will no doubt play a dominant role in developing replicators and <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s. States could use replicating <a class="thought" href="entries/assembler_entry.html">assembler</a>s to build arsenals of advanced weapons, swiftly, easily, and in vast quantity. States could use special replicators directly to wage a sort of germ <a class="thought" href="entries/warfare_entry.html">warfare</a> - one made vastly more practical by <a class="thought" href="entries/program_entry.html">program</a>mable, <a class="thought" href="entries/computer_entry.html">computer</a>-controlled "germs." Depending on their skills, <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s could serve as weapon designers, strategists, or fighters. <a class="thought" href="entries/military_entry.html">Military</a> funds already support <a class="thought" href="entries/research_entry.html">research</a> in both molecular <a class="thought" href="entries/technology_entry.html">technology</a> and <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>.</p>
<p>&#160;States could use <a class="thought" href="entries/assembler_entry.html">assembler</a>s or advanced <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s to achieve sudden, destabilizing breakthroughs. I earlier discussed <a class="thought" href="entries/reason_entry.html">reason</a>s for expecting that the advent of replicating <a class="thought" href="entries/assembler_entry.html">assembler</a>s will bring relatively sudden changes: Able to replicate swiftly, they could become abundant in a <a class="thought" href="entries/matter_entry.html">matter</a> of days. Able to make almost anything, they could be <a class="thought" href="entries/program_entry.html">program</a>med to duplicate existing weapons, but made from superior materials. Able to work with standard, well-understood <a class="thought" href="entries/component_entry.html">component</a>s (atoms) they could suddenly build things designed in anticipation of the <a class="thought" href="entries/assembler_entry.html">assembler</a> breakthrough. These results of design-ahead could include <a class="thought" href="entries/program_entry.html">program</a>mable germs and other nasty novelties. For all these <a class="thought" href="entries/reason_entry.html">reason</a>s, a state that makes the <a class="thought" href="entries/assembler_entry.html">assembler</a> breakthrough could rapidly create a decisive <a class="thought" href="entries/military_entry.html">military</a> force - if not literally overnight, then at least with unprecedented speed.</p>
<p>&#160;States could use advanced <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s to similar ends. Automated <a class="thought" href="entries/engine_entry.html">engine</a>ering <a class="thought" href="entries/system_entry.html">system</a>s will facilitate design-ahead and speed <a class="thought" href="entries/assembler_entry.html">assembler</a> development. Al <a class="thought" href="entries/system_entry.html">system</a>s able to build better <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s will allow an explosion of capability with effects hard to anticipate. Both <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s and replicating <a class="thought" href="entries/assembler_entry.html">assembler</a>s will enable states to expand their <a class="thought" href="entries/military_entry.html">military</a> capabilities by orders of magnitude in a brief <a class="thought" href="entries/time_entry.html">time</a>.</p>
<p>&#160;Replicators can be more potent than nuclear weapons: to devastate <a class="thought" href="entries/earth_entry.html">Earth</a> with bombs would require masses of exotic <a class="thought" href="entries/hardware_entry.html">hardware</a> and rare isotopes, but to destroy all <a class="thought" href="entries/life_entry.html">life</a> with replicators would require only a single speck made of ordinary <a class="thought" href="entries/element_entry.html">element</a>s. Replicators give nuclear war some company as a potential cause of <a class="thought" href="entries/extinction_entry.html">extinction</a>, giving a broader <a class="thought" href="entries/context_entry.html">context</a> to <a class="thought" href="entries/extinction_entry.html">extinction</a> as a moral concern.</p>
<p>&#160;Despite their potential as <a class="thought" href="entries/engine_entry.html">engine</a>s of destruction, <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> and <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s will lend themselves to more subtle uses than do nuclear weapons. A bomb can only blast things, but nanomachines and <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s could be used to infiltrate, seize, change, and govern a territory or a world. Even the most ruthless police have no use for nuclear weapons, but they do have use for bugs, drugs, assassins, and other flexible <a class="thought" href="entries/engine_entry.html">engine</a>s of power. With advanced <a class="thought" href="entries/technology_entry.html">technology</a>, states will be able to consolidate their power over people.</p>
<p>&#160;Like genes, memes, organisms, and <a class="thought" href="entries/hardware_entry.html">hardware</a>, states have evolved. Their institutions have spread (with variations) through <a class="thought" href="entries/growth_entry.html">growth</a>, fission, imitation, and conquest. States at war fight like beasts, but using citizens as their bones, brains, and muscle. The coming breakthroughs will confront states with new pressures and opportunities, encouraging sharp changes in how states behave. This naturally gives cause for concern. States have, historically, excelled at slaughter and oppression.</p>
<p>&#160;In a <a class="thought" href="entries/sense_entry.html">sense</a>, a state is simply the sum of the people making up its organizational apparatus: their <a class="thought" href="entries/action_entry.html">action</a>s add up to make its <a class="thought" href="entries/action_entry.html">action</a>s. But the same might be said of a dog and its cells, though a dog is clearly more than just a clump of cells. Both dogs and states are evolved <a class="thought" href="entries/system_entry.html">system</a>s, with structures that affect how their parts behave. For thousands of years, dogs have evolved largely to please people, because they have survived and reproduced at <a class="thought" href="entries/human_entry.html">human</a> whim. For thousands of years, states have evolved under other selective pressures. Individuals have far more power over their dogs than they do over "their" states. Though states, too, can benefit from pleasing people, their very existence has depended on their capability for <i>using</i> people, whether as leaders, police, or soldiers.</p>
<p>&#160;It may seem paradoxical to say that people have limited power over states: After all, aren't people behind a state's every <a class="thought" href="entries/action_entry.html">action</a>? But in democracies, heads of state bemoan their lack of power, representatives bow to interest groups, bureaucrats are bound by rules, and voters, allegedly in charge, curse the whole mess. The state acts and people affect it, yet no one can claim to control it. In totalitarian states, the apparatus of power has a tradition, structure, and inner <a class="thought" href="entries/logic_entry.html">logic</a> that leaves no one free, neither the rulers nor the ruled. Even kings had to act in ways limited by the traditions of monarchy and the practicalities of power, if they were to remain kings. States are not <a class="thought" href="entries/human_entry.html">human</a>, though they are made of humans.</p>
<p>&#160;Despite this, <a class="thought" href="entries/history_entry.html">history</a> shows that change is possible, even change for the better. But changes always move from one semi-autonomous, inhuman <a class="thought" href="entries/system_entry.html">system</a> to another - equally inhuman but perhaps more humane. In our hope for improvements, we must not confuse states that wear a <a class="thought" href="entries/human_entry.html">human</a> face with states that have humane institutions.</p>
<p>&#160;Describing states as quasi-organisms captures only one aspect of a complex reality, yet it suggests how they may evolve in response to the coming breakthroughs. The <a class="thought" href="entries/growth_entry.html">growth</a> of <a class="thought" href="entries/government_entry.html">government</a> power, most spectacular in totalitarian countries, suggests one direction.</p>
<p>&#160;States could become more like organisms by dominating their parts more completely. Using replicating <a class="thought" href="entries/assembler_entry.html">assembler</a>s, states could fill the <a class="thought" href="entries/human_entry.html">human</a> environment with miniature surveillance <a class="thought" href="entries/device_entry.html">device</a>s. Using an abundance of speech-understanding <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s, they could listen to everyone without employing half the population as listeners. Using <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> like that proposed for <a class="thought" href="entries/cell_entry.html">cell</a> repair <a class="thought" href="entries/machine_entry.html">machine</a>s, they could cheaply tranquilize, lobotomize, or otherwise modify entire populations. This would simply extend an all too familiar pattern. The world already holds <a class="thought" href="entries/government_entry.html">government</a>s that spy, torture, and drug; advanced <a class="thought" href="entries/technology_entry.html">technology</a> will merely extend the possibilities.</p>
<p>&#160;But with advanced <a class="thought" href="entries/technology_entry.html">technology</a>, states need not control people - they could instead simply <i>discard</i> people. Most people in most states, after all, function either as workers, larval workers, or worker-rearers, and most of these workers make, move, or grow things. A state with replicating <a class="thought" href="entries/assembler_entry.html">assembler</a>s would not need such work. What is more, advanced <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s could replace <a class="thought" href="entries/engine_entry.html">engine</a>ers, scientists, administrators, and even leaders. The combination of <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> and advanced <a class="thought" href="entries/ai_entry.html">AI</a> will make possible intelligent, effective robots; with such robots, a state could prosper while discarding anyone, or even (in principle) everyone.</p>
<p>&#160;The implications of this possibility depend on whether the state exists to serve the people, or the people exist to serve the state.</p>
<p>&#160;In the first case, we have a state shaped by <a class="thought" href="entries/human_entry.html">human</a> beings to serve general <a class="thought" href="entries/human_entry.html">human</a> purposes; democracies tend to be at least rough approximations to this ideal. If a democratically controlled <a class="thought" href="entries/government_entry.html">government</a> loses its need for people, this will basically mean that it no longer needs to use people as bureaucrats or taxpayers. This will open new possibilities, some of which may prove desirable.</p>
<p>&#160;In the second case, we have a state evolved to exploit <a class="thought" href="entries/human_entry.html">human</a> beings, perhaps along totalitarian lines. States have needed people as workers because <a class="thought" href="entries/human_entry.html">human</a> labor has been the necessary foundation of power. What is more, genocide has been expensive and troublesome to organize and execute. Yet, in this century totalitarian states have slaughtered their citizens by the millions. Advanced <a class="thought" href="entries/technology_entry.html">technology</a> will make workers unnecessary and genocide easy. <a class="thought" href="entries/history_entry.html">History</a> suggests that totalitarian states may then eliminate people wholesale. There is some consolation in this. It seems likely that a state willing and able to enslave us <a class="thought" href="entries/biological_entry.html">biological</a>ly would instead simply kill us.</p>
<p>&#160;The threat of advanced <a class="thought" href="entries/technology_entry.html">technology</a> in the hands of <a class="thought" href="entries/government_entry.html">government</a>s makes one thing perfectly clear: we cannot afford to have an oppressive state take the lead in the coming breakthroughs.</p>
<p>&#160;The <a class="thought" href="entries/basic_entry.html">basic</a> problems I have outlined are obvious: in the <a class="thought" href="entries/future_entry.html">future</a>, as in the past, new technologies will lend themselves to accidents and abuse. Since replicators and <a class="thought" href="entries/thinking_entry.html">thinking</a> <a class="thought" href="entries/machine_entry.html">machine</a>s will bring great new powers, the potential for accidents and abuse will likewise be great. These possibilities pose genuine threats to our lives.</p>
<p>&#160;Most people would like a chance to live and be free to choose how to live. This goal may not sound too <a class="thought" href="entries/utopian_entry.html">utopian</a>, at least in some parts of the world. It doesn't mean forcing everyone's <a class="thought" href="entries/life_entry.html">life</a> to fit some grand scheme; it chiefly means avoiding enslavement and <a class="thought" href="entries/death_entry.html">death</a>. Yet, like the achievement of a <a class="thought" href="entries/utopian_entry.html">utopian</a> <a class="thought" href="entries/dream_entry.html">dream</a>, it will bring a <a class="thought" href="entries/future_entry.html">future</a> of wonders.</p>
<p>&#160;Given these <a class="thought" href="entries/life_entry.html">life</a>-and-<a class="thought" href="entries/death_entry.html">death</a> problems and this general goal, we can consider what measures might help us succeed. Our strategy must involve people, principles, and institutions, but it must also rest on tactics which inevitably will involve <a class="thought" href="entries/technology_entry.html">technology</a>.</p><h1>Trustworthy <a class="thought" href="entries/system_entry.html">System</a>s</h1><p>To use such powerful technologies in safety, we must make <a class="thought" href="entries/hardware_entry.html">hardware</a> we can trust. To have trust, we must be able to judge technical facts accurately, an ability that will in turn depend partly on the quality of our institutions for judgment. More fundamentally, though, it will depend on whether trustworthy <a class="thought" href="entries/hardware_entry.html">hardware</a> is physically possible. This is a <a class="thought" href="entries/matter_entry.html">matter</a> of the reliability of <a class="thought" href="entries/component_entry.html">component</a>s and of <a class="thought" href="entries/system_entry.html">system</a>s.</p>
<p>&#160;We can often make reliable <a class="thought" href="entries/component_entry.html">component</a>s, even without <a class="thought" href="entries/assembler_entry.html">assembler</a>s to help. " Reliable" doesn't mean "indestructible" - anything will fail if placed close enough to a nuclear blast. It doesn't even mean "tough" - a television <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> may be reliable, yet not survive being bounced off a concrete floor. Rather, we call something reliable when we can count on it to work as designed.</p>
<p>&#160;A reliable <a class="thought" href="entries/component_entry.html">component</a> need not be a perfect embodiment of a perfect design: it need only be a good enough embodiment of a cautious enough design. A bridge <a class="thought" href="entries/engine_entry.html">engine</a>er may be uncertain about the strength of winds, the weight of traffic, and the strength of steel, but by assuming high winds, heavy traffic, and weak steel, the <a class="thought" href="entries/engine_entry.html">engine</a>er can design a bridge that will stand.</p>
<p>&#160;Unexpected failures in <a class="thought" href="entries/component_entry.html">component</a>s commonly stem from material flaws. But <a class="thought" href="entries/assembler_entry.html">assembler</a>s will build <a class="thought" href="entries/component_entry.html">component</a>s that have a negligible number of their atoms out of place - none, if need be. This will make them perfectly uniform and in a limited <a class="thought" href="entries/sense_entry.html">sense</a> perfectly reliable. Radiation will still cause damage, though, because a cosmic ray can unexpectedly knock atoms loose from anything. In a small enough <a class="thought" href="entries/component_entry.html">component</a> (even in a modern <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/memory_entry.html">memory</a> <a class="thought" href="entries/device_entry.html">device</a>), a single <a class="thought" href="entries/particle_entry.html">particle</a> of radiation can cause a failure.</p>
<p>
<b>[Addition to Web version of <a class="thought" href="entries/engines_of_creation_entry.html">Engines of Creation</a>:</b> A reader of this web version has noted a problem with the math in the following example. As an example of the value of <a class="thought" href="entries/hypertext_entry.html">hypertext</a> as discussed in Chapter 14 and in Eric Drexler's essay "<a class="thought" href="entries/hypertext_entry.html">Hypertext</a> Publishing and the <a class="thought" href="entries/evolution_entry.html">Evolution</a> of <a class="thought" href="entries/knowledge_entry.html">Knowledge</a>", this correspondence about the calculation can be read here. <b>]</b>
</p>
<p>But <a class="thought" href="entries/system_entry.html">system</a>s can work even when their parts fail; the key is redundancy. Imagine a bridge suspended from cables that fail randomly, each breaking about once a year at an unpredictable <a class="thought" href="entries/time_entry.html">time</a>. If the bridge falls when a cable breaks, it will be too dangerous to use. Imagine, though, that a broken cable takes a day to fix (because skilled repair crews with spare cables are on call), and that, though it takes five cables to support the bridge, there are actually <i>six</i>. Now if one cable breaks, the bridge will still stand. By clearing traffic and then replacing the failed cable, the bridge operators can restore safety. To destroy this bridge, a second cable must break in the same day as the first. Supported by six cables, each having a one-in-365 daily chance of breaking, the bridge will likely last about ten years.</p>
<p>&#160;While an improvement, this remains terrible. Yet a bridge with ten cables (five needed, five extra) will fall only if six cables break on the same day: the suspension <a class="thought" href="entries/system_entry.html">system</a> is likely to last over ten million years. With fifteen cables, the expected lifetime is over ten thousand times the age of the <a class="thought" href="entries/earth_entry.html">Earth</a>. Redundancy can bring an exponential explosion of safety.</p>
<p>&#160;Redundancy works best when the redundant <a class="thought" href="entries/component_entry.html">component</a>s are truly independent. If we don't trust the design process, then we must use <a class="thought" href="entries/component_entry.html">component</a>s designed independently; if a bomb, bullet, or cosmic ray may damage several neighboring parts, then we must spread redundant parts more widely. <a class="thought" href="entries/engine_entry.html">Engine</a>ers who want to supply reliable transportation between two islands shouldn't just add more cables to a bridge. They should build two well-separated bridges using different designs, then add a tunnel, a ferry, and a pair of inland airports.</p>
<p>&#160;Computer <a class="thought" href="entries/engine_entry.html">engine</a>ers also use redundancy. Stratus <a class="thought" href="entries/computer_entry.html">Computer</a> Inc., for example, makes a <a class="thought" href="entries/machine_entry.html">machine</a> that uses four <a class="thought" href="entries/central_processing_unit_entry.html">central processing unit</a>s (in two pairs) to do the work of one, but to do it vastly more reliably. Each pair is continually checked for internal consistency, and a failed pair can be replaced while its twin carries on.</p>
<p>&#160;An even more powerful form of redundancy is <i>design </i><a class="thought" href="entries/diversity_entry.html">diversity</a>. In <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/hardware_entry.html">hardware</a>, this means using several <a class="thought" href="entries/computer_entry.html">computer</a>s with <i>different</i> designs, all working in parallel. Now redundancy can correct not just for failures in a piece of <a class="thought" href="entries/hardware_entry.html">hardware</a>, but for errors in its design.</p>
<p>&#160;Much has been made of the problem of writing large, error-free <a class="thought" href="entries/program_entry.html">program</a>s; many people consider such <a class="thought" href="entries/program_entry.html">program</a>s impossible to develop and debug. But <a class="thought" href="entries/research_entry.html">research</a>ers at the UCLA <a class="thought" href="entries/computer_science_entry.html">Computer Science</a> Department have shown that design <a class="thought" href="entries/diversity_entry.html">diversity</a> can also be used in <a class="thought" href="entries/software_entry.html">software</a>: several <a class="thought" href="entries/program_entry.html">program</a>mers can tackle the same problem independently, then all their <a class="thought" href="entries/program_entry.html">program</a>s can be run in parallel and made to vote on the answer. This multiplies the cost of writing and running the <a class="thought" href="entries/program_entry.html">program</a>, but it makes the resulting <a class="thought" href="entries/software_entry.html">software</a> <a class="thought" href="entries/system_entry.html">system</a> resistant to the bugs that appear in some of its parts.</p>
<p>&#160;We can use redundancy to control replicators. Just as repair <a class="thought" href="entries/machine_entry.html">machine</a>s that compare multiple <a class="thought" href="entries/dna_entry.html">DNA</a> strands will be able to correct mutations in a <a class="thought" href="entries/cell_entry.html">cell</a>'s genes, so replicators that compare multiple copies of their instructions (or that use other effective error-correcting <a class="thought" href="entries/system_entry.html">system</a>s) will be able to resist mutation in these "genes." Redundancy can again bring an exponential explosion of safety.</p>
<p>&#160;We can build <a class="thought" href="entries/system_entry.html">system</a>s that are extremely reliable, but this will entail costs. Redundancy makes <a class="thought" href="entries/system_entry.html">system</a>s heavier, bulkier, more expensive, and less efficient. <a class="thought" href="entries/nanotechnology_entry.html">Nanotechnology</a>, though, will make most things far lighter, smaller, cheaper, and more efficient to begin with. This will make redundancy and reliability more practical.</p>
<p>&#160;Today, we are seldom willing to pay for the safest possible <a class="thought" href="entries/system_entry.html">system</a>s; we tolerate failures more-or-less willingly and seldom consider the real limits of reliability. This biases judgments of what can be achieved. A psychological factor also distorts our <a class="thought" href="entries/sense_entry.html">sense</a> of how reliable things can be made: failures stick in our minds, but everyday successes draw little attention. The <a class="thought" href="entries/media_entry.html">media</a> amplify this tendency by reporting the most dramatic failures from around the world, while ignoring the endless and boring successes. Worse yet, the <a class="thought" href="entries/component_entry.html">component</a>s of redundant <a class="thought" href="entries/system_entry.html">system</a>s may fail in visible ways, stirring alarums: imagine how the <a class="thought" href="entries/media_entry.html">media</a> would report a snapped bridge cable, even if the bridge were the super-safe fifteen-cable model described above. And since each added redundant <a class="thought" href="entries/component_entry.html">component</a> adds to the chance of a <a class="thought" href="entries/component_entry.html">component</a> failure, a <a class="thought" href="entries/system_entry.html">system</a>'s reliability can <i>seem</i> worse even as it approaches perfection.</p>
<p>&#160;Appearances aside, redundant <a class="thought" href="entries/system_entry.html">system</a>s made of abundant, flawless <a class="thought" href="entries/component_entry.html">component</a>s can often be made almost perfectly reliable. Redundant <a class="thought" href="entries/system_entry.html">system</a>s spread over wide enough spaces will survive even bullets and bombs.</p>
<p>&#160;But what about design errors? Having a dozen redundant parts will do no good if they share a fatal error in design. Design <a class="thought" href="entries/diversity_entry.html">diversity</a> is one answer; good testing is another. We can reliably evolve good designs without being reliably good designers: we need only be good at testing, good at tinkering, and good at being patient. <a class="thought" href="entries/nature_entry.html">Nature</a> has evolved working molecular <a class="thought" href="entries/machine_entry.html">machine</a>ry through entirely mindless tinkering and testing. Having minds, we can do as well or better.</p>
<p>&#160;We will find it easy to design reliable <a class="thought" href="entries/hardware_entry.html">hardware</a> if we can develop reliable automated <a class="thought" href="entries/engine_entry.html">engine</a>ering <a class="thought" href="entries/system_entry.html">system</a>s. But this raises the wider issue of developing trustworthy <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> <a class="thought" href="entries/system_entry.html">system</a>s. We will have little trouble making <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s with reliable <a class="thought" href="entries/hardware_entry.html">hardware</a>, but what about their <a class="thought" href="entries/software_entry.html">software</a>?</p>
<p>&#160;Like present <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s and <a class="thought" href="entries/human_entry.html">human</a> minds, advanced <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s will be synergistic combinations of many simpler parts. Each part will be more specialized and less intelligent than the <a class="thought" href="entries/system_entry.html">system</a> as a whole. Some parts will look for patterns in pictures, sounds, and other <a class="thought" href="entries/data_entry.html">data</a> and suggest what they might mean. Other parts will compare and judge the suggestions of these parts. Just as the pattern recognizers in the <a class="thought" href="entries/human_entry.html">human</a> visual <a class="thought" href="entries/system_entry.html">system</a> suffer from errors and optical illusions, so will the pattern recognizers in <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s. (Indeed, some advanced <a class="thought" href="entries/machine_entry.html">machine</a> vision <a class="thought" href="entries/system_entry.html">system</a>s already suffer from familiar optical illusions.) And just as other parts of the <a class="thought" href="entries/human_entry.html">human</a> mind can often identify and compensate for illusions, so will other parts of <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s.</p>
<p>&#160;As in <a class="thought" href="entries/human_entry.html">human</a> minds, <a class="thought" href="entries/intelligence_entry.html">intelligence</a> will involve mental parts that make shaky guesses and other parts that discard most of the bad guesses before they draw much attention or affect important decisions. Mental parts that reject <a class="thought" href="entries/action_entry.html">action</a> ideas on ethical grounds correspond to what we call a <a class="thought" href="entries/conscience_entry.html">conscience</a>. <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s with many parts will have room for redundancy and design <a class="thought" href="entries/diversity_entry.html">diversity</a>, making reliability possible.</p>
<p>&#160;A genuine, flexible <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a> must evolve ideas. To do this, it must find or form hypotheses, generate variations, test them, and then modify or discard those found inadequate. Eliminating any of these abilities would make it stupid, stubborn, or insane ("Durn <a class="thought" href="entries/machine_entry.html">machine</a> can't think and won't learn from its mistakes - junk it!"). To avoid becoming trapped by initial misconceptions, it will have to consider conflicting views, seeing how well each explains the <a class="thought" href="entries/data_entry.html">data</a>, and seeing whether one view can explain another.</p>
<p>&#160;Scientific communities go through a similar process. And in a paper called "The Scientific Community Metaphor," William A. Kornfeld and Carl Hewitt of the MIT <a class="thought" href="entries/ai_entry.html">Artificial Intelligence</a> Laboratory suggest that <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a>ers model their <a class="thought" href="entries/program_entry.html">program</a>s still more closely on the evolved structure of the scientific community. They point to the pluralism of <a class="thought" href="entries/science_entry.html">science</a>, to its <a class="thought" href="entries/diversity_entry.html">diversity</a> of competing proposers, supporters, and critics. Without proposers, ideas cannot appear; without supporters, they cannot grow; and without critics to weed them, bad ideas can crowd out the good. This holds true in <a class="thought" href="entries/science_entry.html">science</a>, in <a class="thought" href="entries/technology_entry.html">technology</a>, in <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s, and among the parts of our own minds.</p>
<p>&#160;Having a world full of diverse and redundant proposers, supporters, and critics is what makes the advance of <a class="thought" href="entries/science_entry.html">science</a> and <a class="thought" href="entries/technology_entry.html">technology</a> reliable. Having more proposers makes good proposals more common; having more critics makes bad proposals more vulnerable. Better, more numerous ideas are the result. A similar form of redundancy can help <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s to develop sound ideas.</p>
<p>&#160;People sometimes guide their <a class="thought" href="entries/action_entry.html">action</a>s by standards of truth and <a class="thought" href="entries/ethics_entry.html">ethics</a>, and we should be able to evolve <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s that do likewise, but more reliably. Able to think a million times faster than us, they will have more <a class="thought" href="entries/time_entry.html">time</a> for second <a class="thought" href="entries/thought_entry.html">thought</a>s. It seems that <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s can be made trustworthy, at least by <a class="thought" href="entries/human_entry.html">human</a> standards.</p>
<p>&#160;I have often compared <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s to individual <a class="thought" href="entries/human_entry.html">human</a> minds, but the resemblance need not be close. A <a class="thought" href="entries/system_entry.html">system</a> that can mimic a person may need to be personlike, but an automated <a class="thought" href="entries/engine_entry.html">engine</a>ering <a class="thought" href="entries/system_entry.html">system</a> probably doesn't. One proposal (called an Agora <a class="thought" href="entries/system_entry.html">system</a>, after the Greek term for a meeting and market place) would consist of many independent pieces of <a class="thought" href="entries/software_entry.html">software</a> that interact by offering one another services in exchange for money. Most pieces would be simpleminded specializts, some able to suggest a design change, and others able to analyze one. Much as <a class="thought" href="entries/earth_entry.html">Earth</a>'s <a class="thought" href="entries/ecology_entry.html">ecology</a> has evolved extraordinary organisms, so this <a class="thought" href="entries/computer_entry.html">computer</a> economy could evolve extraordinary designs - and perhaps in a comparably mindless fashion. What is more, since the <a class="thought" href="entries/system_entry.html">system</a> would be spread over many <a class="thought" href="entries/machine_entry.html">machine</a>s and have parts written by many people, it could be diverse, robust, and hard for any group to seize and abuse.</p>
<p>&#160;Eventually, one way or another, automated <a class="thought" href="entries/engine_entry.html">engine</a>ering <a class="thought" href="entries/system_entry.html">system</a>s will be able to design things more reliably than any group of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/engine_entry.html">engine</a>ers can today. Our challenge will be to design them correctly. We will need <a class="thought" href="entries/human_entry.html">human</a> institutions that reliably develop reliable <a class="thought" href="entries/system_entry.html">system</a>s.</p>
<p>&#160;Human institutions are evolved artificial <a class="thought" href="entries/system_entry.html">system</a>s, and they can often solve problems that their individual members cannot. This makes them a sort of "<a class="thought" href="entries/ai_entry.html">artificial intelligence</a> <a class="thought" href="entries/system_entry.html">system</a>." Corporations, armies, and <a class="thought" href="entries/research_entry.html">research</a> laboratories all are examples, as are the looser structures of the market and the scientific community. Even <a class="thought" href="entries/government_entry.html">government</a>s may be seen as <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> <a class="thought" href="entries/system_entry.html">system</a>s - gross, sluggish, and befuddled, yet superhuman in their sheer capability. And what are constitutional checks and balances but an attempt to increase a <a class="thought" href="entries/government_entry.html">government</a>'s reliability through institutional <a class="thought" href="entries/diversity_entry.html">diversity</a> and redundancy? When we build intelligent <a class="thought" href="entries/machine_entry.html">machine</a>s, we will use them to check and balance one another.</p>
<p>&#160;By applying the sane principles, we may be able to develop reliable, technically oriented institutions having strong checks and balances, then use these to guide the development of the <a class="thought" href="entries/system_entry.html">system</a>s we will need to handle the coming breakthroughs.</p><h1>Tactics for the <a class="thought" href="entries/assembler_entry.html">Assembler</a> Breakthrough</h1><p>Some force in the world (whether trustworthy or not) will take the lead in developing <a class="thought" href="entries/assembler_entry.html">assembler</a>s; call it the "leading force." Because of the strategic importance of <a class="thought" href="entries/assembler_entry.html">assembler</a>s, the leading force will presumably be some organization or institution that is effectively controlled by some <a class="thought" href="entries/government_entry.html">government</a> or group of <a class="thought" href="entries/government_entry.html">government</a>s. To simplify <a class="thought" href="entries/matter_entry.html">matter</a>s, pretend for the moment that we (the good guys, attempting to be wise) can make policy for the leading force. For citizens of democratic states, this seems a good attitude to take.</p>
<p>&#160;What should we do to improve our chances of reaching a <a class="thought" href="entries/future_entry.html">future</a> worth living in? What <i>can</i> we do?</p>
<p>&#160;We can begin with what must <i>not</i> happen: we must not let a single replicating <a class="thought" href="entries/assembler_entry.html">assembler</a> of the wrong kind be loosed on an unprepared world. Effective preparations seem possible (as I will describe), but it seems that they must be based on <a class="thought" href="entries/assembler_entry.html">assembler</a>-built <a class="thought" href="entries/system_entry.html">system</a>s that can be built only after dangerous replicators have already become possible. Design-ahead can help the leading force prepare, yet even vigorous, foresighted <a class="thought" href="entries/action_entry.html">action</a> seems inadequate to prevent a <a class="thought" href="entries/time_entry.html">time</a> of danger. The <a class="thought" href="entries/reason_entry.html">reason</a> is straightforward: dangerous replicators will be far simpler to design than <a class="thought" href="entries/system_entry.html">system</a>s that can thwart them, just as a bacterium is far simpler than an <a class="thought" href="entries/immune_system_entry.html">immune system</a>. We will need tactics for containing <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> while we learn how to tame it.</p>
<p>&#160;One obvious tactic is isolation: the leading force will be able to contain replicator <a class="thought" href="entries/system_entry.html">system</a>s behind multiple walls or in laboratories in <a class="thought" href="entries/space_entry.html">space</a>. Simple replicators will have no <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, and they won't be designed to escape and run wild. Containing them seems no great challenge.</p>
<p>&#160;Better yet, we will be able to design replicators that <i>can't</i> escape and run wild. We can build them with counters (like those in cells) that limit them to a fixed number of replications. We can build them to have requirements for special synthetic "vitamins," or for bizarre environments found only in the laboratory. Though replicators could be made tougher and more voracious than any modern pests, we can also make them useful but harmless. Because we will design them from scratch, replicators need not have the <a class="thought" href="entries/element_entry.html">element</a>ary survival skills that <a class="thought" href="entries/evolution_entry.html">evolution</a> has built into living cells.</p>
<p>&#160;Further, they need not be able to evolve. We can give replicators redundant copies of their "genetic" instructions, along with repair mechanisms to correct any mutations. We can design them to stop working long before enough damage accumulates to make a lasting mutation a significant possibility. Finally, we can design them in ways that would hamper <a class="thought" href="entries/evolution_entry.html">evolution</a> even if mutations <i>could</i> occur.</p>
<p>&#160;Experiments show that most <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/program_entry.html">program</a>s (other than specially designed <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/program_entry.html">program</a>s, such as Dr. Lenat's <a class="thought" href="entries/eurisko_entry.html">EURISKO</a>) seldom respond to mutations by changing slightly; instead, they simply fail. Because they cannot vary in useful ways, they cannot evolve. Unless they are specially designed, replicators directed by nanocomputers will share this handicap. Modern organisms are fairly good at evolving partly because they descend from ancestors that evolved. They are evolved to evolve; this is one <a class="thought" href="entries/reason_entry.html">reason</a> for the complexities of sexual reproduction and the shuffling of <a class="thought" href="entries/chromosome_entry.html">chromosome</a> segments during the production of sperm and egg cells. We can simply neglect to give replicators similar talents.</p>
<p>&#160;It will be easy for the leading force to make replicating <a class="thought" href="entries/assembler_entry.html">assembler</a>s useful, harmless, and stable. Keeping <a class="thought" href="entries/assembler_entry.html">assembler</a>s from being stolen and abused is a different and greater problem, because it will be a game played against intelligent opponents. As one tactic, we can reduce the incentive to steal <a class="thought" href="entries/assembler_entry.html">assembler</a>s by making them available in safe forms. This will also reduce the incentive for other groups to develop <a class="thought" href="entries/assembler_entry.html">assembler</a>s independently. The leading force, after all, will be followed by trailing forces.</p><h1>Limited <a class="thought" href="entries/assembler_entry.html">Assembler</a>s</h1><p>In Chapter 4, I described how a <a class="thought" href="entries/system_entry.html">system</a> of <a class="thought" href="entries/assembler_entry.html">assembler</a>s in a vat could build an excellent rocket <a class="thought" href="entries/engine_entry.html">engine</a>. I also pointed out that we will be able to make <a class="thought" href="entries/assembler_entry.html">assembler</a> <a class="thought" href="entries/system_entry.html">system</a>s that act like seeds, absorbing sunlight and ordinary materials and growing to become almost anything. These special-purpose <a class="thought" href="entries/system_entry.html">system</a>s will not replicate themselves, or will do so only a fixed number of times. They will make only what they were <a class="thought" href="entries/program_entry.html">program</a>med to make, <i>when</i> they are told to make it. Anyone lacking special <a class="thought" href="entries/assembler_entry.html">assembler</a>-built tools would be unable to reprogram them to serve other purposes.</p>
<p>&#160;Using limited <a class="thought" href="entries/assembler_entry.html">assembler</a>s of this sort, people will be able to make as much as they want of whatever they want, subject to limits built into the <a class="thought" href="entries/machine_entry.html">machine</a>s. If none is <a class="thought" href="entries/program_entry.html">program</a>med to make nuclear weapons, none will; if none is <a class="thought" href="entries/program_entry.html">program</a>med to make dangerous replicators, none will. If some are <a class="thought" href="entries/program_entry.html">program</a>med to make houses, cars, <a class="thought" href="entries/computer_entry.html">computer</a>s, toothbrushes, and whatnot, then these products can become cheap and abundant. <a class="thought" href="entries/machine_entry.html">Machine</a>s built by limited <a class="thought" href="entries/assembler_entry.html">assembler</a>s will enable us to open <a class="thought" href="entries/space_entry.html">space</a>, heal the biosphere, and repair <a class="thought" href="entries/human_entry.html">human</a> cells. Limited <a class="thought" href="entries/assembler_entry.html">assembler</a>s can bring almost unlimited wealth to the people of the world.</p>
<p>&#160;This tactic will ease the moral pressure to make unlimited <a class="thought" href="entries/assembler_entry.html">assembler</a>s available immediately. But limited <a class="thought" href="entries/assembler_entry.html">assembler</a>s will still leave legitimate needs unfulfilled. Scientists will need freely <a class="thought" href="entries/program_entry.html">program</a>mable <a class="thought" href="entries/assembler_entry.html">assembler</a>s to conduct studies; <a class="thought" href="entries/engine_entry.html">engine</a>ers will need them to test designs. These needs can be served by sealed <a class="thought" href="entries/assembler_entry.html">assembler</a> laboratories.</p><h1>Sealed <a class="thought" href="entries/assembler_entry.html">Assembler</a> Laboratories</h1><p>Picture a <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/access_entry.html">access</a>ory the size of your thumb, with a state-of-the-<a class="thought" href="entries/art_entry.html">art</a> plug on its bottom. Its surface looks like boring gray plastic, imprinted with a serial number, yet this sealed <a class="thought" href="entries/assembler_entry.html">assembler</a> lab is an <a class="thought" href="entries/assembler_entry.html">assembler</a>-built object that contains many things. Inside, sitting above the plug, is a large nanoelectronic <a class="thought" href="entries/computer_entry.html">computer</a> running advanced molecular-simulation <a class="thought" href="entries/software_entry.html">software</a> (based on the <a class="thought" href="entries/software_entry.html">software</a> developed during <a class="thought" href="entries/assembler_entry.html">assembler</a> development). With the <a class="thought" href="entries/assembler_entry.html">assembler</a> lab plugged in and turned on, your <a class="thought" href="entries/assembler_entry.html">assembler</a>-built home <a class="thought" href="entries/computer_entry.html">computer</a> displays a three-dimensional picture of whatever the lab <a class="thought" href="entries/computer_entry.html">computer</a> is simulating, representing atoms as colored spheres. With a joystick, you can direct the simulated <a class="thought" href="entries/assembler_entry.html">assembler</a> arm to build things. <a class="thought" href="entries/program_entry.html">Program</a>s can move the arm faster, building elaborate structures on the screen in the blink of an eye. The simulation always works perfectly, because the nanocomputer cheats: as you make the simulated arm move simulated <a class="thought" href="entries/molecule_entry.html">molecule</a>s, the <a class="thought" href="entries/computer_entry.html">computer</a> directs an actual arm to move actual <a class="thought" href="entries/molecule_entry.html">molecule</a>s. It then checks the results whenever needed to correct its calculations.</p>
<p>&#160;The end of this thumb-sized object holds a sphere built in many concentric layers. Fine wires carry power and signals through the layers; these let the nanocomputer in the base communicate with the <a class="thought" href="entries/device_entry.html">device</a>s at the sphere's center. The outermost layer consists of sensors. Any attempt to remove or puncture it triggers a signal to a layer near the core. The next layer in is a thick spherical shell of prestressed diamond composite, with its outer layers stretched and its inner layers compressed. This surrounds a layer of thermal insulator which in turn surrounds a peppercorn-sized spherical shell made up of microscopic, carefully arranged blocks of metal and oxidizer. These are laced with electrical igniters. The outer sensor layer, if punctured, triggers these igniters. The metal-and-oxidizer demolition charge then burns in a fraction of a second, producing a gas of metal oxides denser than water and almost as hot as the surface of the Sun. But the blaze is tiny; it swiftly cools, and the diamond sphere confines its great pressure.</p>
<p>&#160;This demolition charge surrounds a smaller composite shell, which surrounds another layer of sensors, which can also trigger the demolition charge. These sensors surround the cavity which contains the actual sealed <a class="thought" href="entries/assembler_entry.html">assembler</a> lab.</p>
<p>&#160;These elaborate precautions justify the term "sealed." Someone outside cannot open the lab <a class="thought" href="entries/space_entry.html">space</a> without destroying the <a class="thought" href="entries/content_entry.html">content</a>s, and <i>no <a class="thought" href="entries/assembler_entry.html">assembler</a>s or </i><a class="thought" href="entries/assembler_entry.html">assembler</a><i>-built structures can escape from within</i>. The <a class="thought" href="entries/system_entry.html">system</a> is designed to let out <a class="thought" href="entries/information_entry.html">information</a>, but not dangerous replicators or dangerous tools. Each sensor layer consists of many redundant layers of sensors, each <i>intended</i> to detect any possible penetration, and each making up for possible flaws in the others. Penetration, by triggering the demolition charge, raises the lab to a temperature beyond the melting point of all possible substances and makes the survival of a dangerous <a class="thought" href="entries/device_entry.html">device</a> impossible. These protective mechanisms all gang up on something about a millionth their size - that is, on whatever will fit in the lab, which provides a spherical work <a class="thought" href="entries/space_entry.html">space</a> no wider than a <a class="thought" href="entries/human_entry.html">human</a> hair.</p>
<p>&#160;Though small by ordinary standards, this work <a class="thought" href="entries/space_entry.html">space</a> holds room enough for millions of <a class="thought" href="entries/assembler_entry.html">assembler</a>s and thousands of trillions of atoms. These sealed labs will let people build and test <a class="thought" href="entries/device_entry.html">device</a>s, even voracious replicators, in complete safety. Children will use the atoms inside them as a construction <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> with almost unlimited parts. Hobbyists will exchange <a class="thought" href="entries/program_entry.html">program</a>s for building various gadgets. <a class="thought" href="entries/engine_entry.html">Engine</a>ers will build and test new <a class="thought" href="entries/nanotechnology_entry.html">nanotech</a>nologies. Chemists, materials scientists, and biologists will build apparatus and run experiments. In labs built around <a class="thought" href="entries/biological_entry.html">biological</a> samples, biomedical <a class="thought" href="entries/engine_entry.html">engine</a>ers will develop and test early <a class="thought" href="entries/cell_entry.html">cell</a> repair <a class="thought" href="entries/machine_entry.html">machine</a>s.</p>
<p>&#160;In the course of this work, people will naturally develop useful designs, whether for <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/circuit_entry.html">circuit</a>s, strong materials, medical <a class="thought" href="entries/device_entry.html">device</a>s, or whatever. After a public review of their safety, these things could be made available outside the sealed labs by <a class="thought" href="entries/program_entry.html">program</a>ming limited <a class="thought" href="entries/assembler_entry.html">assembler</a>s to make them. Sealed labs and limited <a class="thought" href="entries/assembler_entry.html">assembler</a>s will form a <a class="thought" href="entries/complementary_entry.html">complementary</a> pair: The first will let us invent freely; the second will let us enjoy the fruits of our <a class="thought" href="entries/invention_entry.html">invention</a> safely. The chance to pause between design and release will help us avoid deadly surprises.</p>
<p>&#160;Sealed <a class="thought" href="entries/assembler_entry.html">assembler</a> labs will enable the whole of society to apply its <a class="thought" href="entries/creativity_entry.html">creativity</a> to the problems of <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>. And this will speed our preparations for the <a class="thought" href="entries/time_entry.html">time</a> when an independent force learns how to build something nasty.</p><h1>Hiding <a class="thought" href="entries/information_entry.html">Information</a></h1><p>In another tactic for buying <a class="thought" href="entries/time_entry.html">time</a>, the leading force can attempt to burn the bridge it built from bulk to molecular <a class="thought" href="entries/technology_entry.html">technology</a>. This means destroying the records of how the first <a class="thought" href="entries/assembler_entry.html">assembler</a>s were made (or making the records thoroughly inaccessible). The leading force may be able to develop the first, crude <a class="thought" href="entries/assembler_entry.html">assembler</a>s in such a way that no one knows the details of more than a small fraction of the whole <a class="thought" href="entries/system_entry.html">system</a>. Imagine that we develop <a class="thought" href="entries/assembler_entry.html">assembler</a>s by the route outlined in Chapter 1. The <a class="thought" href="entries/protein_entry.html">protein</a> <a class="thought" href="entries/machine_entry.html">machine</a>s that we use to build the first crude <a class="thought" href="entries/assembler_entry.html">assembler</a>s will then promptly become obsolete. If we destroy the records of the <a class="thought" href="entries/protein_entry.html">protein</a> designs, this will hamper efforts to duplicate them, yet will not hamper further <a class="thought" href="entries/progress_entry.html">progress</a> in <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a>.</p>
<p>&#160;If sealed labs and limited <a class="thought" href="entries/assembler_entry.html">assembler</a>s are widely available, people will have little scientific or economic motivation to redevelop <a class="thought" href="entries/nanotechnology_entry.html">nanotechnology</a> independently, and burning the bridge from bulk <a class="thought" href="entries/technology_entry.html">technology</a> will make independent development more difficult. Yet these can be no more than delaying tactics. They won't stop independent development; the <a class="thought" href="entries/human_entry.html">human</a> urge for power will spur efforts which will eventually succeed. Only detailed, universal policing on a totalitarian scale could stop independent development indefinitely. If the policing were conducted by anything like a modern <a class="thought" href="entries/government_entry.html">government</a>, this would be a cure roughly as dangerous as the disease. And even then, would people maintain perfect vigilance <i>forever</i>?</p>
<p>&#160;It seems that we must eventually learn to live in a world with untrustworthy replicators. One sort of tactic would be to hide behind a wall or to run far away. But these are brittle methods: dangerous replicators might breach the wall or cross the distance, and bring utter disaster. And, though walls can be made proof against small replicators, no fixed wall will be proof against large-scale, organized malice. We will need a more robust, flexible approach.</p><h1>Active Shields</h1><p>It seems that we can build nanomachines that act somewhat like the white blood cells of the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/immune_system_entry.html">immune system</a>: <a class="thought" href="entries/device_entry.html">device</a>s that can fight not just <a class="thought" href="entries/bacteria_entry.html">bacteria</a> and viruses, but dangerous replicators of all sorts. Call an automated defense of this sort an <i>active shield</i>, to distinguish it from a fixed wall.</p>
<p>&#160;Unlike ordinary <a class="thought" href="entries/engine_entry.html">engine</a>ering <a class="thought" href="entries/system_entry.html">system</a>s, reliable active shields must do more than just cope with <a class="thought" href="entries/nature_entry.html">nature</a> or clumsy users. They must also cope with a far greater challenge - with the entire range of threats that intelligent forces can design and build under prevailing circumstances. Building and improving prototype shields will be akin to running both sides of an arms race on a laboratory scale. But the goal here will be to seek the minimum requirements for a defense that reliably prevails.</p>
<p>&#160;In Chapter 5, I described how Dr. Lenat and his <a class="thought" href="entries/eurisko_entry.html">EURISKO</a> <a class="thought" href="entries/program_entry.html">program</a> evolved successful fleets to fight according to the rules of a naval-<a class="thought" href="entries/warfare_entry.html">warfare</a> simulation game. In a similar way, we can make into a game the deadly serious effort to develop reliable shields, using sealed <a class="thought" href="entries/assembler_entry.html">assembler</a> labs of various sizes as playing fields. We can turn loose a horde of <a class="thought" href="entries/engine_entry.html">engine</a>ers, <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/hacker_entry.html">hacker</a>s, biologists, hobbyists, and automated <a class="thought" href="entries/engine_entry.html">engine</a>ering <a class="thought" href="entries/system_entry.html">system</a>s, all invited to pit their <a class="thought" href="entries/system_entry.html">system</a>s against one another in games limited only by the initial conditions, the laws of <a class="thought" href="entries/nature_entry.html">nature</a>, and the walls of the sealed labs. These competitors will evolve threats and shields in an open-ended series of microbattles. When replicating <a class="thought" href="entries/assembler_entry.html">assembler</a>s have brought abundance, people will have <a class="thought" href="entries/time_entry.html">time</a> enough for so important a game. Eventually we can test promising shield <a class="thought" href="entries/system_entry.html">system</a>s in Earthlike environments in <a class="thought" href="entries/space_entry.html">space</a>. Success will make possible a <a class="thought" href="entries/system_entry.html">system</a> able to protect <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/life_entry.html">life</a> and <a class="thought" href="entries/earth_entry.html">Earth</a>'s biosphere from the worst that a fistful of loose replicators can do.</p><h1>Is Success Possible?</h1><p>With our present uncertainties, we cannot yet describe either threats or shields with any accuracy. Does this mean we can't have any confidence that effective shields are possible? Apparently we can; there is a difference, after all, between knowing that something is possible and knowing how to do it. And in this case, the world holds examples of <a class="thought" href="entries/analog_entry.html">analog</a>ous successes.</p>
<p>&#160;There is nothing fundamentally <a class="thought" href="entries/novel_entry.html">novel</a> about defending against invading replicators; <a class="thought" href="entries/life_entry.html">life</a> has been doing it for ages. Replicating <a class="thought" href="entries/assembler_entry.html">assembler</a>s, though unusually potent, will be physical <a class="thought" href="entries/system_entry.html">system</a>s not unlike those we already know. Experience suggests that they can be controlled.</p>
<p>&#160;Viruses are molecular <a class="thought" href="entries/machine_entry.html">machine</a>s that invade cells; cells use molecular <a class="thought" href="entries/machine_entry.html">machine</a>s (such as restriction enzymes and antibodies) to defend against them. <a class="thought" href="entries/bacteria_entry.html">Bacteria</a> are cells that invade organisms; organisms use cells (such as white blood cells) to defend against them. Similarly, societies use police to defend against criminals and armies to defend against invaders. On a less physical level, minds use <a class="thought" href="entries/meme_entry.html">meme</a> <a class="thought" href="entries/system_entry.html">system</a>s such as the scientific method to defend against nonsense, and societies use institutions such as courts to defend against the power of other institutions.</p>
<p>&#160;The <a class="thought" href="entries/biological_entry.html">biological</a> examples in the last paragraph show that even after a billion-year arms race, molecular <a class="thought" href="entries/machine_entry.html">machine</a>s have maintained successful defenses against molecular replicators. Failures have been common too, but the successes do indicate that defense is possible. These successes suggest that we can indeed use nanomachines to defend against nanomachines. Though <a class="thought" href="entries/assembler_entry.html">assembler</a>s will bring many advances, there seems no <a class="thought" href="entries/reason_entry.html">reason</a> why they should permanently tip the balance against defense.</p>
<p>&#160;The examples given above - some involving viruses, some involving institutions - are diverse enough to suggest that successful defense rests on general principles. One might ask, Why do all these defenses succeed? But turn the question around: Why should they fail? Each conflict pits similar <a class="thought" href="entries/system_entry.html">system</a>s against each other, giving the attacker no obvious advantage. In each conflict, moreover, the attacker faces a defense <i>that is well established</i>. The defenders fight on home ground, giving them advantages such as prepared positions, detailed local <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, stockpiled resources, and abundant allies - when the <a class="thought" href="entries/immune_system_entry.html">immune system</a> recognizes a germ, it can mobilize the resources of an entire body. All these advantages are general and <a class="thought" href="entries/basic_entry.html">basic</a>, having little to do with the details of a <a class="thought" href="entries/technology_entry.html">technology</a>. We can give our active shields the same advantages over dangerous replicators. And they need not sit idle while dangerous weapons are amassed, any more than the <a class="thought" href="entries/immune_system_entry.html">immune system</a> sits idle while <a class="thought" href="entries/bacteria_entry.html">bacteria</a> multiply.</p>
<p>&#160;It would be hard to predict the outcome of an open-ended arms race between powers equipped with replicating <a class="thought" href="entries/assembler_entry.html">assembler</a>s. But before this situation can arise, the leading force seems likely to acquire a temporary but overwhelming <a class="thought" href="entries/military_entry.html">military</a> advantage. If the outcome of an arms race is in doubt, then the leading force will likely use its strength to ensure that no opponents are allowed to catch up. If it does so, then active shields will not have to withstand attacks backed by the resources of half a continent or half a <a class="thought" href="entries/solar_system_entry.html">solar system</a>; they will instead be like a police force or an <a class="thought" href="entries/immune_system_entry.html">immune system</a>, facing attacks backed only by whatever resources can be gathered in secret within the protected territory.</p>
<p>&#160;In each case of successful defense that I cited above, the attackers and the shields have developed through broadly similar processes. The <a class="thought" href="entries/immune_system_entry.html">immune system</a>, shaped by genetic <a class="thought" href="entries/evolution_entry.html">evolution</a>, meets threats also shaped by genetic <a class="thought" href="entries/evolution_entry.html">evolution</a>. Armies, shaped by <a class="thought" href="entries/human_entry.html">human</a> minds, also meet similar threats. Likewise, both active shields and dangerous replicators will be shaped by memetic <a class="thought" href="entries/evolution_entry.html">evolution</a>. But if the leading force can develop automated <a class="thought" href="entries/engine_entry.html">engine</a>ering <a class="thought" href="entries/system_entry.html">system</a>s that work a millionfold faster than <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/engine_entry.html">engine</a>ers, and if it can use them for a single year, then it can build active shields based on a million years' worth of <a class="thought" href="entries/engine_entry.html">engine</a>ering advance. With such <a class="thought" href="entries/system_entry.html">system</a>s we may be able to explore the limits of the possible well enough to build a reliable shield against all physically possible threats.</p>
<p>&#160;Even without our knowing the details of the threats and the shields, there seems <a class="thought" href="entries/reason_entry.html">reason</a> to believe that shields are possible. And the examples of memes controlling memes and of institutions controlling institutions also suggest that <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s can control <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s.</p>
<p>&#160;In building active shields, we will be able to use the power of replicators and <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s to multiply the traditional advantages of the defending force: we can give it overwhelming strength through abundant, replicator-built <a class="thought" href="entries/hardware_entry.html">hardware</a> with designs based on the equivalent of a million-year lead in <a class="thought" href="entries/technology_entry.html">technology</a>. We can build active shields having strength and reliability that will put past <a class="thought" href="entries/system_entry.html">system</a>s to shame.</p>
<p>&#160;Nanotechnology and <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> could bring the ultimate tools of destruction, but they are not inherently destructive. With care, we can use them to build the ultimate tools of peace.</p>
</td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D74411" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id74412"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Drexler: Engines of Destruction<br><span class="mindxheader"><i>posted on 01/14/2007 2:31 PM by <a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/profile.php?id=2395">doojie</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D74411%23id74412" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D74412" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p> It seems Drexler has not developed any ideas already developed earlier by one called Yahweh.
<br>
<br>
 Example: Tower of Babel. Humans unite to build a tower "whose top may reach unto God". Organization focusing on one singular goal, leading to entropy and accelerated destruction due to no redundancy.
<br>
<br>
Solution: Yahweh creates redundnacy by confusing their languages, so that their imaginations may function, but total destruction will be avoided.
<br>
<br>
Example: Empires form with names like Egypt, Babylon, Persia, Greece, Rome.
<br>
<br>
Solution: A small nation called Israel, conditioned to live by "God's law" in all environments "inform" each empire. The empire breaks apart, I srael remains to "inform" later empires.
<br>
<br>
 Israel's function was to create increasing redundancy. The reason for this is stated in Romans 8:7: The natural, physical mind is enmity against God. It cannopt be subject to God's laws. This has two basic results:
<br>
1.There can be no human authority representing the truth of "God" since ho human can be subject to God's laws.
<br>
2. Any attempt to do so results in a continual splintering and speciation of "God concepts" into infinity.
<br>
<br>
 These results have two corollaries in mathematics:
<br>
Godel's incompleteness theorem stating that no system with the complexity of number theory will be complete. There will always exist truths that can neither be proven nor disproven. Also, the consistency of such a system cannot be proven from within the system itself.
<br>
Theorem which extends to Chaitin's theorem, that in any axiomatic system, there exists an infinity of undecideable propositions.
<br>
<br>
 Godel's theorem has an analogue in law: no matter how complete we try to make laws, there will always exist "gaps" that must be filled by more and more laws, into infinity.
<br>
<br>
 Redundancy, therefore, is built into the system by the nature of our thinking.
<br>
<br>
 That same redundancy is driven by the need to replicate which is fueled by the "selfish Gene", seeking to replicate itself perfectly into future generations, so that social institutions will be driven to replicate themselves physically, yet continually speciating due to the incompleteness of their symbolic thought processes.
<br>
<br>
 Higher complexity, intelligence, and self awareness results. Because we are driven to replicate, social forms will follow the genetic algorithm at a social level, seeking to prove its "truth" by conversion of more and more into a singular form, but finding opposition due to incompleteness of thought processes.
<br>
<br>
 Drexler's system has already been designed, and is working quite well.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id74416"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Chapter 11: The Engines of Destruction<br><span class="mindxheader"><i>posted on 01/14/2007 2:54 PM by <a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/profile.php?id=1561">czarstar</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D74411%23id74416" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D74416" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p> <center><p class="mindxquote"> What will we do when replicating assemblers can make almost anything without human labor?  </p></center>
<br>
This is happening now with the advancement of robotics.  The elite are growing wealthier in their automated factories.  The master/servant Monetary Monarch is becoming solidified in robotic arms.  Advancement is great but social advancement must parallel or there will be an great uprising.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id74439"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Chapter 11: The Engines of Destruction<br><span class="mindxheader"><i>posted on 01/15/2007 5:20 AM by <a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/profile.php?id=1573">Extropia</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D74411%23id74439" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D74439" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I will not deny that there is  a divide between rich and poor. But I would argue that people from low income familiies (in the West, at least) hardly live the life of hardship that their ancestors endured. In fact, I would be so bold as to say their standards of living would place them above most of the aristocracy of passed ages!
<br>
<br>
Just look at what we expect from our computers: Kurzweil, in 1979, had use of a multimillion-dollar IBM 7094 with 32K memory and .25 MIPS processor speed. Yawn. I have a 2.0 Ghz Dell Laptop with 2048MB 667 Mhz SDRAM, a 100GB hardrive and a 256 MB graphics card. If that is not enough, my fast Internet connection links me to Google's datafarms, turning my laptop into a window on hundreds of petabytes of information that kings of old would have gone to war for.
<br>
<br>
Because I am wealthier than Kurzweil? Um....no. Because the law of accelerating returns dramatically reduced the cost of IT. Nanotech will bring this kind of price drop to many new areas, perhaps all of technology.
<br>
<br>
In any case, it is worth remembering that we already have a grey goo attack to contend with. if grey goo is something that uses up precious resources in order to replicate itself, then quite clearly the human race is grey goo. Because Earth has finite resources, the only way to 'make them go further' is to learn to work with matter and energy at finer and finer scales- invariably heading towards shuttling individual atoms with precision. Even that may not stave of Malthusian disaster permenantly, but any solution after that will probably be up to minds superior to humans to uncover.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id74441"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Chapter 11: The Engines of Destruction<br><span class="mindxheader"><i>posted on 01/15/2007 5:28 AM by <a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/profile.php?id=1573">Extropia</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D74411%23id74441" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D74441" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>What will we do when replicating assemblers can make almost anything without human labor? 
<br>
<br>
Paradoxically, we will all be working harder.
<br>
<br>
Why? Because no longer will we be working because we HAVE to, but because we WANT to. The immense improvements in computational power/ software capability that shall acompany the rise of the smart robot workforce will enable the crafting of virtual worlds beyond the ken of the most forward-thinking Second Lifer, leading to an explosion of new career opportunities. Nanofactories, claytronics and fog swarms will ensure virtual reality exists in the natural environment, while nanobots or some kind of brain/machine interface will let us 'go' to cyberspace. The boundary between the two will no longer exist.
<br>
<br>
 Dedicating their time to pursuing what they love, people will inevitably put more time and effort into their chosen professions than they would in today's climate where (save for the lucky minority) work is DULL DULL DULL DULL DULL DULL repeat ad infinitum.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id74442"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Chapter 11: The Engines of Destruction<br><span class="mindxheader"><i>posted on 01/15/2007 6:46 AM by <a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/profile.php?id=1973">Jake Witmer</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D74411%23id74442" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D74442" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>...I agree with you, as far as the humans that are still alive.  And no, that isn't a radical environmental doom and gloom remark.  It's a remark cautioning against the now ubiquitous (even here) view that government (coercion) is the answer to every problem.
<br>
<br>
Let's all make it to the singularity folks!  No reason not to, other than: "we didn't want to do our homework before we went to go vote, and we voted for too much government".  That would be a shame.  Check out my blawgs, where I talk about this subject in greater detail:
<br>
<br>
<a href="http://web.archive.org/web/20100614011813/http://jcwitmer.blogspot.com/index.html" target="_blank">http://jcwitmer.blogspot.com/index.html</a>
<br>
<a href="http://web.archive.org/web/20100614011813/http://freealaska.blogspot.com/" target="_blank">http://freealaska.blogspot.com/</a>
<br>
<br>
Also, check out Eric Dondero's blog where he does much the similar:
<br>
<a href="http://web.archive.org/web/20100614011813/http://www.mainstreamlibertarian.com/" target="_blank">http://www.mainstreamlibertarian.com</a>
<br>
<br>
Then, get scholarly, and check out:
<br>
<a href="http://web.archive.org/web/20100614011813/http://www.hawaii.edu/powerkills" target="_blank">http://www.hawaii.edu/powerkills</a>
<br>
<br>
If we never get past the point of tearing down those with great ideas, the "molecular assembler" revolution may never arrive.  At least one smart person on this board has figured this out: 
<br>
<br>
<a href="http://web.archive.org/web/20100614011813/http://www.optimal.org/" target="_blank">http://www.optimal.org</a>
<br>
<br>
Those with less enlightened political ideas should adapt and imitate Mr. Voss.
<br>
<br>
-Jake Witmer</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id126887"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="80"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="599"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Chapter 11: The Engines of Destruction<br><span class="mindxheader"><i>posted on 07/06/2008 2:04 AM by <a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/profile.php?id=1973">Jake Witmer</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D74411%23id126887" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20100614011813/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D126887" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I hereby disavow all prior recommendations to visit the site "www.mainstreamlibertarian.com".  If you do visit the site, please also visit <a href="http://web.archive.org/web/20100614011813/http://www.ericdondero.com/" target="_blank">http://www.ericdondero.com</a>
<br>
<br>
Eric Dondero has either been outed as a fool or as an agent provacateur, and interacting with such people is wasteful at best, and dangerous at worst.  Eric is not without cunning, but he has continually compromised 100% of his philosophy without apparent cause or logical defense.  He is not to be trusted as an advocate for freedom, nor as a friend.
<br>
<br>
My past alliance with him was based on the misunderstanding that he was in some way dedicated to free market political reform.  He has since been proven to be an advocate of mindless militarism above all other ideas.  This negates 100% of the value he has to free market reform, because he will support the candidate who is the greatest whore to American military might, irrespective of how much risk, danger, or obvious destruction they might pose to the idea of free markets.
<br>
<br>
Of course, Eric occasionally supports actual libertarian candidates, because if he didn't, noone would listen to him at all.
<br>
<br>
Don't bother with "mainstream libertarian" if you want useful information.  There are vastly better sources.  Such as "Third Party Watch" and <a href="http://web.archive.org/web/20100614011813/http://lastfreevoice.wordpress.com/" target="_blank">http://lastfreevoice.wordpress.com/</a>
<br>
<br>
Eric is unable to determine the difference between state control and individual freedom, or he simply doesn't care.  As one example of his dementia: Because he was then admittedly trying to land a job with the (doomed) Giuliani campaign for president, he advocated that libertarians support Giuliani over Ron Paul.  Now then, even if you're an advocate of the free market, you might conceivably have had problems with Ron Paul, but there is no doubt that he was more in favor of unrestricted markets than Giuliani was, or ever would be.  And Eric was ugly and incessant in his fraudulent pimping of Giuliani, and his infantile smears of Ron Paul (his former employer).
<br>
<br>
-Jake</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20100614011813im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>