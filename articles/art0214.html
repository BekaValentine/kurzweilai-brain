<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>Can a Machine Think?</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/meme/memelist.html?m=4">Will Machines Become Conscious?</a> &gt; 
Can a Machine Think?
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20090905165511/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0214.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0214.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/articles/art0214.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">Can a Machine Think?</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0082.html" target="_top">Clinton W. Kelly</a><br></span></td>
</table>
<br>
<div class="TeaserText">There are three ways to create an AI: model the mind, model the brain, and artificial life. Which one will work?</div>
<br>
<br><p>Originally published March 22, 2001 at <a href="http://web.archive.org/web/20090905165511/http://www.cisp.org/imp/march_2001/03_01kelly.htm" target="_new">iMP Magazine</a>. Published on KurzweilAI.net June 26, 2001.</p>
<p>Why do we think <a class="thought" href="entries/computer_entry.html">computer</a>s may have the "right stuff?" The <a class="thought" href="entries/reason_entry.html">reason</a>s are among some of the most significant philosophical concepts of the late 20<sup>th</sup> century.</p>
<p>In one variant or another, the question "can a <a class="thought" href="entries/machine_entry.html">machine</a> think" has occupied the attention of philosophers and others for centuries, stimulated from <a class="thought" href="entries/time_entry.html">time</a>-to-<a class="thought" href="entries/time_entry.html">time</a> by the emergence of ingenious mechanisms which suggested at least the possibility of an affirmative answer. In our own times, we have seen the creation of <a class="thought" href="entries/machine_entry.html">machine</a>s that are autonomous--robots, for example, that can perform tasks without constant <a class="thought" href="entries/human_entry.html">human</a> supervision. Does this mean that the <a class="thought" href="entries/device_entry.html">device</a> thinks? <a class="thought" href="entries/thinking_entry.html">Thinking</a> about what it means for a <a class="thought" href="entries/machine_entry.html">machine</a> to think means <a class="thought" href="entries/thinking_entry.html">thinking</a>, as well, about ourselves. Indeed, what does it mean to think? Does <a class="thought" href="entries/thinking_entry.html">thinking</a> define humanity? Do <a class="thought" href="entries/animal_entry.html">animal</a>s think? </p><h1><a class="thought" href="entries/logic_entry.html">Logic</a> and <a class="thought" href="entries/reason_entry.html">Reason</a>ing: <a class="thought" href="entries/machine_entry.html">Machine</a>s Which (Who?) Play <a class="thought" href="entries/chess_entry.html">Chess</a></h1><p>One of these ingenious "<a class="thought" href="entries/thinking_entry.html">thinking</a>" mechanisms caught the public's attention in 1809. The Emperor Napoleon I, a <a class="thought" href="entries/chess_entry.html">chess</a> player certainly of prominence and reportedly of ability, lost a <a class="thought" href="entries/chess_entry.html">chess</a> game in 15 moves to a seeming <a class="thought" href="entries/thinking_entry.html">thinking</a> <a class="thought" href="entries/machine_entry.html">machine</a>; a clockwork automaton known as "the Turk." Reports of the <a class="thought" href="entries/time_entry.html">time</a> say that Napoleon "angrily stalked from the room." </p>
<p>The Turk, named for one of its <a class="thought" href="entries/component_entry.html">component</a> parts, a mannequin dressed in elegant Turkish attire, had been built for the Austrian Empress Maria Theresa in 1769 by the Baron von Kempelen, a Hungarian <a class="thought" href="entries/engine_entry.html">engine</a>er. The <a class="thought" href="entries/machine_entry.html">machine</a> consisted of the mannequin, whose mechanical arm moved the <a class="thought" href="entries/chess_entry.html">chess</a> pieces, and a cabinet at which the mannequin sat. Inside the cabinet was a shining, brass clockwork mechanism. This mechanism was supposed to be responsible for deciding the automaton's moves and for positioning the mannequin's arm. The cabinet was opened for inspection before each game to convince the audience that the mechanism was all that it contained.</p>
<p>The Turk did not win every game but it won enough of them to establish a reputation as a player of rank. Its success gave rise to much speculation about how a cabinet full of gears could successfully compete with well-known <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/chess_entry.html">chess</a> masters. How could this clockwork mechanism think? In fact, it couldn't. The Turk was a magician's illusion; the cabinet cleverly designed to conceal a <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/chess_entry.html">chess</a> player.</p>
<p>Now, fast-forward some 188 years to 11 May 1997. Another prominent <a class="thought" href="entries/chess_entry.html">chess</a> player, grandmaster and world champion Gary Kasparov, has lost the sixth game and the match to a <a class="thought" href="entries/machine_entry.html">machine</a>; but this automaton was no illusion. A creation of <a class="thought" href="entries/silicon_entry.html">silicon</a> and <a class="thought" href="entries/software_entry.html">software</a> (not brass gears), special purpose <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/hardware_entry.html">hardware</a> and clever instructions encoding the insights of skilled players, <a class="thought" href="entries/ibm_entry.html">IBM</a>'s <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a> was the first <a class="thought" href="entries/machine_entry.html">machine</a> to defeat a world champion. Within the limits imposed by the game, this <a class="thought" href="entries/machine_entry.html">machine</a> seemed to think. Observers commented on its style of play almost as if they regarded it as <a class="thought" href="entries/human_entry.html">human</a>.</p>
<p>For many people, the outcome of this <a class="thought" href="entries/chess_entry.html">chess</a> match between <a class="thought" href="entries/human_entry.html">human</a> and <a class="thought" href="entries/machine_entry.html">machine</a> signaled the beginning of a major change in the way we view ourselves and our place in the <a class="thought" href="entries/universe_entry.html">universe</a>. <a class="thought" href="entries/chess_entry.html">Chess</a> has long been regarded as the most cerebral of games. The ability to play <a class="thought" href="entries/chess_entry.html">chess</a> well has always been considered a hallmark of <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/logic_entry.html">logic</a> and <a class="thought" href="entries/reason_entry.html">reason</a>ing. Now we have a <a class="thought" href="entries/machine_entry.html">machine</a> that solves a problem that we have always solved with the highest <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. Suddenly, there appears to be a whole range of activities which had been the sole province of humans that is now open to <a class="thought" href="entries/computer_entry.html">computer</a>s. If a <a class="thought" href="entries/computer_entry.html">computer</a> can unseat the world's best <a class="thought" href="entries/chess_entry.html">chess</a> player, some wondered, "How long will it be before I lose my seat down at the office?"</p>
<p>So <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a> plays a mean game of <a class="thought" href="entries/chess_entry.html">chess</a>. What else can it do? Essentially nothing; but there are a very large number (tens of thousands?) of less well-known <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/program_entry.html">program</a>s from the field of <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> (<a class="thought" href="entries/ai_entry.html">AI</a>) with performance equally impressive in their areas as <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a>'s. Each of these, like <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a>, captures in some limited way <a class="thought" href="entries/element_entry.html">element</a>s of intelligent behavior. There are <a class="thought" href="entries/program_entry.html">program</a>s that: play <a class="thought" href="entries/chess_entry.html">Chess</a>, Backgammon, Go and Bridge; solve word problems; detect credit card fraud; pick stocks; troubleshoot <a class="thought" href="entries/machine_entry.html">machine</a>ry; find <a class="thought" href="entries/information_entry.html">information</a> on the <a class="thought" href="entries/www_entry.html">World Wide Web</a>; target advertising; screen loan applicants; monitor compliance of Bosnian combatants with arms restrictions; predict chemical reactions; make medical diagnoses; reduce emissions from an electric generating plant; daily schedule 1000s of telephone repair personnel; screen pap smears; simulate production from an oil reservoir; conduct logistics planning for Operation Desert Storm; control a process to make soup; detect violations of The Nuclear Test Ban Treaty; read handwriting; write poems; compose music; paint a picture; prove mathematical theorems; design jet <a class="thought" href="entries/engine_entry.html">engine</a>s and <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/system_entry.html">system</a>s; help explore Mars; and, in 1995, drove a car autonomously from Washington, D.<a class="thought" href="entries/c_entry.html">C</a>. to San Diego, California.</p>
<p>It would appear that some of those "seats down at the office" are indeed now occupied by <a class="thought" href="entries/computer_entry.html">computer</a>s. Yet somehow, none of these <a class="thought" href="entries/ai_entry.html">AI</a> applications, impressive and useful as they are, would be called "intelligent" in the general, <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/sense_entry.html">sense</a>. Most of them are predicated on highly controlled situations where there are "rules" and it is challenging, but possible, to anticipate contingencies. Thus, these <a class="thought" href="entries/system_entry.html">system</a>s do beautifully in their niches, but our <a class="thought" href="entries/common_sense_entry.html">common sense</a> concept of <a class="thought" href="entries/intelligence_entry.html">intelligence</a> requires something more.</p><h1>How Do We Know If We Have It?</h1><p>But how do we recognize and measure <a class="thought" href="entries/intelligence_entry.html">intelligence</a>? This is a remarkably difficult issue. Leaving to one side debates over <a class="thought" href="entries/iq_entry.html">IQ</a> and other formal metrics, <a class="thought" href="entries/common_sense_entry.html">common sense</a> notions of <a class="thought" href="entries/intelligence_entry.html">intelligence</a> are based on observations of behavior with the belief that the more complex the behavior, in some <a class="thought" href="entries/sense_entry.html">sense</a>, the more intelligent the <a class="thought" href="entries/animal_entry.html">animal</a>.</p>
<p>The most complex <a class="thought" href="entries/human_entry.html">human</a> behavior is the use of <a class="thought" href="entries/language_entry.html">language</a>--which is not to be confused with <a class="thought" href="entries/communication_entry.html">communication</a>. <a class="thought" href="entries/animal_entry.html">Animal</a>s communicate. Studies of <a class="thought" href="entries/animal_entry.html">animal</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a> with <a class="thought" href="entries/data_entry.html">data</a> on such <a class="thought" href="entries/animal_entry.html">animal</a>s as: mantis shrimp, lobsters, horseshoe crabs, octopi, and sea anemones (as well as the more traditional studies of rats, mice, birds and, of course, primates) show that they also exhibit other complex behaviors. Thus, whatever "<a class="thought" href="entries/intelligence_entry.html">intelligence</a>" is, it exists to some degree across a wide range of organisms. But there is a qualitative, clear and major difference between the ability of humans and that of <a class="thought" href="entries/animal_entry.html">animal</a>s to communicate: <a class="thought" href="entries/animal_entry.html">animal</a>s do not possess anything remotely like <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/language_entry.html">language</a> skills. </p>
<p>The notion of <a class="thought" href="entries/language_entry.html">language</a> and <a class="thought" href="entries/intelligence_entry.html">intelligence</a> has preoccupied many engaged in <a class="thought" href="entries/research_entry.html">research</a> in computing, beginning with pioneers like the British mathematician Alan M. Turing. Turing, a cryptographer during World War II, devised a test for <a class="thought" href="entries/intelligence_entry.html">intelligence</a> in 1950 that focuses on behavior that requires <a class="thought" href="entries/language_entry.html">language</a> skills.</p>
<p>The essence of the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> is a conversation, via a teletype, <i>on any topic whatsoever</i>, between a person, a <a class="thought" href="entries/computer_entry.html">computer</a> and a judge (a <a class="thought" href="entries/human_entry.html">human</a>). The judge's goal is to decide which of the respondents is <a class="thought" href="entries/human_entry.html">human</a>. If a <a class="thought" href="entries/computer_entry.html">computer</a>, said Turing, could answer so as to convince the judge it is a person (not a <a class="thought" href="entries/computer_entry.html">computer</a>) then for all practical purposes the <a class="thought" href="entries/computer_entry.html">computer</a> could be said to "think". More recently, the test is <a class="thought" href="entries/thought_entry.html">thought</a> of as perhaps using speech instead of a teletype <a class="thought" href="entries/machine_entry.html">machine</a>, and perhaps including some requirements for image understanding. No <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/program_entry.html">program</a> has come close to passing the <a class="thought" href="entries/turing_test_entry.html">Turing test</a>.</p>
<p>Since Turing devised the test, objections to it have been voiced in several quarters. The philosopher <a class="thought" href="entries/searle_entry.html">John Searle</a> of the University of California, Berkeley, has raised one of the most interesting and <a class="thought" href="entries/content_entry.html">content</a>ious philosophical arguments against the "sufficiency" of the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> and indeed against <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>. That is, does the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> enough? Will an answer to the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> tell us whether <a class="thought" href="entries/computer_entry.html">computer</a>s can be human? Searle asks us to imagine that he sits in a room with a slot in the door through which come slips of paper with questions written in Chinese characters. Searle does not understand Chinese but he has in the room with him a <a class="thought" href="entries/code_entry.html">code</a> book of instructions in English, which tell him how to develop answers. He follows the instructions, prepares the answer in Chinese, and pushes it through the slot. The answer makes <a class="thought" href="entries/sense_entry.html">sense</a> to the Chinese speakers outside. Now to this outside observer, the "room" appears to understand Chinese. Searle, however, was just following formal rules and was completely ignorant of the meaning of either the questions or the answers. He concludes, since he knows he does not understand Chinese, that mere symbol manipulation, although producing the appearance of <a class="thought" href="entries/intelligence_entry.html">intelligence</a> to the outside observer, cannot produce understanding or awareness in the mechanism doing the manipulation, in this instance Searle himself. </p>
<p>What Searle is saying is that if he does not understand Chinese solely on the basis of running a <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/program_entry.html">program</a> for understanding Chinese (the instructions in the <a class="thought" href="entries/code_entry.html">code</a> book), then neither does any <a class="thought" href="entries/digital_entry.html">digital</a> <a class="thought" href="entries/computer_entry.html">computer</a>. <a class="thought" href="entries/digital_entry.html">Digital</a> <a class="thought" href="entries/computer_entry.html">computer</a>s, says Searle, "merely manipulate formal symbols according to rules in the <a class="thought" href="entries/program_entry.html">program</a>." He continues: "What goes for Chinese goes for other forms of cognition as well. Just manipulating the symbols is not by itself enough to guarantee <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, cognition, perception, understanding, <a class="thought" href="entries/thinking_entry.html">thinking</a> and so forth." Searle's test means that <a class="thought" href="entries/language_entry.html">language</a> is more than symbol manipulation, a bias that is implicit in the <a class="thought" href="entries/turing_test_entry.html">Turing test</a>, and this raises the bar, so to speak, for what constitutes "<a class="thought" href="entries/thought_entry.html">thought</a>." </p>
<p>Searle also links <a class="thought" href="entries/intelligence_entry.html">intelligence</a> and <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, suggesting that conscious intentionality is the essence of intelligent behavior. <a class="thought" href="entries/minsky_entry.html">Marvin Minsky</a> of MIT, one of the founders of <a class="thought" href="entries/ai_entry.html">AI</a>, believes that <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, specifically <a class="thought" href="entries/emotion_entry.html">emotion</a>, is critical for setting and changing goals; clearly an important part of intelligent behavior. Others have no difficulty in separating <a class="thought" href="entries/intelligence_entry.html">intelligence</a> from <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. One author says "it's a lot easier to imagine the possibility of an intelligent <a class="thought" href="entries/computer_entry.html">computer</a> than it is to imagine the possibility of a conscious <a class="thought" href="entries/computer_entry.html">computer</a> or a <a class="thought" href="entries/computer_entry.html">computer</a> with <a class="thought" href="entries/free_will_entry.html">free will</a>."</p>
<p>There are also arguments against the "necessariness"' of the <a class="thought" href="entries/turing_test_entry.html">Turing Test</a> based on observations of <a class="thought" href="entries/animal_entry.html">animal</a> behavior. These have lead ethologists and others to believe that there are non-verbal cognitive behaviors which also are indicative of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. For example: some <a class="thought" href="entries/animal_entry.html">animal</a>s can form concepts, can categorize things, form a cognitive map of the landscape, learn, adapt to new situations, remember and act upon cause and effect, i.e., use what worked before, and develop problem-solving strategies. These people argue that although "Elephants don't play <a class="thought" href="entries/chess_entry.html">chess</a>" and "Dogs don't argue syllogisms," both exhibit intelligent behavior. Apes, chimps and orangutans prepare and transport tools ahead of time; pigeons can make relative numerosity judgments; mappies practice deception as do vervet monkeys and chimps, and bees can create mental maps and do spatial <a class="thought" href="entries/reason_entry.html">reason</a>ing. </p>
<p>All these observations of <a class="thought" href="entries/animal_entry.html">animal</a> behavior suggest that <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is complex, multi-faceted and very hard to define. The <a class="thought" href="entries/turing_test_entry.html">Turing Test</a> captures one kind of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>; other tests are required to capture non-verbal behaviors characteristic of intelligent <a class="thought" href="entries/animal_entry.html">animal</a>s which perceive, move around, <a class="thought" href="entries/reason_entry.html">reason</a>, and survive in the real world. Thus, to devise a test, or series of tests, for what constitutes a "<a class="thought" href="entries/thinking_entry.html">thinking</a> <a class="thought" href="entries/machine_entry.html">machine</a>" means developing criteria for such properties as perception, contingent or <a class="thought" href="entries/context_entry.html">context</a> dependent decisions, and problem-solving. This need not be at a high cognitive level like responding to <a class="thought" href="entries/chess_entry.html">chess</a> moves; rather, a fairly primitive "<a class="thought" href="entries/thinking_entry.html">thinking</a> <a class="thought" href="entries/machine_entry.html">machine</a>" would have to recognize an obstacle, back up and then move around it. This sequences of moves turns out to be very challenging to design.</p><h1>Why Do We Believe We Can Construct A "<a class="thought" href="entries/thinking_entry.html">Thinking</a> <a class="thought" href="entries/machine_entry.html">Machine</a>?"--What A <a class="thought" href="entries/computer_entry.html">Computer</a> Can And Cannot Do</h1><p>We now know that we can make <a class="thought" href="entries/computer_entry.html">computer</a>s excel on limited problems such as recognizing speech (if it is grammatical, carefully pronounced and the <a class="thought" href="entries/context_entry.html">context</a> is restricted), scheduling a factory, recognizing a particular object in a scene, designing a jet <a class="thought" href="entries/engine_entry.html">engine</a>, or even performing a complex medical diagnosis. But we are very far from creating a <a class="thought" href="entries/computer_entry.html">computer</a> which can pass an unrestricted <a class="thought" href="entries/turing_test_entry.html">Turing Test</a>--even leaving aside Searle's objections to the test. As one writer put it, "<a class="thought" href="entries/computer_entry.html">computer</a>s have mastered intellectual tasks, such as <a class="thought" href="entries/chess_entry.html">chess</a> and integral <a class="thought" href="entries/calculus_entry.html">calculus</a>, but they have yet to attain the skills of a lobster in dealing with the real world." Given the gap between these niche capabilities and the requirements of the unrestricted <a class="thought" href="entries/turing_test_entry.html">Turing Test</a>, why do we think we can create an intelligent <a class="thought" href="entries/machine_entry.html">machine</a>--a <a class="thought" href="entries/machine_entry.html">machine</a> which can pass the unrestricted <a class="thought" href="entries/turing_test_entry.html">Turing Test</a>? Why do we think <a class="thought" href="entries/computer_entry.html">computer</a>s may have the "right stuff?" The <a class="thought" href="entries/reason_entry.html">reason</a>s are among some of the most significant philosophical concepts of the late 20<sup>th</sup> century.</p>
<p>The <a class="thought" href="entries/philosophy_entry.html">philosophy</a> which dominated <a class="thought" href="entries/thinking_entry.html">thinking</a> about the mind for almost three centuries is called Cartesian dualism; the position first <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> forth by the French mathematician and philosopher Rene Descartes in the early-1600's, that there are two kinds of substances in the world: mental and physical or immaterial "mind stuff" apart from material substance. If we held this belief today, there would be little <a class="thought" href="entries/reason_entry.html">reason</a> to suppose we could make much <a class="thought" href="entries/progress_entry.html">progress</a> creating <a class="thought" href="entries/intelligence_entry.html">intelligence</a> using a <a class="thought" href="entries/computer_entry.html">computer</a>. Today, most philosophers instead argue that the mind (and <a class="thought" href="entries/intelligence_entry.html">intelligence</a>) is an emergent property of material processes at the micro-level. That is to say, <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, which includes <a class="thought" href="entries/thinking_entry.html">thinking</a>, arises from <a class="thought" href="entries/brain_entry.html">brain</a>'s biochemistry, which is shaped by heredity and environment. The fundamental insight about <a class="thought" href="entries/biology_entry.html">biology</a> and mind suggests that if we simulate the <a class="thought" href="entries/brain_entry.html">brain</a> at the right level of detail, mind and <a class="thought" href="entries/intelligence_entry.html">intelligence</a> may also emerge from the simulation. The open issue is how far down in the structure do we have to go? Can we get mind and <a class="thought" href="entries/intelligence_entry.html">intelligence</a> by simulating <a class="thought" href="entries/brain_entry.html">brain</a> processes at the higher "psychological" level-- how we read, for example--or do we require lower-level neuro-physiological detail?</p>
<p>What we know of the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> suggests it is almost unimaginably complex. It contains approximately 100 billion <a class="thought" href="entries/neuron_entry.html">neuron</a>s of different types, densely interconnected, with each <a class="thought" href="entries/neuron_entry.html">neuron</a> linked to 10s of thousands of others. By contrast, a snail has about 100,000 <a class="thought" href="entries/neuron_entry.html">neuron</a>s, a bee about 600,000, and a laboratory rat about 65 million. But a <a class="thought" href="entries/brain_entry.html">brain</a> is much more than <a class="thought" href="entries/neuron_entry.html">neuron</a>s. The <a class="thought" href="entries/neuron_entry.html">neuron</a>s, and other types of cells, are immersed in a complicated <a class="thought" href="entries/chemistry_entry.html">chemistry</a> which they influence and which affects them, and which develops over <a class="thought" href="entries/time_entry.html">time</a>. The correct way to think of the <a class="thought" href="entries/brain_entry.html">brain</a> is as a complex, dynamic, nonlinear chemical <a class="thought" href="entries/system_entry.html">system</a>, not just as a <a class="thought" href="entries/network_entry.html">network</a> of <a class="thought" href="entries/neuron_entry.html">neuron</a>s. Why do we think, even in principle, without for the moment considering the formidable practical issues, that we can simulate this? The answer requires examining the theoretical limits of <a class="thought" href="entries/computation_entry.html">computation</a>; limits on what a <a class="thought" href="entries/computer_entry.html">computer</a> can do.</p>
<p>The concept of <a class="thought" href="entries/computation_entry.html">computation</a> was first formalized by Turing in 1935, well before there were <a class="thought" href="entries/electronic_entry.html">electronic</a> <a class="thought" href="entries/computer_entry.html">computer</a>s. Turing's goal was to formalize some intuitive concepts of methods for mathematical <a class="thought" href="entries/reason_entry.html">reason</a>ing. To do this, he employed a mechanical metaphor which is called the <a class="thought" href="entries/turing_machine_entry.html">Turing machine</a>. It consists of an infinite tape, a sensing head for reading and writing symbols on the tape, and a control box with a finite number of internal states. In the control box is a table (the <a class="thought" href="entries/software_entry.html">software</a> <a class="thought" href="entries/program_entry.html">program</a>) which the <a class="thought" href="entries/machine_entry.html">machine</a> uses to determine what <a class="thought" href="entries/action_entry.html">action</a> to take. For each possible state of the control box, and for each possible symbol being read by the sensing head, the table has an entry which tells the <a class="thought" href="entries/machine_entry.html">machine</a> what symbol to print on the tape, in which direction to move the sensing head along the tape, and which state to enter next. So imagine the head scooting back and forth along the tape reading and writing symbols. <a class="thought" href="entries/thought_entry.html">Thought</a> of this way, the <a class="thought" href="entries/turing_machine_entry.html">Turing machine</a> is simply a <a class="thought" href="entries/device_entry.html">device</a> for transforming one string of symbols into another string according to a predetermined <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of rules; the table in the control box. The advantage of the <a class="thought" href="entries/turing_machine_entry.html">Turing Machine</a> is not as an actual <a class="thought" href="entries/device_entry.html">device</a> to do <a class="thought" href="entries/computation_entry.html">computation</a> but to clarify operations masked in real <a class="thought" href="entries/computer_entry.html">computer</a>s. However, your <a class="thought" href="entries/personal_computer_entry.html">personal computer</a> (as well as the largest <a class="thought" href="entries/supercomputer_entry.html">supercomputer</a>) are <a class="thought" href="entries/turing_machine_entry.html">Turing Machine</a>s at their core. </p>
<p>The simplicity of the <a class="thought" href="entries/turing_machine_entry.html">Turing Machine</a> helps people establish theoretical limits on the ultimate problem-solving capabilities of real <a class="thought" href="entries/computer_entry.html">computer</a>s. One such result, called the Church-Turing thesis, is that if anything can be computed at all, it can be computed by a <a class="thought" href="entries/turing_machine_entry.html">Turing machine</a>. No physical process is known to exist that can be used to build a <a class="thought" href="entries/device_entry.html">device</a> <a class="thought" href="entries/computation_entry.html">computation</a>ally more powerful than a <a class="thought" href="entries/turing_machine_entry.html">Turing machine</a>. The Church-Turing Thesis is called a thesis, not a theorem, because it is not amenable to proof. Nevertheless, it is believed by most mathematicians; no evidence to the contrary has turned up.</p>
<p>There are things which a <a class="thought" href="entries/turing_machine_entry.html">Turing machine</a> cannot do. There are numbers which are uncomputable, numbers which a <a class="thought" href="entries/turing_machine_entry.html">Turing machine</a> cannot generate even by executing an infinite number of steps. Most people believe that uncomputability is not important in real-world processes. Thus, if we describe real-world processes (like the functioning of a <a class="thought" href="entries/neuron_entry.html">neuron</a> in a <a class="thought" href="entries/brain_entry.html">brain</a>) by the appropriate equations, those equations can be solved/computed, by a <a class="thought" href="entries/turing_machine_entry.html">Turing machine</a> given sufficient <a class="thought" href="entries/time_entry.html">time</a>. So if you accept that the <a class="thought" href="entries/brain_entry.html">brain</a> is a physical process, that there is no mysterious "mind stuff", then in principle it can be simulated by a <a class="thought" href="entries/turing_machine_entry.html">Turing machine</a>. To restate the Church-Turing Thesis: the <a class="thought" href="entries/brain_entry.html">brain</a> is a physical process, physical processes are computable, all computable processes can be computed by a <a class="thought" href="entries/turing_machine_entry.html">Turing Machine</a> (or any <a class="thought" href="entries/digital_entry.html">digital</a> <a class="thought" href="entries/computer_entry.html">computer</a>). </p>
<p>If you wish to simulate such features of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>/<a class="thought" href="entries/consciousness_entry.html">consciousness</a> as playing <a class="thought" href="entries/chess_entry.html">chess</a> or doing symbolic integration, then a relatively coarse level of simulation, a psychological-level, will likely suffice. If you wish to have <a class="thought" href="entries/creativity_entry.html">creativity</a>, <a class="thought" href="entries/emotion_entry.html">emotion</a>al responses, an aesthetic <a class="thought" href="entries/sense_entry.html">sense</a>, or even self-awareness, then a very fine-grained, neurophysiological-level simulation will likely be required, and the end may only be realized when we have totally duplicated a living brain; either as a simulation or in some, perhaps organic, type of "<a class="thought" href="entries/hardware_entry.html">hardware</a>".</p>
<p>Not everyone agrees that simulation is the answer. Searle argues that a simulation of a process is not that process. A simulation of an airplane does not fly, a simulation of the digestive process does not digest. Searle believes that <a class="thought" href="entries/consciousness_entry.html">consciousness</a> emerges as a result of natural processes, but that simulation and <a class="thought" href="entries/computation_entry.html">computation</a> cannot themselves create <a class="thought" href="entries/consciousness_entry.html">consciousness</a>.</p>
<p><a class="thought" href="entries/ai_entry.html">AI</a> is based on faith that there are significant features of <a class="thought" href="entries/intelligence_entry.html">intelligence</a> which can "be floated on top of entirely different sorts of <a class="thought" href="entries/substrate_entry.html">substrate</a>s than those of organic brains." This is a consequence of the Church-Turing thesis. The computing <a class="thought" href="entries/hardware_entry.html">hardware</a> doesn't <a class="thought" href="entries/matter_entry.html">matter</a>; <a class="thought" href="entries/silicon_entry.html">silicon</a>, Tinkertoys (MIT students built a Tic-Tac-Toe playing <a class="thought" href="entries/computer_entry.html">computer</a> out of Tinkertoys), or living <a class="thought" href="entries/neuron_entry.html">neuron</a>s are all <a class="thought" href="entries/computation_entry.html">computation</a>ally equivalent. But Searle claims the "<a class="thought" href="entries/hardware_entry.html">hardware</a>" does make a difference, and to achieve <a class="thought" href="entries/intelligence_entry.html">intelligence</a> or <a class="thought" href="entries/consciousness_entry.html">consciousness</a> we will have to replicate some of the organic processes themselves. Some counter by saying that a simulation of <a class="thought" href="entries/information_entry.html">information</a> processing is <a class="thought" href="entries/information_entry.html">information</a> processing. A simulation of two plus two still comes out four. <a class="thought" href="entries/intelligence_entry.html">Intelligence</a> comes about through <a class="thought" href="entries/information_entry.html">information</a> processing, the argument goes, so a simulation of <a class="thought" href="entries/information_entry.html">information</a> processing can yield <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. That is, the simulation captures causality. It is difficult to confirm or refute Searle's position on philosophical grounds. Ultimately, it and other positions will be decided empirically.</p>
<p>Another class of objections is raised by the British mathematician and physicist <a class="thought" href="entries/penrose_entry.html">Roger Penrose</a>. He bases this on his conviction that mathematicians can solve problems, which by a theorem proven by the mathematician Kurt G&#246;del, can have no guaranteed <a class="thought" href="entries/algorithm_entry.html">algorithm</a>ic solution, where by "<a class="thought" href="entries/algorithm_entry.html">algorithm</a>," he means a process that guarantees a solution, although not necessarily an efficient one (as opposed to a "<a class="thought" href="entries/heuristic_entry.html">heuristic</a>," which is a process learned from experience that may give the right answer or one that is close enough but is not guaranteed to). He, therefore, concludes that humans use non-<a class="thought" href="entries/algorithm_entry.html">algorithm</a>ic or uncomputable processes to solve these problems. Penrose argues at length and persuasively, but the argument may be flawed. <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a> uses a process which, although it does not guarantee a solution to the <a class="thought" href="entries/chess_entry.html">chess</a> problem (a win), still wins an impressive number of games. Like <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a>, humans often seem to use <a class="thought" href="entries/heuristic_entry.html">heuristic</a>s to attempt solutions. Like the process underlying <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a>, these don't guarantee a solution, but nevertheless often produce one and--unlike a <a class="thought" href="entries/chess_entry.html">chess</a> game--are well suited to adapting to changing conditions. The G&#246;del theorem speaks of <a class="thought" href="entries/algorithm_entry.html">algorithm</a>s which <i>always</i> guarantee a solution. The answer may be that humans succeed on these G&#246;del problems not through the use of uncomputable (non-Turing) processes but through the use of <a class="thought" href="entries/heuristic_entry.html">heuristic</a>s. This doesn't rule out the possibility that humans may also use uncomputable processes, but it seems to make it less likely. On the other hand, Penrose may be correct; in which case <a class="thought" href="entries/intelligence_entry.html">intelligence</a> through <a class="thought" href="entries/computation_entry.html">computation</a> will be unachievable </p><h1>Means to an End</h1><p>Approaches to try to realize the potential in the Church-Turing Thesis fall into three categories: Symbolic ("Model the Mind"), Connectionist or Artificial Neural <a class="thought" href="entries/system_entry.html">System</a>s ("Model The <a class="thought" href="entries/brain_entry.html">Brain</a>"), and a relatively new body of practice grouped under the heading of <a class="thought" href="entries/artificial_life_entry.html">Artificial Life</a> ("Model <a class="thought" href="entries/evolution_entry.html">Evolution</a>").</p>
<p>Symbolic <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s are designed and <a class="thought" href="entries/program_entry.html">program</a>med "Top Down", rather than trained or evolved. They tend to be propositional, using a list of rules and facts to simulate a general psychological theory of some aspect of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, or to simulate the application of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> in some specific area of expertise; there are <a class="thought" href="entries/system_entry.html">system</a>s that simulate "<a class="thought" href="entries/reason_entry.html">reason</a>ing", <a class="thought" href="entries/system_entry.html">system</a>s that simulate "knowing", and <a class="thought" href="entries/system_entry.html">system</a>s which do both. A common approach used in symbolic <a class="thought" href="entries/ai_entry.html">AI</a> is the production <a class="thought" href="entries/system_entry.html">system</a>. It generally has three parts: a list of rules of the form IF-THEN, called production rules or productions; a control mechanism used to decide when and how to apply a given rule; and a working <a class="thought" href="entries/memory_entry.html">memory</a>, a 'blackboard' where the results of rule activations or "firings" are posted. An IF-THEN rule representing facts might look like the following: <i>If</i> an <a class="thought" href="entries/animal_entry.html">animal</a> has pointed teeth and <u>if</u> an <a class="thought" href="entries/animal_entry.html">animal</a> has claws and <i>if</i> an <a class="thought" href="entries/animal_entry.html">animal</a> has forward eyes, <i>then</i> the <a class="thought" href="entries/animal_entry.html">animal</a> is likely a <a class="thought" href="entries/carnivore_entry.html">carnivore</a>. A rule is "fired" when the IF-clauses are satisfied, and the results of the firing, the "THENs", are posted on the "blackboard". These results may be taken up by the If-clauses of other rules causing them to fire in-turn. A typical production <a class="thought" href="entries/system_entry.html">system</a> will have thousands of rules. Many of the niche application examples cited earlier are based on production <a class="thought" href="entries/system_entry.html">system</a>s. <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a> incorporates production rules to evaluate the strategic worth of <a class="thought" href="entries/chess_entry.html">chess</a> positions. </p>
<p>Production <a class="thought" href="entries/system_entry.html">system</a>s and other methods used in symbolic <a class="thought" href="entries/ai_entry.html">AI</a> have been much less successful in more general problem solving; among the <a class="thought" href="entries/reason_entry.html">reason</a>s is a lack of commonsense <a class="thought" href="entries/knowledge_entry.html">knowledge</a> which, for example, would lead a <a class="thought" href="entries/system_entry.html">system</a> doing medical diagnoses to prescribe smallpox treatment for a car with rust spots. The number of "facts" which make up the body of commonsense <a class="thought" href="entries/knowledge_entry.html">knowledge</a> is immense; probably millions of rules to represent enough <a class="thought" href="entries/knowledge_entry.html">knowledge</a> so that new concepts could be "explained" in terms of previous rules and so that the <a class="thought" href="entries/system_entry.html">system</a> could "bootstrap" itself. A <a class="thought" href="entries/system_entry.html">system</a> exhibiting <a class="thought" href="entries/intelligence_entry.html">intelligence</a> would also likely require additional millions of rules, describing <a class="thought" href="entries/reason_entry.html">reason</a>ing processes. Aside from the fact that we don't understand these processes, the effort required to write such a <a class="thought" href="entries/program_entry.html">program</a> and to get it to work reliably poses a practical problem we don't know how to solve. A possible way around this problem is to create <a class="thought" href="entries/system_entry.html">system</a>s which can learn. While <a class="thought" href="entries/symbolic_system_entry.html">symbolic system</a>s which learn can be constructed, they tend not to scale well; the more rules they learn, the slower they run. It is tempting to believe that the doubling of <a class="thought" href="entries/computation_entry.html">computation</a>al power every 18 months will solve this problem, but experience to date suggests that is unlikely. Symbolic approaches may also have a fundamental flaw; critics argue that rules and other symbolic means are only rough approximations of sub-symbolic processes underlying <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, and that to obtain <a class="thought" href="entries/intelligence_entry.html">intelligence</a> these processes must be included.</p>
<p>Problems with scaling-up <a class="thought" href="entries/symbolic_system_entry.html">symbolic system</a>s and concern about what they might have left out gave rise to the connectionist or artificial neural <a class="thought" href="entries/system_entry.html">system</a> approach, based on studies of the <a class="thought" href="entries/brain_entry.html">brain</a>'s <a class="thought" href="entries/architecture_entry.html">architecture</a>. The most <a class="thought" href="entries/salient_entry.html">salient</a> characteristic of the <a class="thought" href="entries/brain_entry.html">brain</a> is the dense interconnection among the <a class="thought" href="entries/neuron_entry.html">neuron</a>s. Perhaps, the "<a class="thought" href="entries/hardware_entry.html">hardware</a>" does <a class="thought" href="entries/matter_entry.html">matter</a> to some degree, and if many simple processors representing <a class="thought" href="entries/neuron_entry.html">neuron</a>s were densely interconnected, <a class="thought" href="entries/brain_entry.html">brain</a>-like behavior might result without writing millions of lines of <a class="thought" href="entries/code_entry.html">code</a>. <a class="thought" href="entries/intelligence_entry.html">Intelligence</a> might spontaneously emerge from the interactions of many simple processors.</p>
<p>To investigate the connectionist or artificial neural <a class="thought" href="entries/system_entry.html">system</a> hypothesis, mathematical models loosely approximating some of the features of <a class="thought" href="entries/animal_entry.html">animal</a> nervous <a class="thought" href="entries/system_entry.html">system</a>s have been constructed; these are largely limited from a few hundred to a few thousand "<a class="thought" href="entries/neuron_entry.html">neuron</a>s" which are interconnected by links with variable weights or strengths. The <a class="thought" href="entries/neuron_entry.html">neuron</a>s are generally modeled as a simple thresholding function. If the weighted sum of inputs to a <a class="thought" href="entries/neuron_entry.html">neuron</a> exceeds some <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> threshold value, the <a class="thought" href="entries/neuron_entry.html">neuron</a> fires and outputs a signal which goes to all those <a class="thought" href="entries/neuron_entry.html">neuron</a>s to which it is connected. It is hard to see how such a simple process can give rise to complex behavior, but some remarkable performance has been obtained; one <a class="thought" href="entries/neuron_entry.html">neuron</a> can't do much but <a class="thought" href="entries/network_entry.html">network</a>s of <a class="thought" href="entries/neuron_entry.html">neuron</a>s can do a lot. </p>
<p>The key point about artificial neural <a class="thought" href="entries/system_entry.html">system</a>s is that they are trained, not <a class="thought" href="entries/program_entry.html">program</a>med; they learn. <a class="thought" href="entries/machine_entry.html">Machine</a>s that learn are absolutely crucial to obtaining intelligent behavior. It is impossible to <a class="thought" href="entries/program_entry.html">program</a> in everything a <a class="thought" href="entries/machine_entry.html">machine</a> must know to pass the <a class="thought" href="entries/turing_test_entry.html">Turing test</a> or do much else. <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a> does not learn. If the size of the <a class="thought" href="entries/chess_entry.html">chess</a> board were changed, another row or column added, or if some of the <a class="thought" href="entries/chess_entry.html">chess</a> pieces were given additional moves, <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a> would be lost but a <a class="thought" href="entries/human_entry.html">human</a> would learn to cope. <a class="thought" href="entries/learning_entry.html">Learning</a> in a neural net takes place by changing the pattern of weights which determines its response. <a class="thought" href="entries/information_entry.html">Information</a> is likewise stored in patterns of weights distributed across the net. Artificial neural <a class="thought" href="entries/system_entry.html">system</a>s excel at <a class="thought" href="entries/pattern_recognition_entry.html">pattern recognition</a> whether the pattern is visual, or exists in more abstract <a class="thought" href="entries/data_entry.html">data</a>. They do less well, thus far, in solving problems requiring explicit rational or logical <a class="thought" href="entries/thought_entry.html">thought</a> where <a class="thought" href="entries/symbolic_system_entry.html">symbolic system</a>s excel. The remarkable thing about artificial neural <a class="thought" href="entries/system_entry.html">system</a>s is that so much performance has been obtained out of (relative to the <a class="thought" href="entries/brain_entry.html">brain</a>) ridiculously simple <a class="thought" href="entries/system_entry.html">system</a>s. </p>
<p>Mathematicians describe complex <a class="thought" href="entries/system_entry.html">system</a>s as ones which are composed of very large numbers of interacting parts. The <a class="thought" href="entries/brain_entry.html">brain</a> certainly qualifies. A characteristic of complex <a class="thought" href="entries/system_entry.html">system</a>s is that they have emergent properties; properties which occur suddenly when a certain level of <a class="thought" href="entries/complexity_entry.html">complexity</a> is reached, and whose emergence could not have been predicted from <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of the parts and the interactions. Simulating at most a few thousand very simple <a class="thought" href="entries/neuron_entry.html">neuron</a>s is well below the level of <a class="thought" href="entries/complexity_entry.html">complexity</a> at which <a class="thought" href="entries/intelligence_entry.html">intelligence</a> might kick in. A single <a class="thought" href="entries/neuron_entry.html">neuron</a> doesn't think and isn't conscious, yet the <a class="thought" href="entries/brain_entry.html">brain</a> does and is.</p>
<p>To explore the potential of artificial neural <a class="thought" href="entries/system_entry.html">system</a>s, and to see if <a class="thought" href="entries/intelligence_entry.html">intelligence</a> will emerge at some level of <a class="thought" href="entries/complexity_entry.html">complexity</a>, will require the capability to simulate very large numbers of <a class="thought" href="entries/neuron_entry.html">neuron</a>s and their interconnections. But numbers alone are not sufficient; it is necessary to model the <a class="thought" href="entries/neuron_entry.html">neuron</a> itself in more detail;to move beyond the simple caricature of thresholding and capture much more of the <a class="thought" href="entries/complexity_entry.html">complexity</a> inherent in the functioning of the <a class="thought" href="entries/biological_entry.html">biological</a> <a class="thought" href="entries/neuron_entry.html">neuron</a>, and to acknowledge there are many different kinds of <a class="thought" href="entries/neuron_entry.html">neuron</a>s. </p>
<p>Constructing a <a class="thought" href="entries/machine_entry.html">machine</a> which might think using this type of connectionist approach now seems to be a <a class="thought" href="entries/hardware_entry.html">hardware</a> as well as a <a class="thought" href="entries/software_entry.html">software</a> problem; today's <a class="thought" href="entries/computer_entry.html">computer</a>s can't handle the required calculations in a <a class="thought" href="entries/reason_entry.html">reason</a>able <a class="thought" href="entries/time_entry.html">time</a>.</p>
<p>What is the size of the simulation problem? The <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> has about one-hundred billion <a class="thought" href="entries/neuron_entry.html">neuron</a>s; by some reckoning it processes <a class="thought" href="entries/information_entry.html">information</a> at a rate of about a million-billion bits/sec (10<sup>15</sup>) to 10 billion-billion bits/sec (10<sup>19</sup>). It is much slower than a <a class="thought" href="entries/computer_entry.html">computer</a> at the "<a class="thought" href="entries/component_entry.html">component</a>" level, but more than compensates with massive parallelism. The best simulations run at about 10 to 100 billion (10<sup>10</sup>-10<sup>11</sup>) bits/sec. The difference in performance is somewhere between a factor of 10,000 (10<sup>4</sup>), to one of 1000 million (10<sup>9</sup>). If <a class="thought" href="entries/computer_entry.html">computer</a> performance continues to double every 18 months, this difference will be erased somewhere between the years 2020 and 2040 without making any far-fetched assumptions about <a class="thought" href="entries/technology_entry.html">technology</a>. That certainly will not automatically result in <a class="thought" href="entries/machine_entry.html">machine</a>-based <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, but it does suggest that if we understand enough about <a class="thought" href="entries/brain_entry.html">brain</a> functioning, the <a class="thought" href="entries/computer_entry.html">computer</a> capacity will exist in one form or another to exploit that understanding. But what if we don't have that level of understanding?</p>
<p>How, if we don't understand something, can we replicate it? The answer leads us to the third approach to <a class="thought" href="entries/ai_entry.html">AI</a>, derived from the relatively new discipline of <a class="thought" href="entries/artificial_life_entry.html">artificial life</a>. <a class="thought" href="entries/artificial_life_entry.html">Artificial life</a> started with the mathematician John von Neumann's work on self-reproducing automata and focuses on the creation of <a class="thought" href="entries/life_entry.html">life</a>-like <a class="thought" href="entries/system_entry.html">system</a>s using the simulation and emulation of <a class="thought" href="entries/biological_entry.html">biological</a> and ethological processes. Two of these are key to creating an artificial nervous <a class="thought" href="entries/system_entry.html">system</a>: directed <a class="thought" href="entries/evolution_entry.html">evolution</a> and <a class="thought" href="entries/self_organizing_entry.html">self-organization</a>.</p>
<p>Directed <a class="thought" href="entries/evolution_entry.html">evolution</a> is a way to artificially speed up the process of <a class="thought" href="entries/evolution_entry.html">evolution</a>, and to direct the process toward an explicit goal; in this case, <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. One way to use it is to evolve the <a class="thought" href="entries/software_entry.html">software</a> we need to simulate a nervous <a class="thought" href="entries/system_entry.html">system</a>. We put <a class="thought" href="entries/code_entry.html">code</a> representing the functions of all the things we believe may be important to <a class="thought" href="entries/intelligence_entry.html">intelligence</a> in a simulation. We randomly create some variants of these, run the simulations, pick some winners, let them "breed" (i.e., exchange some <a class="thought" href="entries/code_entry.html">code</a>), create offspring, throw in some mutations, and repeat the process. While this sounds simpler than it is, it captures the essential ingredients of the process. It has been used to create solutions to some very hard problems, but never on this scale.</p>
<p>On the surface, this is what mathematicians would call an "intractable problem;" you not only have to simulate a nervous <a class="thought" href="entries/system_entry.html">system</a>, you have to simulate a large family of candidate <a class="thought" href="entries/system_entry.html">system</a>s, and do it perhaps thousands of times. We have now far outstripped the projected capabilities of <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/technology_entry.html">technology</a>. A possible solution may lie in using directed <a class="thought" href="entries/evolution_entry.html">evolution</a> on <a class="thought" href="entries/hardware_entry.html">hardware</a> and evolving a nervous <a class="thought" href="entries/system_entry.html">system</a> directly.</p>
<p>Imitating a nervous <a class="thought" href="entries/system_entry.html">system</a> in <a class="thought" href="entries/hardware_entry.html">hardware</a> is an enormous challenge. It may be that <a class="thought" href="entries/silicon_entry.html">silicon</a> itself, the stuff of chips, is unsuitable and that <a class="thought" href="entries/protein_entry.html">protein</a>s or some other bio-material might be preferable. Two points seem clear: first, whatever the material, the <a class="thought" href="entries/system_entry.html">system</a> is so complex, containing perhaps millions of <a class="thought" href="entries/neuron_entry.html">neuron</a>s, that it will likely have to be constructed by harnessing the capacity of some materials or <a class="thought" href="entries/component_entry.html">component</a>s to self-organize or self-assemble into higher-<a class="thought" href="entries/order_entry.html">order</a> <a class="thought" href="entries/system_entry.html">system</a>s using instructions implicit in the <a class="thought" href="entries/component_entry.html">component</a>s. Having to somehow otherwise connect up these <a class="thought" href="entries/neuron_entry.html">neuron</a>s individually, as is done in <a class="thought" href="entries/semiconductor_entry.html">semiconductor</a> fabrication, seems impossible; particularly so when you realize that the <a class="thought" href="entries/architecture_entry.html">architecture</a> of the interconnections themselves is shaped by <a class="thought" href="entries/learning_entry.html">learning</a>. You can't really specify all those connections in advance. Second, the <a class="thought" href="entries/self_organizing_entry.html">self-organization</a> would be pushed in a particular direction favoring <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, using directed <a class="thought" href="entries/evolution_entry.html">evolution</a>.</p>
<p>Two brief examples suggest possibilities: first, a number of <a class="thought" href="entries/research_entry.html">research</a>ers have used <a class="thought" href="entries/self_organizing_entry.html">self-organization</a> to grow rat hippocampal <a class="thought" href="entries/neuron_entry.html">neuron</a>s in patterns to form simple "<a class="thought" href="entries/circuit_entry.html">circuit</a>s". Second, <a class="thought" href="entries/research_entry.html">research</a>ers at the University of Sussex and others have used directed <a class="thought" href="entries/evolution_entry.html">evolution</a> to evolve <a class="thought" href="entries/novel_entry.html">novel</a> <a class="thought" href="entries/digital_entry.html">digital</a> <a class="thought" href="entries/circuit_entry.html">circuit</a>s. This is done by taking advantage of a type of <a class="thought" href="entries/integrated_circuit_entry.html">integrated circuit</a> called a field-<a class="thought" href="entries/program_entry.html">program</a>mable gate array in which connections among <a class="thought" href="entries/component_entry.html">component</a>s on the <a class="thought" href="entries/chip_entry.html">chip</a> are under <a class="thought" href="entries/software_entry.html">software</a> control. Very recently, other <a class="thought" href="entries/research_entry.html">research</a>ers, using the same <a class="thought" href="entries/technology_entry.html">technology</a>, have started to evolve artificial neural <a class="thought" href="entries/system_entry.html">system</a>s in <a class="thought" href="entries/hardware_entry.html">hardware</a>. Whether these approaches can scale to the levels required is unknown.</p><h1>Can A <a class="thought" href="entries/machine_entry.html">Machine</a> Think?</h1><p>There are good <a class="thought" href="entries/reason_entry.html">reason</a>s to believe a sufficiently complex <a class="thought" href="entries/machine_entry.html">machine</a> could one day pass the unrestricted <a class="thought" href="entries/turing_test_entry.html">Turing test</a>. Whether or not that constitutes sufficient or necessary proof of <a class="thought" href="entries/intelligence_entry.html">intelligence</a> or <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, will be the subject of continuing philosophical debate. <a class="thought" href="entries/machine_entry.html">Machine</a>s have been created (e.g., <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a>) which outperform humans in many niche areas. Some make extensive use of the particular strengths of <a class="thought" href="entries/computer_entry.html">computer</a>s such as rapid <a class="thought" href="entries/search_entry.html">search</a> and large <a class="thought" href="entries/memory_entry.html">memory</a>, while others try to simulate <a class="thought" href="entries/human_entry.html">human</a> problem-solving or some of the <a class="thought" href="entries/machine_entry.html">machine</a>ry of the <a class="thought" href="entries/brain_entry.html">brain</a>. Some of <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a>'s predecessors tried to reproduce the methods of <a class="thought" href="entries/human_entry.html">human</a> grandmasters, i.e., recognizing key <a class="thought" href="entries/configuration_entry.html">configuration</a>s of pieces on the board. <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a> relies more on massive and rapid <a class="thought" href="entries/search_entry.html">search</a>es of possible sequences of moves. </p>
<p>While it is not possible to predict which of the three major approaches to <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> might be the basis for an intelligent <a class="thought" href="entries/machine_entry.html">machine</a> (perhaps all of them will be incorporated to some degree), it seems a safe bet that a major <a class="thought" href="entries/component_entry.html">component</a> will resemble the functioning of a <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> at the level of individual <a class="thought" href="entries/neuron_entry.html">neuron</a>s. If we can simulate the functioning of the <a class="thought" href="entries/brain_entry.html">brain</a> at a deep level, the resulting <a class="thought" href="entries/network_entry.html">network</a> would literally be a <i>tabula rasa</i>, a blank mind. It would not show <a class="thought" href="entries/intelligence_entry.html">intelligence</a> nor <a class="thought" href="entries/consciousness_entry.html">consciousness</a> unless it was subjected to experiences similar to those of a <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a>. It must be able to investigate the environment around it, interact with that environment, and learn <a class="thought" href="entries/common_sense_entry.html">common sense</a> and all the other things which contribute to <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, since you cannot directly <a class="thought" href="entries/program_entry.html">program</a> in <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. </p>
<p>In the nearer-term, the pursuit of <a class="thought" href="entries/machine_entry.html">machine</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a> will continue to yield large benefits; we will be able to talk to our <a class="thought" href="entries/computer_entry.html">computer</a>s to dictate e-mail or documents, to command intelligent <a class="thought" href="entries/software_entry.html">software</a> agents to find <a class="thought" href="entries/information_entry.html">information</a> for us, and generally interact naturally with a variety of increasingly more complicated <a class="thought" href="entries/device_entry.html">device</a>s using spoken <a class="thought" href="entries/language_entry.html">language</a>. We can imagine <a class="thought" href="entries/computer_entry.html">computer</a>s that learn to do what you want them to do, and <a class="thought" href="entries/software_entry.html">software</a> and <a class="thought" href="entries/system_entry.html">system</a>s that can fix themselves or develop new capabilities.</p>
<p>There is no way to predict the impact of <a class="thought" href="entries/machine_entry.html">machine</a>s having true <a class="thought" href="entries/intelligence_entry.html">intelligence</a>; the only way to find out is to try and construct them. We may fail, but as we try we will learn much that is valuable about ourselves, and the <a class="thought" href="entries/brain_entry.html">brain</a> that makes us <a class="thought" href="entries/human_entry.html">human</a>.</p>
<p>Orinally published March 22, 2001, <a href="http://web.archive.org/web/20090905165511/http://www.cisp.org/imp/march_2001/03_01kelly.htm" target="_new">iMP Magazine</a>.  &#169; 2001. Clinton W. Kelly III. All rights reserved.</p>
</td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D5869" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id5873"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Behold!  Machines Who Think (Already)<br><span class="mindxheader"><i>posted on 03/20/2002 10:14 PM by mentifex@scn.org</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id5873" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D5873" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>The big question now is, "Can the AI genie be put back in the bottle?"  Machines are already thinking with http://www.scn.org/~mentifex/jsaimind.html -- the Robot AI Mind in JavaScript -- but the AI has a very low IQ and the thinking is of a minimalist nature.  But real, True AI is now loose on the 'Net, available also at http://mind.sourceforge.net/mind4th.html in Win32Forth and in ports to Visual Basic and JavaScript.  Does anyone know of any other real AI projects floating around on the 'Net, with freely avaialble source code to inspect and run?</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16241"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Behold!  Machines Who Think (Already)<br><span class="mindxheader"><i>posted on 04/05/2003 1:07 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=169">Robert</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id16241" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16241" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>The machine has yet to declare, as Descarte did, "I think therefore I am." We, Humans, have not progressed, to the point, beyond which, our programs can only decieve the limited in intelligence as to thier ability to mimic life. The best current test of self aware intelligence is the "Turing Test". </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16490"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Behold!  Machines Who Think (Already)<br><span class="mindxheader"><i>posted on 04/23/2003 1:28 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=247">gdorring</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id16490" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16490" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I think that your point concerning the 'ability to mimic life' is an important one'one that should be more enthusiastically explicated.  As of right now, all that computers have been able to do is 'simulate' intelligence; there has not been, and will never be, a computer that can actually 'replicate' intelligence.  The reason for this is due to a linguistic distinction between syntactics and semantics.  Briefly, syntactics refers to the grammatical rules of language.  Syntax is the governing system that orders our words and makes them into coherent intelligible statements.  Computers operate at a syntactic level'that is, there is a system of rules that dictate the arrangement of binary code.  The ones and zeros in themselves do not represent anything, but when they are arranged in specific orders, i.e. when they give an output to a corresponding input, they become meaningful to the interpretive user.  Semantics, on the other hand, refers to the meaning of symbols.  Humans operate on a semantic level where symbols such as the word C-A-T actually refer to a physical cat in the real world.  This 'aboutness' of the symbol is referred to as intentionality.  So if syntactics refers to the dyadic relationship between ones and zeros, then semantics refers to the triadic relationship between perceiver-symbol-object.  A computer will never be able to understand that the ones and zeros that manifest themselves as the word C-A-T on the display screen actually refers to a real physical cat in the world.  Computers will absolutely never break through the syntactic (dyadic) bulwark!  Computers will never think in the true sense of the term!  Strong AI is an impossibility.
<br>
<br>
Also, just a note about your claim that the Turing Test is the best test of self-awareness intelligence:  You should really read Alan Turing's 'Computing Machinery and Intelligence.'  You will be surprised to find that the Turing Test is fallible and only shows that a computer can simulate intelligence.  (This also renders your comments inconsistent in the last post, sorry).  You should also read John Searle's 'Can Computers Think?'  It is here that he explicates the fundamental problem with the Turing Test by use of his Gedanken Experiment, also known as the Chinese Room Experiment.  This ties directly into the syntactic/semantic distinction.  If you want me to go on about this let me know.
<br>
<br>
PS  Have you ever noticed that Descartes' notorious Cogito argument ("I think, therefore I exist") isn't even logically correct.  In reference to Aristotelian logic, there is a missing premise to complete the modus ponens argument!! haha</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16495"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Behold!  Machines Who Think (Already)<br><span class="mindxheader"><i>posted on 04/23/2003 2:59 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=169">Robert</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id16495" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16495" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Syntactics, symantics, The rules of the language we speak and read. They differ from country to country, from region to region. Why do so many have difficulty with the most wide spread language in the world, the language of technology, the english language? The english language has the capability to evolve to include the most complex of ideas and concepts using the simplest alphabet created to date. I.E. the word pneumonoultramicroscopicsilicovolcanoeconiosus is a specfic word in english that other less sophisticated languages would be completely inadquete to deal with. Therefore: language is important to the expression of thought but does not preclude the thought necessary to sentience. </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id5870"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>mind<br><span class="mindxheader"><i>posted on 03/20/2002 5:55 PM by heart@ta.ck</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id5870" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D5870" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>the mind is what the brain does, the brain is the hardware, so just port the mind to other hardware.  Understand what the different functions of the brain are, port that.  I know it's not simple, but it's do-able.
<br>
<br>
A-life is a dead end in the pursuit of AI.
<br>
Random evolution != intelligence</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id5872"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: mind<br><span class="mindxheader"><i>posted on 03/20/2002 6:15 PM by elenduil@uomail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id5872" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D5872" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Isnt our own intelligence the result of evolution? (wich is in a sence random)</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16240"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: mind<br><span class="mindxheader"><i>posted on 04/05/2003 12:54 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=169">Robert</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id16240" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16240" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Evoloution is random only in it's search for all viable options! That which increases survival is tried in infinite variation, to find a better survival rate.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16494"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: mind<br><span class="mindxheader"><i>posted on 04/23/2003 2:29 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=169">Robert</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id16494" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16494" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Simple Replication of brain matter, in my opinion, will not result in a mind or intelligence.
<br>
Sensorial inputs and imbedded programming need to be present in the structure. Not,instinct as we beleive occurs in lower lifeforms, but a structure of testing and analysis. A,real world,direct test of sensation and perception to co-ordinate what we do to what affects us. I.E. I cry, an entity, responds  and hugs or feeds or cleans until what bothered me or made me uncomfortable goes away.  </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10898"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Can a Machine Think?<br><span class="mindxheader"><i>posted on 10/18/2002 12:55 PM by entell</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id10898" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10898" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I think it is quite useless to try to replicate the brain in silicon (or whatever) 
<br>
to make intelligent machines. I believe the brain is simply a tool for 
<br>
intelligence to present itself on. Much like software running on PCs. 
<br>
The PC can do and be many things based on what software it runs. The software 
<br>
is what makes the PC what it is. The hardware is just the platform for 
<br>
the software to run itself on. If researchers are trying to replicate 
<br>
the brain to get to intelligence, they will be very sorry when they 
<br>
assemble the artificial brain. I can't believe that brain would be the 
<br>
source of intelligence. If so, there is a very interesting question to 
<br>
be asked: I don't understand why noone asks the 
<br>
difference between a dead person and a living one. Or even better, a 
<br>
normal living person and a person in a coma. The brain is alive and
<br>
ticking yet there is no consciousness. Therefore consciousness cannot
<br>
possibly be a product of the brain. Does everyone agree? Any comments
<br>
on this?</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10917"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Can a Machine Think?<br><span class="mindxheader"><i>posted on 10/19/2002 1:45 AM by ELDRAS</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id10917" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10917" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>from eldras:
<br>
<br>
Of course a machine thinks. 
<br>
<br>
Pne needs to be dextrous at definitions.
<br>
<br>
It took me 20 years so i suppose most here have done a lot too.
<br>
<br>
The article suggest three ways to attempt a thinking machine.
<br>
<br>
<br>
I say (and have used)...all three are important.
<br>
<br>
<br>
John Searle's chineese room is a complete botch up. He's afriend of a friend, i've never jarred with him, though his students adore him, his idea that it's impossible for a machine to think is utter tosh. 
<br>
<br>
It revolves around the nothion of understanding and is drawn from his jewsih religious beliefs ie like Einstein, one can't get away from the progreamming that there is a soul, if one's had it!
<br>
<br>
<br>
<br>
Well of course we're evolved machines.
<br>
<br>
that's one model of what we are anyhow.
<br>
<br>
machines do think already.
<br>
<br>
<br>
Let's define thinking for a bit if we attack this debate in earnest.
<br>
<br>
<br>
What is thought?
<br>
<br>
<br>
Questions &amp; Answers.
<br>
<br>
<br>
Let's keep it simple; if we don't then epistomological taughtological antropomorphic etymologies might conjugate too many oxymoronic nonclematures.   OK?
<br>
<br>
<br>
thought is questions and answers.
<br>
<br>
can machine have questions and answers?
<br>
<br>
yes Look on the internet.
<br>
<br>
ty any chat bot.
<br>
<br>
Use a calculator.
<br>
<br>
<br>
The issue of causation...ie how did they get them, is another issue.
<br>
<br>
machines think.
<br>
<br>
Anyone who asserts that machiones don't thinbk, is guilty of  disfocus.
<br>
<br>
<br>
Machines think, but not as much as men presently.
<br>
<br>
<br>
<br>
HOW DO MEN THINK
<br>
<br>
<br>
That's pretty easy. I know i understand how the brain workd.
<br>
<br>
<br>
men have questions &amp; answers.
<br>
<br>
<br>
They have them as reflexes to evolved goals. These goals are retrospectively apparent.
<br>
<br>
<br>
But not more than that. 
<br>
<br>
happy to argue the opposite.
<br>
<br>
i don't see AI as more than a card game which 
<br>
<br>
I for one have solved.
<br>
<br>
<br>
If anybody else has architected for strong AI and stopped like me seeing the dangers of a launch, I'd love a jar.
<br>
<br>
<br>
<br>
Ta Salutant!
<br>
<br>
<br>
<br>
ELDRAS
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16244"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Can a Machine Think?<br><span class="mindxheader"><i>posted on 04/05/2003 3:17 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=169">Robert</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id16244" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16244" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>You say "Pne needs to be dextrous at definitions"?
<br>
 And it took you 20 years? 
<br>
I have read your missive and am wonderous that you ,in your infinite wisdom and, limited vocabulary, have been able to declare "of course a machine thinks."
<br>
Which machines have you conversed with lately?
<br>
Have you spoken of philosophy with your car, or perhaps discussed cosmology or even metaphysics with your toaster?
<br>
What "nothion of understanding" can be derived from  anyones heretidy?
<br>
What is, please forgive my ignorance, a "nothion" anyway?
<br>
Perhaps, if you understood the English language better, I would not be confused by your statements.
<br>
Your concepts and opinions would be better appreciated by all, with a better command of the language that is spoken and written by the majority of the populations of the world.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16080"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>I think thyey don't<br><span class="mindxheader"><i>posted on 03/31/2003 7:55 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=189">Reem****</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id16080" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16080" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I am gonna to make a report about this issue,but in my opinion, machines just follow orders but they don't think. It's just programmed to do what we want not what it wants, so we(humans) think but not machines. I think that the small ant has the ability to feel and distinguish more than any robot.Emotions are part of intelligence in my point of view and robots have nothing to do with emotins.  If we programmed them to say Today is hot at given temperature it will, but it cann't really distinguish that, and if the temperature rise more,but we programmed it to say it is cold,it will say that.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16245"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: I think thyey don't<br><span class="mindxheader"><i>posted on 04/05/2003 3:29 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=169">Robert</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id16245" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16245" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Of course you are completely correct, at this time.
<br>
Science, and the practitioners of science, believes that if we can create an artificial "Human" without the traditional preoccupations of sex and power, that our society can greatly benifit from such a creation. Also, there is that in our ego, that would feel a great satisfaction in doing what only God has been able to do before. Create a new kind of life! </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16496"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: I think thyey don't<br><span class="mindxheader"><i>posted on 04/23/2003 3:05 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=169">Robert</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id16496" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16496" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Our current technology might be capable of sentient thought, but our lack of understanding of our own thought processes inhibit our ability to invest this  capability in our machines.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16242"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Can a Machine Think?<br><span class="mindxheader"><i>posted on 04/05/2003 1:15 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=169">Robert</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id16242" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16242" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Nothing is useless! Things are either possible or not, or probable or not. The investigation into the possible or probable cannot be useless, as it either proves or disproves our understanding of the universe.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16497"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Can a Machine Think?<br><span class="mindxheader"><i>posted on 04/23/2003 3:18 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=169">Robert</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id16497" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16497" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Why not. The ability and desire to create is uppermost in most of humanity. Would not it be the most glorious thing to create a new life!</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10932"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Can a Machine Think?<br><span class="mindxheader"><i>posted on 10/19/2002 6:03 PM by Claire</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id10932" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10932" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>No.
<br>
<br>
<br>
Claire</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id10934"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Can a Machine Think?<br><span class="mindxheader"><i>posted on 10/19/2002 6:51 PM by eldras</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id10934" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D10934" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Could you pracy what you just said</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16243"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Can a Machine Think?<br><span class="mindxheader"><i>posted on 04/05/2003 2:25 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=169">Robert</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id16243" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16243" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>You make a simple statement of negation to the concept of a machine thinking. I am amazed that so few adult humans can manage it,in even the most rudimentary form!</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id16239"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Can a Machine Think?<br><span class="mindxheader"><i>posted on 04/05/2003 12:47 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=169">Robert</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id16239" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D16239" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Redact: Can humans think? Mostly they don't, they react.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id23646"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Can a Machine Think?<br><span class="mindxheader"><i>posted on 02/13/2004 4:31 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=1061">upwing</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id23646" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D23646" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I have heard it claimed that Turing did not believe in the Turing Test and that Pascal did not believe in Pascal's Wager. Does anyone reading this know if either one of these claims is true or false? (References with page numbers please.)</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id23663"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Can a Machine Think?<br><span class="mindxheader"><i>posted on 02/14/2004 8:13 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=662">Tomaz_(Thomas)_Kristan</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id23663" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D23663" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Nobody knows. But it doesn't matter a bit!</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id23787"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Can a Machine Think?<br><span class="mindxheader"><i>posted on 02/19/2004 8:08 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=1061">upwing</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id23787" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D23787" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>"Nobody knows."
<br>
This utterance is often used to refer to a large (not small) number of people having been consulted. (Indeed, some would say that either nobody knows or somebody knows.) But, anyway, thanks for your time.
<br>
<br>
"But it doesn't matter a bit!"
<br>
I should think that the views or arguments of a Turing or a Thomas here might constitute at least a bit (of information), perhaps even a "wit" (of wisdom).
<br>
<br>
-------------------------
<br>
<br>
I have heard it claimed that Turing did not believe in the Turing Test and that Pascal did not believe in Pascal's Wager. Does anyone reading this know if either one of these claims is true or false? (References with page numbers please.)
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id23794"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Can a Machine Think?<br><span class="mindxheader"><i>posted on 02/19/2004 9:43 AM by <a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/profile.php?id=662">Tomaz_(Thomas)_Kristan</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5869%23id23794" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090905165511/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D23794" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>It would matter, if he had left any argument against. Since non of them had, the probability that they had them, is small. Smaller than the probability, that it's just an urban legend. Like that one of Darwin, allegedly rejecting his work on the death bed.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090905165511im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>