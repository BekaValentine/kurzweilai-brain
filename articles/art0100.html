<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>The Age of Intelligent Machines: Thoughts About Artificial Intelligence</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20090627042558/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20090627042558/http://www.kurzweilai.net/meme/memelist.html?m=7">Visions of the Future</a> &gt; 
<a href="https://web.archive.org/web/20090627042558/http://www.kurzweilai.net/meme/memelist.html?m=12">The Age of Intelligent Machines</a> &gt; 
The Age of Intelligent Machines: Thoughts About Artificial Intelligence
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20090627042558/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0100.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0100.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20090627042558/http://www.kurzweilai.net/articles/art0100.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">The Age of Intelligent Machines: Thoughts About Artificial Intelligence</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20090627042558/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0023.html" target="_top">Marvin Minsky</a><br></span></td>
</table>
<br>
<div class="TeaserText">One of the visionaries in the field of AI shares his thoughts on AI, from the beginning of the last decade. From Ray Kurzweil's revolutionary book The Age of Intelligent Machines, published in 1990.</div>
<br>
<br><h1>What is <a class="thought" href="entries/intelligence_entry.html">Intelligence</a>?</h1><p>What is <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, anyway? It is only a word that people use to name those unknown processes with which our brains solve problems we call hard. But whenever you learn a skill yourself, you're less impressed or mystified when other people do the same. This is why the meaning of "<a class="thought" href="entries/intelligence_entry.html">intelligence</a>" seems so elusive: it describes not some definite thing but only the momentary horizon of our ignorance about how minds might work. It is hard for scientists who try to understand <a class="thought" href="entries/intelligence_entry.html">intelligence</a> to explain precisely what they do, since our working definitions change from year to year. But it is not at all unusual for <a class="thought" href="entries/science_entry.html">science</a>s to aim at moving targets. <a class="thought" href="entries/biology_entry.html">Biology</a> explores the moving frontier of what we understand of what happens inside our bodies. Only a few decades ago the ability of organisms to reproduce seemed to be a deep and complex mystery. Yet as soon as they understood the <a class="thought" href="entries/element_entry.html">element</a>s of how our gene strings replicate themselves, biologists wondered why it took so long to think of such a simple thing. In the same way each era of <a class="thought" href="entries/psychology_entry.html">psychology</a> explores what we don't then know about processes in our brains.</p>
<p>Then, can we someday build intelligent <a class="thought" href="entries/machine_entry.html">machine</a>s? I take the answer to be yes in principle, because our brains themselves are <a class="thought" href="entries/machine_entry.html">machine</a>s. To be sure, we still know very little about how brains actually work. There is no <a class="thought" href="entries/reason_entry.html">reason</a> for scientists to be ashamed of this, considering that it was only a century ago that we began to suspect that brains were made of separate <a class="thought" href="entries/nerve_entry.html">nerve</a> cells that acted somewhat like <a class="thought" href="entries/computer_entry.html">computer</a> parts and that it is only half a century since we began developing technical ideas for understanding what such <a class="thought" href="entries/system_entry.html">system</a>s could do. These ideas are still barely adequate for dealing with present-day <a class="thought" href="entries/serial_computer_entry.html">serial computer</a>s, which have only thousands of active <a class="thought" href="entries/component_entry.html">component</a>s, and are not yet robust enough to deal with <a class="thought" href="entries/system_entry.html">system</a>s like those in the <a class="thought" href="entries/brain_entry.html">brain</a>, which involve trillions of interconnected parts, all working simultaneously.</p>
<p>Nor do we yet know how to make <a class="thought" href="entries/machine_entry.html">machine</a>s do many of the things that ordinary people do. Some critics maintain that <a class="thought" href="entries/machine_entry.html">machine</a>s will never be able to do same of those things, and some skeptics even claim to have proved such things. None of those purported proofs actually hold up to close examination, because we are still in the dark ages of scientific <a class="thought" href="entries/knowledge_entry.html">knowledge</a> about such <a class="thought" href="entries/matter_entry.html">matter</a>s. In any case, we have not the slightest grounds for believing that <a class="thought" href="entries/human_entry.html">human</a> brains are not <a class="thought" href="entries/machine_entry.html">machine</a>s. Because of this, both <a class="thought" href="entries/psychology_entry.html">psychology</a> and <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> have similar goals: both seek to learn how <a class="thought" href="entries/machine_entry.html">machine</a>s could do many things we can't yet make them do.</p>
<p>Why are so many people annoyed at the <a class="thought" href="entries/thought_entry.html">thought</a> that <a class="thought" href="entries/human_entry.html">human</a> brains are nothing more than "mere <a class="thought" href="entries/machine_entry.html">machine</a>s"? It seems to me that we have a problem with the word "<a class="thought" href="entries/machine_entry.html">machine</a>" because we've grown up to believe that <a class="thought" href="entries/machine_entry.html">machine</a>s can behave only in lifeless, mechanical ways. This view is obsolete, because the ways we use the word "<a class="thought" href="entries/machine_entry.html">machine</a>" are out of date. For centuries words like "<a class="thought" href="entries/machine_entry.html">machine</a>" and "mechanical" were used for describing relatively simple <a class="thought" href="entries/device_entry.html">device</a>s like pulleys, levers, locomotives, and typewriters. The word "<a class="thought" href="entries/computer_entry.html">computer</a>" too inherits from the past that <a class="thought" href="entries/sense_entry.html">sense</a> of pettiness that comes from doing dull arithmetic by many small and boring steps. Because of this, our previous experience can sometimes be a handicap. Our preconceptions of what <a class="thought" href="entries/machine_entry.html">machine</a>s can do date from what happened when we assembled <a class="thought" href="entries/system_entry.html">system</a>s from only a few hundreds or thousands of parts. And that did not prepare us to think about brainlike assemblies of billions of parts. Although we are already building <a class="thought" href="entries/machine_entry.html">machine</a>s with many millions of parts, we continue to think as though nothing has changed. We must learn to change how we think about phenomena that work on those larger scales.</p><h1>What Is <a class="thought" href="entries/ai_entry.html">Artificial Intelligence</a>?</h1><p>Even though we don't yet understand how brains perform many mental skills, we can still work toward making <a class="thought" href="entries/machine_entry.html">machine</a>s that do the same or similar things. "<a class="thought" href="entries/ai_entry.html">Artificial intelligence</a>" is simply the name we give to that <a class="thought" href="entries/research_entry.html">research</a>. But as I already pointed out, this means that the focus of that <a class="thought" href="entries/research_entry.html">research</a> will keep changing, since as soon as we think we understand one mystery, we have to move on to the next. In fact, <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a> has made enormous <a class="thought" href="entries/progress_entry.html">progress</a> in only a few decades, and because of that rapidity, the field has acquired a somewhat shady reputation! This paradox resulted from the fact that whenever an <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a> project made a useful new discovery, that product usually quickly spun off to form a new scientific or commercial specialty with its own distinctive name. These changes in name led outsiders to ask, Why do we see so little <a class="thought" href="entries/progress_entry.html">progress</a> in the central field of <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>? Here are a few specialties that originated at least in part from <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a> but later split into separate fields and, in some instances, commercial enterprises: <a class="thought" href="entries/robotics_entry.html">robotics</a>, <a class="thought" href="entries/pattern_recognition_entry.html">pattern recognition</a>, <a class="thought" href="entries/expert_system_entry.html">expert system</a>s, automatic theorem proving, cognitive <a class="thought" href="entries/psychology_entry.html">psychology</a>, word processing, <a class="thought" href="entries/machine_entry.html">machine</a> vision, <a class="thought" href="entries/knowledge_engineering_entry.html">knowledge engineering</a>, symbolic applied <a class="thought" href="entries/mathematics_entry.html">mathematics</a>, and <a class="thought" href="entries/computation_entry.html">computation</a>al <a class="thought" href="entries/linguistics_entry.html">linguistics</a>.</p>
<p>For example, many <a class="thought" href="entries/research_entry.html">research</a>ers in the 1950s worked toward discovering ways to make <a class="thought" href="entries/machine_entry.html">machine</a>s recognize various sorts of patterns. As their findings were applied to problems involved with vision, speech, and several other areas, those fields evolved their own more distinct techniques, they organized their own technical societies and journals, and they stopped using the term "<a class="thought" href="entries/ai_entry.html">artificial intelligence</a>." Similarly, an early concern of <a class="thought" href="entries/ai_entry.html">AI</a> was to develop techniques for enabling <a class="thought" href="entries/computer_entry.html">computer</a>s to understand <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/language_entry.html">language</a>; this spawned a field called <a class="thought" href="entries/computation_entry.html">computation</a>al <a class="thought" href="entries/linguistics_entry.html">linguistics</a>. Again, many ideas from <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> had a large influence among psychologists, who applied those ideas to their studies of the mind but used the title "cognitive <a class="thought" href="entries/psychology_entry.html">psychology</a>."</p>
<p>I can illustrate how <a class="thought" href="entries/ai_entry.html">AI</a> projects develop by recounting the <a class="thought" href="entries/research_entry.html">research</a> of James Slagle, who, as a graduate student at MIT in 1960, developed a <a class="thought" href="entries/program_entry.html">program</a> to solve <a class="thought" href="entries/calculus_entry.html">calculus</a> problems; he named it with the initials of "symbolic automatic integration." Although there were many problems that SAINT couldn't solve, it surpassed the performance of average MIT students. When he first approached this subject, most scientists considered solving those problems to require substantial <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. But after Slagle's work we had to ask ourselves instead why students take so long to learn to do such basically straightforward things.</p>
<p>How did SAINT solve those problems? It employed about 100 formulas from the domains of <a class="thought" href="entries/algebra_entry.html">algebra</a> and <a class="thought" href="entries/calculus_entry.html">calculus</a> and applied to these about a dozen pattern-matching methods for deciding which formula might be most likely to help solve a given problem. Since any particular attempt might fail, the <a class="thought" href="entries/program_entry.html">program</a> had to employ a good deal of trial and error. If one method did not work, the <a class="thought" href="entries/program_entry.html">program</a> automatically went on to try another. Sometimes one of them would work, but frequently a problem was too hard for any single such method to work. The <a class="thought" href="entries/system_entry.html">system</a> was <a class="thought" href="entries/program_entry.html">program</a>med in that case to proceed on to certain other methods, methods that attempted to split each hard problem into several simpler ones. In this way, if no particular method worked, SAINT was equipped with a great variety of alternatives.</p>
<p>Now we can make an important point. For years the public has been told, <a class="thought" href="entries/computer_entry.html">Computer</a>s do only what they're <a class="thought" href="entries/program_entry.html">program</a>med to do. But now you can see why that's not quite true: We can write <a class="thought" href="entries/program_entry.html">program</a>s that cause the <a class="thought" href="entries/machine_entry.html">machine</a> to <a class="thought" href="entries/search_entry.html">search</a> for solutions. Often such <a class="thought" href="entries/search_entry.html">search</a>es produce results that greatly surprise their <a class="thought" href="entries/program_entry.html">program</a>mers.</p>
<p>The idea of making <a class="thought" href="entries/program_entry.html">program</a>s <a class="thought" href="entries/search_entry.html">search</a> greatly expanded their powers. But it also led to new kinds of problems: <a class="thought" href="entries/search_entry.html">search</a> processes could generate so many possible alternatives that the <a class="thought" href="entries/program_entry.html">program</a>s were in constant danger of getting lost, repeating themselves, or persisting at fruitless attempts that had already consumed large amounts of <a class="thought" href="entries/time_entry.html">time</a>. Much <a class="thought" href="entries/research_entry.html">research</a> in the 1960s was focused on finding methods to reduce that sort of fruitless <a class="thought" href="entries/search_entry.html">search</a>. Slagle himself experimented with some mathematical theories of how to take into account both how much effort had been spent on each solution attempt and how much apparent <a class="thought" href="entries/progress_entry.html">progress</a> had been made. Thus the SAINT <a class="thought" href="entries/program_entry.html">program</a> worked as well as it did, not merely because of its specialized <a class="thought" href="entries/knowledge_entry.html">knowledge</a> about <a class="thought" href="entries/calculus_entry.html">calculus</a>, but also because of other <a class="thought" href="entries/knowledge_entry.html">knowledge</a> about the <a class="thought" href="entries/search_entry.html">search</a> itself. To prevent the <a class="thought" href="entries/search_entry.html">search</a> from simply floundering around, making one random attempt after another, some of the <a class="thought" href="entries/program_entry.html">program</a>'s <a class="thought" href="entries/knowledge_entry.html">knowledge</a> was applied to recognize conditions in which its other, more specialized <a class="thought" href="entries/knowledge_entry.html">knowledge</a> might be particularly useful.</p>
<p>When SAINT first appeared, it was acclaimed an outstanding example of work in the field of <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>. Later other workers analyzed more carefully its virtues and deficiencies, and this <a class="thought" href="entries/research_entry.html">research</a> improved our understanding of the <a class="thought" href="entries/basic_entry.html">basic</a> <a class="thought" href="entries/nature_entry.html">nature</a> of those <a class="thought" href="entries/calculus_entry.html">calculus</a> problems. Eventually ways were found to replace all the trial and error processes in SAINT by methods that worked without any <a class="thought" href="entries/search_entry.html">search</a>. The resulting commercial product, a <a class="thought" href="entries/program_entry.html">program</a> called MACSYMA, actually surpassed the abilities of professional mathematicians in this area. But once the subject was so well understood, we ceased to think of it as needing <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. This area is now generally seen as belonging no longer to <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> but to a separate specialty called symbolic applied <a class="thought" href="entries/mathematics_entry.html">mathematics</a>.</p><h1><a class="thought" href="entries/robotics_entry.html">Robotics</a> and <a class="thought" href="entries/common_sense_entry.html">Common Sense</a></h1><p>In the 1960s we first began to equip <a class="thought" href="entries/computer_entry.html">computer</a>s with mechanical hands and television eyes. Our goal was to endow <a class="thought" href="entries/machine_entry.html">machine</a>s with the sorts of abilities children use when playing with toys and building blocks. We found this much harder to do than expected. Indeed, a scholar of the <a class="thought" href="entries/history_entry.html">history</a> of <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> might get a <a class="thought" href="entries/sense_entry.html">sense</a> of watching <a class="thought" href="entries/evolution_entry.html">evolution</a> in reverse. Even in its earliest years we saw <a class="thought" href="entries/computer_entry.html">computer</a>s playing <a class="thought" href="entries/chess_entry.html">chess</a> and doing <a class="thought" href="entries/calculus_entry.html">calculus</a>, but it took another decade for us to begin to learn to make <a class="thought" href="entries/machine_entry.html">machine</a>s that could begin to act like children playing with building blocks! What makes it easier to design <a class="thought" href="entries/program_entry.html">program</a>s that imitate experts than to make them simulate novices? The amazing answer is, Experts are simpler than novices! To see why it was harder to make <a class="thought" href="entries/program_entry.html">program</a>s play with toys than pass <a class="thought" href="entries/calculus_entry.html">calculus</a> exams, let's consider what's involved in enabling a <a class="thought" href="entries/robot_entry.html">robot</a> to copy simple structures composed of blocks: we had to provide our <a class="thought" href="entries/robot_entry.html">robot</a> with hundreds of small <a class="thought" href="entries/program_entry.html">program</a>s organized into a <a class="thought" href="entries/system_entry.html">system</a> that engaged many different domains of <a class="thought" href="entries/knowledge_entry.html">knowledge</a>. Here are a few of the sorts of problems this <a class="thought" href="entries/system_entry.html">system</a> had to deal with:</p>
<ul>
<li>The relation between the hand and the eye</li>
<li>Recognizing objects from their visual appearances</li>
<li>Recognizing objects partially hidden from view</li>
<li>Recognizing relations between different objects</li>
<li>Fitting together three-dimensional shapes</li>
<li>Understanding how objects can support one another to form stable structures</li>
<li>Planning a sequence of <a class="thought" href="entries/action_entry.html">action</a>s to assemble a structure</li>
<li>Moving in <a class="thought" href="entries/space_entry.html">space</a> so as to avoid collisions</li>
<li>Controlling the fingers of a hand for grasping an object</li>
</ul>
<p>It is very hard for any adult to remember or appreciate how complex are the properties of ordinary physical things. Once when an early version of our block-building <a class="thought" href="entries/program_entry.html">program</a> was asked to find a new place to put a block, it tried to place it on top of itself! The <a class="thought" href="entries/program_entry.html">program</a> could not anticipate how that <a class="thought" href="entries/action_entry.html">action</a> would change the situation. To catalog only enough fragments of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> to enable a <a class="thought" href="entries/robot_entry.html">robot</a> to build a simple blocklike house from an unspecified variety of available materials would be an encyclopedic task. College students usually learn <a class="thought" href="entries/calculus_entry.html">calculus</a> in half a year, but it takes ten times longer for children to master their building toys. We all forget how hard it was to learn such things when we were young.</p><h1>Expertise and <a class="thought" href="entries/common_sense_entry.html">Common Sense</a></h1><p>Many <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/program_entry.html">program</a>s already exist that do things most people would regard as requiring <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. But none of those <a class="thought" href="entries/program_entry.html">program</a>s can work outside of some very small domain or specialty. We have separate <a class="thought" href="entries/program_entry.html">program</a>s for playing <a class="thought" href="entries/chess_entry.html">chess</a>, designing transformers, proving <a class="thought" href="entries/geometry_entry.html">geometry</a> theorems, and diagnosing kidney diseases. But none of those <a class="thought" href="entries/program_entry.html">program</a>s can do any of the things the others do. By itself each lacks the liveliness and versatility that any normal person has. And no one yet knows how to put many such <a class="thought" href="entries/program_entry.html">program</a>s together so that they can usefully communicate with one another. In my book, <i>The </i><a class="thought" href="entries/society_of_mind_entry.html">Society of Mind</a>, I outline some ideas on how that might be done inside our brains.</p>
<p>Putting together different ideas is just what children learn to do: we usually call this <a class="thought" href="entries/common_sense_entry.html">common sense</a>. Few youngsters can design transformers or diagnose renal ailments, but whenever those children speak or play, they combine a thousand different skills. Why is it so much easier for <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/program_entry.html">program</a>mers to simulate adult, expert skills than to make <a class="thought" href="entries/program_entry.html">program</a>s perform childlike sorts of commonsense <a class="thought" href="entries/thought_entry.html">thought</a>? I suspect that part of the answer lies in the amounts of variety. We can often simulate much of what a specializt does by assembling a collection of special methods, all of which share the same common character. Then so long as we remain within some small and tidy problem world, that specializt's domain of expertise, we need merely apply different combinations of basically similar rules. This high degree of uniformity makes it easy to design a higher-level supervisory <a class="thought" href="entries/program_entry.html">program</a> to decide which method to apply. However, although the "methods" of everyday <a class="thought" href="entries/thinking_entry.html">thinking</a> may, by themselves, seem simpler than those of experts, our collections of commonsense methods deal with a great many more different types of problems and situations. Consider how many different things each normal child must learn about the simplest-seeming physical objects, such as the peculiarities of blocks that are heavy, big, smooth, dangerous, pretty, delicate, or belong to someone else. Then consider that the child must learn quite different kinds of strategies for handling solids and liquids; strings, tapes, and cloths; jellies and muds as well as things he is told are prohibited, poisonous, or likely to cut or bite.</p>
<p>What are the consequences of the fact that the domain of commonsense <a class="thought" href="entries/thinking_entry.html">thinking</a> is so immensely varied and disorderly? One problem is simply accumulating so much <a class="thought" href="entries/knowledge_entry.html">knowledge</a>. But <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a> also encountered a second, more subtle problem. We had to face the simple fact that in <a class="thought" href="entries/order_entry.html">order</a> for a <a class="thought" href="entries/machine_entry.html">machine</a> to behave as though it "knows" anything, there must exist, inside that <a class="thought" href="entries/machine_entry.html">machine</a>, some sort of structure to embody or "represent" that <a class="thought" href="entries/knowledge_entry.html">knowledge</a>. Now, a specialized, or "expert," <a class="thought" href="entries/system_entry.html">system</a> can usually get by with very few types of what we call <a class="thought" href="entries/knowledge_representation_entry.html">knowledge representation</a>s. But in <a class="thought" href="entries/order_entry.html">order</a> to span that larger <a class="thought" href="entries/universe_entry.html">universe</a> of situations we meet in ordinary <a class="thought" href="entries/life_entry.html">life</a>, we appear to need a much larger variety of types of representations. This leads to a second, harder type of problem: <a class="thought" href="entries/knowledge_entry.html">knowledge</a> represented in different ways must be applied in different ways. This imposes on each child obligations of a higher type: they have to learn which types of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> to apply to which kinds of situations and how to apply them. In other words, we have to accumulate not merely <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, but also a good deal of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> about <a class="thought" href="entries/knowledge_entry.html">knowledge</a>. Now, experts too have to do that, but because commonsense <a class="thought" href="entries/knowledge_entry.html">knowledge</a> is of more varied types, an ordinary person has to learn (albeit quite unconsciously) much more <a class="thought" href="entries/knowledge_entry.html">knowledge</a> about representations of <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, that is, which types of representation skills to use for different purposes and how to use them.</p>
<p>If this sounds very complicated, it is because it actually is. Until the last half century we had only simple theories of mind, and these explained only a little of what <a class="thought" href="entries/animal_entry.html">animal</a>s could do in the impoverished worlds of laboratory experiments. Not until the 1930s did psychologists like <a class="thought" href="entries/piaget_entry.html">Jean Piaget</a> discover how many aspects of a child's mind develop through complicated processes, sometimes composed of intricate sequences of stagelike periods. We still don't know very much about such <a class="thought" href="entries/matter_entry.html">matter</a>s, except that the mind is much more complex than imagined in older philosophies. In <i>The </i><a class="thought" href="entries/society_of_mind_entry.html">Society of Mind</a>, I portray it as a sort of tangled-up bureaucracy, composed of many different experts, or as I call them, "agencies," that each develop different ways to represent what they learn. But how can experts using different <a class="thought" href="entries/language_entry.html">language</a>s communicate with one another? The solution proposed in my book is simply that they never come to do it very well! And that explains why <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/consciousness_entry.html">consciousness</a> seems so mysterious. Each part of the mind receives only hints of what the other parts are about, and no <a class="thought" href="entries/matter_entry.html">matter</a> how hard a mind may try, it can never make very much <a class="thought" href="entries/sense_entry.html">sense</a> of itself.</p><h1><a class="thought" href="entries/supercomputer_entry.html">Supercomputer</a>s and <a class="thought" href="entries/nanotechnology_entry.html">Nanotechnology</a></h1><p>Many problems we regard as needing cleverness can sometimes be solved by resorting to exhaustive <a class="thought" href="entries/search_entry.html">search</a>es, that is, by using massive, raw <a class="thought" href="entries/computer_entry.html">computer</a> power. This is what happens in most of those inexpensive pocket <a class="thought" href="entries/chess_entry.html">chess</a> <a class="thought" href="entries/computer_entry.html">computer</a>s. These little <a class="thought" href="entries/machine_entry.html">machine</a>s use <a class="thought" href="entries/program_entry.html">program</a>s much like the ones that we developed in the 1960s, using what were then some of the largest <a class="thought" href="entries/research_entry.html">research</a> <a class="thought" href="entries/computer_entry.html">computer</a>s in the world. Those old <a class="thought" href="entries/program_entry.html">program</a>s worked by examining the consequences of tens of thousands of possible moves before choosing one to actually make. But in those days the <a class="thought" href="entries/program_entry.html">program</a>s took so long to make those moves that the concepts they used were discarded as inadequate. Today, however, we can run the same <a class="thought" href="entries/program_entry.html">program</a>s on faster <a class="thought" href="entries/computer_entry.html">computer</a>s so that they can consider millions of possible moves, and now they play much better <a class="thought" href="entries/chess_entry.html">chess</a>. However, that shouldn't fool us into <a class="thought" href="entries/thinking_entry.html">thinking</a> that we now understand the <a class="thought" href="entries/basic_entry.html">basic</a> problem any better. There is good <a class="thought" href="entries/reason_entry.html">reason</a> to believe that outstanding <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/chess_entry.html">chess</a> players actually examine merely dozens, rather than millions, of possible moves, subjecting each to more <a class="thought" href="entries/thought_entry.html">thought</a>ful analysis.</p>
<p>In any case, as <a class="thought" href="entries/computer_entry.html">computer</a>s improved in speed and <a class="thought" href="entries/memory_entry.html">memory</a> size, quite a few <a class="thought" href="entries/program_entry.html">program</a>ming methods became practical, ones that had actually been discarded in the earlier years of <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a>. An <a class="thought" href="entries/apple_entry.html">Apple</a> desktop <a class="thought" href="entries/computer_entry.html">computer</a> (or an Amiga, Atari, <a class="thought" href="entries/ibm_entry.html">IBM</a>, or whatever) can do more than could a typical million-dollar <a class="thought" href="entries/machine_entry.html">machine</a> of a decade earlier, yet private citizens can afford to play games with them. In 1960 a million-<a class="thought" href="entries/bit_entry.html">bit</a> <a class="thought" href="entries/memory_entry.html">memory</a> cost a million dollars; today a <a class="thought" href="entries/memory_entry.html">memory</a> of the same size (and working a hundred times faster) can be purchased for the price of a good dinner. Some seers predict another hundredfold decrease in size and cast, perhaps in less than a decade, when we learn how to make each microcircuit ten times smaller in linear size and thus a hundred times smaller in area. What will happen after that? No one knows, but we can be sure of one thing: those two-dimensional chips we use today make very inefficient use of <a class="thought" href="entries/space_entry.html">space</a>. Once we start to build three-dimensional microstructures, we might gain another millionfald in density. To be sure, that would involve serious new problems with power, insulation, and heat. For a <a class="thought" href="entries/futurist_entry.html">futurist</a>ic but sensible discussion of such possibilities, I recommend Eric Drexler's <a class="thought" href="entries/engines_of_creation_entry.html">Engines of Creation</a> (Falcon Press, 1986).</p>
<p>Not only have small <a class="thought" href="entries/component_entry.html">component</a>s become cheaper; they have also become faster. In 1960 a typical <a class="thought" href="entries/component_entry.html">component</a> required a microsecond to function; today our <a class="thought" href="entries/circuit_entry.html">circuit</a>s operate a thousand times faster. Few optimists, however, predict another thousandfold increase in speed over the next generation. Does this mean that even with decreasing costs we will soon encounter limits on what we can make <a class="thought" href="entries/computer_entry.html">computer</a>s do? The answer is no, because we are just beginning a new era of parallel <a class="thought" href="entries/computer_entry.html">computer</a>s.</p>
<p>Most <a class="thought" href="entries/computer_entry.html">computer</a>s today are still serial; that is, they do only one thing at a <a class="thought" href="entries/time_entry.html">time</a>. Typically, a <a class="thought" href="entries/serial_computer_entry.html">serial computer</a> has millions of <a class="thought" href="entries/memory_entry.html">memory</a> <a class="thought" href="entries/element_entry.html">element</a>s, but only a few of them operate at any moment, while the rest of them wait for their turn: in each cycle of operation, a <a class="thought" href="entries/serial_computer_entry.html">serial computer</a> can retrieve and use only one of the items in its <a class="thought" href="entries/memory_entry.html">memory</a> banks. Wouldn't it be better to keep more of the <a class="thought" href="entries/hardware_entry.html">hardware</a> in actual operation? A more active type of <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/architecture_entry.html">architecture</a> was proposed in <a class="thought" href="entries/hillis_entry.html">Daniel Hillis</a>'s <a class="thought" href="entries/connection_machine_entry.html">Connection Machine</a> (MIT Press, 1986), which describes a way to assemble a large <a class="thought" href="entries/machine_entry.html">machine</a> from a large number of very small, <a class="thought" href="entries/serial_computer_entry.html">serial computer</a>s that operate concurrently and pass messages among themselves. Only a few years after being conceived, <a class="thought" href="entries/connection_machine_entry.html">Connection Machine</a>s are already commercially available, and they indeed appear to have fulfilled their promise to break through some of the speed limitations of <a class="thought" href="entries/serial_computer_entry.html">serial computer</a>s. In certain respects they are now the fastest <a class="thought" href="entries/computer_entry.html">computer</a>s in the world.</p>
<p>This is not to say that parallel <a class="thought" href="entries/computer_entry.html">computer</a>s do not have their own limitations. For, just as one cannot start building a house before the boards and bricks have arrived, you cannot always start work simultaneously on all aspects of solving a problem. T would certainly be nice if we could take any <a class="thought" href="entries/program_entry.html">program</a> for a <a class="thought" href="entries/serial_computer_entry.html">serial computer</a>, divide it into a million parts, and then get the answer a million times faster by running those parts simultaneously on that many <a class="thought" href="entries/computer_entry.html">computer</a>s in parallel. But that can't be done, in general, particularly when certain parts of the solution depend upon the solutions to other parts. Nevertheless, this quite often turns out to be feasible in actual practice. And although this is only a guess, I suspect that it will happen surprisingly often for the purposes of <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>. Why do I think so? Simply because it seems very clear that our brains themselves must work that way.</p>
<p>Consider that <a class="thought" href="entries/brain_entry.html">brain</a> cells work at very modest speeds in comparison to the speeds of <a class="thought" href="entries/computer_entry.html">computer</a> parts. They work at rates of less than a thousand operations per second, a million times slower than what happens inside a modern <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/circuit_entry.html">circuit</a> <a class="thought" href="entries/chip_entry.html">chip</a>. Could any <a class="thought" href="entries/computer_entry.html">computer</a> with such slow parts do all the things that a person can do? The answer must lie in parallel <a class="thought" href="entries/computation_entry.html">computation</a>: different parts of the <a class="thought" href="entries/brain_entry.html">brain</a> must do many more different things at the same <a class="thought" href="entries/time_entry.html">time</a>. True, that would take at least a billion <a class="thought" href="entries/nerve_entry.html">nerve</a> cells working in parallel, but the <a class="thought" href="entries/brain_entry.html">brain</a> has many times that number of cells.</p><h1><a class="thought" href="entries/ai_entry.html">AI</a> and the World of the <a class="thought" href="entries/future_entry.html">Future</a></h1><p>Intelligent <a class="thought" href="entries/machine_entry.html">machine</a>s may be within the technological reach of the next century. Over the next few generations we'll have to face the problems they pose. Unless some unforeseen obstacles appear, our mind-<a class="thought" href="entries/engine_entry.html">engine</a>ering skills could grow to the point of enabling us to construct accomplished artificial scientists, artists, composers, and personal companions. Is <a class="thought" href="entries/ai_entry.html">AI</a> merely another advance in <a class="thought" href="entries/technology_entry.html">technology</a>, or is it a turning point in <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/evolution_entry.html">evolution</a> that should be a focus of discussion and planning by all mankind? The prospect of intelligent <a class="thought" href="entries/machine_entry.html">machine</a>s is one that we're ill prepared to think about, because it raises such unusual moral, social, artistic, philosophical, and religious issues. Are we obliged to treat <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>s as <a class="thought" href="entries/sentient_entry.html">sentient</a> beings? Should they have rights? And what should we do when there remains no real need for honest work, when artificial workers can do everything from mining, fanning, <a class="thought" href="entries/medicine_entry.html">medicine</a>, and manufacturing all the way to house cleaning? Must our lives then drift into pointless restlessness and all our social schemes disintegrate?</p>
<p>These questions have been discussed most <a class="thought" href="entries/thought_entry.html">thought</a>fully in the literary works of such writers as <a class="thought" href="entries/asimov_entry.html">Isaac Asimov</a>, Gregory Benford, <a class="thought" href="entries/clarke_entry.html">Arthur C. Clarke</a>, Frederick Pohl, and Jack Williamson, who all tried to imagine how such presences might change the aspirations of humanity. Some optimistic <a class="thought" href="entries/futurist_entry.html">futurist</a>s maintain that once we've satisfied all our worldly needs, we might then turn to the worlds of the mind. But consider how that enterprise itself would be affected by the presence of those artificial mindlike entities. That same <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/technology_entry.html">technology</a> would offer ways to modify the <a class="thought" href="entries/hardware_entry.html">hardware</a> of our brains and thus to endlessly extend the mental worlds we could explore.</p>
<p>You might ask why this essay mixes both <a class="thought" href="entries/computer_entry.html">computer</a>s and <a class="thought" href="entries/psychology_entry.html">psychology</a>. The <a class="thought" href="entries/reason_entry.html">reason</a> is that though we'd like to talk about making intelligent <a class="thought" href="entries/machine_entry.html">machine</a>s, people are the only such <a class="thought" href="entries/intelligence_entry.html">intelligence</a> we can imitate or study now. One trouble, though, is that we still don't know&#160;enough about how people work! Does this mean that we can't develop smart <a class="thought" href="entries/machine_entry.html">machine</a>s before we get some better theories of <a class="thought" href="entries/psychology_entry.html">psychology</a>? Not necessarily. There certainly could be ways to make very smart <a class="thought" href="entries/machine_entry.html">machine</a>s based on principles that our brains do not use, as in the case of those very fast, dumb <a class="thought" href="entries/chess_entry.html">chess</a> <a class="thought" href="entries/machine_entry.html">machine</a>s. But since we're the first very smart <a class="thought" href="entries/machine_entry.html">machine</a>s to have evolved, we just might represent one of the simplest ways!</p>
<p>But, you might object, there's more to a <a class="thought" href="entries/human_entry.html">human</a> mind than merely intellect. What about <a class="thought" href="entries/emotion_entry.html">emotion</a>, <a class="thought" href="entries/intuition_entry.html">intuition</a>, courage, inspiration, <a class="thought" href="entries/creativity_entry.html">creativity</a>, and so forth. Surely it would be easier simply to understand <a class="thought" href="entries/intelligence_entry.html">intelligence</a> than to try to analyze all those other aspects of our personalities! Not so, I maintain, because traditional distinctions like those between <a class="thought" href="entries/logic_entry.html">logic</a> and <a class="thought" href="entries/intuition_entry.html">intuition</a>, between intellect and <a class="thought" href="entries/emotion_entry.html">emotion</a>, unwisely try to separate <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and meaning from purpose and intention. In The <a class="thought" href="entries/society_of_mind_entry.html">Society of Mind</a>, I argue that little can be done without combining <a class="thought" href="entries/element_entry.html">element</a>s of both. Furthermore, when we put them together, it becomes easier, rather than harder, to understand such <a class="thought" href="entries/matter_entry.html">matter</a>s, because, though there are many kinds of questions, the answers to each of them illuminate the rest.</p>
<p>Many people firmly believe that <a class="thought" href="entries/computer_entry.html">computer</a>s, by their <a class="thought" href="entries/nature_entry.html">nature</a>, lack such admirable <a class="thought" href="entries/human_entry.html">human</a> qualities as imagination, sympathy, and <a class="thought" href="entries/creativity_entry.html">creativity</a>. <a class="thought" href="entries/computer_entry.html">Computer</a>s, so that opinion goes, can be only logical and literal. Because they can't make new ideas, intelligent <a class="thought" href="entries/machine_entry.html">machine</a>s lie, if at all, in <a class="thought" href="entries/future_entry.html">future</a>s too remote for concern. However, we have to be wary of such words as "<a class="thought" href="entries/creativity_entry.html">creativity</a>." We may only mislead ourselves when we ask our <a class="thought" href="entries/machine_entry.html">machine</a>s to do those things that we admire most. No one could deny that our <a class="thought" href="entries/machine_entry.html">machine</a>s, as we know them today, lack many useful qualities that we take for granted in ourselves. But it may be wrong to seek the sources of those qualities in the exceptional performances we see in our cultural heroes. Instead, we ought to look more carefully at what we ordinary people do: the things we call <a class="thought" href="entries/common_sense_entry.html">common sense</a> and scarcely ever consider at all. Experience has shown that <a class="thought" href="entries/science_entry.html">science</a> frequently develops most fruitfully once we learn to examine the things that seem the simplest, instead of those that seem the most mysterious.</p>
</td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p><br>
<img src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/articles/images/aiminksyjones01.jpg" vspace="10"><br>
<span class="PhotoCredit">Photo by Lou Jones www.fotojones.com</span>
<br>
<span class="Caption">Marvin Minsky.</span>
<br>
<br>
<br></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20090627042558/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D5601" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id5602"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>The Psychology of A.I.<br><span class="mindxheader"><i>posted on 03/05/2002 2:27 AM by Spacetaker@juno.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20090627042558/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D5601%23id5602" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20090627042558/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D5602" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>The union of psychology with the study Artificial Intelligence sets an intrinsic goal to be achieved by the researcher.  This goal is commonly understood to be the replication of human activities, both in the physical and cognitive sense, in an accurate representation or recreation of the human mind in either an abstraction or application.  In doing so, we must have an intimate comprehension of what it is to be human and of the cognitive processes that are occuring as we learn and interact with our world.  Therefore, it becomes apparent that in order to create an intelligence that mimics the human experience we need to endow it with all of the functions and capabilites that we as humans possess.  This in my mind is one of the key failures that expert systems exhibit when taken out of their specified context.  No human is born with an innate understanding for complex issues, such as language and metacognition.  Artificial Intelligence should thus be treated as a child exploring its world, using its inborn capabilities to further its knowledge and grow from a novice to the level of an expert.  For the most part, all adults have specific talents that they particularly excell at, be it anything from chess to culinary arts.  However, unlike expert systems these experts are also capable of other functions, like driving a car or playing a musical instrument.  They are able to perform these tasks because they evolved from being a novice with the foundations to pursue seemingly anything.  Expert systems lack this breadth of ability.  Perhaps one of the greatest problems encountered in this field has been not so much the constraints that technology has placed on computational speed and efficiency of robots (which Minsky has correctly identified as a limit), but the available models of the mind that we have at our expense.  Connectionist models in my eye are currently the most successful and promising representations of how the mind operates and appears to be leading us on the right path.  Yet as paradigms change so too will our perceptions of cognition, which will in turn affect our understanding of: emotion, semantic meaning, neural networks, and overall perception.  This will prove to be an unavoidable and blessed event, as it will force us to attain a better level of understanding for both ourselves and our artificial counterparts.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20090627042558im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>