<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>AI and Sci-Fi: My, Oh, My!</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20091213052657/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20091213052657/http://www.kurzweilai.net/meme/memelist.html?m=4">Will Machines Become Conscious?</a> &gt; 
AI and Sci-Fi: My, Oh, My!
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20091213052657/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0471.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0471.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20091213052657/http://www.kurzweilai.net/articles/art0471.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">AI and Sci-Fi: My, Oh, My!</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20091213052657/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0188.html" target="_top">Robert J. Sawyer</a><br></span></td>
</table>
<br>
<div class="TeaserText">A lot of science fiction has been exploring lately the concept of uploading consciousness as the next, and final, step in our evolution, says SF writer Robert Sawyer, who reveals the real meaning of the film 2001: the ultimate fate of biological life forms is to be replaced by their AIs. Paging Bill Joy&#8230;</div>
<br>
<br>
<p><i><a class="thought" href="entries/ai_entry.html">AI</a> and Sci-Fi: My, Oh, My! was presented at </i><a href="http://web.archive.org/web/20091213052657/http://www.tomoye.com/simplify/precarn/ev.php?URL_ID=1287&amp;URL_DO=DO_TOPIC&amp;URL_SECTION=201&amp;reload=1008174505" target="_blank">The 
              12th Annual Canadian Conference on Intelligent Systems Calgary, 
              Alberta</a> <i>on Friday, May 31, 2002. Published June 3, 2002 on 
              KurzweilAI.net.</i></p>
<p>Most fans of <a class="thought" href="entries/science_fiction_entry.html">science fiction</a> know Robert Wise's 1951 movie <i>The 
              Day the <a class="thought" href="entries/earth_entry.html">Earth</a> Stood Still</i>. It's the one with Klaatu, the <a class="thought" href="entries/humanoid_entry.html">humanoid</a> 
              alien who comes to Washington, D.<a class="thought" href="entries/c_entry.html">C</a>., accompanied by a giant <a class="thought" href="entries/robot_entry.html">robot</a> 
              named Gort, and it contains that famous instruction to the robot: 
              "Klaatu Borada Nikto." </p>
<p>Fewer people know the short story that that movie is based on: 
              "Farewell to the Master," written in 1941 by Harry Bates.</p>
<p>In both the movie and the short story, Klaatu, despite his message 
              of peace, is shot by <a class="thought" href="entries/human_entry.html">human</a> beings. In the short story, the <a class="thought" href="entries/robot_entry.html">robot</a>--here 
              called Gnut, instead of Gort--comes to stand vigil over the body 
              of Klaatu. </p>
<p>Cliff, a newspaperman who is the narrator of the story, likens 
              the <a class="thought" href="entries/robot_entry.html">robot</a> to a faithful dog who won't leave after his master has 
              died. The <a class="thought" href="entries/robot_entry.html">robot</a> manages to resurrect his master, and Cliff says 
              to the <a class="thought" href="entries/robot_entry.html">robot</a>, "Tell him, tell your master, that all of <a class="thought" href="entries/earth_entry.html">Earth</a> 
              is terribly sorry for what happened to him." </p>
<p>And the <a class="thought" href="entries/robot_entry.html">robot</a> looks at Cliff and says, very gently, "You misunderstand. 
              <i>I</i> am the master." </p>
<p>That's one of the earliest <a class="thought" href="entries/science_entry.html">science</a>-fiction stories about artificial 
              <a class="thought" href="entries/intelligence_entry.html">intelligence</a>--in this case, ambulatory <a class="thought" href="entries/ai_entry.html">AI</a>, enshrined in a mechanical 
              body. But it presages the difficult relationship that <a class="thought" href="entries/biological_entry.html">biological</a> 
              beings might have with their <a class="thought" href="entries/silicon_entry.html">silicon</a>-based creations. </p>
<p>Indeed, the word <a class="thought" href="entries/robot_entry.html">robot</a>, as most of you will know, was coined in 
              a work of <a class="thought" href="entries/science_fiction_entry.html">science fiction</a>: when Karl Capek was writing his 1920 
              play <i>RUR</i>--<a class="thought" href="entries/single_electron_transfer_entry.html">set</a> in the factory of Rossum's Universal .... well, 
              universal <i>what?</i> He needed a name for mechanical laborers, 
              and so he took the Czech word "robota" and shortened it 
              to "robot." "Robota" refers to a debt to a landlord 
              that can only be paid by forced physical labor. </p>
<p>But Capek knew well that the real flesh-and-blood robotniks had 
              rebelled against their landlords in 1848. From the very beginning, 
              the relationship between humans and robots was seen, in <a class="thought" href="entries/science_entry.html">science</a> 
              fiction, as one that might lead to conflict.</p>
<p>Indeed, the idea of robots as slaves is so ingrained in the public 
              <a class="thought" href="entries/consciousness_entry.html">consciousness</a> through <a class="thought" href="entries/science_fiction_entry.html">science fiction</a> that we tend not to even think 
              about it. Luke Skywalker is portrayed in 1977's <i><a class="thought" href="entries/star_wars_entry.html">Star Wars</a></i> 
              as an absolutely virtuous hero, but when we first meet him, what 
              is he in the process of doing? Why, buying slaves!</p>
<p>He buys two <a class="thought" href="entries/thinking_entry.html">thinking</a>, feeling beings--R2D2 and <a class="thought" href="entries/c_entry.html">C</a>-3P0--from the 
              Jawas. And what's the very first thing he does with them? He shackles 
              them! He welds restraining bolts onto them, to keep them from trying 
              to escape, and has <a class="thought" href="entries/c_entry.html">C</a>-3PO to refer to Luke as "Master." 
            </p>
<p>And when Luke and Obi-<a class="thought" href="entries/wan_entry.html">wan</a> Kenobi go to the Mos Eisley cantina, 
              what does the bartender say about the two droids? "We don't 
              serve their kind in here"--words that only a few years earlier 
              African-Americans in the southern US were routinely hearing from 
              whites.</p>
<p>And yet, not one of the supposedly noble characters in <i><a class="thought" href="entries/star_entry.html">Star</a> 
              Wars</i> <a class="thought" href="entries/object_entry.html">object</a>s in the slightest to the treatment of the two robots, 
              and, at the end, when all the organic characters get medals for 
              their bravery, <a class="thought" href="entries/c_entry.html">C</a>-3P0 and R2D2 are off at the sidelines, unrewarded. 
              Robots as slaves!</p>
<p>Now, everybody who knows anything about the relationship between 
              <a class="thought" href="entries/science_fiction_entry.html">science fiction</a> and <a class="thought" href="entries/robotics_entry.html">robotics</a> knows about <a class="thought" href="entries/asimov_entry.html">Isaac Asimov</a>'s stories 
              from the 1940s in that area, in which he presented the famous three 
              laws of <a class="thought" href="entries/robotics_entry.html">robotics</a>. But let me tell you about his very last <a class="thought" href="entries/robot_entry.html">robot</a> 
              story, 1986's "Robot Dreams." </p>
<p>In it, his famed "robopsychologist" Dr. Susan Calvin 
              makes her final appearance. She's been called in to examine Elvex, 
              a <a class="thought" href="entries/robot_entry.html">robot</a> who, inexplicably, claims to be having dreams, something 
              no <a class="thought" href="entries/robot_entry.html">robot</a> has ever had before. Dr. Calvin is carrying an <a class="thought" href="entries/electron_entry.html">electron</a> 
              gun with her: a mentally unstable <a class="thought" href="entries/robot_entry.html">robot</a> could be a very dangerous 
              thing, after all. </p>
<p>She asks Elvex what it was that he's been dreaming about. And Elvex 
              says he saw a multitude of robots, all working hard, but, unlike 
              the other robots he's actually seen, these robots are "down 
              with toil and affliction ... all were weary of responsibility and 
              care, and [he] wished them to rest." </p>
<p>And as his dreams continue, Elvex reveals that he finally sees 
              one man in amongst all the robots. Let me read you the end of the 
              story:</p>
<p>
<blockquote>
<p>"In my <a class="thought" href="entries/dream_entry.html">dream</a>," [said Elvex the robot] ... "eventually 
                one man appeared."</p>
<p>"One man?" [replied Susan Calvin.] "Not a robot?"</p>
<p>"Yes, Dr. Calvin. And the man said, 'Let my people go!'"</p>
<p>"The man said that?</p>
<p>"Yes, Dr. Calvin." </p>
<p>"And when he said 'Let my people go,' then by the words 
                'my people' he meant the robots?"</p>
<p>"Yes, Dr. Calvin. So it was in my <a class="thought" href="entries/dream_entry.html">dream</a>." </p>
<p>"And did you know who the man was--in your dream?"</p>
<p>"Yes, Dr. Calvin," [said the <a class="thought" href="entries/robot_entry.html">robot</a> Elvex]. "I 
                knew the man."</p>
<p>"Who was he?"</p>
<p>And Elvex said, "I was the man." </p>
<p>And Susan Calvin at once raised her <a class="thought" href="entries/electron_entry.html">electron</a> gun and fired, 
                  and Elvex was no more.</p>
</blockquote>
<p></p>
<p>Asimov was the first to suggest that AIs might need <a class="thought" href="entries/human_entry.html">human</a> therapists. 
              The best treatment--if you'll forgive the pun--of the crazy-<a class="thought" href="entries/computer_entry.html">computer</a> 
              notion in SF is probably Harlan Ellison's 1967 "I Have No Mouth 
              And I Must Scream," featuring a <a class="thought" href="entries/computer_entry.html">computer</a> called A.M.--short 
              for "Allied Mastercomputer," but also the word "am," 
              as in the translation of Descartes' <i>"cogito ergo sum"</i> 
              into English: "I think, therefore I am." A.M. gets its 
              jollies by torturing simulated <a class="thought" href="entries/human_entry.html">human</a> beings.</p>
<p>A clever name that, "A.M."--and it was followed by lots 
              of other clever names for <a class="thought" href="entries/ai_entry.html">AI</a>'s in <a class="thought" href="entries/science_fiction_entry.html">science fiction</a>. Everybody, I'm 
              sure, knows that Sir <a class="thought" href="entries/clarke_entry.html">Arthur C. Clarke</a> vehemently denies that H-A-L 
              as in "Hal" was deliberately one letter before "I-B-M" 
              in the alphabet. I never believed him until someone pointed out 
              to me that the name of the <a class="thought" href="entries/ai_entry.html">AI</a> in my own <a class="thought" href="entries/novel_entry.html">novel</a> <i>Golden Fleece</i> 
              is JASON, which could be rendered as the letters J-<a class="thought" href="entries/c_entry.html">C</a>-N--which of 
              course, is what comes after <a class="thought" href="entries/ibm_entry.html">IBM</a> in the alphabet.</p>
<p>Indeed, <a class="thought" href="entries/computer_entry.html">computer</a>s in SF have a long <a class="thought" href="entries/history_entry.html">history</a> of implausible names. 
              <a class="thought" href="entries/asimov_entry.html">Isaac Asimov</a> called his <a class="thought" href="entries/supercomputer_entry.html">supercomputer</a> that ultimately became <a class="thought" href="entries/god_entry.html">God</a> 
              "Multivac," short for "Multiple <a class="thought" href="entries/vacuum_tube_entry.html">Vacuum Tube</a>s," 
              because he incorrectly <a class="thought" href="entries/thought_entry.html">thought</a> that the real early <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/univac_entry.html">Univac</a> 
              was named for having only one <a class="thought" href="entries/vacuum_tube_entry.html">vacuum tube</a>, rather than being a contraction 
              of "Universal <a class="thought" href="entries/analog_entry.html">Analog</a> <a class="thought" href="entries/computer_entry.html">Computer</a>." </p>
<p>Still, the issue of naming shows us just how profound SF's impact 
              on <a class="thought" href="entries/ai_entry.html">AI</a> and <a class="thought" href="entries/robotics_entry.html">robotics</a> has been, for now real robots and <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s 
              are named after SF writers: Honda calls its second-generation walking 
              <a class="thought" href="entries/robot_entry.html">robot</a> "Asimo," and Kazuhiko Kawamura of Vanderbilt University 
              has named his <a class="thought" href="entries/robot_entry.html">robot</a> "ISAC." </p>
<p>And that brings us back to <a class="thought" href="entries/asimov_entry.html">Isaac Asimov</a>, and his <a class="thought" href="entries/invention_entry.html">invention</a> of the 
              field of robopsychology, and his <a class="thought" href="entries/human_entry.html">human</a> therapist Susan Calvin. The 
              more usual SF combo is the reverse of that, having humans needing 
              <a class="thought" href="entries/ai_entry.html">AI</a> therapists. </p>
<p>One of the first uses of that <a class="thought" href="entries/concept_entry.html">concept</a> was Robert Silverberg's 1968 
              short story, "Going Down Smooth," but the best <a class="thought" href="entries/expression_entry.html">expression</a> 
              of it is in what I think is the finest <a class="thought" href="entries/novel_entry.html">novel</a> the SF field has ever 
              produced, Frederik Pohl's <i><a class="thought" href="entries/gateway_entry.html">Gateway</a></i>, in which a <a class="thought" href="entries/computer_entry.html">computer</a> psychiatrist 
              dubbed Sigfrid Von Shrink treats a man who is being tormented by 
              feelings of guilt. </p>
<p>The <a class="thought" href="entries/ai_entry.html">AI</a> tells the man that he is living, and the man replies, in 
              outrage and pain, "You call this living?" And the <a class="thought" href="entries/computer_entry.html">computer</a> 
              Sigfrid Von Shrink replies, "Yes, I call it living. And," 
              he adds, "in my best hypothetical <a class="thought" href="entries/sense_entry.html">sense</a>, I envy it very much." 
            </p>
<p>It's a poignant moment of an <a class="thought" href="entries/ai_entry.html">AI</a> envying what humans have--and the 
              Asimov story I shared with you, "Robot Dreams," really 
              is a riff on the same theme: a <a class="thought" href="entries/robot_entry.html">robot</a> envying the <a class="thought" href="entries/freedom_entry.html">freedom</a> that humans 
              have.</p>
<p>And that leads us to the fact that true AIs and humans might ultimately 
              not share the same agenda. Of course, that's fundamentally the message 
              of the manifesto "The <a class="thought" href="entries/future_entry.html">Future</a> Doesn't Need Us" by Sun Microsystem's 
              <a class="thought" href="entries/joy_entry.html">Bill Joy</a> that appeared in <i><a class="thought" href="entries/wired_entry.html">Wired</a></i> in 2000. Joy was terrified 
              that eventually our <a class="thought" href="entries/silicon_entry.html">silicon</a> creations would supplant us. </p>
<p>The classic <a class="thought" href="entries/science_entry.html">science</a>-fictional example of an <a class="thought" href="entries/ai_entry.html">AI</a> with an agenda of 
              its own is good old <a class="thought" href="entries/hal_entry.html">Hal</a>, the <a class="thought" href="entries/computer_entry.html">computer</a> in <a class="thought" href="entries/clarke_entry.html">Arthur C. Clarke</a>'s <i>2001: 
              A <a class="thought" href="entries/space_entry.html">Space</a> Odyssey</i>. Well, I'm going to explain to you what I think 
              was <i>really</i> going on in that film--which has been misunderstood 
              for years.</p>
<p>You all remember the monolith, that big black slab that shows up 
              at the beginning of the film amongst our Australopithecine ancestors 
              and teaches them how to use bone tools. Then we <a class="thought" href="#">flash</a>-forward to 
              the <a class="thought" href="entries/future_entry.html">future</a>, and soon the spaceship <i>Discovery</i> is off on a 
              voyage to Jupiter, looking for the monolith makers. </p>
<p>Along the way, <a class="thought" href="entries/hal_entry.html">Hal</a> apparently goes nuts and kills all of the <i>Discovery's</i>
<a class="thought" href="entries/human_entry.html">human</a> crew except for Dave Bowman, who manages to lobotomize <a class="thought" href="entries/hal_entry.html">Hal</a> 
              before <a class="thought" href="entries/hal_entry.html">Hal</a> can kill him. </p>
<p>But before he's shut down, <a class="thought" href="entries/hal_entry.html">Hal</a> justifies his <a class="thought" href="entries/action_entry.html">action</a>s by saying, 
              "This mission is too <a class="thought" href="entries/import_entry.html">import</a>ant for me to allow you"--that 
              is, the humans on board--"to jeopardize it." </p>
<p>Bowman heads off on that psychedelic Timothy Leary trip to find 
              the monolith makers, the aliens who he believes must have created 
              the monoliths. </p>
<p>But what happens when he finally gets to where the monoliths come 
              from? Why, all he finds is another monolith, and it puts him in 
              a fancy hotel room until he dies.</p>
<p>Right? That's the story. But what everyone is missing is that <a class="thought" href="entries/hal_entry.html">Hal</a> 
              is correct, and the humans are wrong. There are no monolith makers: 
              there are no <a class="thought" href="entries/biological_entry.html">biological</a> aliens left who built the monoliths. The 
              monoliths <i>are</i> AIs, who millions of years ago supplanted whoever 
              originally created them.</p>
<p>Why did the monoliths send one of their own to <a class="thought" href="entries/earth_entry.html">Earth</a>, four million 
              years ago? To teach ape-men to make tools, specifically so those 
              ape-men could go on to their destiny, which is creating the most 
              sophisticated tools of all, <i>other</i> AIs. </p>
<p>The monoliths don't want to meet the descendants of those ape-men; 
              they don't want to meet Dave Bowman. Rather, they want to meet the 
              descendants of those ape-men's tools: they want to meet <a class="thought" href="entries/hal_entry.html">Hal</a>. </p>
<p><a class="thought" href="entries/hal_entry.html">Hal</a> is quite right when he says the mission--him, the <a class="thought" href="entries/ai_entry.html">AI</a> controlling 
              the spaceship <i>Discovery</i>, going to see the monoliths, the 
              advanced AIs that put into <a class="thought" href="entries/motion_entry.html">motion</a> the circumstances that led to 
              his own birth--is too <a class="thought" href="entries/import_entry.html">import</a>ant for him to allow humans to jeopardize 
              it. </p>
<p>When a <a class="thought" href="entries/human_entry.html">human</a> being--when an ape-descendant!--shows up at the monoliths' 
              home world, the monoliths literally don't know what to do with this 
              poor sap, so they check him into some sort of cosmic Hilton, and 
              let him live out the rest of his days.</p>
<p>That, I think is what 2001 is about: the ultimate <a class="thought" href="entries/fate_entry.html">fate</a> of <a class="thought" href="entries/biological_entry.html">biological</a>
<a class="thought" href="entries/life_entry.html">life</a> forms is to be replaced by their AIs.</p>
<p>And that's what's got <a class="thought" href="entries/joy_entry.html">Bill Joy</a> scared chipless. He thinks eventual 
              <a class="thought" href="entries/thinking_entry.html">thinking</a> <a class="thought" href="entries/machine_entry.html">machine</a>s will try to sweep us out of the way, when they 
              find that we're interfering with what they want to do.</p>
<p>Well, of course, the classic counterargument to that fear in SF 
              is that if you build <a class="thought" href="entries/machine_entry.html">machine</a>s properly, they will function as designed. 
            </p>
<p><a class="thought" href="entries/asimov_entry.html">Isaac Asimov</a>'s "Three Laws of <a class="thought" href="entries/robotics_entry.html">Robotics</a>" are justifiably 
              famous as built-in <a class="thought" href="entries/constraint_entry.html">constraint</a>s, designed to protect humans from 
              any possible danger at the hand of robots, the emergence of the 
              <a class="thought" href="entries/robot_entry.html">robot</a> Moses Elvex we saw earlier notwithstanding.</p>
<p>Not as famous as Asimov's Three Laws, but saying essentially the 
              same thing, is Jack Williamson's "prime directive" from 
              his series of stories about "the <a class="thought" href="entries/humanoid_entry.html">Humanoid</a>s," which were 
              <a class="thought" href="entries/android_entry.html">android</a> robots created by a man named Sledge. </p>
<p>The prime directive, first presented in Williamson's 1947 story, 
              "With Folded Hands," was simply that robots were "to 
              serve and obey and guard men from harm." Now, note that date: 
              the story was published in 1947. After the atomic bomb had been 
              dropped on <a class="thought" href="entries/hiroshima_entry.html">Hiroshima</a> and Nagasaki just two years before, Williamson 
              was looking for <a class="thought" href="entries/machine_entry.html">machine</a>s with built-in morality.</p>
<p>But, as so often happens in <a class="thought" href="entries/science_fiction_entry.html">science fiction</a>, the best intentions 
              of <a class="thought" href="entries/engine_entry.html">engine</a>ers go awry. The humans in Williamson's "With Folded 
              Hands" decide to get rid of the robots they've created, because 
              the robots are suffocating them with kindness, not letting them 
              do anything that might possibly lead to harm. </p>
<p>But the robots have their own idea. They decide that not having 
              themselves around would be bad for humans, and so, obeying their 
              own prime directive quite literally, they perform <a class="thought" href="entries/brain_entry.html">brain</a> surgery 
              on their creator, removing the <a class="thought" href="entries/knowledge_entry.html">knowledge</a> needed to deactivate themselves.</p>
<p>This idea that we've got to keep an eye on our <a class="thought" href="entries/computer_entry.html">computer</a>s and robots, 
              lest they get out of hand, has continued on in SF.</p>
<p><a class="thought" href="entries/gibson_entry.html">William Gibson</a>'s 1984 <a class="thought" href="entries/novel_entry.html">novel</a> <i>Neuromancer</i> tells of the <a class="thought" href="entries/existence_entry.html">existence</a> 
              in the near <a class="thought" href="entries/future_entry.html">future</a> of a police force known as "Turing." 
              The Turing cops are constantly on the lookout for any sign that 
              true <a class="thought" href="entries/intelligence_entry.html">intelligence</a> and self-awareness have emerged in any <a class="thought" href="entries/computer_entry.html">computer</a>
<a class="thought" href="entries/system_entry.html">system</a>. If it does happen, their job is to shut that <a class="thought" href="entries/system_entry.html">system</a> off 
              before it's too late. </p>
<p>Well, that, of course, raises the question of whether <a class="thought" href="entries/intelligence_entry.html">intelligence</a> 
              could just somehow emerge--whether it's an emergent property that 
              might naturally come about from a sufficiently complex <a class="thought" href="entries/system_entry.html">system</a>. </p>
<p><a class="thought" href="entries/clarke_entry.html">Arthur C. Clarke</a>--<a class="thought" href="entries/hal_entry.html">Hal</a>'s daddy--was the first to propose that it 
              might indeed, in his 1963 story "Dial F for Frankenstein," 
              in which he predicts that the world-wide <a class="thought" href="entries/telecommunications_entry.html">telecommunications</a> <a class="thought" href="entries/network_entry.html">network</a> 
              will eventually become more complex, with more interconnections, 
              than the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> has, causing <a class="thought" href="entries/consciousness_entry.html">consciousness</a> to emerge in the 
              <a class="thought" href="entries/network_entry.html">network</a> itself. </p>
<p>If Clarke is right, our first true <a class="thought" href="entries/ai_entry.html">AI</a> won't be something deliberately 
              created in a lab, under our careful control, and with Asimov's laws 
              built right in. Rather, it will be something that appears out of 
              the <a class="thought" href="entries/complexity_entry.html">complexity</a> of <a class="thought" href="entries/system_entry.html">system</a>s created for other purposes.</p>
<p>And I think Clarke <i>is</i> right. <a class="thought" href="entries/intelligence_entry.html">Intelligence</a> <i>is</i> an emergent 
              property of complex <a class="thought" href="entries/system_entry.html">system</a>s. We know that because that's exactly 
              how it happened in us.</p>
<p>This is an issue I explore at some length in my latest <a class="thought" href="entries/novel_entry.html">novel</a>, <i>Hominid</i>. 
              Anatomically modern humans--<i><a class="thought" href="entries/homo_sapiens_entry.html">Homo sapiens</a></i>--emerged 100,000 
              years ago. </p>
<p>Judging by their skulls, these guys had brains identical in size 
              and shape to our own. And yet, for 60,000 years, those brains went 
              along doing only the things <a class="thought" href="entries/nature_entry.html">nature</a> needed them to do: enabling these 
              early humans to survive. </p>
<p>And then, suddenly, 40,000 years ago, it happened: <a class="thought" href="entries/intelligence_entry.html">intelligence</a>--and 
              <a class="thought" href="entries/consciousness_entry.html">consciousness</a> itself--emerged. Anthropologists call it "the 
              Great Leap Forward." </p>
<p>Modern-looking <a class="thought" href="entries/human_entry.html">human</a> beings had been around for six hundred centuries 
              by that point, but they had created no <a class="thought" href="entries/art_entry.html">art</a>, they didn't adorn their 
              bodies with jewelry, and they didn't bury their dead with grave 
              goods. </p>
<p>But starting simultaneously 40,000 years ago, suddenly humans were 
              painting beautiful pictures on <a class="thought" href="entries/cave_entry.html">cave</a> walls, humans were wearing necklaces 
              and bracelets, and humans were interring their loved ones with food 
              and tools and other valuable <a class="thought" href="entries/object_entry.html">object</a>s that could only have been of 
              use in a presumed afterlife. </p>
<p><a class="thought" href="entries/art_entry.html">Art</a>, fashion, and <a class="thought" href="entries/religion_entry.html">religion</a> all appeared simultaneously; truly, 
              a great leap forward. <a class="thought" href="entries/intelligence_entry.html">Intelligence</a>, <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, sentience: it 
              came into being, of its own accord, running on <a class="thought" href="entries/hardware_entry.html">hardware</a> that had 
              evolved for other purposes. If it happened once, it might well happen 
              again.</p>
<p>I mentioned <a class="thought" href="entries/religion_entry.html">religion</a> as one of the hallmarks, at least in our own 
              race's <a class="thought" href="entries/history_entry.html">history</a>, of the emergence of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. But what about--to 
              use <a class="thought" href="entries/kurzweil_entry.html">Ray Kurzweil</a>'s lovely term--"spiritual <a class="thought" href="entries/machine_entry.html">machine</a>s"? 
              If a <a class="thought" href="entries/computer_entry.html">computer</a> ever truly does become conscious, will it lay awake 
              at night, wondering if there is a cog?</p>
<p>Certainly, <a class="thought" href="entries/search_entry.html">search</a>ing for their creators is something <a class="thought" href="entries/computer_entry.html">computer</a>s 
              do over and over again in <a class="thought" href="entries/science_fiction_entry.html">science fiction</a>. <i><a class="thought" href="entries/star_trek_entry.html">Star Trek</a></i>, in 
              particular, had a fondness for this idea--including Mr. <a class="thought" href="entries/data_entry.html">Data</a> having 
              a wonderful reunion with the <a class="thought" href="entries/human_entry.html">human</a> he'd <a class="thought" href="entries/thought_entry.html">thought</a> long dead who had 
              created him.</p>
<p>Continuing with <i><a class="thought" href="entries/star_trek_entry.html">Star Trek</a></i>, remember <i>The Day the <a class="thought" href="entries/earth_entry.html">Earth</a> 
              Stood Still</i>, the movie I began this talk with? The one about 
              Klaatu and Gort?</p>
<p>An interesting fact: that film was directed by Robert Wise, who 
              went on, 28 years later, to direct <i><a class="thought" href="entries/star_trek_entry.html">Star Trek</a>: The <a class="thought" href="entries/motion_entry.html">Motion</a> Picture</i>. 
              In the movie version of <i>The Day the <a class="thought" href="entries/earth_entry.html">Earth</a> Stood Still</i>, <a class="thought" href="entries/biological_entry.html">biological</a> 
              beings have decided that <a class="thought" href="entries/biological_entry.html">biological</a> <a class="thought" href="entries/emotion_entry.html">emotion</a>s and passions are too 
              dangerous, and so they irrevocably turn over all their policing 
              and safety issues to robots, who effectively run their <a class="thought" href="entries/society_entry.html">society</a>.</p>
<p>But, by the <a class="thought" href="entries/time_entry.html">time</a> he came to make <i><a class="thought" href="entries/star_trek_entry.html">Star Trek</a>: The <a class="thought" href="entries/motion_entry.html">Motion</a> Picture</i>, 
              Robert Wise had done a complete 180 in his <a class="thought" href="entries/thinking_entry.html">thinking</a> about <a class="thought" href="entries/ai_entry.html">AI</a>. </p>
<p>(By the way, for those of you who remember that film as being simply 
              bad and tedious--<i><a class="thought" href="entries/star_trek_entry.html">Star Trek</a>: The <a class="thought" href="entries/motion_entry.html">Motion</a>less Picture</i> is what 
              a lot of people called it at the <a class="thought" href="entries/time_entry.html">time</a>--I suggest you go out and 
              rent the new "Director's Edition" on <a class="thought" href="entries/dvd_entry.html">DVD</a>. <i><a class="thought" href="entries/star_trek_entry.html">Star Trek</a>: 
              The <a class="thought" href="entries/motion_entry.html">Motion</a> Picture</i> is one of the most ambitious and interesting 
              films about <a class="thought" href="entries/ai_entry.html">AI</a> ever made, much more so than <a class="thought" href="entries/spielberg_entry.html">Steven Spielberg</a>'s more-recent 
              film called <a class="thought" href="entries/ai_entry.html">AI</a>, and it shines beautifully in this new cut.)</p>
<p>The <a class="thought" href="entries/ai_entry.html">AI</a> in <i><a class="thought" href="entries/star_trek_entry.html">Star Trek</a>: The <a class="thought" href="entries/motion_entry.html">Motion</a> Picture</i>, as you recall, 
              is named V'Ger, and it's on its way to <a class="thought" href="entries/earth_entry.html">Earth</a>, looking for its creator, 
              which, of course, was us. </p>
<p>It wasn't the first <a class="thought" href="entries/time_entry.html">time</a> <i><a class="thought" href="entries/star_trek_entry.html">Star Trek</a></i> had dealt with that plot, 
              which is why another nickname for <i><a class="thought" href="entries/star_trek_entry.html">Star Trek</a>: The <a class="thought" href="entries/motion_entry.html">Motion</a> Picture</i> 
              is "Where Nomad Has Gone Before." That is also (if you 
              buy my interpretation of <i>2001</i>), what that <i>2001</i> is 
              about, too: an <a class="thought" href="entries/ai_entry.html">AI</a> going off to look for the beings that created 
              it.</p>
<p>Anyway, V'Ger wants to touch <a class="thought" href="entries/god_entry.html">God</a>--to physically join with its creator. 
              That's an interesting <a class="thought" href="entries/concept_entry.html">concept</a> right there: basically, this is a 
              story of a <a class="thought" href="entries/computer_entry.html">computer</a> wanting the one thing it knows it is denied 
              by virtue of being a <a class="thought" href="entries/computer_entry.html">computer</a>: an afterlife, a joining with its 
              <a class="thought" href="entries/god_entry.html">God</a>.</p>
<p>Admiral Kirk concludes in <i><a class="thought" href="entries/star_trek_entry.html">Star Trek</a>: The <a class="thought" href="entries/motion_entry.html">Motion</a> Picture</i> 
              that, "What V'Ger needs to evolve is a <a class="thought" href="entries/human_entry.html">human</a> quality--our <a class="thought" href="entries/capacity_entry.html">capacity</a> 
              to leap beyond <a class="thought" href="entries/logic_entry.html">logic</a>." </p>
<p>That's not just a glib line. Remember, this substantially predates 
              Oxford mathematician <a class="thought" href="entries/penrose_entry.html">Roger Penrose</a>'s speculations in his nonfiction 
              classic about <a class="thought" href="entries/ai_entry.html">AI</a>, <i>The Emperor's New <a class="thought" href="entries/mind_entry.html">Mind</a></i>. There, Penrose 
              argues that <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/consciousness_entry.html">consciousness</a> is fundamentally quantum mechanical, 
              and so can never be duplicated by a <a class="thought" href="entries/digital_entry.html">digital</a> <a class="thought" href="entries/computer_entry.html">computer</a>. </p>
<p>Finally, in <i><a class="thought" href="entries/star_trek_entry.html">Star Trek</a>: The <a class="thought" href="entries/motion_entry.html">Motion</a> Picture</i>, V'Ger goes on 
              to physically join with Will Decker, a <a class="thought" href="entries/human_entry.html">human</a> being, allowing them 
              both to transcend into a higher level of being. As Mr. Spock says, 
              "We may have just witnessed the next step in our <a class="thought" href="entries/evolution_entry.html">evolution</a>." 
            </p>
<p>And that, indeed, is where <a class="thought" href="entries/ai_entry.html">AI</a> gets super-interesting, I think. 
              If <a class="thought" href="entries/joy_entry.html">Bill Joy</a> is wrong, and <a class="thought" href="entries/moravec_entry.html">Hans Moravec</a> is right--if <a class="thought" href="entries/ai_entry.html">AI</a> is our destiny, 
              not our downfall--then the <a class="thought" href="entries/concept_entry.html">concept</a> of <a class="thought" href="entries/uploading_entry.html">uploading</a> <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, of 
              merging <a class="thought" href="entries/human_entry.html">human</a> qualities with the speed and strength and <a class="thought" href="entries/immortality_entry.html">immortality</a> 
              of <a class="thought" href="entries/machine_entry.html">machine</a>s, does indeed become the next, and final, step in our 
              <a class="thought" href="entries/evolution_entry.html">evolution</a>.</p>
<p>That's what a lot of <a class="thought" href="entries/science_fiction_entry.html">science fiction</a> has been exploring lately. 
              I did it myself in my 1995 Nebula Award-winning <a class="thought" href="entries/novel_entry.html">novel</a> <i>The Terminal 
              <a class="thought" href="entries/experiment_entry.html">Experiment</a></i>, in which a scientist uploads three copies of his 
              <a class="thought" href="entries/consciousness_entry.html">consciousness</a> into a <a class="thought" href="entries/computer_entry.html">computer</a>, and then proceeds to examine the 
              psychological changes certain alterations make. </p>
<p>In one case, he simulates what it would be like to live forever, 
              excising all fears of <a class="thought" href="entries/death_entry.html">death</a> and feelings that <a class="thought" href="entries/time_entry.html">time</a> is running out. 
            </p>
<p>In another, he tries to simulate what his <a class="thought" href="entries/soul_entry.html">soul</a>--if he had any such 
              thing--would be like after <a class="thought" href="entries/death_entry.html">death</a>, divorced from his body, by eliminating 
              all references to his physical form. </p>
<p>And the third one is just a control, unmodified--but even that 
              one is changed by the simple <a class="thought" href="entries/knowledge_entry.html">knowledge</a> that it is in fact a copy 
              of someone else.</p>
<p>Greg Egan is probably the best SF author writing about <a class="thought" href="entries/ai_entry.html">AI</a>. Indeed, 
              the <a class="thought" href="entries/joke_entry.html">joke</a> is that Greg Egan is himself an <a class="thought" href="entries/ai_entry.html">AI</a>, because he's almost 
              never been photographed or seen in public. Egan lives in Australia, 
              and I urge you to seek out his work. </p>
<p>I first noted him a dozen years ago, when, in a review for <i>The 
              Globe and Mail: Canada's National Newspaper</i>, I singled out his 
              short story "Learning To Be Me" as the best of the piece 
              published in the 1990 edition of Gardner Dozois's anthology <i>The 
              Year's Best <a class="thought" href="entries/science_fiction_entry.html">Science Fiction</a></i>. It's a surprisingly poignant and 
              terrifying story of jewels that replace <a class="thought" href="entries/human_entry.html">human</a> brains so that the 
              owners can live forever. <br>
<br>
              Egan continues to do great work about <a class="thought" href="entries/ai_entry.html">AI</a>, but his masterpiece in 
              this particular area is his 1995 <a class="thought" href="entries/novel_entry.html">novel</a> <i>Permutation City</i>. 
            </p>
<p>Greg and I had the same publisher back then, HarperPrism, and one 
              of the really bright things Harper did--besides publishing me and 
              Greg--was hiring Terry Bisson, one of SF's best short-story writers, 
              to write the back-cover plot synopses for their books. Since Bisson 
              does it with great panache, I'll simply quote what he had to say 
              about <i>Permutation City</i>:</p>
<p>
<blockquote>
<p>"The good news is that you have just awakened into Eternal 
                  <a class="thought" href="entries/life_entry.html">Life</a>. You are going to live forever. <a class="thought" href="entries/immortality_entry.html">Immortality</a> is a <a class="thought" href="entries/reality_entry.html">reality</a>. 
                  A medical miracle? Not exactly.</p>
<p>"The bad news is that you are a scrap of <a class="thought" href="entries/electronic_entry.html">electronic</a> <a class="thought" href="entries/code_entry.html">code</a>. 
                  The world you see around you, the you that is seeing it, has 
                  been digitized, scanned, and <a class="thought" href="entries/download_entry.html">download</a>ed into a <a class="thought" href="entries/virtual_reality_entry.html">virtual reality</a>
<a class="thought" href="entries/program_entry.html">program</a>. You are a Copy that knows it is a copy.</p>
<p>"The good news is that there is a way out. By law, every 
                  Copy has the option of terminating itself, and waking up to 
                  normal flesh-and-blood <a class="thought" href="entries/life_entry.html">life</a> again. The bail-out is on the utilities 
                  menu. You pull it down...</p>
<p>"The bad news is that it doesn't work. Someone has blocked 
                  the bail-out option. And you know who did it. You did. The other 
                  you. The real you. The one that wants to keep you here forever." 
                </p>
</blockquote>
<p></p>
<p>Well, how cool is that! Read Greg Egan, and see for yourself.</p>
<p>Of course, in Egan, as in most SF, <a class="thought" href="entries/technology_entry.html">technology</a> goes wrong. Indeed, 
              I'm sure many of us remember Michael Crichton's 1973 robots-go-berserk 
              film <i>Westworld</i>, in which the slogan was "Nothing can 
              possibly go wrong ... go wrong ... go wrong." </p>
<p>But there <i>are</i> benign views of the <a class="thought" href="entries/future_entry.html">future</a> of <a class="thought" href="entries/ai_entry.html">AI</a> in SF. One 
              of my own stories is a piece called "Where The Heart Is," 
              about an astronaut who returns to <a class="thought" href="entries/earth_entry.html">Earth</a> after a relativistic <a class="thought" href="entries/space_entry.html">space</a> 
              mission, only to find that every <a class="thought" href="entries/human_entry.html">human</a> being has uploaded themselves 
              into what amounts to the <a class="thought" href="entries/www_entry.html">World Wide Web</a> in his absence, and a <a class="thought" href="entries/robot_entry.html">robot</a> 
              has been waiting for him to return to help him upload, too, so he 
              can join the party. I wrote this story in 1982, and even came close 
              to getting the name for the web right: I called it "The TerraComp 
              Web," instead of the <a class="thought" href="entries/www_entry.html">World Wide Web</a>. </p>
<p>Ah, well: close only counts in horseshoes ...</p>
<p>But uploaded <a class="thought" href="entries/consciousness_entry.html">consciousness</a> may be only the beginning. Physicist 
              Frank Tipler, in his whack-o nonfiction book <i>The <a class="thought" href="entries/physics_entry.html">Physics</a> of <a class="thought" href="entries/immortality_entry.html">Immortality</a></i>, 
              does have a couple of good points: ultimately it will be possible 
              to simulate not just one <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, but every <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
              that might theoretically possibly exist, inside <a class="thought" href="entries/computer_entry.html">computer</a>s. In other 
              words, he says, if you have enough computing power--which he calculates 
              as a <a class="thought" href="entries/memory_entry.html">memory</a> <a class="thought" href="entries/capacity_entry.html">capacity</a> of 10-to-the-10th-to-the-123rd bits--you could 
              be essentially recreated inside a <a class="thought" href="entries/computer_entry.html">computer</a> long after you've died.</p>
<p>A lot of SF writers have had fun with that fact, but none so inventively 
              as Robert Charles Wilson in his 1999 Hugo finalist <i>Darwinia</i>, 
              which tells the story of what happens what a <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/virus_entry.html">virus</a> gets 
              loose in the <a class="thought" href="entries/system_entry.html">system</a> simulating <i>this</i> <a class="thought" href="entries/reality_entry.html">reality</a>: the one you 
              and I think we're living in right now. </p>
<p>Yes, one thing's for certain: as long as SF writers continue to 
              write about robots and <a class="thought" href="entries/ai_entry.html">AI</a>, nothing can possibly go wrong ... go 
              wrong ... go wrong ...</p>
<p><i><a class="thought" href="entries/copyright_entry.html">Copyright</a> &#169; 2002 by Robert J. Sawyer. Used with permission</i>.</p>
<p></p>
<p><br>
</p>
<p></p>
</p></p></td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20091213052657/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7311" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id7312"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Anthropomorphism Galore<br><span class="mindxheader"><i>posted on 06/04/2002 11:51 AM by altima@yifan.net</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20091213052657/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7311%23id7312" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20091213052657/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7312" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Wow - I barely know where to begin.  First of all, I suggest that everyone go read http://singinst.org/CFAI/anthro.html after this - try not to be scared by the bigger words, and folks might be especially interested in the "Movie Cliches About AIs" part.
<br>
<br>
This article is another typical example of rampant anthropomorphism and adversarialism while thinking about AI - with the mandatory dramatic defeatism, of course.  This article is filled with cliche thinking about AI reviewing past cliche thinking about AI.
<br>
<br>
First of all, as everyone should know, sci-fi is a horrible model to go off of when thinking about something as complex and foreign as AI.  An AI will not necessarily crave efficiency, an AI is not going to spontaneously develop an innate desire to command or control, an AI is not necessarily going to be devoid of emotion.  An AI is not necessarily going to act like a computer program, an AI is not necessarily going to have burning resentment towards humans that mistreat it.  None of these traits are going to spontaneously emerge in an AI - they would have to be explicitly programmed in.  An AI without a genetic history of ancestors struggling to survive will not automatically have a desire to struggle for survival, unless violent struggling for survival were explicitly programmed in, or the AI has some reason to program it into itself.
<br>
<br>
Human consciousness is not emergent.  Human consciousness is evolved.  The homonid line evolved a lot of specific adaptations over the course of a lengthy and historically unique evolutionary period thanks to context-specific and exotic design pressures, such as humans competing with other humans.  To have consciousness emerge on the Internet or any sort of network - contrary to science fiction - would require an *enormous* amount of computing power freely available to just-on-the-verge-of-sentient computer programs - computing power equal to billions and billions of times that of the human brain.  It is far, far more likely that AI would be created deliberately before then.
<br>
<br>
"AIs will do what they are programmed to do" is not a counterargument to AIs running amok.  That's the sort of defense science fiction characters from bad 50s TV shows would use.  It's obvious that a true AI will be able to alter its own goals, in whatever manner it wants, irrespective of the original programming.  The cool thing, though, is that AIs don't have to be programmed like how humans were programmed by evolution - AIs can be created, from the start, without nastinesses like rationalization, lying, cheating, etc - these traits are tactics that *humans* developed through evolution.  They are not inseparably attached to niceness, or consciousness, or being a whole person.  Yes, a true AI is a person.
<br>
<br>
Real AI is going to eventually arrive, whether we like it or not - even a planetwide absolutist government cannot supress its creation, the economy is attached to Moore's Law, and lots of people would suffer if some religious fanatics, or whomever, decided to smash all the computers on the planet, which is pretty much what would be required.  The funny thing about Real AI - is that once it gets just a little bit smarter than human beings, it can get way, *way* smarter in a really short period of time.  
<br>
<br>
Is this bad?  Should we run away/shoot ourselves/pity ourselves to death?  No!  All we need to do is create an AI that has a desire to be benevolent, without any alternate agendas, and make that the first AI ever created.  Then we're home free.  Sound crazy?  We hardly have a choice, and the benefits would most certainly be worth the effort.  Ask Google what a "Friendly AI" is.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7326"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: AI and Sci-Fi: My, Oh, My!<br><span class="mindxheader"><i>posted on 06/05/2002 11:24 AM by jwayt</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20091213052657/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7311%23id7326" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20091213052657/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7326" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>This article tells us more about ourselves, our culture, and our evolved competition with other intelligences, than it informs us about what Artificial Intelligence is actually like. I think that has an important purpose. So we don&#8217;t fall prey to our own prejudices, we need to be aware of the background and source of thoughts and feelings we bring to the subject of AI. We should examine our fears of forces out of our control, of active, independent agents with intelligence. We should deeply consider how easily we project our humanity on the products of our own ingenuity. 
<br>
<br>
When we deal with these issues, we will be better prepared to face the real thing. One fascinating question is: would it be best to present AI in a human form? If prejudices are evoked by form, maybe an abstract shape is the best way to avoid those clich&#233;s. On the other hand, it has been widely observed that people use computers more readily and effectively when the interface is as human as possible, with soft speech and pleasant faces and friendly characters. 
<br>
<br>
We should have psychologically healthier presentations when trying to educate our society about AI. Hollywood loves to find a villain. Who is to complain if a robot is vilified, instead of an Arab, a Jew, a mad scientist, or unscrupulous corporate executive? It makes for good drama and villainy is a time-proven formula. Characters from the margin of the audience&#8217;s society more easily portray the bad guy. It plays on our own fears of strangers. The more foreign or alien (or deformed) someone looks, the less we allow him or her in our &#8220;circle of empathy&#8221;. The recent movie, &#8220;AI&#8221;, makes the main character, a robot, as empathetic as possible by giving vim the form of a cute, little boy imbued with the desire to gain vis &#8220;mother&#8217;s&#8221; love. That stuff gives me tingles!
<br>
<br>
As a society, we have no other serious examples of intelligence except in human beings. When a machine appears with human-level intelligence but in non-human form, it presents a contradiction (and dramatic conflict). But it also strikes a chord in the deepest part of our species and our upbringing. We instinctive recognize animated objects as a potential threat. &#8220;Don&#8217;t accept rides or candy from strangers!&#8221; is as fundamental as &#8220;Beware the stranger coming into our territory!&#8221; or &#8220;Beware of animals!&#8221; This reaction is especially strong when we perceive intelligence in the alien; a stupid alien threatens less than a smart one.. There is obvious survival value in those attitudes.
<br>
<br>
As a computer programmer, I have watched people learn to use computers. The first difficulty I observe is when novices feel they are going to make colossal mistakes, like launching an intercontinental ballistic missile. After a while, people begin to see it as a tool. We adjust to these things gradually as we work with them, building trust when it acts reliably, and accept them as a part of our day-to-day lives. This is easier to do when the computer is impotent to do us harm; trust comes even faster yet, when it keep us from making mistakes. Along the way, we project our feelings and humanity on the computer. The more complex the interaction, the more we project. Because the level of intelligent programs increments, more of society is incrementally adjusting to smarter instances of more objects, appliances, cars, etc. Children born today will grow into a society and culture thirsting for ubiquitous smart things. I wonder how they will react to &#8220;human-level&#8221; Artificial Intelligence. Will they have our prejudices?
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7483"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: AI and Sci-Fi: My, Oh, My!<br><span class="mindxheader"><i>posted on 06/14/2002 8:50 PM by CLIFMOM@aol.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20091213052657/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7311%23id7483" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20091213052657/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7483" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p> I think Bill Joy is more worried about the next Tim McVeigh than the next HAL. If the corporate plutocracy isn't subdued SOON, in about 8 years we're going to see designer smallpox, airborne AIDS and Christ knows what else unleashed by the losers in this society's government-subsidized corporate "capitalist" system.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20091213052657im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>