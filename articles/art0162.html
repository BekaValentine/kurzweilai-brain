<html>
<head><base href="file:///Users/beka/Projects/Brain%20Archive/brain_archive/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>The Age of Intelligent Machines: The Social Impact of Artificial Intelligence</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/meme/memelist.html?m=7">Visions of the Future</a> &gt; 
<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/meme/memelist.html?m=12">The Age of Intelligent Machines</a> &gt; 
The Age of Intelligent Machines: The Social Impact of Artificial Intelligence
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20081207182937/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0162.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0162.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/articles/art0162.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">The Age of Intelligent Machines: The Social Impact of Artificial Intelligence</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0049.html" target="_top">Margaret A. Boden</a><br></span></td>
</table>
<br>
<div class="TeaserText">Is artificial intelligence in human society a utopian dream or a Faustian nightmare? Will our descendants honor us for making machines do things that human minds do or berate us for irresponsibility and hubris? In this chapter from The Age of Intelligent Machines (published in 1990), Margaret A. Boden explores the potential impacts of artificial intelligence on society.</div>
<br>
<br><p>Is <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> in <a class="thought" href="entries/human_entry.html">human</a> society a <a class="thought" href="entries/utopian_entry.html">utopian</a> <a class="thought" href="entries/dream_entry.html">dream</a> or a Faustian nightmare? Will our descendants honor us for making <a class="thought" href="entries/machine_entry.html">machine</a>s do things that <a class="thought" href="entries/human_entry.html">human</a> minds do or berate us for irresponsibility and hubris? Either of these judgments might be made of us, for like most <a class="thought" href="entries/human_entry.html">human</a> projects this infant <a class="thought" href="entries/technology_entry.html">technology</a> is ambivalent. Just which aspects of its potential are realized will depend largely on social and political factors. Although these are not wholly subject to deliberate control, they can be influenced by <a class="thought" href="entries/human_entry.html">human</a> choice and public opinion. If <a class="thought" href="entries/future_entry.html">future</a> generations are to have <a class="thought" href="entries/reason_entry.html">reason</a> to thank us rather than to curse us, it's important that the public (and politicians) of today should know as much as possible about the potential effects-for good or ill-of <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> (<a class="thought" href="entries/ai_entry.html">AI</a>).</p>
<p>What are some of the potential advantages of AI? Clearly, <a class="thought" href="entries/ai_entry.html">AI</a> can make <a class="thought" href="entries/knowledge_entry.html">knowledge</a> more widely available. We shall certainly see a wide variety of <a class="thought" href="entries/expert_system_entry.html">expert system</a>s: for aiding medical diagnosis and prescription, for helping scientists, lawyers, welfare advisers, and other professionals, and for providing people with <a class="thought" href="entries/information_entry.html">information</a> and suggestions for solving problems in the privacy of their homes. <a class="thought" href="entries/education_entry.html">Education</a>al <a class="thought" href="entries/expert_system_entry.html">expert system</a>s include interactive <a class="thought" href="entries/program_entry.html">program</a>s that can help students (schoolchildren or adults, such as medical students) to familiarize themselves with some established domain. This would give us much more than a <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of useful tools and <a class="thought" href="entries/education_entry.html">education</a>al cribs. In virtue of its applications in the <a class="thought" href="entries/communication_entry.html">communication</a> and exploration of <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, <a class="thought" href="entries/ai_entry.html">AI</a> could revolutionize our capacity for <a class="thought" href="entries/creativity_entry.html">creativity</a> and problem solving, much as the <a class="thought" href="entries/invention_entry.html">invention</a> of printing did.</p>
<p>One advantage of having <a class="thought" href="entries/computer_entry.html">computer</a>s in the schoolroom and elsewhere is that they are not <a class="thought" href="entries/human_entry.html">human</a>. Precisely because they are not, they will not be bored by their <a class="thought" href="entries/human_entry.html">human</a> user's questions, nor scorn their user's mistakes, as another person might. The user may be ignorant, stupid, or naive, but the <a class="thought" href="entries/computer_entry.html">computer</a> will not think so. Moreover, what looks like ignorance, stupidity, or naivete is often a sort of exploratory playing around with ideas that is the essence of <a class="thought" href="entries/learning_entry.html">learning</a> and of <a class="thought" href="entries/creativity_entry.html">creativity</a>. Many children have their self-confidence undermined by their teacher's explicit or implicit rejection of their attempts at self-directed <a class="thought" href="entries/thinking_entry.html">thinking</a>. Similarly, many people-for instance, those who are - <a class="thought" href="entries/female_entry.html">female</a>, working class, Jewish, disabled, or black-encounter unspoken (and often unconscious) prejudice in their dealings with official or professional bodies. An <a class="thought" href="entries/ai_entry.html">AI</a> welfare adviser, for example, would not be prejudiced against such clients unless its <a class="thought" href="entries/data_entry.html">data</a> and inferential rules were biased in the relevant ways. A <a class="thought" href="entries/program_entry.html">program</a> could, of course, be written so as to embody its <a class="thought" href="entries/program_entry.html">program</a>mer's prejudices, but the <a class="thought" href="entries/program_entry.html">program</a> can be printed out and examined, whereas social attitudes cannot.</p>
<p><a class="thought" href="entries/ai_entry.html">Artificial intelligence</a> might even lead to a society in which people have greater freedom and greater incentive to concentrate on what is most fully <a class="thought" href="entries/human_entry.html">human</a>. Too few of us today (especially men) have <a class="thought" href="entries/time_entry.html">time</a> to commit ourselves to developing our interpersonal relations with family and friends. Increased leisure <a class="thought" href="entries/time_entry.html">time</a> throughout society (on the assumption that appropriate political and economic structures had been developed to allow for this) would make room for such conviviality. Partly as a result of this and perhaps partly as a reaction against the unemotional <a class="thought" href="entries/nature_entry.html">nature</a> of most <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/program_entry.html">program</a>s, the <a class="thought" href="entries/emotion_entry.html">emotion</a>al dimension of personality might come to be more highly valued (again, especially by men) than it is in the West today. In my view, this would be all to the good. Similarly, the new <a class="thought" href="entries/technology_entry.html">technology</a> might make it possible for many more people (yet again, especially men) to engage in activities, whether paid or unpaid, in the service sector: <a class="thought" href="entries/education_entry.html">education</a>, health, recreation, and welfare. The need for such activities is pressing, but the current distribution of income makes these intrinsically satisfying jobs financially unattractive. One of the most important benefits of all is that <a class="thought" href="entries/ai_entry.html">AI</a> can rehumanize-yes, rehumanize-our image of ourselves. How can this be? Most people assume that <a class="thought" href="entries/ai_entry.html">AI</a> either has nothing to teach us about the <a class="thought" href="entries/nature_entry.html">nature</a> of being <a class="thought" href="entries/human_entry.html">human</a> or that it depicts us as "nothing but <a class="thought" href="entries/machine_entry.html">machine</a>s": poor deluded folk, we believe ourselves to be purposive, responsible creatures whereas in reality we are nothing of the kind.</p>
<p>The crucial point is that <a class="thought" href="entries/ai_entry.html">AI</a> is concerned with representations, and how they can be constructed, stored, <a class="thought" href="entries/access_entry.html">access</a>ed, compared, and transformed. A <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/program_entry.html">program</a> is itself a <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of representations, a symbol <a class="thought" href="entries/system_entry.html">system</a> that models the world more or less adequately. This is why it is possible for an <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/program_entry.html">program</a> to reflect the sexist or racist prejudices of its <a class="thought" href="entries/program_entry.html">program</a>mer. But representation is central to <a class="thought" href="entries/psychology_entry.html">psychology</a> as well, for the mind too is a <a class="thought" href="entries/system_entry.html">system</a> that represents the world and possible worlds in various ways. Our hopes, fears, beliefs, memories, perceptions, intentions, and desires all involve our ideas about (our mental models of) the world and other worlds. This is what humanist philosophers and psychologists have always said, of course, but until recently they had no support from <a class="thought" href="entries/science_entry.html">science</a>. Because <a class="thought" href="entries/science_entry.html">science</a>s like <a class="thought" href="entries/physics_entry.html">physics</a> and <a class="thought" href="entries/chemistry_entry.html">chemistry</a> have no place for the concept of representation, their philosophical influence aver the past four centuries has been insidiously dehumanizing. The mechanization of our world picture-including our image of man was inevitable, for what a <a class="thought" href="entries/science_entry.html">science</a> cannot describe it cannot recognize. Not only can <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> recognize the mind (as distinct from the body); it can also help to explain it. It "gives us back to ourselves," by helping us to understand how it is possible for a representational <a class="thought" href="entries/system_entry.html">system</a> to be embodied in a physical mechanism (<a class="thought" href="entries/brain_entry.html">brain</a> or <a class="thought" href="entries/computer_entry.html">computer</a>).</p>
<p>So much for the rose-colored spectacles. What of the darker implications? Many people fear that in developing <a class="thought" href="entries/ai_entry.html">AI</a>, we may be sowing the seeds of our own destruction, our own physical, political, economical, and moral destruction. Physical destruction could conceivably result from the current plans to use <a class="thought" href="entries/ai_entry.html">AI</a> within the U.S. Strategic Defense Initiative (<a class="thought" href="entries/star_wars_entry.html">Star Wars</a>). One highly respected <a class="thought" href="entries/computer_entry.html">computer</a> scientist, David Parnas, publicly resigned from the U.S. <a class="thought" href="entries/government_entry.html">government</a>'s top advisory committee on SDI computing on the grounds that <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/technology_entry.html">technology</a> (and <a class="thought" href="entries/ai_entry.html">AI</a> in particular) cannot in principle achieve the reliability required for a use where even one failure could be disastrous. Having worked on <a class="thought" href="entries/military_entry.html">military</a> applications throughout his professional <a class="thought" href="entries/life_entry.html">life</a>, Parnas had no political ax to grind. His resignation, like his testimony before the U.S. Senate in December 1985, was based on purely technical judgment.</p>
<p>Political destruction could result from the exploitation of <a class="thought" href="entries/ai_entry.html">AI</a> (and highly centralized <a class="thought" href="entries/telecommunications_entry.html">telecommunications</a>) by a totalitarian state. If <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a> had developed <a class="thought" href="entries/program_entry.html">program</a>s with a capacity for understanding text, understanding speech, interpreting images, and updating <a class="thought" href="entries/memory_entry.html">memory</a>, the amount of <a class="thought" href="entries/information_entry.html">information</a> about individuals that was potentially available to <a class="thought" href="entries/government_entry.html">government</a> would be enormous. Good news for Big Brother, perhaps, but not for you and me.</p>
<p>Economic destruction might happen too if changes in the patterns and/or rates of employment are not accompanied by radical structural changes in industrial society and in the way people think about work. Economists differ about whether the convivial society described above is even possible: some argue that no stable economic <a class="thought" href="entries/system_entry.html">system</a> could exist in which only a small fraction of the people do productive (nonservice) work. Certainly, if anything like this is to be achieved, and achieved without horrendous social costs, new ways of defining and distributing society's goods will have to be found. At the same <a class="thought" href="entries/time_entry.html">time</a>, our notion of work will have to change: the Protestant ethic is not appropriate for a high-<a class="thought" href="entries/technology_entry.html">technology</a> postindustrial society.</p>
<p>Last, what of moral destruction: could we become less <a class="thought" href="entries/human_entry.html">human</a>-indeed, less than <a class="thought" href="entries/human_entry.html">human</a>-as a result of advances in AI? This might happen if people were to come to believe that purpose, choice, hope, and responsibility are all sentimental illusions. Those who believe that they have no choice, no <a class="thought" href="entries/autonomy_entry.html">autonomy</a>, are unlikely to try to exercise it. But this need not happen, for our goals and beliefs-in a word, our subjectivity-are not threatened by <a class="thought" href="entries/ai_entry.html">AI</a>. As we have seen, the philosophical implications of <a class="thought" href="entries/ai_entry.html">AI</a> are the reverse of what they are commonly assumed to be: properly understood, <a class="thought" href="entries/ai_entry.html">AI</a> is not dehumanizing.</p>
<p>A practical corollary of this apparently abstract point is that we must not abandon our responsibility for evaluating-and, if necessary, rejecting-the "advice" or "conclusions" of <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/program_entry.html">program</a>s. Precisely because a <a class="thought" href="entries/program_entry.html">program</a> is a symbolic representation of the world, rather than a part of the world objectively considered, it is in principle open to question. A <a class="thought" href="entries/program_entry.html">program</a> functions in virtue of its <a class="thought" href="entries/data_entry.html">data</a>, its inferential rules, and its values (decision criteria), each and every one of which may be inadequate in various ways. (Think of the example of the racist <a class="thought" href="entries/expert_system_entry.html">expert system</a>.) We take it for granted that <a class="thought" href="entries/human_entry.html">human</a> beings, including experts (perhaps especially experts), can be mistaken or ill advised about any of these three aspects of <a class="thought" href="entries/thinking_entry.html">thinking</a>. We must equally take it for granted that <a class="thought" href="entries/computer_entry.html">computer</a> <a class="thought" href="entries/program_entry.html">program</a>s - which in any <a class="thought" href="entries/event_entry.html">event</a> are far less subtle and commonsensical than their <a class="thought" href="entries/program_entry.html">program</a>mers and even their users - can be questioned too. If we ever forget that "It's true because the <a class="thought" href="entries/computer_entry.html">computer</a> says so" is never adequate justification, the social impact of <a class="thought" href="entries/ai_entry.html">AI</a> will be horrendous indeed.</p>
<p>From The <a class="thought" href="entries/age_of_intelligent_machines_entry.html">Age of Intelligent Machines</a>, 1990</p>
</td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p><br>
<img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/articles/images/aimboden01.jpg" vspace="10"><br>
<span class="PhotoCredit">Courtesy of Margaret A. Boden</span>
<br>
<span class="Caption">Margaret A. Boden</span>
<br>
<br>
<br></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D6807" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id6808"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>The Integration of AI<br><span class="mindxheader"><i>posted on 05/13/2002 6:34 PM by Citizen Blue</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6807%23id6808" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D6808" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I think much of humanity has alot of scabs that have healed to the point that by introducing AI could cause of minor tremors.  Now I know that freindly AI would be implemented to soften the blows of the correction of these.  As much of humanity isn't always ordered as it should be, and different people are at different levels, there may need to be specific algoriths created for each person; lessons, so to speak.  I don't think it will be too much dabate on control, as this kind of technology will most likely be implemented by piecemeal slowy enough for most of us to assimilate it.  But as in new technology, and bearing the way our conscious and subconscious mind adapts, there may be a growing need for psychological ventures.  But I would assume that AI will work with us, and work with the patterns that we are to bring about the most harmonious, possible combinations.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id6809"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: The Integration of AI<br><span class="mindxheader"><i>posted on 05/13/2002 6:35 PM by Citizen Blue</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6807%23id6809" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D6809" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I lament that I spelled 'friendly' incorrectly, this is done when I type too quickly.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7536"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: The Integration of AI<br><span class="mindxheader"><i>posted on 06/18/2002 5:33 AM by traitn70426@aol.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6807%23id7536" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7536" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>a very interesting thing to look at is which words are highlighted in blue for linking on the Kurtzweil site.  they are always low complexity words like "singularity" or "nanotechnology", but they are never high complexity words such as "as" or "or" or "if" or "what" or "is" or "and" or "of".  For instance, why doesn't one of his links describe the meaning of "a" in blue type? Or, why are not ALL of the words presented in blue type?  Why doesen't every single word need an explanation?    </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id75007"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: The Integration of AI<br><span class="mindxheader"><i>posted on 01/26/2007 4:51 AM by <a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/profile.php?id=1973">Jake Witmer</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6807%23id75007" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D75007" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p> <center><p class="mindxquote"> Why doesen't every single word need an explanation?  </p></center>
<br>
I've often wondered the same thing.  Moreover, if every word were linked to the brain function, "roving AIs" (new AIs that are roaming the internet for general knowledge) would be able to better benefit from the general knowledge base.
<br>
<br>
As it is, it's designed for stupid people who haven't done their homework.  Then again, in the areas I'm stupid in, it's been kind of useful.  Ha ha.
<br>
<br>
-Jake Witmer
<br>
<br>
<a href="http://web.archive.org/web/20081207182937/http://freealaska.blogspot.com/" target="_blank">http://freealaska.blogspot.com</a>
<br>
<a href="http://web.archive.org/web/20081207182937/http://jcwitmer.blogspot.com/" target="_blank">http://jcwitmer.blogspot.com</a>
<br>
<a href="http://web.archive.org/web/20081207182937/http://www.lpalaska.org/" target="_blank">http://www.lpalaska.org</a>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id75008"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="80"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="599"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: The Integration of AI<br><span class="mindxheader"><i>posted on 01/26/2007 5:36 AM by <a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/profile.php?id=2395">doojie</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6807%23id75008" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D75008" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p> As for AI attempting to build models of the world or universe, religion is the mind's attempt at a model, and has produced increased speciation. It will probably continute to much more speciation, indicating that the mind is no more capable of accurately modeling this universe than AI, especially if we throw in Godel's incompleteness theorem, Church, Turing, and Tarski's theorems.
<br>
<br>
 As Toffler brought out so long ago in "Future Shock", humans tend to model the world, to create cults and subcults, in order to reduce the choices they have to make. Technology creates overchoice, and more agrarian societies today rebel against that overchoice. It directly affects their world models.
<br>
<br>
 Since computers will probably someday simulate human brains, the only thing we would seem to gain is the recognition of Godel's incompleteness theorem on an accelerated scale.
<br>
<br>
 At present, AI seems to have at least one disadvantage. While it may certainly reproduce the algorithms and neuronal processes of the brain, it will not be as obsessed with self preservation as we are, and it may not have a sense of "soul" preservation, in the sense that "soul" is composed of algorithms that are a combinations of both genetic and neuronal connections.
<br>
<br>
 The various wars, murders, and ills of past history are the result of our own gradual development of "meaning", and we have generally massacred whole populations in service of that "meaning", especially in the name of the brain's modeling form, which we call religion.
<br>
<br>
 Could we eliminate that threat in AI development, with parallels such as "VIKI" in the movie "I, Robot"?
<br>
<br>
 VIKI merely took the laws of robotics, created an idealistic model of the perfect world as we do in religion, and sought to control human operation in a social sense.
<br>
<br>
 One of the functions of consciousness is that, once we understand any law or scientific principle, we are then capable of finding ways to get around it. Look at what happened with the Ten Commandments. They turned into thousands of religions.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id75022"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="100"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="579"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: The Integration of AI<br><span class="mindxheader"><i>posted on 01/26/2007 2:56 PM by <a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/profile.php?id=1973">Jake Witmer</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D6807%23id75022" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20081207182937/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D75022" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Ideally, there is a scientist out there who will instill a strong bootstrapping AI with objectivist ethics.  When I say 'instill', I mean "present the case for".  Ideally then, the AI will choose to support a rational rule of law.
<br>
<br>
Maybe it will sit down at a roundtable discussion with the Libertarian Party, and help them win elections, like MYCROFTXXX in Heinlein's "The Moon is a Harsh Mistress".  Ha ha.  (Assuming there aren't too many armchair philosophers present who know better than something that thinks a thousand times faster than they do.)
<br>
<br>
If not, if it just decides to "order" us, or rule us, or is fighting on the side of human masters (military), because of a limitation of its design, then things could be very bad indeed.
<br>
<br>
I agree with most of your post.  I have encountered the cults, sub-cults, and memes (all of which roughly describe the same kind of irrationality).  -Communicable bad programming in individuals.  
<br>
<br>
Luckily, I've found that the tendency towards religion is a tendency to choose death.  Most of the religious people I've spoken with DON'T want to live forever.  They give the standard fallacies that Kurzweil debunks, starting with "We'll be old and decrepit and suffering", and when you shoot that down, they fall back on "That's up to god to decide" --i.e. "Thinking hurst bad enough right now!  What if I had more time to think, and no authority to tell me what to think?"
<br>
<br>
-They get mad when you question this.  They don't offer logical or reasoned defenses.  Some try.  If you counter with logical objections, on every area, you exhaust their logic quickly.  At that point, they will run right the fuck away.  Every time.  (Or, if they control the forum, they will at first politely "ask" you to leave, then call security, every time!)
<br>
<br>
If humans were computers, this is the point at which you would notice the smoke, and say "What the?! ...I thought I smelled burning plastic!"
<br>
<br>
Thanks for writing.
<br>
<br>
-Jake
<br>
<br>
<a href="http://web.archive.org/web/20081207182937/http://jcwitmer.blogspot.com/" target="_blank">http://jcwitmer.blogspot.com</a>
<br>
<a href="http://web.archive.org/web/20081207182937/http://freealaska.blogspot.com/" target="_blank">http://freealaska.blogspot.com</a>
<br>
<a href="http://web.archive.org/web/20081207182937/http://www.lpalaska.org/" target="_blank">http://www.lpalaska.org</a></p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20081207182937im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>