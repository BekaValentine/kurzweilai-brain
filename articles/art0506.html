<html>
<head><base href="https://kurzweilai-brain.gothdyke.mom/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>On the Search for the Neural Correlate of Consciousness</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/meme/memelist.html?m=4">Will Machines Become Conscious?</a> &gt; 
On the Search for the Neural Correlate of Consciousness
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20080628060911/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0506.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0506.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/articles/art0506.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">On the Search for the Neural Correlate of Consciousness</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0190.html" target="_top">David Chalmers</a><br></span></td>
</table>
<br>
<div class="TeaserText">There's a variety of proposed neural systems associated with conscious experience, but no way to directly observe or measure consciousness. Chalmers suggests though that there may  be a "consciousness module" -- a functional area responsible for the integration of information in the brain, with high-bandwidth communication between its parts. </div>
<br>
<br><i>Originally published March 
            1998 in </i><a href="http://web.archive.org/web/20080628060911/http://mitpress.mit.edu/0262082624" target="_blank">Toward 
            a Science of Consciousness II: The Second Tucson Discussions and Debates</a><i> 
            (MIT Press). Published on KurzweilAI.net on June 26, 2002.</i>
<p><br>
              From the author: This paper appears in <i>Toward a <a class="thought" href="entries/science_entry.html">Science</a> of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a> 
              II: The Second Tucson Discussions and Debates</i> (S. Hameroff, 
              A. Kaszniak, and A.Scott, eds), published with MIT Press in 1998. 
              It is a transcript of my talk at the second Tucson conference in 
              April 1996, lightly edited to include the <a class="thought" href="entries/content_entry.html">content</a>s of overheads 
              and to exclude some diversions with a <a class="thought" href="entries/consciousness_entry.html">consciousness</a> meter. A more 
              in-depth argument for some of the claims in this paper can be found 
              in Chapter 6 of my book <a href="http://web.archive.org/web/20080628060911/http://www.amazon.com/exec/obidos/redirect?tag=fantasticvoya-20&amp;path=ASIN%2F0195117891%2Fqid%3D1024289206%2Fsr%3D1-1%2Fref%3Dsr_1_1" target="_blank"><i>The 
              Conscious Mind</i></a> (Chalmers, 1996).</p>
<p>&#160;</p>
<p>I'm going to talk about one aspect of the role that <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a> 
              plays in the <a class="thought" href="entries/search_entry.html">search</a> for a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. Whether or not 
              <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a> can solve all the problems of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> single 
              handedly, there is no question that it has a major role to play. 
              We've seen at this conference that there's a vast amount of <a class="thought" href="entries/progress_entry.html">progress</a> 
              in neurobiological <a class="thought" href="entries/research_entry.html">research</a>, and that much of it is clearly bearing 
              on the problems of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. But the <a class="thought" href="entries/concept_entry.html">concept</a>ual foundations 
              of this sort of <a class="thought" href="entries/research_entry.html">research</a> are only beginning to be laid. So I will 
              look at some of the things that are going on from a philosopher's 
              perspective and will see if there's anything helpful to say about 
              these foundations. </p>
<p>We've all been hearing a lot about the "neural correlate of 
              <a class="thought" href="entries/consciousness_entry.html">consciousness</a>". This phrase is intended to refer to the neural 
              <a class="thought" href="entries/system_entry.html">system</a> or <a class="thought" href="entries/system_entry.html">system</a>s primarily associated with conscious <a class="thought" href="entries/experience_entry.html">experience</a>. 
              I gather that the catchword of the day is "NCC". We all 
              have an NCC inside our head, we just have to find out what it is. 
              In recent years there have been quite a few proposals about the 
              <a class="thought" href="entries/identity_entry.html">identity</a> of the NCC. One of the most famous proposals is Crick and 
              Koch's suggestion concerning 40-hertz oscillations. That proposal 
              has since faded away a little but there are all sorts of other suggestions 
              out there. It's almost got to a point where it's reminiscent of 
              <a class="thought" href="entries/particle_entry.html">particle</a> <a class="thought" href="entries/physics_entry.html">physics</a>, where they have something like 236 <a class="thought" href="entries/particle_entry.html">particle</a>s and 
              people talk about the "particle zoo". In the study of 
              <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, one might talk about the "neural correlate zoo". 
              There have also been a <a class="thought" href="entries/number_entry.html">number</a> of related proposals about what we 
              might call the "cognitive correlate of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>" 
              (CCC?). </p>
<p>A small list of suggestions that have been put forward might include: 
            </p>
<p>
<ul>
<li>40-hertz oscillations in the <a class="thought" href="entries/cerebral_cortex_entry.html">cerebral cortex</a> (Crick and Koch 
                1990)</li>
<li>Intralaminar <a class="thought" href="entries/nucleus_entry.html">nucleus</a> in the thalamus (Bogen 1995)</li>
<li>Re-entrant loops in thalamocortical <a class="thought" href="entries/system_entry.html">system</a>s (Edelman 1989)</li>
<li>40-hertz rhythmic activity in thalamocortical <a class="thought" href="entries/system_entry.html">system</a>s (Llinas 
                et al 1994) </li>
<li><a class="thought" href="entries/nucleus_entry.html">Nucleus</a> reticularis (Taylor and Alavi 1995)</li>
<li>Extended reticular-thalamic activation <a class="thought" href="entries/system_entry.html">system</a> (Newman and Baars 
                1993)</li>
<li>Anterior cingulate <a class="thought" href="entries/system_entry.html">system</a> (Cotterill 1994)</li>
<li>Neural assemblies bound by NMDA (Flohr 1995) </li>
<li>Temporally-extended neural activity (Libet 1994) </li>
<li>Backprojections to lower cortical areas (Cauller and Kulics 
                1991)</li>
<li><a class="thought" href="entries/neuron_entry.html">Neuron</a>s in extrastriate visual cortex projecting to prefrontal 
                areas (Crick and Koch 1995) </li>
<li>Neural activity in area V5/MT (Tootell et al 1995) </li>
<li>Certain <a class="thought" href="entries/neuron_entry.html">neuron</a>s in the superior temporal sulcus (Logothetis 
                and Schall 1989) </li>
<li><a class="thought" href="entries/neuron_entry.html">Neuron</a>al gestalts in an epicenter (Greenfield 1995) </li>
<li>Outputs of a comparator <a class="thought" href="entries/system_entry.html">system</a> in the hippocampus (Gray 1995) 
              </li>
<li><a class="thought" href="entries/quantum_coherence_entry.html">Quantum coherence</a> in microtubules (Hameroff 1994) </li>
<li>Global workspace (Baars 1988) </li>
<li>Activated semantic memories (Hardcastle 1995) </li>
<li>High-quality representations (Farah 1994) </li>
<li>Selector inputs to <a class="thought" href="entries/action_entry.html">action</a> <a class="thought" href="entries/system_entry.html">system</a>s (Shallice 1988)
<p>There are a few intriguing commonalities among the proposals 
                  on this list. A <a class="thought" href="entries/number_entry.html">number</a> of them give a central role to interactions 
                  between the thalamus and the cortex, for example. All the same, 
                  the sheer <a class="thought" href="entries/number_entry.html">number</a> and <a class="thought" href="entries/diversity_entry.html">diversity</a> of the proposals can be a little 
                  overwhelming. I propose to step back a little and try to make 
                  <a class="thought" href="entries/sense_entry.html">sense</a> of all this activity by asking some foundational questions. 
                </p>
<p>A central question is this: how is it, in fact, that one can 
                  <a class="thought" href="entries/search_entry.html">search</a> for the neural correlate of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>? As we all 
                  know, there are problems in measuring <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. It's not 
                  a directly and straightforwardly observable <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a>. It would 
                  be a lot easier if we had a way of getting at <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
                  directly; if we had, for example, a <a class="thought" href="entries/consciousness_entry.html">consciousness</a> meter. </p>
<p>If we had a <a class="thought" href="entries/consciousness_entry.html">consciousness</a> meter, <a class="thought" href="entries/search_entry.html">search</a>ing for the NCC would 
                  be straightforward. We'd <a class="thought" href="entries/wave_entry.html">wave</a> the <a class="thought" href="entries/consciousness_entry.html">consciousness</a> meter and measure 
                  a subject's <a class="thought" href="entries/consciousness_entry.html">consciousness</a> directly. At the same <a class="thought" href="entries/time_entry.html">time</a>, we'd monitor 
                  the underlying <a class="thought" href="entries/brain_entry.html">brain</a> processes. After a <a class="thought" href="entries/number_entry.html">number</a> of trials, we'd 
                  say OK, such-and-such <a class="thought" href="entries/brain_entry.html">brain</a> processes are correlated with <a class="thought" href="entries/experience_entry.html">experience</a>s 
                  of various kinds, so that's the neural correlate of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. 
                </p>
<p>Alas, we don't have a <a class="thought" href="entries/consciousness_entry.html">consciousness</a> meter, and there seem to 
                  be principled <a class="thought" href="entries/reason_entry.html">reason</a>s why we can't have one. <a class="thought" href="entries/consciousness_entry.html">Consciousness</a> just 
                  isn't the sort of thing that can be measured directly. So: What 
                  do we do without a <a class="thought" href="entries/consciousness_entry.html">consciousness</a> meter? How can the <a class="thought" href="entries/search_entry.html">search</a> go 
                  forward? How does all this <a class="thought" href="entries/experiment_entry.html">experiment</a>al <a class="thought" href="entries/research_entry.html">research</a> proceed? </p>
<p>I think the answer is this: we get there through principles 
                  of <i>interpretation</i>. These are principles by which we interpret 
                  physical <a class="thought" href="entries/system_entry.html">system</a>s to judge whether or not they have <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. 
                  We might call these <i>pre-<a class="thought" href="entries/experiment_entry.html">experiment</a>al bridging principles</i>. 
                  These are the criteria that we bring to bear in looking at <a class="thought" href="entries/system_entry.html">system</a>s 
                  to say (a) whether or not they are conscious now, and (b) what 
                  <a class="thought" href="entries/information_entry.html">information</a> they are conscious of, and what <a class="thought" href="entries/information_entry.html">information</a> they 
                  are not. We can't reach in directly and grab those <a class="thought" href="entries/experience_entry.html">experience</a>s 
                  and "transpersonalize" them into our own, so we rely 
                  on external criteria instead. </p>
<p>That's a perfectly <a class="thought" href="entries/reason_entry.html">reason</a>able thing to do. But in doing this 
                  we have to realize that something interesting is going on. These 
                  principles of interpretation are not themselves <a class="thought" href="entries/experiment_entry.html">experiment</a>ally 
                  determined or <a class="thought" href="entries/experiment_entry.html">experiment</a>ally tested. In a <a class="thought" href="entries/sense_entry.html">sense</a> they are pre-<a class="thought" href="entries/experiment_entry.html">experiment</a>al 
                  assumptions. <a class="thought" href="entries/experiment_entry.html">Experiment</a>al <a class="thought" href="entries/research_entry.html">research</a> gives us a lot of <a class="thought" href="entries/information_entry.html">information</a> 
                  about processing; then we bring in the bridging principles to 
                  interpret the <a class="thought" href="entries/experiment_entry.html">experiment</a>al results, whatever those results may 
                  be. They are the principles by which we make <i>inferences</i> 
                  from facts about processing to facts about <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, so 
                  they are <a class="thought" href="entries/concept_entry.html">concept</a>ually prior to the <a class="thought" href="entries/experiment_entry.html">experiment</a>s themselves. We 
                  can't actually refine them <a class="thought" href="entries/experiment_entry.html">experiment</a>ally (except perhaps through 
                  first-person <a class="thought" href="entries/experiment_entry.html">experiment</a>ation!), because we don't have any independent 
                  <a class="thought" href="entries/access_entry.html">access</a> to the independent variable. Instead, these principles 
                  will be based on some combination of (a) <a class="thought" href="entries/concept_entry.html">concept</a>ual judgments 
                  about what counts as a conscious process and (b) <a class="thought" href="entries/information_entry.html">information</a> 
                  gleaned from our first-person perspective on our own <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. 
                </p>
<p>I think we are all stuck in this boat. The point applies whether 
                  one is a <a class="thought" href="entries/reduction_entry.html">reduction</a>ist or an anti-<a class="thought" href="entries/reduction_entry.html">reduction</a>ist about <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. 
                  A hard-line <a class="thought" href="entries/reduction_entry.html">reduction</a>ist might put some of these points slightly 
                  differently, but either way, the <a class="thought" href="entries/experiment_entry.html">experiment</a>al work is going 
                  to require pre-<a class="thought" href="entries/experiment_entry.html">experiment</a>al <a class="thought" href="entries/reason_entry.html">reason</a>ing to determine the criteria 
                  for ascription of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. Of course such principles are 
                  usually left implicit in empirical <a class="thought" href="entries/research_entry.html">research</a>. We don't usually 
                  see papers saying "Here is the bridging principle, here 
                  are the <a class="thought" href="entries/data_entry.html">data</a>, and here is what follows." But it's useful 
                  to make them explicit. The very presence of these principles 
                  has some strong and interesting consequences in the <a class="thought" href="entries/search_entry.html">search</a> for 
                  the NCC. </p>
<p>In a <a class="thought" href="entries/sense_entry.html">sense</a>, in relying on these principles we are taking a 
                  leap into the epistemological unknown. Because we don't measure 
                  <a class="thought" href="entries/consciousness_entry.html">consciousness</a> directly, we have to make something of a leap 
                  of faith. It may not be a big leap, but nevertheless it suggests 
                  that everyone doing this sort of work is engaged in philosophical 
                  <a class="thought" href="entries/reason_entry.html">reason</a>ing. Of course one can always choose to stay on solid 
                  ground, talking about the empirical results in a neutral way; 
                  but the price of doing so is that one gains no particular insight 
                  into <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. Conversely, as soon as we draw any conclusions 
                  about <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, we have gone beyond the <a class="thought" href="entries/information_entry.html">information</a> given, 
                  so we need to pay careful attention to the <a class="thought" href="entries/reason_entry.html">reason</a>ing involved. 
                </p>
<p>So what are these principles of interpretation? The first and 
                  by far the most prevalent such principle is a very straightforward 
                  one: it's a principle of verbal report. When someone says "Yes, 
                  I see that table now", we infer that they are conscious 
                  of the table. When someone says "Yes, I see red now", 
                  we infer that they are having an <a class="thought" href="entries/experience_entry.html">experience</a> of red. Of course 
                  one might always say "How do you know?" -- a philosopher 
                  might suggest that we may be faced with a fully functioning 
                  zombie - but in fact most of us don't believe that the people 
                  around us are zombies, and in practice we are quite prepared 
                  to rely on this principle. As pre-<a class="thought" href="entries/experiment_entry.html">experiment</a>al assumptions go, 
                  this is a relatively "safe" one -- it doesn't require 
                  a huge leap of faith -- and it is very widely used. </p>
<p>So the principle here is that when <a class="thought" href="entries/information_entry.html">information</a> is verbally 
                  reported, it is conscious. One can extend this slightly, as 
                  no one believes that an <i>actual</i> verbal report is required 
                  for <a class="thought" href="entries/consciousness_entry.html">consciousness</a>; we are conscious of much more than we report 
                  on any given occasion. So an extended principle might say that 
                  when <a class="thought" href="entries/information_entry.html">information</a> is directly <i>available</i> for verbal report, 
                  it is conscious. </p>
<p><a class="thought" href="entries/experiment_entry.html">Experiment</a>al <a class="thought" href="entries/research_entry.html">research</a>ers don't rely only on these principles 
                  of verbal report and reportability. These principles can be 
                  somewhat limiting when we want to do broader <a class="thought" href="entries/experiment_entry.html">experiment</a>s. In 
                  particular, we don't want to just restrict our studies of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
                  to subjects that have <a class="thought" href="entries/language_entry.html">language</a>. In fact just this morning we 
                  saw a beautiful example of <a class="thought" href="entries/research_entry.html">research</a> on <a class="thought" href="entries/consciousness_entry.html">consciousness</a> in <a class="thought" href="entries/language_entry.html">language</a>-free 
                  creatures. I'm referring to the work of Nikos Logothetis and 
                  his colleagues (e.g. Logothetis &amp; Schall 1989; Leopold &amp; 
                  Logothetis 1996). This work uses <a class="thought" href="entries/experiment_entry.html">experiment</a>s on binocular rivalry 
                  in monkeys to draw conclusions about the neural processes associated 
                  with <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. How do Logothetis <i>et al</i> manage to 
                  draw conclusions about a monkey's <a class="thought" href="entries/consciousness_entry.html">consciousness</a> without getting 
                  any verbal reports? What they do is rely on a monkey's pressing 
                  bars: if a monkey can be made to press a bar in an appropriate 
                  way in response to a stimulus, we'll say that that stimulus 
                  was consciously perceived. </p>
<p>The criterion at play seems to require that the <a class="thought" href="entries/information_entry.html">information</a> 
                  be available for an arbitrary response. If it turned out that 
                  the monkey could press a bar in response to a red <a class="thought" href="entries/light_entry.html">light</a> but 
                  couldn't do anything else, we would be tempted to say that it 
                  wasn't a case of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> at all, but some sort of subconscious 
                  connection. If on the other hand we find <a class="thought" href="entries/information_entry.html">information</a> that is 
                  available for response in all sorts of different ways, then 
                  we'll say that it is conscious. Actually Logothetis and his 
                  colleagues also use some subtler <a class="thought" href="entries/reason_entry.html">reason</a>ing about similarities 
                  with binocular rivalry in humans to buttress the claim that 
                  the monkey is having the relevant conscious <a class="thought" href="entries/experience_entry.html">experience</a>, but 
                  it is clearly the response that carries the most weight. </p>
<p>The underlying general principle is something like this: When 
                  <a class="thought" href="entries/information_entry.html">information</a> is <i>directly available for global control</i> 
                  in a cognitive <a class="thought" href="entries/system_entry.html">system</a>, then it is conscious. If <a class="thought" href="entries/information_entry.html">information</a> 
                  is available for response in many different motor modalities, 
                  we will say that it is conscious, at least in a range of relatively 
                  familiar <a class="thought" href="entries/system_entry.html">system</a>s such as humans and primates and so on. This 
                  principle squares well with the previous principle in cases 
                  where the <a class="thought" href="entries/capacity_entry.html">capacity</a> for verbal report is present: availability 
                  for verbal report and availability for global control seem to 
                  go together in such cases (report is one of the key aspects 
                  of control, after all, and it is rare to find <a class="thought" href="entries/information_entry.html">information</a> that 
                  is reportable but not available more widely). But this principle 
                  is also applicable more widely. </p>
<p>A correlation between <a class="thought" href="entries/consciousness_entry.html">consciousness</a> and global availability 
                  (for short) seems to fit the first-person evidence -- the evidence 
                  gleaned from our own conscious <a class="thought" href="entries/experience_entry.html">experience</a> -- quite well. When 
                  <a class="thought" href="entries/information_entry.html">information</a> is present in my <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, it is generally 
                  reportable, and it can generally be brought to bear in the control 
                  of behavior in all sorts of different ways. I can talk about 
                  it, I can point in the general direction of a stimulus, I can 
                  press bars, and so on. Conversely, when we find <a class="thought" href="entries/information_entry.html">information</a> 
                  that is directly available in this way for report and other 
                  aspects of control, it is generally conscious <a class="thought" href="entries/information_entry.html">information</a>. I 
                  think one can bear this out by consideration of cases. </p>
<p>There are some interesting puzzle cases to consider, such as 
                  the case of blindsight, where one has <i>some</i> kind of availability 
                  for control but arguably no conscious <a class="thought" href="entries/experience_entry.html">experience</a>. Those cases 
                  might best be handled by invoking the directness criterion: 
                  insofar as the <a class="thought" href="entries/information_entry.html">information</a> here is available for report and 
                  other control processes at all, it is available only indirectly, 
                  by comparison to the direct and automatic availability in standard 
                  cases. One might also stipulate that it is availability for 
                  <i>voluntary</i> control that is relevant, to deal with certain 
                  cases of involuntary unconscious response, although that is 
                  a complex issue. I discuss a <a class="thought" href="entries/number_entry.html">number</a> of puzzle cases in more 
                  detail elsewhere (Chalmers 1996, forthcoming), where I also 
                  give a much more detailed defense of the idea that something 
                  like global availability is the key pre-empirical criterion 
                  for the ascription of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. </p>
<p>But this remains at best a first-<a class="thought" href="entries/order_entry.html">order</a> approximation of the 
                  functional criteria that come into play. I'm less concerned 
                  today to get all the fine details right than to work with the 
                  idea that some such functional criterion is required and indeed 
                  is implicit in all the empirical <a class="thought" href="entries/research_entry.html">research</a> on the neural correlate 
                  of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. If you disagree with the criterion I've suggested 
                  here - presumably because you can think of counterexamples -- 
                  you may want to use those counterexamples to refine it or to 
                  come up with a better criterion of your own. But the point I 
                  want to focus on here is that in the very act of <a class="thought" href="entries/experiment_entry.html">experiment</a>ally 
                  distinguishing conscious from unconscious processes, some such 
                  criterion is always at play. </p>
<p>So the question I want to ask is: if <i>something</i> like 
                  this is right, then what follows? That is, if some such bridging 
                  principles are implicit in the <a class="thought" href="entries/method_entry.html">method</a>ology of the <a class="thought" href="entries/search_entry.html">search</a> for 
                  the NCC, then what are the consequences? I will use global availability 
                  as my central functional criterion in the discussion that follows, 
                  but many of the points should generalize. </p>
<p>The first thing one can do is produce what philosophers might 
                  call a <i>rational reconstruction</i> of the <a class="thought" href="entries/search_entry.html">search</a> for the 
                  neural correlate of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. With a rational reconstruction 
                  we can say, maybe things don't work exactly like this in practice, 
                  but the rational underpinnings of the process have something 
                  like this form. That is, if one were to try to <i>justify</i> 
                  the conclusions one has reached as well as one can, one's justification 
                  would follow the shape of the rational reconstruction. In this 
                  case, a rational reconstruction might look something like this: 
                </p>
<p>(1) <a class="thought" href="entries/consciousness_entry.html">Consciousness</a> &lt;-&gt; global availability (bridging principle) 
                </p>
<p>(2) Global availability &lt;-&gt; neural process N (empirical 
                  work) </p>
<p>so </p>
<p>(3) <a class="thought" href="entries/consciousness_entry.html">Consciousness</a> &lt;-&gt; neural process N (conclusion). 
                </p>
<p>According to this reconstruction, one implicitly embraces some 
                  sort of pre-<a class="thought" href="entries/experiment_entry.html">experiment</a>al bridging principle that one finds plausible 
                  on independent grounds, such as <a class="thought" href="entries/concept_entry.html">concept</a>ual or phenomenological 
                  grounds. Then one does the empirical <a class="thought" href="entries/research_entry.html">research</a>. Instead of measuring 
                  <a class="thought" href="entries/consciousness_entry.html">consciousness</a> directly, we detect the functional property. One 
                  sees that when this functional property (e.g. global availability) 
                  is present, it is correlated with a certain neural process (e.g. 
                  40-hertz oscillations). Combining the pre-empirical premise 
                  and the empirical result, we arrive at the conclusion that this 
                  neural process is a candidate for the NCC. </p>
<p>Of course it doesn't work nearly so simply in practice. The 
                  two stages are very intertwined; our pre-<a class="thought" href="entries/experiment_entry.html">experiment</a>al principles 
                  may themselves be refined as <a class="thought" href="entries/experiment_entry.html">experiment</a>al <a class="thought" href="entries/research_entry.html">research</a> goes along. 
                  Nevertheless I think one can make a separation, at least at 
                  the rational level, into pre-empirical and <a class="thought" href="entries/experiment_entry.html">experiment</a>al <a class="thought" href="entries/component_entry.html">component</a>s, 
                  for the sake of analysis. So with this sort of rational reconstruction 
                  in hand, what sort of conclusions follow? There are about six 
                  consequences that I want to draw out here. </p>
<p><br>
                  (1) The first conclusion is a characterization of the neural 
                  correlates of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. If the NCC is arrived at through 
                  this sort of <a class="thought" href="entries/method_entry.html">method</a>ology, then whatever it turns out to be, 
                  it will be a mechanism of <i>global availability</i>. The presence 
                  of the NCC wherever global availability is present suggests 
                  that it is a mechanism that <i>subserves</i> the process of 
                  global availability in the <a class="thought" href="entries/brain_entry.html">brain</a>. The only alternative that 
                  we have to worry about is that it might be a <i>symptom</i> 
                  rather than a <i>mechanism</i> of global availability; but that 
                  possibility ought to be addressable in principle by dissociation 
                  studies, by lesioning, and so on. If a process is a mere symptom 
                  of availability, we ought to be able to empirically dissociate 
                  it from the process of global availability while leaving the 
                  latter intact. The resulting <a class="thought" href="entries/data_entry.html">data</a> would suggest to us that <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
                  can be present even when the neural process in question is not, 
                  thus indicating that it wasn't a perfect correlate of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
                  after all. </p>
<p>(A related line of <a class="thought" href="entries/reason_entry.html">reason</a>ing supports the idea that a true 
                  NCC must be a mechanism of <i>direct</i> availability for global 
                  control. Mechanisms of indirect availability will in principle 
                  be dissociable from the empirical evidence for <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, 
                  for example by directly stimulating the mechanisms of direct 
                  availability. The indirect mechanisms will be "screened 
                  off" by the direct mechanisms in much the same way as the 
                  <a class="thought" href="entries/retina_entry.html">retina</a> is screened off as an NCC by the visual cortex.) </p>
<p>In fact, if one looks at the various proposals that are out 
                  there, this template seems to fit them pretty well. For example, 
                  the 40-hertz oscillations discussed by Crick and Koch were put 
                  forward precisely because of the role they might play in binding 
                  and integrating <a class="thought" href="entries/information_entry.html">information</a> into working <a class="thought" href="entries/memory_entry.html">memory</a>, and working 
                  <a class="thought" href="entries/memory_entry.html">memory</a> is of course a central mechanism whereby <a class="thought" href="entries/information_entry.html">information</a> 
                  is made available for global control in a cognitive <a class="thought" href="entries/system_entry.html">system</a>. 
                  Similarly, it is plausible that Libet's extended neural activity 
                  is relevant precisely because the temporal extendedness of activity 
                  is what gives certain <a class="thought" href="entries/information_entry.html">information</a> the <a class="thought" href="entries/capacity_entry.html">capacity</a> to dominate later 
                  processes that lead to control. Baars' global workspace is a 
                  particularly explicit proposal of a mechanism in this direction; 
                  it is put forward explicitly as a mechanism whereby <a class="thought" href="entries/information_entry.html">information</a> 
                  can be globally disseminated. All of these mechanisms and many 
                  of the others seem to be candidates for mechanisms of global 
                  availability in the <a class="thought" href="entries/brain_entry.html">brain</a>. </p>
<p><br>
                  (2) This reconstruction suggests that a full story about the 
                  neural processes associated with <a class="thought" href="entries/consciousness_entry.html">consciousness</a> will to do two 
                  things. Firstly, it will <i>explain</i> global availability 
                  in the <a class="thought" href="entries/brain_entry.html">brain</a>. Once we know all about the relevant neural processes, 
                  we will know precisely how <a class="thought" href="entries/information_entry.html">information</a> is made directly available 
                  for global control in the <a class="thought" href="entries/brain_entry.html">brain</a>, and this will be an explanation 
                  in the full <a class="thought" href="entries/sense_entry.html">sense</a>. Global availability is a functional property, 
                  and as always the problem of explaining the performance of a 
                  function is a problem to which mechanistic explanation is well-suited. 
                  So we can be confident that in a century or two, global availability 
                  will be straightforwardly explained. Secondly, this explanation 
                  of availability will do something else: it will isolate the 
                  processes that <i>underlie</i> <a class="thought" href="entries/consciousness_entry.html">consciousness</a> itself. If the 
                  bridging principle is granted, then mechanisms of availability 
                  will automatically be correlates of phenomenology in the full 
                  <a class="thought" href="entries/sense_entry.html">sense</a>. </p>
<p>Now, I don't think this gives us a full <i>explanation</i> 
                  of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. One can always raise the question of why it 
                  is that these processes of availability should give rise to 
                  <a class="thought" href="entries/consciousness_entry.html">consciousness</a> in the first place. As yet we have no explanation 
                  of why this is, and it may well be that the full details concerning 
                  the processes of availability still won't answer this question. 
                  Certainly, nothing in the standard <a class="thought" href="entries/method_entry.html">method</a>ology I have outlined 
                  answers the question; that <a class="thought" href="entries/method_entry.html">method</a>ology <i>assumes</i> a relation 
                  between availability and <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, and therefore does nothing 
                  to <i>explain</i> it. The relationship between the two is instead 
                  taken as something of a primitive. So the hard problem still 
                  remains. But who knows: somewhere along the line we may be led 
                  to the relevant insights that show why the link is there, and 
                  the hard problem may then be solved. In any case, whether or 
                  not we have solved the hard problem, we may nevertheless have 
                  isolated the <i>basis</i> of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> in the <a class="thought" href="entries/brain_entry.html">brain</a>. We 
                  just have to keep in <a class="thought" href="entries/mind_entry.html">mind</a> the distinction between correlation 
                  and explanation. </p>
<p><br>
                  (3) Given this <a class="thought" href="entries/paradigm_entry.html">paradigm</a>, it is likely that there are going to 
                  be many different neural correlates of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. I take 
                  it that this is not going to surprise many people; but the rational 
                  reconstruction gives us a way of seeing just why such a multiplicity 
                  of correlates should exist. There will be many neural correlates 
                  of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> because there may well be many different mechanisms 
                  of global availability. There will be mechanisms of availability 
                  in different modalities: the mechanisms of visual availability 
                  may be quite different from the mechanisms of auditory availability, 
                  for example. (Of course they <i>may</i> be the same, in that 
                  we could find a later area that integrates and disseminates 
                  all this <a class="thought" href="entries/information_entry.html">information</a>, but that's an open question.) There will 
                  also be mechanisms at different stages of the processing path 
                  whereby <a class="thought" href="entries/information_entry.html">information</a> is made globally available: early mechanisms 
                  and later ones. So these may all be candidates for the NCC. 
                  And there will be mechanisms at many different levels of description: 
                  for example, 40-hertz oscillations may well be redescribed as 
                  high-quality representations, or as part of a global workspace, 
                  at a different level of description. So it may turn out that 
                  a <a class="thought" href="entries/number_entry.html">number</a> of the <a class="thought" href="entries/animal_entry.html">animal</a>s in the zoo, so to speak, can co-exist, 
                  because they are compatible in one of these ways. </p>
<p>I won't speculate much further on just what the neural correlates 
                  of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> <i>are</i>. No doubt some of the ideas in the 
                  initial list will prove to be entirely off-track, while some 
                  of the others will prove closer to the mark. As we philosophers 
                  like to say, humbly, that's an empirical question. But I hope 
                  the <a class="thought" href="entries/concept_entry.html">concept</a>ual issues are becoming clearer. </p>
<p><br>
                  (4) This way of <a class="thought" href="entries/thinking_entry.html">thinking</a> about things allows one to make <a class="thought" href="entries/sense_entry.html">sense</a> 
                  of a idea that is sometimes floated: that of a <i><a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
                  module</i>. Sometimes this notion is disparaged; sometimes it 
                  is embraced. But this picture of the <a class="thought" href="entries/method_entry.html">method</a>ology in the <a class="thought" href="entries/search_entry.html">search</a> 
                  for an NCC suggests that it is at least possible that there 
                  could turn out to be such a module. What would it take? It would 
                  require that there turns out to be some sort of functionally 
                  localizable, internally integrated area, through which all global 
                  availability runs. It needn't be anatomically localizable, but 
                  to qualify as a module it would need to be localizable in some 
                  broader <a class="thought" href="entries/sense_entry.html">sense</a>. For example, the parts of the module would have 
                  to have high-<a class="thought" href="entries/bandwidth_entry.html">bandwidth</a> <a class="thought" href="entries/communication_entry.html">communication</a> among themselves, compared 
                  to the relatively low-<a class="thought" href="entries/bandwidth_entry.html">bandwidth</a> <a class="thought" href="entries/communication_entry.html">communication</a> that they have 
                  with other areas. Such a thing <i>could</i> turn out to exist. 
                  It doesn't strike me as especially <i>likely</i> that things 
                  will turn out this way; it seems just as likely that there will 
                  be multiple independent mechanisms of global availability in 
                  the <a class="thought" href="entries/brain_entry.html">brain</a>, scattered around without any special degree of mutual 
                  integration. If that's so, we will likely say that there doesn't 
                  turn out to be a <a class="thought" href="entries/consciousness_entry.html">consciousness</a> module after all. But that's 
                  another one of those empirical questions. </p>
<p>If something like this does turn out to exist in the <a class="thought" href="entries/brain_entry.html">brain</a>, 
                  it would resemble Baars' <a class="thought" href="entries/concept_entry.html">concept</a>ion of a global workspace: a 
                  functional area responsible for the integration of <a class="thought" href="entries/information_entry.html">information</a> 
                  in the <a class="thought" href="entries/brain_entry.html">brain</a> and for its dissemination to multiple nonconscious 
                  specialized processes. In fact I should acknowledge that many 
                  of the ideas I'm putting forward here are compatible with things 
                  that Baars has been saying for years about the role of global 
                  availability in the study of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. Indeed, this way 
                  of looking at things suggests that some of his ideas are almost 
                  forced on one by the <a class="thought" href="entries/method_entry.html">method</a>ology. The special epistemological 
                  role of global availability helps explain why the idea of a 
                  global workspace provides a useful way of <a class="thought" href="entries/thinking_entry.html">thinking</a> about almost 
                  any empirical proposal about <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. If NCC's are identified 
                  as such precisely because of their role in global control, then 
                  at least on a first approximation, we should expect the global 
                  workspace idea to be a natural fit. </p>
<p><br>
                  (5) We can also apply this picture to a question that has been 
                  discussed frequently at this conference: are the neural correlates 
                  of <i>visual</i> <a class="thought" href="entries/consciousness_entry.html">consciousness</a> to be found in V1, in the extrastriate 
                  visual cortex, or elsewhere? If our picture of the <a class="thought" href="entries/method_entry.html">method</a>ology 
                  is correct, then the answer will presumably depend on which 
                  visual area is most directly implicated in global availability. 
                </p>
<p>Crick and Koch have suggested that the visual NCC is not to 
                  be found within V1, as V1 does not contain <a class="thought" href="entries/neuron_entry.html">neuron</a>s that project 
                  to the prefrontal cortex. This <a class="thought" href="entries/reason_entry.html">reason</a>ing has been criticized 
                  by Ned Block for conflating <a class="thought" href="entries/access_entry.html">access</a> <a class="thought" href="entries/consciousness_entry.html">consciousness</a> and phenomenal 
                  <a class="thought" href="entries/consciousness_entry.html">consciousness</a> (see Block, this volume); but interestingly, the 
                  picture I have developed suggests that it may be good <a class="thought" href="entries/reason_entry.html">reason</a>ing. 
                  The prefrontal cortex is known to be associated with control 
                  processes; so <i>if</i> a given area in the visual cortex projects 
                  to prefrontal areas, then it may well be a mechanism of direct 
                  availability. And if it does not project in this way, it is 
                  less likely to be such a mechanism; at best it might be <i>indirectly</i> 
                  associated with global availability. Of course there is still 
                  plenty of room to raise questions about the empirical details. 
                  But the broader point is that for the sort of <a class="thought" href="entries/reason_entry.html">reason</a>s discussed 
                  in (2) above, it is likely that the neural processes involved 
                  in <i>explaining</i> <a class="thought" href="entries/access_entry.html">access</a> <a class="thought" href="entries/consciousness_entry.html">consciousness</a> will simultaneously 
                  be involved in a story about the <i>basis</i> of phenomenal 
                  <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. If something like this is implicit in their <a class="thought" href="entries/reason_entry.html">reason</a>ing, 
                  Crick and Koch might escape the charge of conflation. Of course 
                  the <a class="thought" href="entries/reason_entry.html">reason</a>ing does depend on these somewhat shaky bridging principles, 
                  but then all work on the neural correlates of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
                  must appeal to such principles somewhere, so this can't be held 
                  against Crick and Koch in particular. </p>
<p><br>
                  (6) Sometimes the neural correlate of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> is conceived 
                  of as the <a class="thought" href="entries/holy_grail_entry.html">Holy Grail</a> for a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. It will 
                  make everything fall into place. For example, once we discover 
                  the NCC, then we'll have a definitive test for <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, 
                  enabling us to discover <a class="thought" href="entries/consciousness_entry.html">consciousness</a> wherever it arises. That 
                  is, we might use the neural correlate itself as a sort of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
                  meter. If a <a class="thought" href="entries/system_entry.html">system</a> has 40-hertz oscillations (say), then it 
                  is conscious; if it has none, then it is not conscious. Or if 
                  a thalamocortical <a class="thought" href="entries/system_entry.html">system</a> turns out to be the NCC, then a <a class="thought" href="entries/system_entry.html">system</a> 
                  without that <a class="thought" href="entries/system_entry.html">system</a> is unlikely to be conscious. This sort of 
                  <a class="thought" href="entries/reason_entry.html">reason</a>ing is not usually put quite so baldly as this, but I 
                  think one finds some version of it quite frequently. </p>
<p>This <a class="thought" href="entries/reason_entry.html">reason</a>ing can be tempting, but one should not succumb 
                  to the temptation. Given the very <a class="thought" href="entries/method_entry.html">method</a>ology that comes into 
                  play here, there is no way to definitely establish a given NCC 
                  as an independent test for <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. The primary criterion 
                  for <a class="thought" href="entries/consciousness_entry.html">consciousness</a> will always remain the functional property 
                  we started with: global availability, or verbal report, or whatever. 
                  That's how we discovered the correlations in the first place. 
                  40-hertz oscillations (or whatever) are relevant <i>only</i> 
                  because of the role they play in satisfying this criterion. 
                  True, in cases where we know that this association between the 
                  NCC and the functional property is present, the NCC might itself 
                  function as a sort of "signature" of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>; 
                  but once we dissociate the NCC from the functional property, 
                  all bets are off. To take an extreme example, if we have 40-hertz 
                  oscillations in a test tube, that almost certainly won't yield 
                  <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. But the point applies equally in less extreme 
                  cases. Because it was the bridging principles that gave us all 
                  the traction in the <a class="thought" href="entries/search_entry.html">search</a> for an NCC in the first place, it's 
                  not clear that anything follows in cases where the functional 
                  criterion is thrown it away. So there's no free lunch here: 
                  one can't get something for nothing. </p>
<p>Once one recognizes the central role that pre-<a class="thought" href="entries/experiment_entry.html">experiment</a>al 
                  assumptions play in the <a class="thought" href="entries/search_entry.html">search</a> for the NCC, one realizes that 
                  there are some limitations on just what we can expect this <a class="thought" href="entries/search_entry.html">search</a> 
                  to tell us. Still, whether or not the NCC is the <a class="thought" href="entries/holy_grail_entry.html">Holy Grail</a>, 
                  I hope that I have said enough to make it clear that the quest 
                  for it is likely to enhance our understanding considerably. 
                  And I hope to have convinced you that there are <a class="thought" href="entries/import_entry.html">import</a>ant ways 
                  in which <a class="thought" href="entries/philosophy_entry.html">philosophy</a> and <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a> can come together to help 
                  clarify some of the deep problems involved in the study of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. 
                </p>
<p>References</p>
<p>Baars, B.J. 1988. <i>A Cognitive Theory of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i>. 
                  Cambridge University Press. </p>
<p>Bogen, J.E. 1995. On the neurophysiology of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, 
                  parts I and II. <i><a class="thought" href="entries/consciousness_entry.html">Consciousness</a> and Cognition</i>, 4:52-62 
                  &amp; 4:137-58. </p>
<p>Cauller, L.J. &amp; Kulics, A.T. 1991. The neural basis of 
                  the behaviorally relevant N1 <a class="thought" href="entries/component_entry.html">component</a> of the somatosensory 
                  evoked potential in awake monkeys: Evidence that backward cortical 
                  projections signal conscious touch sensation. <i><a class="thought" href="entries/experiment_entry.html">Experiment</a>al 
                  <a class="thought" href="entries/brain_entry.html">Brain</a> <a class="thought" href="entries/research_entry.html">Research</a></i> 84:607-619. </p>
<p>Chalmers, D.J. 1996. The Conscious Mind: <i>In <a class="thought" href="entries/search_entry.html">Search</a> of a 
                  Fundamental Theory</i>. Oxford University Press. </p>
<p>Chalmers, D.J. (forthcoming). Availability: the cognitive basis 
                  of <a class="thought" href="entries/experience_entry.html">experience</a>? <i>Behavioral and <a class="thought" href="entries/brain_entry.html">Brain</a> <a class="thought" href="entries/science_entry.html">Science</a>s</i>. Also in 
                  N. Block, O. Flanagan, &amp; G. G&#252;zeldere (eds) <i>The 
                  <a class="thought" href="entries/nature_entry.html">Nature</a> of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i> (MIT Press, 1997). </p>
<p>Cotterill, R. 1994. On the unity of conscious <a class="thought" href="entries/experience_entry.html">experience</a>. <i>Journal 
                  of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a> Studies</i> 2:290-311. </p>
<p>Crick, F. and Koch, <a class="thought" href="entries/c_entry.html">C</a>. 1990. Towards a neurobiological theory 
                  of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. <i>Seminars in the <a class="thought" href="entries/neuroscience_entry.html">Neuroscience</a>s 2</i>: 263-275. 
                </p>
<p>Crick, F. &amp; Koch, <a class="thought" href="entries/c_entry.html">C</a>. 1995. Are we aware of neural activity 
                  in primary visual cortex? <i><a class="thought" href="entries/nature_entry.html">Nature</a></i> 375: 121-23. </p>
<p>Edelman, G.M. 1989. The Remembered Present: <i>A <a class="thought" href="entries/biological_entry.html">Biological</a> 
                  Theory of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i>. New York: <a class="thought" href="entries/basic_entry.html">Basic</a> Books. </p>
<p>Farah, M.J. 1994. Visual <a class="thought" href="entries/perception_entry.html">perception</a> and visual awareness after 
                  <a class="thought" href="entries/brain_entry.html">brain</a> damage: A tutorial overview. In (<a class="thought" href="entries/c_entry.html">C</a>. Umilta and M. Moscovitch, 
                  eds.) <i><a class="thought" href="entries/consciousness_entry.html">Consciousness</a> and Unconscious <a class="thought" href="entries/information_entry.html">Information</a> Processing: 
                  Attention and Performance 15</i>. MIT Press. </p>
<p>Flohr, H. 1995. Sensations and <a class="thought" href="entries/brain_entry.html">brain</a> processes. <i>Behavioral 
                  <a class="thought" href="entries/brain_entry.html">Brain</a> <a class="thought" href="entries/research_entry.html">Research</a></i> 71:157-61. </p>
<p>Gray, J.A. 1995. The <a class="thought" href="entries/content_entry.html">content</a>s of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>: A neuropsychological 
                  conjecture. <i>Behavioral and <a class="thought" href="entries/brain_entry.html">Brain</a> <a class="thought" href="entries/science_entry.html">Science</a>s</i> 18:659-722. 
                </p>
<p>Greenfield, S. 1995. <i>Journey to the Centers of the <a class="thought" href="entries/mind_entry.html">Mind</a></i>. 
                  W.H. Freeman. </p>
<p>Hameroff, S.R. 1994. <a class="thought" href="entries/quantum_coherence_entry.html">Quantum coherence</a> in microtubules: A neural 
                  basis for emergent <a class="thought" href="entries/consciousness_entry.html">consciousness</a>? <i>Journal of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a> 
                  Studies</i> 1:91-118. </p>
<p>Hardcastle, V.G. 1996. <i>Locating <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i>. Philadephia: 
                  John Benjamins. </p>
<p>Jackendoff, R. 1987. <i><a class="thought" href="entries/consciousness_entry.html">Consciousness</a> and the <a class="thought" href="entries/computation_entry.html">Computation</a>al 
                  <a class="thought" href="entries/mind_entry.html">Mind</a></i>. MIT Press. </p>
<p>Leopold, D.A. &amp; Logothetis, N.K. 1996. Activity-changes 
                  in early visual cortex reflect monkeys' percepts during binocular 
                  rivalry. <i><a class="thought" href="entries/nature_entry.html">Nature</a></i> 379: 549-553. </p>
<p>Libet, B. 1993. The neural <a class="thought" href="entries/time_entry.html">time</a> factor in conscious and unconscious 
                  events. In <i><a class="thought" href="entries/experiment_entry.html">Experiment</a>al and Theoretical Studies of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i> 
                  (Ciba Foundation Symposium 174). New York: Wiley. </p>
<p>Llinas, R.R., Ribary, U., Joliot, M. &amp; Wang, X.-J. 1994. 
                  <a class="thought" href="entries/content_entry.html">Content</a> and <a class="thought" href="entries/context_entry.html">context</a> in temporal thalamocortical binding. In 
                  (G. Buzsaki, R.R. Llinas, &amp; W. Singer, eds.) <i>Temporal 
                  Coding in the <a class="thought" href="entries/brain_entry.html">Brain</a></i>. Berlin: Springer Verlag. </p>
<p>Logothetis, N. &amp; Schall, J. 1989. <a class="thought" href="entries/neuron_entry.html">Neuron</a>al correlates of 
                  subjective visual <a class="thought" href="entries/perception_entry.html">perception</a>. <i><a class="thought" href="entries/science_entry.html">Science</a></i> 245:761-63. </p>
<p>Shallice, T. 1988. <a class="thought" href="entries/information_entry.html">Information</a>-processing models of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>: 
                  possibilities and problems. In (A. Marcel and E. Bisiach, eds.) 
                  <i><a class="thought" href="entries/consciousness_entry.html">Consciousness</a> in Contemporary <a class="thought" href="entries/science_entry.html">Science</a></i>. Oxford University 
                  Press. </p>
<p>Taylor, J.G. &amp; Alavi, F.N. 1993. Mathematical analysis 
                  of a competitive <a class="thought" href="entries/network_entry.html">network</a> for attention. In (J.G. Taylor, ed.) 
                  <i>Mathematical Approaches to <a class="thought" href="entries/neural_network_entry.html">Neural Network</a>s</i>. Elsevier. 
                </p>
<p>Tootell, R.B., Reppas, J.B., Dale, A.M., Look, R.B., Sereno, 
                  M.I., Malach, R., Brady, J. &amp; Rosen, B.R. 1995. Visual <a class="thought" href="entries/motion_entry.html">motion</a> 
                  aftereffect in <a class="thought" href="entries/human_entry.html">human</a> cortical area MT revealed by functional 
                  magnetic resonance imaging. <i><a class="thought" href="entries/nature_entry.html">Nature</a></i> 375:139-41. </p>
<p><a class="thought" href="entries/copyright_entry.html">Copyright</a> &#169; 1998 MIT Press, from <i><a href="http://web.archive.org/web/20080628060911/http://mitpress.mit.edu/0262082624" target="_blank">Toward 
                  a Science of Consciousness II: The Second Tucson Discussions 
                  and Debates</a></i>. Used with permission.</p>
</li>
</ul>
</p></td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7902" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id7903"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Neural correlates of consciousness<br><span class="mindxheader"><i>posted on 07/02/2002 7:02 AM by ricardo.sanz@aslab.org</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7902%23id7903" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7903" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>It is my impression that the problem/search of "Neural Correlates of Consciousness" in a human is equivalent to the search of "Mechanical Equivalents of Vehicleness" in a Chevrolet.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7968"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: On the Search for the Neural Correlate of Consciousness<br><span class="mindxheader"><i>posted on 07/05/2002 7:24 PM by clifmom@aol.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7902%23id7968" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7968" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p> Here's the question that I wish these philosophical gasbags would answer: "Is death equivalent to a dreamless sleep or if the universe is really a computer simulation, will its programmers send us to hell if they choose?"</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7987"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: On the Search for the Neural Correlate of Consciousness<br><span class="mindxheader"><i>posted on 07/06/2002 11:04 PM by azb0@earthlink.net</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7902%23id7987" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7987" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>The concept that "the (universal) programmers, if the exist, might "send us all to hell" begs a deeper question:  While we may not be in control of our environment (the stimuli presented to our senses), are we in control of "how we feel or interpret that stimuli"?  I claim that, at foundation, we must be, or else there is no "we" at all.
<br>
<br>
Hard as you might imagine being tortured extendedly, the torturer cannot control when your "mind" (the actual "experiencer") simply shunts the input into a bit-bucket.  If they could control the actual "sense of your experience", there is no justification for claiming there is a "you" to begin with.
<br>
<br>
About Endless Sleep:
<br>
<br>
Consider the following "stories of a regular Joe".  In the first story, Joe is just a happy guy, goes to bed one night fully expecting to wake the next morning.  Unfortunately, a meteor crushes his house and obliterates him.  Endless sleep, no more "Joe" (or "Joe-pattern").
<br>
<br>
In the second story, prior to the meteor strike, benevolent aliens scan Joe in his sleep, (somehow) capturing the entire informational "essense" of Joe.  A year after Joe's unfortunate demise, this Joe-essense in fed into a genetically recreated Joe, and awakened in a (similar) bedroom.  What does this entity "feel"?  It is rational (if not certain) to assume that this person would feel exactly like "Joe" would, waking up.  All memories of the "previous night" (a year ago) still fresh.
<br>
<br>
Fine.  But is this Joe?  (Yes, and No).
<br>
<br>
To see this, suppose these aliens performed the very same action, except the meteor in question misses the earth entirely.  A year later, the "New Joe" is started up, feeling (internally) exactly as Joe would under the circumstances ... except, the original Joe is still living and experiencing in the world.  There is no "pressing reason" that either Joe would be aware of the other (although we could invent ways that this might happen.)
<br>
<br>
Who or what is Joe?
<br>
<br>
Try to imagine that every night, when the previous you (not you) went to bed, you were scanned in your sleep, and then "killed" in the ordinarily assumed "complete" way.  However, before morning comes, a perfect bio-clone of that version is placed in your bed, and fed your "previous state".  You awake, certain that "you are the same you" that you recall.  Are you really?
<br>
<br>
Really, try to imagine that you have only existed since you last awoke, albeit with layers of memories consistent with having had a "long history".  Would there be any way to tell?
<br>
<br>
What if this were a "truth", but rather than occurring each night while we sleep, it occurs every nano-second as the underlying fabric of space/time "quantum clones" us from an old and dead self into a new one, it also existing for just an instant.
<br>
<br>
What would such a picture say about our sensation of possessing a "continued self" in the world?
<br>
<br>
Cheers!
<br>
<br>
____tony____
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7991"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: On the Search for the Neural Correlate of Consciousness<br><span class="mindxheader"><i>posted on 07/07/2002 5:04 AM by Citizen Blue</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7902%23id7991" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7991" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I personally believe that when identical entities are at separate places, each one will believe to be the one identity; when entities' consciousnesses are compartmentalized e.g. human brains they would not be 
<br>
 able to fathom the others same consciousness at the same time and place. It may seem a Cartesion paradox; much as if one were to travel back or forward in time to met himself. 
<br>
 The question whether he is the same would have its meaning in the respective frames or points of references of each self; But have no fear he would be him by the principle of identity.  Don't make him angry.
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id7992"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: On the Search for the Neural Correlate of Consciousness<br><span class="mindxheader"><i>posted on 07/07/2002 7:38 AM by azb0@earthlink.net</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7902%23id7992" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D7992" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>It is a feature of the Cartesian View, (maybe more generally, the reductionist view) that we cannot help but view ourselves as "objects" embedded in an "environment", rather than manifestations of a wholistic matrix of interacting forces.  Our conscious self, in the habit of viewing the world through one set of localized eyeballs, certainly reinforces this view.
<br>
<br>
If there were "two identical me", one at the beach, one in the Alps, then each would have a different view of the world.  That very fact makes them "not identical".  It is only (in my view) the habit of thinking that my consciousness has to "go somewhere", like a physical, incompressible fluid being poured into and out of containers, that leads me to think that one (or both) of them must be "me", and that they would somehow possess some intrinsic identicality.
<br>
<br>
In a similar way, I feel that the sense of being the "same me" as I stare at the moving hands of a clock may be simply a learned sensation that "I continue", rather than being a "new me" inheriting from a "gone me" every moment that passes.
<br>
<br>
(I like the "Don't make him angry" part. :)
<br>
<br>
Cheers!
<br>
<br>
____tony____
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id8095"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="80"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="599"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: On the Search for the Neural Correlate of Consciousness<br><span class="mindxheader"><i>posted on 07/09/2002 10:07 PM by Citizen Blue</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7902%23id8095" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D8095" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Do I get a consolation prize if I tell you that I am not the same as I was 10 years ago? But something inside tells me that it is the same consciousness.  Could this simply be due to the continuity of the situation? If a sock is darned so much that none of the original yarn comprises it, is it considered the same sock? 
<br>
If that is the case, then would this be a relativistic happenstance.  (I personally feel that it goes much deeper; I mean the deepness of the universe may have caused me to have my singular consciousness; but then I would be running into my personal beliefs of the situation.)
<br>
<br>
Thanks.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id8917"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="100"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="579"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: On the Search for the Neural Correlate of Consciousness<br><span class="mindxheader"><i>posted on 08/14/2002 8:26 AM by laocadia2000@yahoo.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7902%23id8917" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D8917" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>You're not talking about 'consciousness' are you. You're talking about identity and that's 'ego' identity, right?  Run this past a practicing buddah/yoga master and see what he says about consciousness.  When you meditate, you're looking for something different than identity aren't you?
<br>
I think I'd know if I'd been cloned, there would be a different 'feel' to memories, ways of knowing.  Now if you could explain what a memory was.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id8923"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="120"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="559"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: On the Search for the Neural Correlate of Consciousness<br><span class="mindxheader"><i>posted on 08/14/2002 12:49 PM by azb@llnl.gov</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7902%23id8923" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D8923" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>In response to:
<br>
<br>
- "I think I'd know if I'd been cloned, there would be a different 'feel' to memories, ways of knowing."
<br>
<br>
Why?  Which "I" is the "I" that would know, or feel this way?  Certainly not the "ego-I", the sense of self that views the world from the location of one set of eyeballs.
<br>
<br>
What if there is only one "transcendent consciousness", each of us an ego-tized manifestation of this same consciousness (by virtue of sense of locale).
<br>
<br>
We may all be "clones" of one another in this sense, and the "different feel" you propose may be what we already feel.  Thus, one more "clone" would not make any difference to our feelings, or ways of knowing.  Just yet another person in the world (person, as in "localization in the transcendent conciousness.")
<br>
<br>
Cheers! ____tony b____</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id14503"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: On the Search for the Neural Correlate of Consciousness<br><span class="mindxheader"><i>posted on 02/07/2003 9:40 AM by stuart mcgregor</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D7902%23id14503" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20080628060911/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D14503" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Is the main problem that when we look at this issue neurally we use the term a neural correlate of consciousness. But this still leaves the issue of what is the neural correlate correlated with? We get no nearer the topic we originally wanted to investigate, except to say that it is correlated with x brain pattern. Great in practical terms, but not as good in philosophical ones.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20080628060911im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>