<html>
<head><base href="https://kurzweilai-brain.gothdyke.mom/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>Facing Up to the Problem of Consciousness</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/meme/memelist.html?m=4">Will Machines Become Conscious?</a> &gt; 
Facing Up to the Problem of Consciousness
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20071011094955/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0512.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0512.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/articles/art0512.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">Facing Up to the Problem of Consciousness</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0190.html" target="_top">David Chalmers</a><br></span></td>
</table>
<br>
<div class="TeaserText">The vague term "consciousness" poses the most baffling problems in the science of the mind. Philosopher David Chalmers presents a nonreductive theory of consciousness based on principles of structural coherence (tied to awareness) and organizational invariance (e.g., a silicon isomorph of a human can be conscious) and a double-aspect view of information (physical and phenomenal aspects).</div>
<br>
<br>
<p><i>Published on KurzweilAI.net August 17, 2002</i></p>
<p><i>[This appeared in the </i>Journal of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a> Studies<i> 
              in 1995. Also online is my response, "<a href="http://web.archive.org/web/20071011094955/http://www.u.arizona.edu/~chalmers/papers/moving.html" target="_blank">Moving 
              Forward on the problem of Consciousness</a>," to 26 articles 
              commenting on this paper. That paper elaborates and extends many 
              of the ideas in this one. -- David Chalmers]</i> </p>
<h1>1 Introduction</h1>
<p><a class="thought" href="entries/consciousness_entry.html">Consciousness</a> poses the most baffling problems in the <a class="thought" href="entries/science_entry.html">science</a> of 
              the <a class="thought" href="entries/mind_entry.html">mind</a>. There is nothing that we know more intimately than conscious 
              <a class="thought" href="entries/experience_entry.html">experience</a>, but there is nothing that is harder to explain. All 
              sorts of mental phenomena have yielded to scientific investigation 
              in recent years, but <a class="thought" href="entries/consciousness_entry.html">consciousness</a> has stubbornly resisted. Many 
              have tried to explain it, but the explanations always seem to fall 
              short of the target. Some have been led to suppose that the problem 
              is intractable, and that no good explanation can be given. </p>
<p>To make <a class="thought" href="entries/progress_entry.html">progress</a> on the problem of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, we have to confront 
              it directly. In this paper, I first isolate the truly hard part 
              of the problem, separating it from more tractable parts and giving 
              an account of why it is so difficult to explain. I critique some 
              recent work that uses reductive <a class="thought" href="entries/method_entry.html">method</a>s to address <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, 
              and argue that such <a class="thought" href="entries/method_entry.html">method</a>s inevitably fail to come to grips with 
              the hardest part of the problem. Once this failure is recognized, 
              the door to further <a class="thought" href="entries/progress_entry.html">progress</a> is opened. In the second half of the 
              paper, I argue that if we move to a new kind of nonreductive explanation, 
              a naturalistic account of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> can be given. I put forward 
              my own candidate for such an account: a nonreductive theory based 
              on principles of structural coherence and organizational invariance 
              and a double-aspect view of <a class="thought" href="entries/information_entry.html">information</a>. </p>
<h1>2 The easy problems and the hard problem</h1>
<p>There is not just one problem of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. "Consciousness" 
              is an ambiguous term, referring to many different phenomena. Each 
              of these phenomena needs to be explained, but some are easier to 
              explain than others. At the start, it is useful to divide the associated 
              problems of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> into "hard" and "easy" 
              problems. The easy problems of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> are those that seem 
              directly susceptible to the standard <a class="thought" href="entries/method_entry.html">method</a>s of <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a>, 
              whereby a <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a> is explained in terms of <a class="thought" href="entries/computation_entry.html">computation</a>al or neural 
              mechanisms. The hard problems are those that seem to resist those 
              <a class="thought" href="entries/method_entry.html">method</a>s. </p>
<p>The easy problems of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> include those of explaining 
              the following phenomena:<br>
</p>
<ul>
<li>the ability to discriminate, categorize, and react to environmental 
                stimuli; </li>
<li>the integration of <a class="thought" href="entries/information_entry.html">information</a> by a cognitive <a class="thought" href="entries/system_entry.html">system</a>; </li>
<li>the reportability of mental states; </li>
<li>the ability of a <a class="thought" href="entries/system_entry.html">system</a> to <a class="thought" href="entries/access_entry.html">access</a> its own internal states; </li>
<li>the focus of attention; </li>
<li>the deliberate control of behavior; </li>
<li>the difference between wakefulness and sleep. </li>
</ul>
<p>All of these phenomena are associated with the notion of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. 
              For example, one sometimes says that a mental state is conscious 
              when it is verbally reportable, or when it is internally <a class="thought" href="entries/access_entry.html">access</a>ible. 
              Sometimes a <a class="thought" href="entries/system_entry.html">system</a> is said to be conscious of some <a class="thought" href="entries/information_entry.html">information</a> when 
              it has the ability to react on the basis of that <a class="thought" href="entries/information_entry.html">information</a>, or, 
              more strongly, when it attends to that <a class="thought" href="entries/information_entry.html">information</a>, or when it can 
              integrate that <a class="thought" href="entries/information_entry.html">information</a> and exploit it in the sophisticated control 
              of behavior. We sometimes say that an <a class="thought" href="entries/action_entry.html">action</a> is conscious precisely 
              when it is deliberate. Often, we say that an <a class="thought" href="entries/organism_entry.html">organism</a> is conscious 
              as another way of saying that it is awake. </p>
<p>There is no real issue about whether <i>these</i> phenomena can 
              be explained scientifically. All of them are straightforwardly vulnerable 
              to explanation in terms of <a class="thought" href="entries/computation_entry.html">computation</a>al or neural mechanisms. To 
              explain <a class="thought" href="entries/access_entry.html">access</a> and reportability, for example, we need only specify 
              the mechanism by which <a class="thought" href="entries/information_entry.html">information</a> about internal states is retrieved 
              and made available for verbal report. To explain the integration 
              of <a class="thought" href="entries/information_entry.html">information</a>, we need only exhibit mechanisms by which <a class="thought" href="entries/information_entry.html">information</a> 
              is brought together and exploited by later processes. For an account 
              of sleep and wakefulness, an appropriate neurophysiological account 
              of the processes responsible for <a class="thought" href="entries/organism_entry.html">organism</a>s' contrasting behavior 
              in those states will suffice. In each case, an appropriate cognitive 
              or neurophysiological model can clearly do the explanatory work. 
            </p>
<p>If these phenomena were all there was to <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, then <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
              would not be much of a problem. Although we do not yet have anything 
              close to a complete explanation of these phenomena, we have a clear 
              idea of how we might go about explaining them. This is why I call 
              these problems the easy problems. Of course, "easy" is 
              a relative term. Getting the details right will probably take a 
              century or two of difficult empirical work. Still, there is every 
              <a class="thought" href="entries/reason_entry.html">reason</a> to believe that the <a class="thought" href="entries/method_entry.html">method</a>s of <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a> and <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a> 
              will succeed. </p>
<p>The really hard problem of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> is the problem of <i><a class="thought" href="entries/experience_entry.html">experience</a></i>. 
              When we think and perceive, there is a whir of <a class="thought" href="entries/information_entry.html">information</a>-processing, 
              but there is also a subjective aspect. As Nagel (1974) has put it, 
              there is <i>something it is like</i> to be a conscious <a class="thought" href="entries/organism_entry.html">organism</a>. 
              This subjective aspect is <a class="thought" href="entries/experience_entry.html">experience</a>. When we see, for example, 
              we <i><a class="thought" href="entries/experience_entry.html">experience</a></i> visual sensations: the felt quality of redness, 
              the <a class="thought" href="entries/experience_entry.html">experience</a> of dark and <a class="thought" href="entries/light_entry.html">light</a>, the quality of depth in a visual 
              field. Other <a class="thought" href="entries/experience_entry.html">experience</a>s go along with <a class="thought" href="entries/perception_entry.html">perception</a> in different modalities: 
              the sound of a clarinet, the smell of mothballs. Then there are 
              bodily sensations, from pains to orgasms; mental images that are 
              conjured up internally; the felt quality of <a class="thought" href="entries/emotion_entry.html">emotion</a>, and the <a class="thought" href="entries/experience_entry.html">experience</a> 
              of a stream of conscious <a class="thought" href="entries/thought_entry.html">thought</a>. What unites all of these states 
              is that there is something it is like to be in them. All of them 
              are states of <a class="thought" href="entries/experience_entry.html">experience</a>. </p>
<p>It is undeniable that some <a class="thought" href="entries/organism_entry.html">organism</a>s are subjects of <a class="thought" href="entries/experience_entry.html">experience</a>. 
              But the question of how it is that these <a class="thought" href="entries/system_entry.html">system</a>s are subjects of 
              <a class="thought" href="entries/experience_entry.html">experience</a> is perplexing. Why is it that when our cognitive <a class="thought" href="entries/system_entry.html">system</a>s 
              engage in visual and auditory <a class="thought" href="entries/information_entry.html">information</a>-processing, we have visual 
              or auditory <a class="thought" href="entries/experience_entry.html">experience</a>: the quality of <a class="thought" href="entries/deep_blue_entry.html">deep blue</a>, the sensation 
              of middle C? How can we explain why there is something it is like 
              to entertain a mental image, or to <a class="thought" href="entries/experience_entry.html">experience</a> an <a class="thought" href="entries/emotion_entry.html">emotion</a>? It is 
              widely agreed that <a class="thought" href="entries/experience_entry.html">experience</a> arises from a physical basis, but 
              we have no good explanation of why and how it so arises. Why should 
              physical processing give rise to a rich inner <a class="thought" href="entries/life_entry.html">life</a> at all? It seems 
              <a class="thought" href="entries/object_entry.html">object</a>ively unreasonable that it should, and yet it does. </p>
<p>If any problem qualifies as <i>the</i> problem of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, 
              it is this one. In this central <a class="thought" href="entries/sense_entry.html">sense</a> of "consciousness," 
              an <a class="thought" href="entries/organism_entry.html">organism</a> is conscious if there is something it is like to be 
              that <a class="thought" href="entries/organism_entry.html">organism</a>, and a mental state is conscious if there is something 
              it is like to be in that state. Sometimes terms such as "phenomenal 
              <a class="thought" href="entries/consciousness_entry.html">consciousness</a>" and "qualia" are also used here, but 
              I find it more natural to speak of "conscious <a class="thought" href="entries/experience_entry.html">experience</a>" 
              or simply "experience." Another useful way to avoid confusion 
              (used by e.g. Newell 1990, Chalmers 1996) is to reserve the term 
              "consciousness" for the phenomena of <a class="thought" href="entries/experience_entry.html">experience</a>, using 
              the less loaded term "awareness" for the more straightforward 
              phenomena described earlier. If such a convention were widely adopted, 
              <a class="thought" href="entries/communication_entry.html">communication</a> would be much easier; as things stand, those who talk 
              about "consciousness" are frequently talking past each 
              other. </p>
<p>The ambiguity of the term "consciousness" is often exploited 
              by both philosophers and scientists writing on the subject. It is 
              common to see a paper on <a class="thought" href="entries/consciousness_entry.html">consciousness</a> begin with an invocation 
              of the mystery of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, noting the strange intangibility 
              and ineffability of subjectivity, and worrying that so far we have 
              no theory of the <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a>. Here, the topic is clearly the hard 
              problem - the problem of <a class="thought" href="entries/experience_entry.html">experience</a>. In the second half of the paper, 
              the tone becomes more optimistic, and the author's own theory of 
              <a class="thought" href="entries/consciousness_entry.html">consciousness</a> is outlined. Upon examination, this theory turns out 
              to be a theory of one of the more straightforward phenomena - of 
              reportability, of introspective <a class="thought" href="entries/access_entry.html">access</a>, or whatever. At the close, 
              the author declares that <a class="thought" href="entries/consciousness_entry.html">consciousness</a> has turned out to be tractable 
              after all, but the reader is left feeling like the victim of a bait-and-<a class="thought" href="entries/switch_entry.html">switch</a>. 
              The hard problem remains untouched. </p>
<h1>3 Functional explanation</h1>
<p>Why are the easy problems easy, and why is the hard problem hard? 
              The easy problems are easy precisely because they concern the explanation 
              of cognitive <i>abilities</i> and <i>functions</i>. To explain a 
              cognitive function, we need only specify a mechanism that can perform 
              the function. The <a class="thought" href="entries/method_entry.html">method</a>s of <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a> are well-suited for 
              this sort of explanation, and so are well-suited to the easy problems 
              of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. By contrast, the hard problem is hard precisely 
              because it is not a problem about the performance of functions. 
              The problem persists even when the performance of all the relevant 
              functions is explained. (Here "function" is not used in 
              the narrow teleological <a class="thought" href="entries/sense_entry.html">sense</a> of something that a <a class="thought" href="entries/system_entry.html">system</a> is designed 
              to do, but in the broader <a class="thought" href="entries/sense_entry.html">sense</a> of any causal role in the production 
              of behavior that a <a class="thought" href="entries/system_entry.html">system</a> might perform.) </p>
<p>To explain reportability, for <a class="thought" href="entries/instance_entry.html">instance</a>, is just to explain how 
              a <a class="thought" href="entries/system_entry.html">system</a> could perform the function of producing reports on internal 
              states. To explain internal <a class="thought" href="entries/access_entry.html">access</a>, we need to explain how a <a class="thought" href="entries/system_entry.html">system</a> 
              could be appropriately affected by its internal states and use <a class="thought" href="entries/information_entry.html">information</a> 
              about those states in directing later processes. To explain integration 
              and control, we need to explain how a <a class="thought" href="entries/system_entry.html">system</a>'s central processes 
              can bring <a class="thought" href="entries/information_entry.html">information</a> <a class="thought" href="entries/content_entry.html">content</a>s together and use them in the facilitation 
              of various behaviors. These are all problems about the explanation 
              of functions. </p>
<p>How do we explain the performance of a function? By specifying 
              a <i>mechanism</i> that performs the function. Here, neurophysiological 
              and cognitive modeling are perfect for the task. If we want a detailed 
              low-level explanation, we can specify the neural mechanism that 
              is responsible for the function. If we want a more abstract explanation, 
              we can specify a mechanism in <a class="thought" href="entries/computation_entry.html">computation</a>al terms. Either way, a 
              full and satisfying explanation will result. Once we have specified 
              the neural or <a class="thought" href="entries/computation_entry.html">computation</a>al mechanism that performs the function 
              of verbal report, for example, the bulk of our work in explaining 
              reportability is over. </p>
<p>In a way, the point is trivial. It is a <i><a class="thought" href="entries/concept_entry.html">concept</a>ual</i> fact 
              about these phenomena that their explanation only involves the explanation 
              of various functions, as the phenomena are <i>functionally definable</i>. 
              All it <i>means</i> for reportability to be instantiated in a <a class="thought" href="entries/system_entry.html">system</a> 
              is that the <a class="thought" href="entries/system_entry.html">system</a> has the <a class="thought" href="entries/capacity_entry.html">capacity</a> for verbal reports of internal 
              <a class="thought" href="entries/information_entry.html">information</a>. All it means for a <a class="thought" href="entries/system_entry.html">system</a> to be awake is for it to 
              be appropriately receptive to <a class="thought" href="entries/information_entry.html">information</a> from the environment and 
              for it to be able to use this <a class="thought" href="entries/information_entry.html">information</a> in directing behavior 
              in an appropriate way. To see that this sort of thing is a <a class="thought" href="entries/concept_entry.html">concept</a>ual 
              fact, note that someone who says "you have explained the performance 
              of the verbal report function, but you have not explained reportability" 
              is making a trivial <a class="thought" href="entries/concept_entry.html">concept</a>ual mistake about reportability. All 
              it could <i>possibly</i> take to explain reportability is an explanation 
              of how the relevant function is performed; the same goes for the 
              other phenomena in question. </p>
<p>Throughout the higher-level <a class="thought" href="entries/science_entry.html">science</a>s, reductive explanation works 
              in just this way. To explain the gene, for <a class="thought" href="entries/instance_entry.html">instance</a>, we needed to 
              specify the mechanism that stores and transmits hereditary <a class="thought" href="entries/information_entry.html">information</a> 
              from one generation to the next. It turns out that <a class="thought" href="entries/dna_entry.html">DNA</a> performs 
              this function; once we explain how the function is performed, we 
              have explained the gene. To explain <a class="thought" href="entries/life_entry.html">life</a>, we ultimately need to 
              explain how a <a class="thought" href="entries/system_entry.html">system</a> can reproduce, adapt to its environment, metabolize, 
              and so on. All of these are questions about the performance of functions, 
              and so are well-suited to reductive explanation. The same holds 
              for most problems in <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a>. To explain <a class="thought" href="entries/learning_entry.html">learning</a>, we 
              need to explain the way in which a <a class="thought" href="entries/system_entry.html">system</a>'s behavioral capacities 
              are modified in <a class="thought" href="entries/light_entry.html">light</a> of environmental <a class="thought" href="entries/information_entry.html">information</a>, and the way 
              in which new <a class="thought" href="entries/information_entry.html">information</a> can be brought to bear in adapting a <a class="thought" href="entries/system_entry.html">system</a>'s 
              <a class="thought" href="entries/action_entry.html">action</a>s to its environment. If we show how a neural or <a class="thought" href="entries/computation_entry.html">computation</a>al 
              mechanism does the job, we have explained <a class="thought" href="entries/learning_entry.html">learning</a>. We can say the 
              same for other cognitive phenomena, such as <a class="thought" href="entries/perception_entry.html">perception</a>, <a class="thought" href="entries/memory_entry.html">memory</a>, 
              and <a class="thought" href="entries/language_entry.html">language</a>. Sometimes the relevant functions need to be characterized 
              quite subtly, but it is clear that insofar as <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a> 
              explains these phenomena at all, it does so by explaining the performance 
              of functions. </p>
<p>When it comes to conscious <a class="thought" href="entries/experience_entry.html">experience</a>, this sort of explanation 
              fails. What makes the hard problem hard and almost unique is that 
              it goes <i>beyond</i> problems about the performance of functions. 
              To see this, note that even when we have explained the performance 
              of all the cognitive and behavioral functions in the vicinity of 
              <a class="thought" href="entries/experience_entry.html">experience</a> - perceptual discrimination, categorization, internal 
              <a class="thought" href="entries/access_entry.html">access</a>, verbal report - there may still remain a further unanswered 
              question: <i>Why is the performance of these functions accompanied 
              by <a class="thought" href="entries/experience_entry.html">experience</a>?</i> A simple explanation of the functions leaves 
              this question open. </p>
<p>There is no <a class="thought" href="entries/analog_entry.html">analog</a>ous further question in the explanation of genes, 
              or of <a class="thought" href="entries/life_entry.html">life</a>, or of <a class="thought" href="entries/learning_entry.html">learning</a>. If someone says "I can see that 
              you have explained how <a class="thought" href="entries/dna_entry.html">DNA</a> stores and transmits hereditary <a class="thought" href="entries/information_entry.html">information</a> 
              from one generation to the next, but you have not explained how 
              it is a <i>gene</i>," then they are making a <a class="thought" href="entries/concept_entry.html">concept</a>ual mistake. 
              All it means to be a gene is to be an <a class="thought" href="entries/entity_entry.html">entity</a> that performs the relevant 
              storage and transmission function. But if someone says "I can 
              see that you have explained how <a class="thought" href="entries/information_entry.html">information</a> is discriminated, integrated, 
              and reported, but you have not explained how it is <i><a class="thought" href="entries/experience_entry.html">experience</a>d</i>," 
              they are not making a <a class="thought" href="entries/concept_entry.html">concept</a>ual mistake. This is a nontrivial further 
              question. </p>
<p>This further question is the key question in the problem of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. 
              Why doesn't all this <a class="thought" href="entries/information_entry.html">information</a>-processing go on "in the dark," 
              free of any inner feel? Why is it that when <a class="thought" href="entries/electromagnetic_entry.html">electromagnetic</a> waveforms 
              impinge on a <a class="thought" href="entries/retina_entry.html">retina</a> and are discriminated and categorized by a visual 
              <a class="thought" href="entries/system_entry.html">system</a>, this discrimination and categorization is <a class="thought" href="entries/experience_entry.html">experience</a>d as 
              a sensation of vivid red? We know that conscious <a class="thought" href="entries/experience_entry.html">experience</a> <i>does</i> 
              arise when these functions are performed, but the very fact that 
              it arises is the central mystery. There is an <i>explanatory gap</i> 
              (a term due to Levine 1983) between the functions and <a class="thought" href="entries/experience_entry.html">experience</a>, 
              and we need an explanatory bridge to cross it. A mere account of 
              the functions stays on one side of the gap, so the materials for 
              the bridge must be found elsewhere. </p>
<p>This is not to say that <a class="thought" href="entries/experience_entry.html">experience</a> <i>has</i> no function. Perhaps 
              it will turn out to play an <a class="thought" href="entries/import_entry.html">import</a>ant cognitive role. But for any 
              role it might play, there will be more to the explanation of <a class="thought" href="entries/experience_entry.html">experience</a> 
              than a simple explanation of the function. Perhaps it will even 
              turn out that in the course of explaining a function, we will be 
              led to the key insight that allows an explanation of <a class="thought" href="entries/experience_entry.html">experience</a>. 
              If this happens, though, the discovery will be an <i>extra</i> explanatory 
              reward. There is no cognitive function such that we can say in advance 
              that explanation of that function will <i>automatically</i> explain 
              <a class="thought" href="entries/experience_entry.html">experience</a>. </p>
<p>To explain <a class="thought" href="entries/experience_entry.html">experience</a>, we need a new approach. The usual explanatory 
              <a class="thought" href="entries/method_entry.html">method</a>s of <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a> and <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a> do not suffice. These 
              <a class="thought" href="entries/method_entry.html">method</a>s have been developed precisely to explain the performance 
              of cognitive functions, and they do a good job of it. But as these 
              <a class="thought" href="entries/method_entry.html">method</a>s stand, they are <i>only</i> equipped to explain the performance 
              of functions. When it comes to the hard problem, the standard approach 
              has nothing to say. </p>
<h1>4 Some case-studies</h1>
<p>In the last few years, a <a class="thought" href="entries/number_entry.html">number</a> of works have addressed the problems 
              of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> within the framework of <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a> and <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a>. 
              This might suggest that the analysis above is faulty, but in fact 
              a close examination of the relevant work only lends the analysis 
              further support. When we investigate just which aspects of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
              these studies are aimed at, and which aspects they end up explaining, 
              we find that the ultimate target of explanation is always one of 
              the easy problems. I will illustrate this with two representative 
              examples. </p>
<p>The first is the "neurobiological theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>" 
              outlined by Crick and Koch (1990; see also Crick 1994). This theory 
              centers on certain 35-75 hertz neural oscillations in the cerebral 
              cortex; Crick and Koch hypothesize that these oscillations are the 
              basis of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. This is partly because the oscillations 
              seem to be correlated with awareness in a <a class="thought" href="entries/number_entry.html">number</a> of different modalities 
              - within the visual and olfactory <a class="thought" href="entries/system_entry.html">system</a>s, for example - and also 
              because they suggest a mechanism by which the <i>binding</i> of 
              <a class="thought" href="entries/information_entry.html">information</a> <a class="thought" href="entries/content_entry.html">content</a>s might be achieved. Binding is the process whereby 
              separately represented pieces of <a class="thought" href="entries/information_entry.html">information</a> about a single <a class="thought" href="entries/entity_entry.html">entity</a> 
              are brought together to be used by later processing, as when <a class="thought" href="entries/information_entry.html">information</a> 
              about the color and shape of a perceived <a class="thought" href="entries/object_entry.html">object</a> is integrated from 
              separate visual pathways. Following others (e.g., Eckhorn <i>et 
              al</i> 1988), Crick and Koch hypothesize that binding may be achieved 
              by the synchronized oscillations of <a class="thought" href="entries/neuron_entry.html">neuron</a>al groups representing 
              the relevant <a class="thought" href="entries/content_entry.html">content</a>s. When two pieces of <a class="thought" href="entries/information_entry.html">information</a> are to be 
              bound together, the relevant neural groups will oscillate with the 
              same frequency and phase. </p>
<p>The details of how this binding might be achieved are still poorly 
              understood, but suppose that they can be worked out. What might 
              the resulting theory explain? Clearly it might explain the binding 
              of <a class="thought" href="entries/information_entry.html">information</a> <a class="thought" href="entries/content_entry.html">content</a>s, and perhaps it might yield a more general 
              account of the integration of <a class="thought" href="entries/information_entry.html">information</a> in the <a class="thought" href="entries/brain_entry.html">brain</a>. Crick and 
              Koch also suggest that these oscillations activate the mechanisms 
              of working <a class="thought" href="entries/memory_entry.html">memory</a>, so that there may be an account of this and perhaps 
              other forms of <a class="thought" href="entries/memory_entry.html">memory</a> in the distance. The theory might eventually 
              lead to a general account of how perceived <a class="thought" href="entries/information_entry.html">information</a> is bound 
              and stored in <a class="thought" href="entries/memory_entry.html">memory</a>, for use by later processing. </p>
<p>Such a theory would be valuable, but it would tell us nothing about 
              why the relevant <a class="thought" href="entries/content_entry.html">content</a>s are <a class="thought" href="entries/experience_entry.html">experience</a>d. Crick and Koch suggest 
              that these oscillations are the neural <i>correlates</i> of <a class="thought" href="entries/experience_entry.html">experience</a>. 
              This claim is arguable - does not binding also take place in the 
              processing of unconscious <a class="thought" href="entries/information_entry.html">information</a>? - but even if it is accepted, 
              the <i>explanatory</i> question remains: Why do the oscillations 
              give rise to <a class="thought" href="entries/experience_entry.html">experience</a>? The only basis for an explanatory connection 
              is the role they play in binding and storage, but the question of 
              why binding and storage should themselves be accompanied by <a class="thought" href="entries/experience_entry.html">experience</a> 
              is never addressed. If we do not know why binding and storage should 
              give rise to <a class="thought" href="entries/experience_entry.html">experience</a>, telling a story about the oscillations 
              cannot help us. Conversely, if we <i>knew</i> why binding and storage 
              gave rise to <a class="thought" href="entries/experience_entry.html">experience</a>, the neurophysiological details would be 
              just the icing on the cake. Crick and Koch's theory gains its purchase 
              by <i>assuming</i> a connection between binding and <a class="thought" href="entries/experience_entry.html">experience</a>, 
              and so can do nothing to explain that link. </p>
<p>I do not think that Crick and Koch are ultimately claiming to address 
              the hard problem, although some have interpreted them otherwise. 
              A published interview with Koch gives a clear statement of the limitations 
              on the theory's ambitions. </p>
<blockquote>
<p>Well, let's first forget about the really difficult aspects, 
                like subjective feelings, for they may not have a scientific solution. 
                The subjective state of play, of pain, of pleasure, of seeing 
                blue, of smelling a rose - there seems to be a huge jump between 
                the materialistic level, of explaining <a class="thought" href="entries/molecule_entry.html">molecule</a>s and <a class="thought" href="entries/neuron_entry.html">neuron</a>s, 
                and the subjective level. Let's focus on things that are easier 
                to study - like visual awareness. You're now talking to me, but 
                you're not looking at me, you're looking at the cappuccino, and 
                so you are aware of it. You can say, `It's a cup and there's some 
                liquid in it.' If I give it to you, you'll move your arm and you'll 
                take it - you'll respond in a meaningful manner. That's what I 
                call awareness." ("What is <a class="thought" href="entries/consciousness_entry.html">Consciousness</a>," <i>Discover</i>, 
                November 1992, p. 96.) </p>
</blockquote>
<p>The second example is an approach at the level of cognitive <a class="thought" href="entries/psychology_entry.html">psychology</a>. 
              This is Baars' global workspace theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, presented 
              in his book <i>A Cognitive Theory of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i>. According 
              to this theory, the <a class="thought" href="entries/content_entry.html">content</a>s of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> are contained in a 
              <i>global workspace</i>, a central processor used to mediate <a class="thought" href="entries/communication_entry.html">communication</a> 
              between a host of specialized nonconscious processors. When these 
              specialized processors need to <a class="thought" href="entries/broadcast_entry.html">broadcast</a> <a class="thought" href="entries/information_entry.html">information</a> to the rest 
              of the <a class="thought" href="entries/system_entry.html">system</a>, they do so by sending this <a class="thought" href="entries/information_entry.html">information</a> to the workspace, 
              which acts as a kind of communal blackboard for the rest of the 
              <a class="thought" href="entries/system_entry.html">system</a>, <a class="thought" href="entries/access_entry.html">access</a>ible to all the other processors. </p>
<p>Baars uses this model to address many aspects of <a class="thought" href="entries/human_entry.html">human</a> cognition, 
              and to explain a <a class="thought" href="entries/number_entry.html">number</a> of contrasts between conscious and unconscious 
              cognitive functioning. Ultimately, however, it is a theory of <i>cognitive 
              <a class="thought" href="entries/access_entry.html">access</a>ibility</i>, explaining how it is that certain <a class="thought" href="entries/information_entry.html">information</a>
<a class="thought" href="entries/content_entry.html">content</a>s are widely <a class="thought" href="entries/access_entry.html">access</a>ible within a <a class="thought" href="entries/system_entry.html">system</a>, as well as a theory 
              of <a class="thought" href="entries/information_entry.html">information</a>al integration and reportability. The theory shows 
              promise as a theory of awareness, the functional correlate of conscious 
              <a class="thought" href="entries/experience_entry.html">experience</a>, but an explanation of <a class="thought" href="entries/experience_entry.html">experience</a> itself is not on offer. 
            </p>
<p>One might suppose that according to this theory, the <a class="thought" href="entries/content_entry.html">content</a>s of 
              <a class="thought" href="entries/experience_entry.html">experience</a> are precisely the <a class="thought" href="entries/content_entry.html">content</a>s of the workspace. But even 
              if this is so, nothing internal to the theory <i>explains</i> why 
              the <a class="thought" href="entries/information_entry.html">information</a> within the global workspace is <a class="thought" href="entries/experience_entry.html">experience</a>d. The 
              best the theory can do is to say that the <a class="thought" href="entries/information_entry.html">information</a> is <a class="thought" href="entries/experience_entry.html">experience</a>d 
              because it is <i>globally <a class="thought" href="entries/access_entry.html">access</a>ible</i>. But now the question arises 
              in a different form: why should global <a class="thought" href="entries/access_entry.html">access</a>ibility give rise to 
              conscious <a class="thought" href="entries/experience_entry.html">experience</a>? As always, this bridging question is unanswered. 
            </p>
<p>Almost all work taking a cognitive or neuroscientific approach 
              to <a class="thought" href="entries/consciousness_entry.html">consciousness</a> in recent years could be subjected to a similar 
              critique. The "Neural Darwinism" model of Edelman (1989), 
              for <a class="thought" href="entries/instance_entry.html">instance</a>, addresses questions about perceptual awareness and 
              the self-<a class="thought" href="entries/concept_entry.html">concept</a>, but says nothing about why there should also be 
              <a class="thought" href="entries/experience_entry.html">experience</a>. The "multiple drafts" model of Dennett (1991) 
              is largely directed at explaining the reportability of certain mental 
              <a class="thought" href="entries/content_entry.html">content</a>s. The "intermediate level" theory of Jackendoff 
              (1988) provides an account of some <a class="thought" href="entries/computation_entry.html">computation</a>al processes that 
              underlie <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, but Jackendoff stresses that the question 
              of how these "project" into conscious <a class="thought" href="entries/experience_entry.html">experience</a> remains 
              mysterious. </p>
<p><a class="thought" href="entries/research_entry.html">Research</a>ers using these <a class="thought" href="entries/method_entry.html">method</a>s are often inexplicit about their 
              attitudes to the problem of conscious <a class="thought" href="entries/experience_entry.html">experience</a>, although sometimes 
              they take a clear stand. Even among those who are clear about it, 
              attitudes differ widely. In placing this sort of work with respect 
              to the problem of <a class="thought" href="entries/experience_entry.html">experience</a>, a <a class="thought" href="entries/number_entry.html">number</a> of different strategies are 
              available. It would be useful if these strategic choices were more 
              often made explicit. </p>
<p>The first strategy is simply to <i>explain something else</i>. 
              Some <a class="thought" href="entries/research_entry.html">research</a>ers are explicit that the problem of <a class="thought" href="entries/experience_entry.html">experience</a> is 
              too difficult for now, and perhaps even outside the <a class="thought" href="entries/domain_entry.html">domain</a> of <a class="thought" href="entries/science_entry.html">science</a> 
              altogether. These <a class="thought" href="entries/research_entry.html">research</a>ers instead choose to address one of the 
              more tractable problems such as reportability or the self-<a class="thought" href="entries/concept_entry.html">concept</a>. 
              Although I have called these problems the "easy" problems, 
              they are among the most interesting unsolved problems in cognitive 
              <a class="thought" href="entries/science_entry.html">science</a>, so this work is certainly worthwhile. The worst that can 
              be said of this choice is that in the <a class="thought" href="entries/context_entry.html">context</a> of <a class="thought" href="entries/research_entry.html">research</a> on <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
              it is relatively unambitious, and the work can sometimes be misinterpreted. 
            </p>
<p>The second choice is to take a harder line and <i>deny the <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a></i>. 
              (Variations on this approach are taken by Allport 1988, Dennett 
              1991, and Wilkes 1988.) According to this line, once we have explained 
              the functions such as <a class="thought" href="entries/access_entry.html">access</a>ibility, reportability, and the like, 
              there is no further <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a> called "experience" to 
              explain. Some explicitly deny the <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a>, holding for example 
              that what is not externally verifiable cannot be real. Others achieve 
              the same effect by allowing that <a class="thought" href="entries/experience_entry.html">experience</a> exists, but only if 
              we equate "experience" with something like the <a class="thought" href="entries/capacity_entry.html">capacity</a> 
              to discriminate and report. These approaches lead to a simpler theory, 
              but are ultimately unsatisfactory. <a class="thought" href="entries/experience_entry.html">Experience</a> is the most central 
              and manifest aspect of our mental lives, and indeed is perhaps the 
              key explanandum in the <a class="thought" href="entries/science_entry.html">science</a> of the <a class="thought" href="entries/mind_entry.html">mind</a>. Because of this status 
              as an explanandum, <a class="thought" href="entries/experience_entry.html">experience</a> cannot be discarded like the vital 
              <a class="thought" href="entries/spirit_entry.html">spirit</a> when a new theory comes along. Rather, it is the central 
              fact that any theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> must explain. A theory that 
              denies the <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a> "solves" the problem by ducking 
              the question. </p>
<p>In a third option, some <a class="thought" href="entries/research_entry.html">research</a>ers <i>claim to be explaining <a class="thought" href="entries/experience_entry.html">experience</a></i> 
              in the full <a class="thought" href="entries/sense_entry.html">sense</a>. These <a class="thought" href="entries/research_entry.html">research</a>ers (unlike those above) wish to 
              take <a class="thought" href="entries/experience_entry.html">experience</a> very seriously; they lay out their functional model 
              or theory, and claim that it explains the full subjective quality 
              of <a class="thought" href="entries/experience_entry.html">experience</a> (e.g. Flohr 1992, Humphrey 1992). The relevant step 
              in the explanation is usually passed over quickly, however, and 
              usually ends up looking something like magic. After some details 
              about <a class="thought" href="entries/information_entry.html">information</a> processing are given, <a class="thought" href="entries/experience_entry.html">experience</a> suddenly enters 
              the picture, but it is left obscure <i>how</i> these processes should 
              suddenly give rise to <a class="thought" href="entries/experience_entry.html">experience</a>. Perhaps it is simply taken for 
              granted that it does, but then we have an incomplete explanation 
              and a version of the fifth strategy below. </p>
<p>A fourth, more promising approach appeals to these <a class="thought" href="entries/method_entry.html">method</a>s to <i>explain 
              the <a class="thought" href="entries/structure_entry.html">structure</a> of <a class="thought" href="entries/experience_entry.html">experience</a></i>. For example, it is arguable that 
              an account of the discriminations made by the visual <a class="thought" href="entries/system_entry.html">system</a> can 
              account for the structural relations between different color <a class="thought" href="entries/experience_entry.html">experience</a>s, 
              as well as for the geometric <a class="thought" href="entries/structure_entry.html">structure</a> of the visual field (see 
              e.g., Clark 1992 and Hardin 1992). In general, certain facts about 
              <a class="thought" href="entries/structure_entry.html">structure</a>s found in processing will correspond to and arguably explain 
              facts about the <a class="thought" href="entries/structure_entry.html">structure</a> of <a class="thought" href="entries/experience_entry.html">experience</a>. This strategy is plausible 
              but limited. At best, it takes the <a class="thought" href="entries/existence_entry.html">existence</a> of <a class="thought" href="entries/experience_entry.html">experience</a> for granted 
              and accounts for some facts about its <a class="thought" href="entries/structure_entry.html">structure</a>, providing a sort 
              of nonreductive explanation of the structural aspects of <a class="thought" href="entries/experience_entry.html">experience</a> 
              (I will say more on this later). This is useful for many purposes, 
              but it tells us nothing about why there should be <a class="thought" href="entries/experience_entry.html">experience</a> in 
              the first place. </p>
<p>A fifth and <a class="thought" href="entries/reason_entry.html">reason</a>able strategy is to <i>isolate the <a class="thought" href="entries/substrate_entry.html">substrate</a> 
              of <a class="thought" href="entries/experience_entry.html">experience</a></i>. After all, almost everyone allows that <a class="thought" href="entries/experience_entry.html">experience</a>
<i>arises</i> one way or another from <a class="thought" href="entries/brain_entry.html">brain</a> processes, and it makes 
              <a class="thought" href="entries/sense_entry.html">sense</a> to identify the sort of process from which it arises. Crick 
              and Koch put their work forward as isolating the neural correlate 
              of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, for example, and Edelman (1989) and Jackendoff 
              (1988) make related claims. Justification of these claims requires 
              a careful theoretical analysis, especially as <a class="thought" href="entries/experience_entry.html">experience</a> is not 
              directly observable in <a class="thought" href="entries/experiment_entry.html">experiment</a>al <a class="thought" href="entries/context_entry.html">context</a>s, but when applied judiciously 
              this strategy can shed indirect <a class="thought" href="entries/light_entry.html">light</a> on the problem of <a class="thought" href="entries/experience_entry.html">experience</a>. 
              Nevertheless, the strategy is clearly incomplete. For a satisfactory 
              theory, we need to know more than <i>which</i> processes give rise 
              to <a class="thought" href="entries/experience_entry.html">experience</a>; we need an account of why and how. A full theory 
              of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> must build an explanatory bridge. </p>
<h1>5 The extra ingredient</h1>
<p>We have seen that there are <a class="thought" href="entries/system_entry.html">system</a>atic <a class="thought" href="entries/reason_entry.html">reason</a>s why the usual <a class="thought" href="entries/method_entry.html">method</a>s 
              of <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a> and <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a> fail to account for conscious 
              <a class="thought" href="entries/experience_entry.html">experience</a>. These are simply the wrong sort of <a class="thought" href="entries/method_entry.html">method</a>s: nothing 
              that they give to us can yield an explanation. To account for conscious 
              <a class="thought" href="entries/experience_entry.html">experience</a>, we need an <i>extra ingredient</i> in the explanation. 
              This makes for a challenge to those who are serious about the hard 
              problem of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>: What is your extra ingredient, and why 
              should <i>that</i> account for conscious <a class="thought" href="entries/experience_entry.html">experience</a>? </p>
<p>There is no shortage of extra ingredients to be had. Some propose 
              an injection of <a class="thought" href="entries/chaos_entry.html">chaos</a> and nonlinear <a class="thought" href="entries/dynamics_entry.html">dynamics</a>. Some think that the 
              key lies in nonalgorithmic processing. Some appeal to <a class="thought" href="entries/future_entry.html">future</a> discoveries 
              in neurophysiology. Some suppose that the key to the mystery will 
              lie at the level of <a class="thought" href="entries/quantum_mechanics_entry.html">quantum mechanics</a>. It is easy to see why all 
              these suggestions are put forward. None of the old <a class="thought" href="entries/method_entry.html">method</a>s work, 
              so the solution must lie with <i>something</i> new. Unfortunately, 
              these suggestions all suffer from the same old problems. </p>
<p>Nonalgorithmic processing, for example, is put forward by Penrose 
              (1989; 1994) because of the role it might play in the process of 
              conscious mathematical insight. The arguments about <a class="thought" href="entries/mathematics_entry.html">mathematics</a> 
              are controversial, but even if they succeed and an account of nonalgorithmic 
              processing in the <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/brain_entry.html">brain</a> is given, it will still only be an 
              account of the <i>functions</i> involved in mathematical <a class="thought" href="entries/reason_entry.html">reason</a>ing 
              and the like. For a nonalgorithmic process as much as an <a class="thought" href="entries/algorithm_entry.html">algorithm</a>ic 
              process, the question is left unanswered: why should this process 
              give rise to <a class="thought" href="entries/experience_entry.html">experience</a>? In answering <i>this</i> question, there 
              is no special role for nonalgorithmic processing. </p>
<p>The same goes for nonlinear and chaotic <a class="thought" href="entries/dynamics_entry.html">dynamics</a>. These might provide 
              a <a class="thought" href="entries/novel_entry.html">novel</a> account of the <a class="thought" href="entries/dynamics_entry.html">dynamics</a> of cognitive functioning, quite 
              different from that given by standard <a class="thought" href="entries/method_entry.html">method</a>s in <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a>. 
              But from <a class="thought" href="entries/dynamics_entry.html">dynamics</a>, one only gets more <a class="thought" href="entries/dynamics_entry.html">dynamics</a>. The question about 
              <a class="thought" href="entries/experience_entry.html">experience</a> here is as mysterious as ever. The point is even clearer 
              for new discoveries in neurophysiology. These new discoveries may 
              help us make significant <a class="thought" href="entries/progress_entry.html">progress</a> in understanding <a class="thought" href="entries/brain_entry.html">brain</a> function, 
              but for any neural process we isolate, the same question will always 
              arise. It is difficult to imagine what a proponent of new neurophysiology 
              expects to happen, over and above the explanation of further cognitive 
              functions. It is not as if we will suddenly discover a phenomenal 
              glow inside a <a class="thought" href="entries/neuron_entry.html">neuron</a>! </p>
<p>Perhaps the most popular "extra ingredient" of all is 
              <a class="thought" href="entries/quantum_mechanics_entry.html">quantum mechanics</a> (e.g. Hameroff 1994). The attractiveness of quantum 
              theories of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> may stem from a Law of Minimization of 
              Mystery: <a class="thought" href="entries/consciousness_entry.html">consciousness</a> is mysterious and <a class="thought" href="entries/quantum_mechanics_entry.html">quantum mechanics</a> is mysterious, 
              so maybe the two mysteries have a common source. Nevertheless, quantum 
              theories of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> suffer from the same difficulties as neural 
              or <a class="thought" href="entries/computation_entry.html">computation</a>al theories. Quantum phenomena have some remarkable 
              functional properties, such as nondeterminism and <a class="thought" href="entries/nonlocality_entry.html">nonlocality</a>. It 
              is natural to speculate that these properties may play some role 
              in the explanation of cognitive functions, such as random choice 
              and the integration of <a class="thought" href="entries/information_entry.html">information</a>, and this <a class="thought" href="entries/hypothesis_entry.html">hypothesis</a> cannot be 
              ruled out <i>a priori</i>. But when it comes to the explanation 
              of <a class="thought" href="entries/experience_entry.html">experience</a>, quantum processes are in the same boat as any other. 
              The question of why these processes should give rise to <a class="thought" href="entries/experience_entry.html">experience</a> 
              is entirely unanswered. </p>
<p>(One special attraction of quantum theories is the fact that on 
              some interpretations of <a class="thought" href="entries/quantum_mechanics_entry.html">quantum mechanics</a>, <a class="thought" href="entries/consciousness_entry.html">consciousness</a> plays an 
              active role in "collapsing" the quantum <a class="thought" href="entries/wave_entry.html">wave</a> function. 
              Such interpretations are controversial, but in any case they offer 
              no hope of <i>explaining</i> <a class="thought" href="entries/consciousness_entry.html">consciousness</a> in terms of quantum processes. 
              Rather, these theories <i>assume</i> the <a class="thought" href="entries/existence_entry.html">existence</a> of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, 
              and use it in the explanation of quantum processes. At best, these 
              theories tell us something about a physical role that <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
              may play. They tell us nothing about how it arises.) </p>
<p>At the end of the day, the same criticism applies to <i>any</i> 
              purely physical account of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. For any physical process 
              we specify there will be an unanswered question: Why should this 
              process give rise to <a class="thought" href="entries/experience_entry.html">experience</a>? Given any such process, it is <a class="thought" href="entries/concept_entry.html">concept</a>ually 
              coherent that it could be instantiated in the absence of <a class="thought" href="entries/experience_entry.html">experience</a>. 
              It follows that no mere account of the physical process will tell 
              us why <a class="thought" href="entries/experience_entry.html">experience</a> arises. The emergence of <a class="thought" href="entries/experience_entry.html">experience</a> goes beyond 
              what can be derived from physical theory. </p>
<p>Purely physical explanation is well-suited to the explanation of 
              physical <i><a class="thought" href="entries/structure_entry.html">structure</a>s</i>, explaining macroscopic <a class="thought" href="entries/structure_entry.html">structure</a>s in 
              terms of detailed microstructural constituents; and it provides 
              a satisfying explanation of the performance of <i>functions</i>, 
              accounting for these functions in terms of the physical mechanisms 
              that perform them. This is because a physical account can <i>entail</i> 
              the facts about <a class="thought" href="entries/structure_entry.html">structure</a>s and functions: once the internal details 
              of the physical account are given, the structural and functional 
              properties fall out as an automatic consequence. But the <a class="thought" href="entries/structure_entry.html">structure</a> 
              and <a class="thought" href="entries/dynamics_entry.html">dynamics</a> of physical processes yield only more <a class="thought" href="entries/structure_entry.html">structure</a> and 
              <a class="thought" href="entries/dynamics_entry.html">dynamics</a>, so <a class="thought" href="entries/structure_entry.html">structure</a>s and functions are all we can expect these 
              processes to explain. The facts about <a class="thought" href="entries/experience_entry.html">experience</a> cannot be an automatic 
              consequence of any physical account, as it is <a class="thought" href="entries/concept_entry.html">concept</a>ually coherent 
              that any given process could exist without <a class="thought" href="entries/experience_entry.html">experience</a>. <a class="thought" href="entries/experience_entry.html">Experience</a> 
              may <i>arise</i> from the physical, but it is not <i>entailed</i> 
              by the physical. </p>
<p>The moral of all this is that <i>you can't explain conscious <a class="thought" href="entries/experience_entry.html">experience</a> 
              on the cheap</i>. It is a remarkable fact that reductive <a class="thought" href="entries/method_entry.html">method</a>s 
              - <a class="thought" href="entries/method_entry.html">method</a>s that explain a high-level <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a> wholly in terms of 
              more <a class="thought" href="entries/basic_entry.html">basic</a> physical processes - work well in so many <a class="thought" href="entries/domain_entry.html">domain</a>s. In 
              a <a class="thought" href="entries/sense_entry.html">sense</a>, one <i>can</i> explain most <a class="thought" href="entries/biological_entry.html">biological</a> and cognitive phenomena 
              on the cheap, in that these phenomena are seen as automatic consequences 
              of more fundamental processes. It would be wonderful if reductive 
              <a class="thought" href="entries/method_entry.html">method</a>s could explain <a class="thought" href="entries/experience_entry.html">experience</a>, too; I hoped for a long <a class="thought" href="entries/time_entry.html">time</a> that 
              they might. Unfortunately, there are <a class="thought" href="entries/system_entry.html">system</a>atic <a class="thought" href="entries/reason_entry.html">reason</a>s why these 
              <a class="thought" href="entries/method_entry.html">method</a>s must fail. Reductive <a class="thought" href="entries/method_entry.html">method</a>s are successful in most <a class="thought" href="entries/domain_entry.html">domain</a>s 
              because what needs explaining in those <a class="thought" href="entries/domain_entry.html">domain</a>s are <a class="thought" href="entries/structure_entry.html">structure</a>s and 
              functions, and these are the kind of thing that a physical account 
              can entail. When it comes to a problem over and above the explanation 
              of <a class="thought" href="entries/structure_entry.html">structure</a>s and functions, these <a class="thought" href="entries/method_entry.html">method</a>s are impotent. </p>
<p>This might seem reminiscent of the vitalist claim that no physical 
              account could explain <a class="thought" href="entries/life_entry.html">life</a>, but the cases are disanalogous. What 
              drove vitalist skepticism was doubt about whether physical mechanisms 
              could perform the many remarkable functions associated with <a class="thought" href="entries/life_entry.html">life</a>, 
              such as complex adaptive behavior and reproduction. The <a class="thought" href="entries/concept_entry.html">concept</a>ual 
              claim that explanation of functions is what is needed was implicitly 
              accepted, but lacking detailed <a class="thought" href="entries/knowledge_entry.html">knowledge</a> of biochemical mechanisms, 
              vitalists doubted whether any physical process could do the job 
              and put forward the <a class="thought" href="entries/hypothesis_entry.html">hypothesis</a> of the vital <a class="thought" href="entries/spirit_entry.html">spirit</a> as an alternative 
              explanation. Once it turned out that physical processes could perform 
              the relevant functions, vitalist doubts melted away. </p>
<p>With <a class="thought" href="entries/experience_entry.html">experience</a>, on the other hand, physical explanation of the 
              functions is not in question. The key is instead the <i><a class="thought" href="entries/concept_entry.html">concept</a>ual</i> 
              point that the explanation of functions does not suffice for the 
              explanation of <a class="thought" href="entries/experience_entry.html">experience</a>. This <a class="thought" href="entries/basic_entry.html">basic</a> <a class="thought" href="entries/concept_entry.html">concept</a>ual point is not something 
              that further neuroscientific investigation will affect. In a similar 
              way, <a class="thought" href="entries/experience_entry.html">experience</a> is disanalogous to the <i>&#233;lan vital</i>. 
              The vital <a class="thought" href="entries/spirit_entry.html">spirit</a> was put forward as an explanatory posit, in <a class="thought" href="entries/order_entry.html">order</a> 
              to explain the relevant functions, and could therefore be discarded 
              when those functions were explained without it. <a class="thought" href="entries/experience_entry.html">Experience</a> is not 
              an explanatory posit but an explanandum in its own right, and so 
              is not a candidate for this sort of elimination. </p>
<p>It is tempting to note that all sorts of puzzling phenomena have 
              eventually turned out to be explainable in physical terms. But each 
              of these were problems about the observable behavior of physical 
              <a class="thought" href="entries/object_entry.html">object</a>s, coming down to problems in the explanation of <a class="thought" href="entries/structure_entry.html">structure</a>s 
              and functions. Because of this, these phenomena have always been 
              the kind of thing that a physical account <i>might</i> explain, 
              even if at some points there have been good <a class="thought" href="entries/reason_entry.html">reason</a>s to suspect that 
              no such explanation would be forthcoming. The tempting <a class="thought" href="entries/induction_entry.html">induction</a> 
              from these cases fails in the case of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, which is not 
              a problem about physical <a class="thought" href="entries/structure_entry.html">structure</a>s and functions. The problem of 
              <a class="thought" href="entries/consciousness_entry.html">consciousness</a> is puzzling in an entirely different way. An analysis 
              of the problem shows us that conscious <a class="thought" href="entries/experience_entry.html">experience</a> is just not the 
              kind of thing that a wholly reductive account could succeed in explaining. 
            </p>
<h1>6 Nonreductive explanation</h1>
<p>At this point some are tempted to give up, holding that we will 
              never have a theory of conscious <a class="thought" href="entries/experience_entry.html">experience</a>. McGinn (1989), for 
              example, argues that the problem is too hard for our limited minds; 
              we are "cognitively closed" with respect to the <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a>. 
              Others have argued that conscious <a class="thought" href="entries/experience_entry.html">experience</a> lies outside the <a class="thought" href="entries/domain_entry.html">domain</a> 
              of scientific theory altogether. </p>
<p>I think this pessimism is premature. This is not the place to give 
              up; it is the place where things get interesting. When simple <a class="thought" href="entries/method_entry.html">method</a>s 
              of explanation are ruled out, we need to investigate the alternatives. 
              Given that reductive explanation fails, <i>nonreductive</i> explanation 
              is the natural choice. </p>
<p>Although a remarkable <a class="thought" href="entries/number_entry.html">number</a> of phenomena have turned out to be 
              explicable wholly in terms of entities simpler than themselves, 
              this is not universal. In <a class="thought" href="entries/physics_entry.html">physics</a>, it occasionally happens that 
              an <a class="thought" href="entries/entity_entry.html">entity</a> has to be taken as <i>fundamental</i>. Fundamental entities 
              are not explained in terms of anything simpler. Instead, one takes 
              them as <a class="thought" href="entries/basic_entry.html">basic</a>, and gives a theory of how they relate to everything 
              else in the world. For example, in the nineteenth century it turned 
              out that <a class="thought" href="entries/electromagnetic_entry.html">electromagnetic</a> processes could not be explained in terms 
              of the wholly mechanical processes that previous physical theories 
              appealed to, so Maxwell and others introduced <a class="thought" href="entries/electromagnetic_entry.html">electromagnetic</a> charge 
              and <a class="thought" href="entries/electromagnetic_entry.html">electromagnetic</a> forces as new fundamental <a class="thought" href="entries/component_entry.html">component</a>s of a physical 
              theory. To explain electromagnetism, the <a class="thought" href="entries/ontology_entry.html">ontology</a> of <a class="thought" href="entries/physics_entry.html">physics</a> had 
              to be expanded. New <a class="thought" href="entries/basic_entry.html">basic</a> properties and <a class="thought" href="entries/basic_entry.html">basic</a> laws were needed 
              to give a satisfactory account of the phenomena. </p>
<p>Other features that physical theory takes as fundamental include 
              mass and <a class="thought" href="entries/spacetime_entry.html">space-time</a>. No attempt is made to explain these features 
              in terms of anything simpler. But this does not rule out the possibility 
              of a theory of mass or of <a class="thought" href="entries/spacetime_entry.html">space-time</a>. There is an intricate theory 
              of how these features interrelate, and of the <a class="thought" href="entries/basic_entry.html">basic</a> laws they enter 
              into. These <a class="thought" href="entries/basic_entry.html">basic</a> principles are used to explain many familiar phenomena 
              concerning mass, <a class="thought" href="entries/space_entry.html">space</a>, and <a class="thought" href="entries/time_entry.html">time</a> at a higher level. </p>
<p>I suggest that a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> should take <a class="thought" href="entries/experience_entry.html">experience</a> 
              as fundamental. We know that a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> requires 
              the addition of <i>something</i> fundamental to our <a class="thought" href="entries/ontology_entry.html">ontology</a>, as 
              everything in physical theory is compatible with the absence of 
              <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. We might add some entirely new nonphysical feature, 
              from which <a class="thought" href="entries/experience_entry.html">experience</a> can be derived, but it is hard to see what 
              such a feature would be like. More likely, we will take <a class="thought" href="entries/experience_entry.html">experience</a> 
              itself as a fundamental feature of the world, alongside mass, charge, 
              and <a class="thought" href="entries/spacetime_entry.html">space-time</a>. If we take <a class="thought" href="entries/experience_entry.html">experience</a> as fundamental, then we can 
              go about the business of constructing a theory of <a class="thought" href="entries/experience_entry.html">experience</a>. </p>
<p>Where there is a fundamental property, there are fundamental laws. 
              A nonreductive theory of <a class="thought" href="entries/experience_entry.html">experience</a> will add new principles to the 
              furniture of the <a class="thought" href="entries/basic_entry.html">basic</a> laws of <a class="thought" href="entries/nature_entry.html">nature</a>. These <a class="thought" href="entries/basic_entry.html">basic</a> principles will 
              ultimately carry the explanatory burden in a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. 
              Just as we explain familiar high-level phenomena involving mass 
              in terms of more <a class="thought" href="entries/basic_entry.html">basic</a> principles involving mass and other entities, 
              we might explain familiar phenomena involving <a class="thought" href="entries/experience_entry.html">experience</a> in terms 
              of more <a class="thought" href="entries/basic_entry.html">basic</a> principles involving <a class="thought" href="entries/experience_entry.html">experience</a> and other entities. 
            </p>
<p>In particular, a nonreductive theory of <a class="thought" href="entries/experience_entry.html">experience</a> will specify 
              <a class="thought" href="entries/basic_entry.html">basic</a> principles telling us how <a class="thought" href="entries/experience_entry.html">experience</a> depends on physical features 
              of the world. These <i>psychophysical</i> principles will not interfere 
              with physical laws, as it seems that physical laws already form 
              a <a class="thought" href="entries/closed_system_entry.html">closed system</a>. Rather, they will be a supplement to a physical 
              theory. A physical theory gives a theory of physical processes, 
              and a psychophysical theory tells us how those processes give rise 
              to <a class="thought" href="entries/experience_entry.html">experience</a>. We know that <a class="thought" href="entries/experience_entry.html">experience</a> depends on physical processes, 
              but we also know that this dependence cannot be derived from physical 
              laws alone. The new <a class="thought" href="entries/basic_entry.html">basic</a> principles postulated by a nonreductive 
              theory give us the extra ingredient that we need to build an explanatory 
              bridge. </p>
<p>Of course, by taking <a class="thought" href="entries/experience_entry.html">experience</a> as fundamental, there is a <a class="thought" href="entries/sense_entry.html">sense</a> 
              in which this approach does not tell us why there is <a class="thought" href="entries/experience_entry.html">experience</a> 
              in the first place. But this is the same for any fundamental theory. 
              Nothing in <a class="thought" href="entries/physics_entry.html">physics</a> tells us why there is <a class="thought" href="entries/matter_entry.html">matter</a> in the first place, 
              but we do not count this against theories of <a class="thought" href="entries/matter_entry.html">matter</a>. Certain features 
              of the world need to be taken as fundamental by any scientific theory. 
              A theory of <a class="thought" href="entries/matter_entry.html">matter</a> can still explain all sorts of facts about <a class="thought" href="entries/matter_entry.html">matter</a>, 
              by showing how they are consequences of the <a class="thought" href="entries/basic_entry.html">basic</a> laws. The same 
              goes for a theory of <a class="thought" href="entries/experience_entry.html">experience</a>. </p>
<p>This position qualifies as a variety of dualism, as it postulates 
              <a class="thought" href="entries/basic_entry.html">basic</a> properties over and above the properties invoked by <a class="thought" href="entries/physics_entry.html">physics</a>. 
              But it is an innocent version of dualism, entirely compatible with 
              the scientific view of the world. Nothing in this approach contradicts 
              anything in physical theory; we simply need to add further <i>bridging</i> 
              principles to explain how <a class="thought" href="entries/experience_entry.html">experience</a> arises from physical processes. 
              There is nothing particularly <a class="thought" href="entries/spirit_entry.html">spirit</a>ual or mystical about this theory 
              - its overall shape is like that of a physical theory, with a few 
              fundamental entities connected by fundamental laws. It expands the 
              <a class="thought" href="entries/ontology_entry.html">ontology</a> slightly, to be sure, but Maxwell did the same thing. Indeed, 
              the overall <a class="thought" href="entries/structure_entry.html">structure</a> of this position is entirely naturalistic, 
              allowing that ultimately the <a class="thought" href="entries/universe_entry.html">universe</a> comes down to a <a class="thought" href="entries/network_entry.html">network</a> of 
              <a class="thought" href="entries/basic_entry.html">basic</a> entities obeying simple laws, and allowing that there may 
              ultimately be a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> cast in terms of such laws. 
              If the position is to have a name, a good choice might be <i>naturalistic 
              dualism</i>. </p>
<p>If this view is right, then in some ways a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
              will have more in common with a theory in <a class="thought" href="entries/physics_entry.html">physics</a> than a theory 
              in <a class="thought" href="entries/biology_entry.html">biology</a>. <a class="thought" href="entries/biological_entry.html">Biological</a> theories involve no principles that are fundamental 
              in this way, so <a class="thought" href="entries/biological_entry.html">biological</a> theory has a certain <a class="thought" href="entries/complexity_entry.html">complexity</a> and messiness 
              to it; but theories in <a class="thought" href="entries/physics_entry.html">physics</a>, insofar as they deal with fundamental 
              principles, aspire to simplicity and elegance. The fundamental laws 
              of <a class="thought" href="entries/nature_entry.html">nature</a> are part of the <a class="thought" href="entries/basic_entry.html">basic</a> furniture of the world, and physical 
              theories are telling us that this <a class="thought" href="entries/basic_entry.html">basic</a> furniture is remarkably 
              simple. If a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> also involves fundamental principles, 
              then we should expect the same. The principles of simplicity, elegance, 
              and even <a class="thought" href="entries/beauty_entry.html">beauty</a> that drive physicists' <a class="thought" href="entries/search_entry.html">search</a> for a fundamental 
              theory will also apply to a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. </p>
<p>(A technical note: Some philosophers argue that even though there 
              is a <i><a class="thought" href="entries/concept_entry.html">concept</a>ual</i> gap between physical processes and <a class="thought" href="entries/experience_entry.html">experience</a>, 
              there need be no metaphysical gap, so that <a class="thought" href="entries/experience_entry.html">experience</a> might in a 
              certain <a class="thought" href="entries/sense_entry.html">sense</a> still be physical (e.g. Hill 1991; Levine 1983; Loar 
              1990). Usually this line of argument is supported by an appeal to 
              the notion of <i>a posteriori</i> necessity (Kripke 1980). I think 
              that this position rests on a misunderstanding of <i>a posteriori</i> 
              necessity, however, or else requires an entirely new sort of necessity 
              that we have no <a class="thought" href="entries/reason_entry.html">reason</a> to believe in; see Chalmers 1996 (also Jackson 
              1994 and Lewis 1994) for details. In any case, this position still 
              concedes an <i>explanatory</i> gap between physical processes and 
              <a class="thought" href="entries/experience_entry.html">experience</a>. For example, the principles connecting the physical 
              and the experiential will not be derivable from the laws of <a class="thought" href="entries/physics_entry.html">physics</a>, 
              so such principles must be taken as <i>explanatorily</i> fundamental. 
              So even on this sort of view, the explanatory <a class="thought" href="entries/structure_entry.html">structure</a> of a theory 
              of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> will be much as I have described.) </p>
<h1>7 Outline of a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a></h1>
<p>It is not too soon to begin work on a theory. We are already in 
              a position to understand certain key facts about the relationship 
              between physical processes and <a class="thought" href="entries/experience_entry.html">experience</a>, and about the regularities 
              that connect them. Once reductive explanation is <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> aside, we can 
              lay those facts on the table so that they can play their proper 
              role as the initial pieces in a nonreductive theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, 
              and as <a class="thought" href="entries/constraint_entry.html">constraint</a>s on the <a class="thought" href="entries/basic_entry.html">basic</a> laws that constitute an ultimate 
              theory. </p>
<p>There is an obvious problem that plagues the development of a theory 
              of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, and that is the paucity of <a class="thought" href="entries/object_entry.html">object</a>ive <a class="thought" href="entries/data_entry.html">data</a>. Conscious 
              <a class="thought" href="entries/experience_entry.html">experience</a> is not directly observable in an <a class="thought" href="entries/experiment_entry.html">experiment</a>al <a class="thought" href="entries/context_entry.html">context</a>, 
              so we cannot generate <a class="thought" href="entries/data_entry.html">data</a> about the relationship between physical 
              processes and <a class="thought" href="entries/experience_entry.html">experience</a> at will. Nevertheless, we all have <a class="thought" href="entries/access_entry.html">access</a> 
              to a rich source of <a class="thought" href="entries/data_entry.html">data</a> in our own case. Many <a class="thought" href="entries/import_entry.html">import</a>ant regularities 
              between <a class="thought" href="entries/experience_entry.html">experience</a> and processing can be inferred from considerations 
              about one's own <a class="thought" href="entries/experience_entry.html">experience</a>. There are also good indirect sources 
              of <a class="thought" href="entries/data_entry.html">data</a> from observable cases, as when one relies on the verbal 
              report of a subject as an indication of <a class="thought" href="entries/experience_entry.html">experience</a>. These <a class="thought" href="entries/method_entry.html">method</a>s 
              have their limitations, but we have more than enough <a class="thought" href="entries/data_entry.html">data</a> to get 
              a theory off the ground. </p>
<p>Philosophical analysis is also useful in getting value for money 
              out of the <a class="thought" href="entries/data_entry.html">data</a> we have. This sort of analysis can yield a <a class="thought" href="entries/number_entry.html">number</a> 
              of principles relating <a class="thought" href="entries/consciousness_entry.html">consciousness</a> and cognition, thereby strongly 
              constraining the shape of an ultimate theory. The <a class="thought" href="entries/method_entry.html">method</a> of <a class="thought" href="entries/thought_entry.html">thought</a>-<a class="thought" href="entries/experiment_entry.html">experiment</a>ation 
              can also yield significant rewards, as we will see. Finally, the 
              fact that we are <a class="thought" href="entries/search_entry.html">search</a>ing for a <i>fundamental</i> theory means 
              that we can appeal to such nonempirical <a class="thought" href="entries/constraint_entry.html">constraint</a>s as simplicity, 
              homogeneity, and the like in developing a theory. We must seek to 
              <a class="thought" href="entries/system_entry.html">system</a>atize the <a class="thought" href="entries/information_entry.html">information</a> we have, to extend it as far as possible 
              by careful analysis, and then make the inference to the simplest 
              possible theory that explains the <a class="thought" href="entries/data_entry.html">data</a> while remaining a plausible 
              candidate to be part of the fundamental furniture of the world. 
            </p>
<p>Such theories will always retain an <a class="thought" href="entries/element_entry.html">element</a> of speculation that 
              is not present in other scientific theories, because of the impossibility 
              of conclusive intersubjective <a class="thought" href="entries/experiment_entry.html">experiment</a>al tests. Still, we can 
              certainly construct theories that are compatible with the <a class="thought" href="entries/data_entry.html">data</a> that 
              we have, and evaluate them in comparison to each other. Even in 
              the absence of intersubjective observation, there are numerous criteria 
              available for the evaluation of such theories: simplicity, internal 
              coherence, coherence with theories in other <a class="thought" href="entries/domain_entry.html">domain</a>s, the ability 
              to reproduce the properties of <a class="thought" href="entries/experience_entry.html">experience</a> that are familiar from 
              our own case, and even an overall fit with the dictates of common 
              <a class="thought" href="entries/sense_entry.html">sense</a>. Perhaps there will be significant indeterminacies remaining 
              even when all these <a class="thought" href="entries/constraint_entry.html">constraint</a>s are applied, but we can at least 
              develop plausible candidates. Only when candidate theories have 
              been developed will we be able to evaluate them. </p>
<p>A nonreductive theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> will consist in a <a class="thought" href="entries/number_entry.html">number</a> 
              of <i>psychophysical principles</i>, principles connecting the properties 
              of physical processes to the properties of <a class="thought" href="entries/experience_entry.html">experience</a>. We can think 
              of these principles as encapsulating the way in which <a class="thought" href="entries/experience_entry.html">experience</a> 
              arises from the physical. Ultimately, these principles should tell 
              us what sort of physical <a class="thought" href="entries/system_entry.html">system</a>s will have associated <a class="thought" href="entries/experience_entry.html">experience</a>s, 
              and for the <a class="thought" href="entries/system_entry.html">system</a>s that do, they should tell us what sort of physical 
              properties are relevant to the emergence of <a class="thought" href="entries/experience_entry.html">experience</a>, and just 
              what sort of <a class="thought" href="entries/experience_entry.html">experience</a> we should expect any given physical <a class="thought" href="entries/system_entry.html">system</a> 
              to yield. This is a tall <a class="thought" href="entries/order_entry.html">order</a>, but there is no <a class="thought" href="entries/reason_entry.html">reason</a> why we should 
              not get started. </p>
<p>In what follows, I present my own candidates for the psychophysical 
              principles that might go into a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. The first 
              two of these are <i>nonbasic principles</i> - <a class="thought" href="entries/system_entry.html">system</a>atic connections 
              between processing and <a class="thought" href="entries/experience_entry.html">experience</a> at a relatively high level. These 
              principles can play a significant role in developing and constraining 
              a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, but they are not cast at a sufficiently 
              fundamental level to qualify as truly <a class="thought" href="entries/basic_entry.html">basic</a> laws. The final principle 
              is my candidate for a <i><a class="thought" href="entries/basic_entry.html">basic</a> principle</i> that might form the 
              cornerstone of a fundamental theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. This final 
              principle is particularly speculative, but it is the kind of speculation 
              that is required if we are ever to have a satisfying theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. 
              I can present these principles only briefly here; I argue for them 
              at much greater length in Chalmers (1996).</p>
<p><br>
</p>
<p>1. <b>The principle of structural coherence</b>. This is a principle 
              of coherence between the <i><a class="thought" href="entries/structure_entry.html">structure</a> of <a class="thought" href="entries/consciousness_entry.html">consciousness</a></i> and the 
              <i><a class="thought" href="entries/structure_entry.html">structure</a> of awareness</i>. Recall that "awareness" 
              was used earlier to refer to the various functional phenomena that 
              are associated with <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. I am now using it to refer to 
              a somewhat more specific process in the cognitive underpinnings 
              of <a class="thought" href="entries/experience_entry.html">experience</a>. In particular, the <a class="thought" href="entries/content_entry.html">content</a>s of awareness are to be 
              understood as those <a class="thought" href="entries/information_entry.html">information</a> <a class="thought" href="entries/content_entry.html">content</a>s that are <a class="thought" href="entries/access_entry.html">access</a>ible to 
              central <a class="thought" href="entries/system_entry.html">system</a>s, and brought to bear in a widespread way in the 
              control of behavior. Briefly put, we can think of awareness as <i>direct 
              availability for global control</i>. To a first approximation, the 
              <a class="thought" href="entries/content_entry.html">content</a>s of awareness are the <a class="thought" href="entries/content_entry.html">content</a>s that are directly <a class="thought" href="entries/access_entry.html">access</a>ible 
              and potentially reportable, at least in a <a class="thought" href="entries/language_entry.html">language</a>-using <a class="thought" href="entries/system_entry.html">system</a>. 
            </p>
<p>Awareness is a purely functional notion, but it is nevertheless 
              intimately linked to conscious <a class="thought" href="entries/experience_entry.html">experience</a>. In familiar cases, wherever 
              we find <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, we find awareness. Wherever there is conscious 
              <a class="thought" href="entries/experience_entry.html">experience</a>, there is some corresponding <a class="thought" href="entries/information_entry.html">information</a> in the cognitive 
              <a class="thought" href="entries/system_entry.html">system</a> that is available in the control of behavior, and available 
              for verbal report. Conversely, it seems that whenever <a class="thought" href="entries/information_entry.html">information</a> 
              is available for report and for global control, there is a corresponding 
              conscious <a class="thought" href="entries/experience_entry.html">experience</a>. Thus, there is a direct correspondence between 
              <a class="thought" href="entries/consciousness_entry.html">consciousness</a> and awareness. </p>
<p>The correspondence can be taken further. It is a central fact about 
              <a class="thought" href="entries/experience_entry.html">experience</a> that it has a complex <a class="thought" href="entries/structure_entry.html">structure</a>. The visual field has 
              a complex <a class="thought" href="entries/geometry_entry.html">geometry</a>, for <a class="thought" href="entries/instance_entry.html">instance</a>. There are also relations of similarity 
              and difference between <a class="thought" href="entries/experience_entry.html">experience</a>s, and relations in such things 
              as relative intensity. Every subject's <a class="thought" href="entries/experience_entry.html">experience</a> can be at least 
              partly characterized and decomposed in terms of these structural 
              properties: similarity and difference relations, perceived location, 
              relative intensity, geometric <a class="thought" href="entries/structure_entry.html">structure</a>, and so on. It is also a 
              central fact that to each of these structural features, there is 
              a corresponding feature in the <a class="thought" href="entries/information_entry.html">information</a>-processing <a class="thought" href="entries/structure_entry.html">structure</a> 
              of awareness. </p>
<p>Take color sensations as an example. For every distinction between 
              color <a class="thought" href="entries/experience_entry.html">experience</a>s, there is a corresponding distinction in processing. 
              The different phenomenal colors that we <a class="thought" href="entries/experience_entry.html">experience</a> form a complex 
              three-dimensional <a class="thought" href="entries/space_entry.html">space</a>, varying in hue, saturation, and intensity. 
              The properties of this <a class="thought" href="entries/space_entry.html">space</a> can be recovered from <a class="thought" href="entries/information_entry.html">information</a>-processing 
              considerations: examination of the visual <a class="thought" href="entries/system_entry.html">system</a>s shows that waveforms 
              of <a class="thought" href="entries/light_entry.html">light</a> are discriminated and analyzed along three different axes, 
              and it is this three-dimensional <a class="thought" href="entries/information_entry.html">information</a> that is relevant to 
              later processing. The three-dimensional <a class="thought" href="entries/structure_entry.html">structure</a> of phenomenal 
              color <a class="thought" href="entries/space_entry.html">space</a> therefore corresponds directly to the three dimensional 
              <a class="thought" href="entries/structure_entry.html">structure</a> of visual awareness. This is precisely what we would expect. 
              After all, every color distinction corresponds to some reportable 
              <a class="thought" href="entries/information_entry.html">information</a>, and therefore to a distinction that is represented 
              in the <a class="thought" href="entries/structure_entry.html">structure</a> of processing. </p>
<p>In a more straightforward way, the geometric <a class="thought" href="entries/structure_entry.html">structure</a> of the visual 
              field is directly reflected in a <a class="thought" href="entries/structure_entry.html">structure</a> that can be recovered 
              from visual processing. Every geometric relation corresponds to 
              something that can be reported and is therefore cognitively represented. 
              If we were given only the story about <a class="thought" href="entries/information_entry.html">information</a>-processing in 
              an <a class="thought" href="entries/agent_entry.html">agent</a>'s visual and cognitive <a class="thought" href="entries/system_entry.html">system</a>, we could not <i>directly</i> 
              observe that <a class="thought" href="entries/agent_entry.html">agent</a>'s visual <a class="thought" href="entries/experience_entry.html">experience</a>s, but we could nevertheless 
              infer those <a class="thought" href="entries/experience_entry.html">experience</a>s' structural properties. </p>
<p>In general, any <a class="thought" href="entries/information_entry.html">information</a> that is consciously <a class="thought" href="entries/experience_entry.html">experience</a>d will 
              also be cognitively represented. The fine-grained <a class="thought" href="entries/structure_entry.html">structure</a> of the 
              visual field will correspond to some fine-grained <a class="thought" href="entries/structure_entry.html">structure</a> in visual 
              processing. The same goes for <a class="thought" href="entries/experience_entry.html">experience</a>s in other modalities, and 
              even for nonsensory <a class="thought" href="entries/experience_entry.html">experience</a>s. Internal mental images have geometric 
              properties that are represented in processing. Even <a class="thought" href="entries/emotion_entry.html">emotion</a>s have 
              structural properties, such as relative intensity, that correspond 
              directly to a structural property of processing; where there is 
              greater intensity, we find a greater effect on later processes. 
              In general, precisely because the structural properties of <a class="thought" href="entries/experience_entry.html">experience</a> 
              are <a class="thought" href="entries/access_entry.html">access</a>ible and reportable, those properties will be directly 
              represented in the <a class="thought" href="entries/structure_entry.html">structure</a> of awareness. </p>
<p>It is this isomorphism between the <a class="thought" href="entries/structure_entry.html">structure</a>s of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> 
              and awareness that constitutes the principle of structural coherence. 
              This principle reflects the central fact that even though cognitive 
              processes do not <a class="thought" href="entries/concept_entry.html">concept</a>ually entail facts about conscious <a class="thought" href="entries/experience_entry.html">experience</a>, 
              <a class="thought" href="entries/consciousness_entry.html">consciousness</a> and cognition do not float free of one another but 
              cohere in an intimate way. </p>
<p>This principle has its limits. It allows us to recover structural 
              properties of <a class="thought" href="entries/experience_entry.html">experience</a> from <a class="thought" href="entries/information_entry.html">information</a>-processing properties, 
              but not all properties of <a class="thought" href="entries/experience_entry.html">experience</a> are structural properties. 
              There are properties of <a class="thought" href="entries/experience_entry.html">experience</a>, such as the intrinsic <a class="thought" href="entries/nature_entry.html">nature</a> 
              of a sensation of red, that cannot be fully captured in a structural 
              description. The very intelligibility of inverted spectrum scenarios, 
              where <a class="thought" href="entries/experience_entry.html">experience</a>s of red and green are inverted but all structural 
              properties remain the same, show that structural properties constrain 
              <a class="thought" href="entries/experience_entry.html">experience</a> without exhausting it. Nevertheless, the very fact that 
              we feel compelled to leave structural properties unaltered when 
              we imagine <a class="thought" href="entries/experience_entry.html">experience</a>s inverted between functionally identical <a class="thought" href="entries/system_entry.html">system</a>s 
              shows how central the principle of structural coherence is to our 
              <a class="thought" href="entries/concept_entry.html">concept</a>ion of our mental lives. It is not a <i>logically</i> necessary 
              principle, as after all we can imagine all the <a class="thought" href="entries/information_entry.html">information</a> processing 
              occurring without any <a class="thought" href="entries/experience_entry.html">experience</a> at all, but it is nevertheless 
              a strong and familiar <a class="thought" href="entries/constraint_entry.html">constraint</a> on the psychophysical connection. 
            </p>
<p>The principle of structural coherence allows for a very useful 
              kind of indirect explanation of <a class="thought" href="entries/experience_entry.html">experience</a> in terms of physical 
              processes. For example, we can use facts about neural processing 
              of visual <a class="thought" href="entries/information_entry.html">information</a> to indirectly explain the <a class="thought" href="entries/structure_entry.html">structure</a> of color 
              <a class="thought" href="entries/space_entry.html">space</a>. The facts about neural processing can entail and explain 
              the <a class="thought" href="entries/structure_entry.html">structure</a> of awareness; if we take the coherence principle for 
              granted, the <a class="thought" href="entries/structure_entry.html">structure</a> of <a class="thought" href="entries/experience_entry.html">experience</a> will also be explained. Empirical 
              investigation might even lead us to better understand the <a class="thought" href="entries/structure_entry.html">structure</a> 
              of awareness within a bat, shedding indirect <a class="thought" href="entries/light_entry.html">light</a> on Nagel's vexing 
              question of what it is like to be a bat. This principle provides 
              a natural interpretation of much existing work on the explanation 
              of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> (e.g. Clark 1992 and Hardin 1992 on colors, and 
              Akins 1993 on bats), although it is often appealed to inexplicitly. 
              It is so familiar that it is taken for granted by almost everybody, 
              and is a central plank in the cognitive explanation of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. 
            </p>
<p>The coherence between <a class="thought" href="entries/consciousness_entry.html">consciousness</a> and awareness also allows a 
              natural interpretation of work in <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a> directed at isolating 
              the <i><a class="thought" href="entries/substrate_entry.html">substrate</a></i> (or the <i>neural correlate</i>) of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. 
              Various specific hypotheses have been put forward. For example, 
              Crick and Koch (1990) suggest that 40-Hz oscillations may be the 
              neural correlate of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, whereas Libet (1993) suggests 
              that temporally-extended neural activity is central. If we accept 
              the principle of coherence, the most <i>direct</i> physical correlate 
              of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> is awareness: the process whereby <a class="thought" href="entries/information_entry.html">information</a> is 
              made directly available for global control. The different specific 
              hypotheses can be interpreted as empirical suggestions about how 
              awareness might be achieved. For example, Crick and Koch suggest 
              that 40-Hz oscillations are the <a class="thought" href="entries/gateway_entry.html">gateway</a> by which <a class="thought" href="entries/information_entry.html">information</a> is 
              integrated into working <a class="thought" href="entries/memory_entry.html">memory</a> and thereby made available to later 
              processes. Similarly, it is natural to suppose that Libet's temporally 
              extended activity is relevant precisely because only that sort of 
              activity achieves global availability. The same applies to other 
              suggested correlates such as the "global workspace" of 
              Baars (1988), the "high-quality representations" of Farah 
              (1994), and the "selector inputs to <a class="thought" href="entries/action_entry.html">action</a> <a class="thought" href="entries/system_entry.html">system</a>s" of 
              Shallice (1972). All these can be seen as hypotheses about the <i>mechanisms 
              of awareness</i>: the mechanisms that perform the function of making 
              <a class="thought" href="entries/information_entry.html">information</a> directly available for global control. </p>
<p>Given the coherence between <a class="thought" href="entries/consciousness_entry.html">consciousness</a> and awareness, it follows 
              that a mechanism of awareness will itself be a correlate of conscious 
              <a class="thought" href="entries/experience_entry.html">experience</a>. The question of just <i>which</i> mechanisms in the 
              <a class="thought" href="entries/brain_entry.html">brain</a> govern global availability is an empirical one; perhaps there 
              are many such mechanisms. But if we accept the coherence principle, 
              we have <a class="thought" href="entries/reason_entry.html">reason</a> to believe that the processes that <i>explain</i> 
              awareness will at the same <a class="thought" href="entries/time_entry.html">time</a> be part of the <i>basis</i> of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>.</p>
<p><br>
</p>
<p>2. <b>The principle of organizational invariance</b>. This principle 
              states that any two <a class="thought" href="entries/system_entry.html">system</a>s with the same fine-grained <i>functional 
              organization</i> will have qualitatively identical <a class="thought" href="entries/experience_entry.html">experience</a>s. 
              If the causal <a class="thought" href="entries/pattern_entry.html">pattern</a>s of neural organization were duplicated in 
              <a class="thought" href="entries/silicon_entry.html">silicon</a>, for example, with a <a class="thought" href="entries/silicon_entry.html">silicon</a> <a class="thought" href="entries/chip_entry.html">chip</a> for every <a class="thought" href="entries/neuron_entry.html">neuron</a> and the 
              same <a class="thought" href="entries/pattern_entry.html">pattern</a>s of interaction, then the same <a class="thought" href="entries/experience_entry.html">experience</a>s would arise. 
              According to this principle, what <a class="thought" href="entries/matter_entry.html">matter</a>s for the emergence of <a class="thought" href="entries/experience_entry.html">experience</a> 
              is not the specific physical makeup of a <a class="thought" href="entries/system_entry.html">system</a>, but the abstract 
              <a class="thought" href="entries/pattern_entry.html">pattern</a> of causal interaction between its <a class="thought" href="entries/component_entry.html">component</a>s. This principle 
              is controversial, of course. Some (e.g. Searle 1980) have <a class="thought" href="entries/thought_entry.html">thought</a> 
              that <a class="thought" href="entries/consciousness_entry.html">consciousness</a> is tied to a specific <a class="thought" href="entries/biology_entry.html">biology</a>, so that a <a class="thought" href="entries/silicon_entry.html">silicon</a> 
              isomorph of a <a class="thought" href="entries/human_entry.html">human</a> need not be conscious. I believe that the principle 
              can be given significant support by the analysis of <a class="thought" href="entries/thought_entry.html">thought</a>-<a class="thought" href="entries/experiment_entry.html">experiment</a>s, 
              however. </p>
<p>Very briefly: suppose (for the purposes of a <i>reductio ad absurdum</i>) 
              that the principle is false, and that there could be two functionally 
              isomorphic <a class="thought" href="entries/system_entry.html">system</a>s with different <a class="thought" href="entries/experience_entry.html">experience</a>s. Perhaps only one 
              of the <a class="thought" href="entries/system_entry.html">system</a>s is conscious, or perhaps both are conscious but they 
              have different <a class="thought" href="entries/experience_entry.html">experience</a>s. For the purposes of illustration, let 
              us say that one <a class="thought" href="entries/system_entry.html">system</a> is made of <a class="thought" href="entries/neuron_entry.html">neuron</a>s and the other of <a class="thought" href="entries/silicon_entry.html">silicon</a>, 
              and that one <a class="thought" href="entries/experience_entry.html">experience</a>s red where the other <a class="thought" href="entries/experience_entry.html">experience</a>s blue. The 
              two <a class="thought" href="entries/system_entry.html">system</a>s have the same organization, so we can imagine gradually 
              transforming one into the other, perhaps replacing <a class="thought" href="entries/neuron_entry.html">neuron</a>s one at 
              a <a class="thought" href="entries/time_entry.html">time</a> by <a class="thought" href="entries/silicon_entry.html">silicon</a> chips with the same local function. We thus gain 
              a spectrum of intermediate cases, each with the same organization, 
              but with slightly different physical makeup and slightly different 
              <a class="thought" href="entries/experience_entry.html">experience</a>s. Along this spectrum, there must be two <a class="thought" href="entries/system_entry.html">system</a>s <i>A</i> 
              and <i>B</i> between which we replace less than one tenth of the 
              <a class="thought" href="entries/system_entry.html">system</a>, but whose <a class="thought" href="entries/experience_entry.html">experience</a>s differ. These two <a class="thought" href="entries/system_entry.html">system</a>s are physically 
              identical, except that a small neural <a class="thought" href="entries/circuit_entry.html">circuit</a> in <i>A</i> has been 
              replaced by a <a class="thought" href="entries/silicon_entry.html">silicon</a> <a class="thought" href="entries/circuit_entry.html">circuit</a> in <i>B</i>. </p>
<p>The key step in the <a class="thought" href="entries/thought_entry.html">thought</a>-<a class="thought" href="entries/experiment_entry.html">experiment</a> is to take the relevant 
              neural <a class="thought" href="entries/circuit_entry.html">circuit</a> in <i>A</i>, and install alongside it a causally 
              isomorphic <a class="thought" href="entries/silicon_entry.html">silicon</a> <a class="thought" href="entries/circuit_entry.html">circuit</a>, with a <a class="thought" href="entries/switch_entry.html">switch</a> between the two. What 
              happens when we flip the <a class="thought" href="entries/switch_entry.html">switch</a>? By <a class="thought" href="entries/hypothesis_entry.html">hypothesis</a>, the <a class="thought" href="entries/system_entry.html">system</a>'s conscious 
              <a class="thought" href="entries/experience_entry.html">experience</a>s will change; from red to blue, say, for the purposes 
              of illustration. This follows from the fact that the <a class="thought" href="entries/system_entry.html">system</a> after 
              the change is essentially a version of <i>B</i>, whereas before 
              the change it is just <i>A</i>. </p>
<p>But given the assumptions, there is no way for the <a class="thought" href="entries/system_entry.html">system</a> to <i>notice</i> 
              the changes! Its causal organization stays constant, so that all 
              of its functional states and behavioral dispositions stay fixed. 
              As far as the <a class="thought" href="entries/system_entry.html">system</a> is concerned, nothing unusual has happened. 
              There is no room for the <a class="thought" href="entries/thought_entry.html">thought</a>, "Hmm! Something strange just 
              happened!." In general, the <a class="thought" href="entries/structure_entry.html">structure</a> of any such <a class="thought" href="entries/thought_entry.html">thought</a> must 
              be reflected in processing, but the <a class="thought" href="entries/structure_entry.html">structure</a> of processing remains 
              constant here. If there were to be such a <a class="thought" href="entries/thought_entry.html">thought</a> it must float 
              entirely free of the <a class="thought" href="entries/system_entry.html">system</a> and would be utterly impotent to affect 
              later processing. (If it affected later processing, the <a class="thought" href="entries/system_entry.html">system</a>s 
              would be functionally distinct, contrary to <a class="thought" href="entries/hypothesis_entry.html">hypothesis</a>). We might 
              even flip the <a class="thought" href="entries/switch_entry.html">switch</a> a <a class="thought" href="entries/number_entry.html">number</a> of times, so that <a class="thought" href="entries/experience_entry.html">experience</a>s of red 
              and blue dance back and forth before the <a class="thought" href="entries/system_entry.html">system</a>'s "inner eye." 
              According to <a class="thought" href="entries/hypothesis_entry.html">hypothesis</a>, the <a class="thought" href="entries/system_entry.html">system</a> can never notice these "dancing 
              qualia." </p>
<p>This I take to be a <i>reductio</i> of the original assumption. 
              It is a central fact about <a class="thought" href="entries/experience_entry.html">experience</a>, very familiar from our own 
              case, that whenever <a class="thought" href="entries/experience_entry.html">experience</a>s change significantly and we are 
              paying attention, we can notice the change; if this were not to 
              be the case, we would be led to the skeptical possibility that our 
              <a class="thought" href="entries/experience_entry.html">experience</a>s are dancing before our eyes all the <a class="thought" href="entries/time_entry.html">time</a>. This <a class="thought" href="entries/hypothesis_entry.html">hypothesis</a> 
              has the same status as the possibility that the world was created 
              five minutes ago: perhaps it is logically coherent, but it is not 
              plausible. Given the extremely plausible assumption that changes 
              in <a class="thought" href="entries/experience_entry.html">experience</a> correspond to changes in processing, we are led to 
              the conclusion that the original <a class="thought" href="entries/hypothesis_entry.html">hypothesis</a> is impossible, and that 
              any two functionally isomorphic <a class="thought" href="entries/system_entry.html">system</a>s must have the same sort 
              of <a class="thought" href="entries/experience_entry.html">experience</a>s. To put it in technical terms, the philosophical 
              hypotheses of "absent qualia" and "inverted qualia," 
              while logically possible, are empirically and nomologically impossible. 
            </p>
<p>(Some may worry that a <a class="thought" href="entries/silicon_entry.html">silicon</a> isomorph of a neural <a class="thought" href="entries/system_entry.html">system</a> might 
              be impossible for technical <a class="thought" href="entries/reason_entry.html">reason</a>s. That question is open. The 
              invariance principle says only that <i>if</i> an isomorph is possible, 
              then it will have the same sort of conscious <a class="thought" href="entries/experience_entry.html">experience</a>.) </p>
<p>There is more to be said here, but this gives the <a class="thought" href="entries/basic_entry.html">basic</a> flavor. 
              Once again, this <a class="thought" href="entries/thought_entry.html">thought</a> <a class="thought" href="entries/experiment_entry.html">experiment</a> draws on familiar facts about 
              the coherence between <a class="thought" href="entries/consciousness_entry.html">consciousness</a> and cognitive processing to 
              yield a strong conclusion about the relation between physical <a class="thought" href="entries/structure_entry.html">structure</a> 
              and <a class="thought" href="entries/experience_entry.html">experience</a>. If the argument goes through, we know that the only 
              physical properties directly relevant to the emergence of <a class="thought" href="entries/experience_entry.html">experience</a> 
              are <i>organizational</i> properties. This acts as a further strong 
              <a class="thought" href="entries/constraint_entry.html">constraint</a> on a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>.</p>
<p><br>
</p>
<p>3. <b>The double-aspect theory of <a class="thought" href="entries/information_entry.html">information</a></b>. The two preceding 
              principles have been <i>nonbasic</i> principles. They involve high-level 
              notions such as "awareness" and "organization," 
              and therefore lie at the wrong level to constitute the fundamental 
              laws in a theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. Nevertheless, they act as strong 
              <a class="thought" href="entries/constraint_entry.html">constraint</a>s. What is further needed are <i><a class="thought" href="entries/basic_entry.html">basic</a></i> principles 
              that fit these <a class="thought" href="entries/constraint_entry.html">constraint</a>s and that might ultimately explain them. 
            </p>
<p>The <a class="thought" href="entries/basic_entry.html">basic</a> principle that I suggest centrally involves the notion 
              of <i><a class="thought" href="entries/information_entry.html">information</a></i>. I understand <a class="thought" href="entries/information_entry.html">information</a> in more or less 
              the <a class="thought" href="entries/sense_entry.html">sense</a> of Shannon (1948). Where there is <a class="thought" href="entries/information_entry.html">information</a>, there are 
              <i><a class="thought" href="entries/information_entry.html">information</a> states</i> embedded in an <i><a class="thought" href="entries/information_entry.html">information</a> <a class="thought" href="entries/space_entry.html">space</a></i>. 
              An <a class="thought" href="entries/information_entry.html">information</a> <a class="thought" href="entries/space_entry.html">space</a> has a <a class="thought" href="entries/basic_entry.html">basic</a> <a class="thought" href="entries/structure_entry.html">structure</a> of <i>difference</i> 
              relations between its <a class="thought" href="entries/element_entry.html">element</a>s, characterizing the ways in which 
              different <a class="thought" href="entries/element_entry.html">element</a>s in a <a class="thought" href="entries/space_entry.html">space</a> are similar or different, possibly 
              in complex ways. An <a class="thought" href="entries/information_entry.html">information</a> <a class="thought" href="entries/space_entry.html">space</a> is an abstract <a class="thought" href="entries/object_entry.html">object</a>, but 
              following Shannon we can see <a class="thought" href="entries/information_entry.html">information</a> as <i>physically embodied</i> 
              when there is a <a class="thought" href="entries/space_entry.html">space</a> of distinct physical states, the differences 
              between which can be transmitted down some causal pathway. The states 
              that are transmitted can be seen as themselves constituting an <a class="thought" href="entries/information_entry.html">information</a>
<a class="thought" href="entries/space_entry.html">space</a>. To borrow a phrase from Bateson (1972), physical <a class="thought" href="entries/information_entry.html">information</a> 
              is a <i>difference that makes a difference</i>. </p>
<p>The double-aspect principle stems from the observation that there 
              is a direct isomorphism between certain physically embodied <a class="thought" href="entries/information_entry.html">information</a> 
              spaces and certain <i>phenomenal</i> (or experiential) <a class="thought" href="entries/information_entry.html">information</a> 
              spaces. From the same sort of observations that went into the principle 
              of structural coherence, we can note that the differences between 
              phenomenal states have a <a class="thought" href="entries/structure_entry.html">structure</a> that corresponds directly to 
              the differences embedded in physical processes; in particular, to 
              those differences that make a difference down certain causal pathways 
              implicated in global availability and control. That is, we can find 
              the <i>same</i> abstract <a class="thought" href="entries/information_entry.html">information</a> <a class="thought" href="entries/space_entry.html">space</a> embedded in physical 
              processing and in conscious <a class="thought" href="entries/experience_entry.html">experience</a>. </p>
<p>This leads to a natural <a class="thought" href="entries/hypothesis_entry.html">hypothesis</a>: that <a class="thought" href="entries/information_entry.html">information</a> (or at least 
              some <a class="thought" href="entries/information_entry.html">information</a>) has two <a class="thought" href="entries/basic_entry.html">basic</a> aspects, a physical aspect and a 
              phenomenal aspect. This has the status of a <a class="thought" href="entries/basic_entry.html">basic</a> principle that 
              might underlie and explain the emergence of <a class="thought" href="entries/experience_entry.html">experience</a> from the 
              physical. <a class="thought" href="entries/experience_entry.html">Experience</a> arises by virtue of its status as one aspect 
              of <a class="thought" href="entries/information_entry.html">information</a>, when the other aspect is found embodied in physical 
              processing. </p>
<p>This principle is lent support by a <a class="thought" href="entries/number_entry.html">number</a> of considerations, which 
              I can only outline briefly here. First, consideration of the sort 
              of physical changes that correspond to changes in conscious <a class="thought" href="entries/experience_entry.html">experience</a> 
              suggests that such changes are always relevant by virtue of their 
              role in constituting <i><a class="thought" href="entries/information_entry.html">information</a>al changes</i> - differences 
              within an abstract <a class="thought" href="entries/space_entry.html">space</a> of states that are divided up precisely 
              according to their causal differences along certain causal pathways. 
              Second, if the principle of organizational invariance is to hold, 
              then we need to find some fundamental <i>organizational</i> property 
              for <a class="thought" href="entries/experience_entry.html">experience</a> to be linked to, and <a class="thought" href="entries/information_entry.html">information</a> is an organizational 
              property <i>par excellence</i>. Third, this principle offers some 
              hope of explaining the principle of structural coherence in terms 
              of the <a class="thought" href="entries/structure_entry.html">structure</a> present within <a class="thought" href="entries/information_entry.html">information</a> spaces. Fourth, analysis 
              of the cognitive explanation of our <i>judgments</i> and <i>claims</i> 
              about conscious <a class="thought" href="entries/experience_entry.html">experience</a> - judgments that are functionally explainable 
              but nevertheless deeply tied to <a class="thought" href="entries/experience_entry.html">experience</a> itself - suggests that 
              explanation centrally involves the <a class="thought" href="entries/information_entry.html">information</a> states embedded in 
              cognitive processing. It follows that a theory based on <a class="thought" href="entries/information_entry.html">information</a> 
              allows a deep coherence between the explanation of <a class="thought" href="entries/experience_entry.html">experience</a> and 
              the explanation of our judgments and claims about it. </p>
<p>Wheeler (1990) has suggested that <a class="thought" href="entries/information_entry.html">information</a> is fundamental to 
              the <a class="thought" href="entries/physics_entry.html">physics</a> of the <a class="thought" href="entries/universe_entry.html">universe</a>. According to this "it from bit" 
              doctrine, the laws of <a class="thought" href="entries/physics_entry.html">physics</a> can be cast in terms of <a class="thought" href="entries/information_entry.html">information</a>, 
              postulating different states that give rise to different effects 
              without actually saying what those states <i>are</i>. It is only 
              their position in an <a class="thought" href="entries/information_entry.html">information</a> <a class="thought" href="entries/space_entry.html">space</a> that counts. If so, then 
              <a class="thought" href="entries/information_entry.html">information</a> is a natural candidate to also play a role in a fundamental 
              theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. We are led to a <a class="thought" href="entries/concept_entry.html">concept</a>ion of the world 
              on which <a class="thought" href="entries/information_entry.html">information</a> is truly fundamental, and on which it has two 
              <a class="thought" href="entries/basic_entry.html">basic</a> aspects, corresponding to the physical and the phenomenal 
              features of the world. </p>
<p>Of course, the double-aspect principle is extremely speculative 
              and is also underdetermined, leaving a <a class="thought" href="entries/number_entry.html">number</a> of key questions unanswered. 
              An obvious question is whether <i>all</i> <a class="thought" href="entries/information_entry.html">information</a> has a phenomenal 
              aspect. One possibility is that we need a further <a class="thought" href="entries/constraint_entry.html">constraint</a> on 
              the fundamental theory, indicating just what <i>sort</i> of <a class="thought" href="entries/information_entry.html">information</a> 
              has a phenomenal aspect. The other possibility is that there is 
              no such <a class="thought" href="entries/constraint_entry.html">constraint</a>. If not, then <a class="thought" href="entries/experience_entry.html">experience</a> is much more widespread 
              than we might have believed, as <a class="thought" href="entries/information_entry.html">information</a> is everywhere. This 
              is counterintuitive at first, but on reflection I think the position 
              gains a certain plausibility and elegance. Where there is simple 
              <a class="thought" href="entries/information_entry.html">information</a> processing, there is simple <a class="thought" href="entries/experience_entry.html">experience</a>, and where there 
              is complex <a class="thought" href="entries/information_entry.html">information</a> processing, there is complex <a class="thought" href="entries/experience_entry.html">experience</a>. 
              A <a class="thought" href="entries/mouse_entry.html">mouse</a> has a simpler <a class="thought" href="entries/information_entry.html">information</a>-processing <a class="thought" href="entries/structure_entry.html">structure</a> than a <a class="thought" href="entries/human_entry.html">human</a>, 
              and has correspondingly simpler <a class="thought" href="entries/experience_entry.html">experience</a>; perhaps a thermostat, 
              a maximally simple <a class="thought" href="entries/information_entry.html">information</a> processing <a class="thought" href="entries/structure_entry.html">structure</a>, might have 
              maximally simple <a class="thought" href="entries/experience_entry.html">experience</a>? Indeed, if <a class="thought" href="entries/experience_entry.html">experience</a> is truly a fundamental 
              property, it would be surprising for it to arise only every now 
              and then; most fundamental properties are more evenly spread. In 
              any case, this is very much an open question, but I believe that 
              the position is not as implausible as it is often <a class="thought" href="entries/thought_entry.html">thought</a> to be. 
            </p>
<p>Once a fundamental link between <a class="thought" href="entries/information_entry.html">information</a> and <a class="thought" href="entries/experience_entry.html">experience</a> is on 
              the table, the door is opened to some grander metaphysical speculation 
              concerning the <a class="thought" href="entries/nature_entry.html">nature</a> of the world. For example, it is often noted 
              that <a class="thought" href="entries/physics_entry.html">physics</a> characterizes its <a class="thought" href="entries/basic_entry.html">basic</a> entities only <i>extrinsically</i>, 
              in terms of their relations to other entities, which are themselves 
              characterized extrinsically, and so on. The intrinsic <a class="thought" href="entries/nature_entry.html">nature</a> of 
              physical entities is left aside. Some argue that no such intrinsic 
              properties exist, but then one is left with a world that is pure 
              causal flux (a pure flow of <a class="thought" href="entries/information_entry.html">information</a>) with no properties for 
              the causation to relate. If one allows that intrinsic properties 
              exist, a natural speculation given the above is that the intrinsic 
              properties of the physical - the properties that causation ultimately 
              relates - are themselves phenomenal properties. We might say that 
              phenomenal properties are the internal aspect of <a class="thought" href="entries/information_entry.html">information</a>. This 
              could answer a concern about the causal relevance of <a class="thought" href="entries/experience_entry.html">experience</a> 
              - a natural worry, given a picture on which the physical <a class="thought" href="entries/domain_entry.html">domain</a> 
              is causally closed, and on which <a class="thought" href="entries/experience_entry.html">experience</a> is supplementary to 
              the physical. The <a class="thought" href="entries/information_entry.html">information</a>al view allows us to understand how 
              <a class="thought" href="entries/experience_entry.html">experience</a> might have a subtle kind of causal relevance in virtue 
              of its status as the intrinsic <a class="thought" href="entries/nature_entry.html">nature</a> of the physical. This metaphysical 
              speculation is probably best ignored for the purposes of developing 
              a scientific theory, but in addressing some philosophical issues 
              it is quite suggestive. </p>
<h1>8 Conclusion</h1>
<p>The theory I have presented is speculative, but it is a candidate 
              theory. I suspect that the principles of structural coherence and 
              organizational invariance will be planks in any satisfactory theory 
              of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>; the status of the double-aspect theory of <a class="thought" href="entries/information_entry.html">information</a> 
              is less certain. Indeed, right now it is more of an idea than a 
              theory. To have any hope of eventual explanatory success, it will 
              have to be specified more fully and fleshed out into a more powerful 
              form. Still, reflection on just what is plausible and implausible 
              about it, on where it works and where it fails, can only lead to 
              a better theory. </p>
<p>Most existing theories of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> either deny the <a class="thought" href="entries/phenomenon_entry.html">phenomenon</a>, 
              explain something else, or elevate the problem to an eternal mystery. 
              I hope to have shown that it is possible to make <a class="thought" href="entries/progress_entry.html">progress</a> on the 
              problem even while taking it seriously. To make further <a class="thought" href="entries/progress_entry.html">progress</a>, 
              we will need further investigation, more refined theories, and more 
              careful analysis. The hard problem is a hard problem, but there 
              is no <a class="thought" href="entries/reason_entry.html">reason</a> to believe that it will remain permanently unsolved.[*] 
            </p>
<p>*[[<font size="-1">The arguments in this paper are presented in greater 
              depth in my book <i>The Conscious <a class="thought" href="entries/mind_entry.html">Mind</a></i> (Oxford University Press, 
              1996). Thanks to <a class="thought" href="entries/crick_entry.html">Francis Crick</a>, Peggy DesAutels, Matthew Elton, 
              Liane Gabora, Christof Koch, Paul Rhodes, Gregg Rosenberg, and Sharon 
              Wahl for their comments.</font>]] </p>
<h1>Further Reading</h1>
<p><font size="-1">The problems of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> have been widely discussed 
              in the recent philosophical literature. For some <a class="thought" href="entries/concept_entry.html">concept</a>ual clarification 
              of the various problems of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, see Block 1995, Nelkin 
              1993, and Tye 1995. Those who have stressed the difficulties of 
              explaining <a class="thought" href="entries/experience_entry.html">experience</a> in physical terms include Hodgson 1988, Jackson 
              1982, Levine 1983, Lockwood 1989, McGinn 1989, Nagel 1974, Seager 
              1991, Searle 1991, Strawson 1994, and Velmans 1991, among others. 
              Those who take a reductive approach include Churchland 1995, Clark 
              1992, Dennett 1991, Dretske 1995, Kirk 1994, Rosenthal 1996, and 
              Tye 1995. There have not been many attempts to build detailed nonreductive 
              theories in the literature, but see Hodgson 1988 and Lockwood 1989 
              for some <a class="thought" href="entries/thought_entry.html">thought</a>s in that direction. Two excellent collections of 
              recent articles on <a class="thought" href="entries/consciousness_entry.html">consciousness</a> are Block, Flanagan, and G&#252;zeldere 
              1996 and Metzinger 1995. </font></p>
<p><i>Published in the </i>Journal of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a> Studies<i> in 
              1995. Reprinted with permission.</i></p>
<h1>References</h1>
<p>Akins, K. 1993. What is it like to be boring and myopic? In (B. 
              Dahlbom, ed.) <i>Dennett and his Critics</i>. Oxford: Blackwell. 
            </p>
<p>Allport, A. 1988. What <a class="thought" href="entries/concept_entry.html">concept</a> of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>? In (A. Marcel 
              and E. Bisiach, eds.) <i><a class="thought" href="entries/consciousness_entry.html">Consciousness</a> in Contemporary <a class="thought" href="entries/science_entry.html">Science</a></i>. 
              Oxford: Oxford University Press. </p>
<p>Baars, B.J. 1988. <i>A Cognitive Theory of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i>. Cambridge: 
              Cambridge University Press. </p>
<p>Bateson, G. 1972. <i>Steps to an <a class="thought" href="entries/ecology_entry.html">Ecology</a> of <a class="thought" href="entries/mind_entry.html">Mind</a></i>. Chandler 
              Publishing. </p>
<p>Block, N. 1995. On a confusion about the function of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. 
              <i>Behavioral and <a class="thought" href="entries/brain_entry.html">Brain</a> <a class="thought" href="entries/science_entry.html">Science</a>s.</i> </p>
<p>Block, N, Flanagan, O. &amp; G&#252;zeldere, G, (eds.) 1996. <i>The 
              <a class="thought" href="entries/nature_entry.html">Nature</a> of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a>: Philosophical and Scientific Debates</i>. 
              Cambridge, MA: MIT Press. </p>
<p>Chalmers, D.J. 1996. <i>The Conscious <a class="thought" href="entries/mind_entry.html">Mind</a></i>. New York: Oxford 
              University Press. </p>
<p>Churchland, P.M. 1995. <i>The <a class="thought" href="entries/engine_entry.html">Engine</a> of <a class="thought" href="entries/reason_entry.html">Reason</a>, The Seat of the 
              Soul: A Philosophical Journey into the <a class="thought" href="entries/brain_entry.html">Brain</a></i>. Cambridge, MA: 
              MIT Press. </p>
<p>Clark, A. 1992. <i>Sensory Qualities</i>. Oxford: Oxford University 
              Press. </p>
<p>Crick, F. and Koch, <a class="thought" href="entries/c_entry.html">C</a>. 1990. Toward a neurobiological theory of 
              <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. <i>Seminars in the <a class="thought" href="entries/neuroscience_entry.html">Neuroscience</a>s</i> 2:263-275. </p>
<p>Crick, F. 1994. <i>The Astonishing <a class="thought" href="entries/hypothesis_entry.html">Hypothesis</a>: The Scientific <a class="thought" href="entries/search_entry.html">Search</a> 
              for the <a class="thought" href="entries/soul_entry.html">Soul</a></i>. New York: Scribners. </p>
<p>Dennett, D.<a class="thought" href="entries/c_entry.html">C</a>. 1991. <i><a class="thought" href="entries/consciousness_entry.html">Consciousness</a> Explained</i>. Boston: Little, 
              Brown. </p>
<p>Dretske, F.I. 1995. <i>Naturalizing the <a class="thought" href="entries/mind_entry.html">Mind</a></i>. Cambridge, MA: 
              MIT Press. </p>
<p>Edelman, G. 1989. <i>The Remembered Present: A <a class="thought" href="entries/biological_entry.html">Biological</a> Theory 
              of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i>. New York: <a class="thought" href="entries/basic_entry.html">Basic</a> Books. </p>
<p>Farah, M.J. 1994. Visual <a class="thought" href="entries/perception_entry.html">perception</a> and visual awareness after 
              <a class="thought" href="entries/brain_entry.html">brain</a> damage: A tutorial overview. In (<a class="thought" href="entries/c_entry.html">C</a>. Umilta and M. Moscovitch, 
              eds.) <i><a class="thought" href="entries/consciousness_entry.html">Consciousness</a> and Unconscious <a class="thought" href="entries/information_entry.html">Information</a> Processing: Attention 
              and Performance 15</i>. Cambridge, MA: MIT Press. </p>
<p>Flohr, H. 1992. Qualia and <a class="thought" href="entries/brain_entry.html">brain</a> processes. In (A. Beckermann, 
              H. Flohr, and J. Kim, eds.) <i>Emergence or <a class="thought" href="entries/reduction_entry.html">Reduction</a>?: Prospects 
              for Nonreductive Physicalism</i>. Berlin: De Gruyter. </p>
<p>Hameroff, S.R. 1994. <a class="thought" href="entries/quantum_coherence_entry.html">Quantum coherence</a> in microtubules: A neural 
              basis for emergent <a class="thought" href="entries/consciousness_entry.html">consciousness</a>? <i>Journal of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a> Studies</i> 
              1:91-118. </p>
<p>Hardin, <a class="thought" href="entries/c_entry.html">C</a>.L. 1992. <a class="thought" href="entries/physiology_entry.html">Physiology</a>, phenomenology, and Spinoza's true 
              colors. In (A. Beckermann, H. Flohr, and J. Kim, eds.) <i>Emergence 
              or <a class="thought" href="entries/reduction_entry.html">Reduction</a>?: Prospects for Nonreductive Physicalism</i>. Berlin: 
              De Gruyter. </p>
<p>Hill, <a class="thought" href="entries/c_entry.html">C</a>.S. 1991. <i>Sensations: A Defense of Type <a class="thought" href="entries/materialism_entry.html">Materialism</a></i>. 
              Cambridge: Cambridge University Press. </p>
<p>Hodgson, D. 1988. <i>The <a class="thought" href="entries/mind_entry.html">Mind</a> <a class="thought" href="entries/matter_entry.html">Matter</a>s: <a class="thought" href="entries/consciousness_entry.html">Consciousness</a> and Choice 
              in a Quantum World</i>. Oxford: Oxford University Press. </p>
<p>Humphrey, N. 1992. <i>A <a class="thought" href="entries/history_entry.html">History</a> of the <a class="thought" href="entries/mind_entry.html">Mind</a></i>. New York: Simon 
              and Schuster. </p>
<p>Jackendoff, R. 1987. <i><a class="thought" href="entries/consciousness_entry.html">Consciousness</a> and the <a class="thought" href="entries/computation_entry.html">Computation</a>al <a class="thought" href="entries/mind_entry.html">Mind</a></i>. 
              Cambridge, MA: MIT Press. </p>
<p>Jackson, F. 1982. Epiphenomenal qualia. <i>Philosophical Quarterly</i> 
              32: 127-36. </p>
<p>Jackson, F. 1994. Finding the <a class="thought" href="entries/mind_entry.html">mind</a> in the natural world. In (R. 
              Casati, B. Smith, and S. White, eds.) <i><a class="thought" href="entries/philosophy_entry.html">Philosophy</a> and the Cognitive 
              <a class="thought" href="entries/science_entry.html">Science</a>s</i>. Vienna: H\"older-Pichler-Tempsky. </p>
<p>Kirk, R. 1994. <i>Raw Feeling: A Philosophical Account of the Essence 
              of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i>. Oxford: Oxford University Press. </p>
<p>Kripke, S. 1980. <i>Naming and Necessity</i>. Cambridge, MA: Harvard 
              University Press. </p>
<p>Levine, J. 1983. <a class="thought" href="entries/materialism_entry.html">Materialism</a> and qualia: The explanatory gap. <i>Pacific 
              Philosophical Quarterly</i> 64:354-61. </p>
<p>Lewis, D. 1994. <a class="thought" href="entries/reduction_entry.html">Reduction</a> of <a class="thought" href="entries/mind_entry.html">mind</a>. In (S. Guttenplan, ed.) <i>A 
              Companion to the <a class="thought" href="entries/philosophy_entry.html">Philosophy</a> of <a class="thought" href="entries/mind_entry.html">Mind</a></i>. Oxford: Blackwell. </p>
<p>Libet, B. 1993. The neural <a class="thought" href="entries/time_entry.html">time</a> factor in conscious and unconscious 
              events. In (G.R. Block and J. Marsh, eds.) <i><a class="thought" href="entries/experiment_entry.html">Experiment</a>al and Theoretical 
              Studies of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i> (Ciba Foundation Symposium 174). Chichester: 
              John Wiley and Sons. </p>
<p>Loar, B. 1990. Phenomenal states. <i>Philosophical Perspectives</i> 
              4:81-108. </p>
<p>Lockwood, M. 1989. <i><a class="thought" href="entries/mind_entry.html">Mind</a>, <a class="thought" href="entries/brain_entry.html">Brain</a>, and the Quantum</i>. Oxford: 
              Blackwell. </p>
<p>McGinn, <a class="thought" href="entries/c_entry.html">C</a>. 1989. Can we solve the <a class="thought" href="entries/mind_body_entry.html">mind-body problem</a>? <i><a class="thought" href="entries/mind_entry.html">Mind</a></i> 
              98:349-66. </p>
<p>Metzinger, T. 1995. <i>Conscious <a class="thought" href="entries/experience_entry.html">Experience</a></i>. Paderborn: Sch\"oningh. 
            </p>
<p>Nagel, T. 1974. What is it like to be a bat? <i>Philosophical Review</i> 
              4:435-50. </p>
<p>Nelkin, N. 1993. What is <a class="thought" href="entries/consciousness_entry.html">consciousness</a>? <i><a class="thought" href="entries/philosophy_entry.html">Philosophy</a> of <a class="thought" href="entries/science_entry.html">Science</a></i> 
              60:419-34. </p>
<p>Newell, A. 1990. <i>Unified Theories of Cognition</i>. Cambridge, 
              MA: Harvard University Press. </p>
<p>Penrose, R. 1989. <i>The Emperor's New <a class="thought" href="entries/mind_entry.html">Mind</a></i>. Oxford: Oxford 
              University Press. </p>
<p>Penrose, R. 1994. <i>Shadows of the <a class="thought" href="entries/mind_entry.html">Mind</a></i>. Oxford: Oxford University 
              Press. </p>
<p>Rosenthal, D.M. 1996. A theory of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. In (N. Block, 
              O. Flanagan, and G. G&#252;zeldere, eds.) <i>The <a class="thought" href="entries/nature_entry.html">Nature</a> of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i>. 
              Cambridge, MA: MIT Press. </p>
<p>Seager, W.E. 1991. <i><a class="thought" href="entries/metaphysics_entry.html">Metaphysics</a> of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i>. London: 
              Routledge. </p>
<p>Searle, J.R. 1980. Minds, brains and <a class="thought" href="entries/program_entry.html">program</a>s. <i>Behavioral and 
              <a class="thought" href="entries/brain_entry.html">Brain</a> <a class="thought" href="entries/science_entry.html">Science</a>s</i> 3:417-57. </p>
<p>Searle, J.R. 1992. <i>The Rediscovery of the <a class="thought" href="entries/mind_entry.html">Mind</a></i>. Cambridge, 
              MA: MIT Press. </p>
<p>Shallice, T. 1972. Dual functions of <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. <i>Psychological 
              Review</i> 79:383-93. </p>
<p>Shannon, <a class="thought" href="entries/c_entry.html">C</a>.E. 1948. A mathematical theory of <a class="thought" href="entries/communication_entry.html">communication</a>. <i>Bell 
              <a class="thought" href="entries/system_entry.html">System</a>s Technical Journal</i> 27: 379-423. </p>
<p>Strawson, G. 1994. <i>Mental <a class="thought" href="entries/reality_entry.html">Reality</a></i>. Cambridge, MA: MIT Press. 
            </p>
<p>Tye, M. 1995. <i>Ten Problems of <a class="thought" href="entries/consciousness_entry.html">Consciousness</a></i>. Cambridge, 
              MA: MIT Press. </p>
<p>Velmans, M. 1991. Is <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/information_entry.html">information</a>-processing conscious? <i>Behavioral 
              and <a class="thought" href="entries/brain_entry.html">Brain</a> <a class="thought" href="entries/science_entry.html">Science</a>s</i> 14:651-69. </p>
<p>Wheeler, J.A. 1990. <a class="thought" href="entries/information_entry.html">Information</a>, <a class="thought" href="entries/physics_entry.html">physics</a>, quantum: The <a class="thought" href="entries/search_entry.html">search</a> for 
              links. In (W. Zurek, ed.) <i><a class="thought" href="entries/complexity_entry.html">Complexity</a>, <a class="thought" href="entries/entropy_entry.html">Entropy</a>, and the <a class="thought" href="entries/physics_entry.html">Physics</a> 
              of <a class="thought" href="entries/information_entry.html">Information</a></i>. Redwood City, CA: Addison-Wesley. </p>
<p>Wilkes, K.V. 1988. - , Yishi, Duh, Um and <a class="thought" href="entries/consciousness_entry.html">consciousness</a>. In (A. 
              Marcel and E. Bisiach, eds.) <i><a class="thought" href="entries/consciousness_entry.html">Consciousness</a> in Contemporary <a class="thought" href="entries/science_entry.html">Science</a></i>. 
              Oxford: Oxford University Press. </p>
</td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p>{Sidebar}</p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9076" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id9077"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Head Spinning<br><span class="mindxheader"><i>posted on 08/19/2002 10:59 AM by derecho@prodigy.net</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9077" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9077" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I do not like the analogy between Maxwell adding to the fundemental forces of nature, and consciousness being added to the fundemental forces of nature (adding to the ontology). Maxwell's theories succeeded because we could MEASURE the forces involved. His was a purely mathematical derivation that was proven in the lab. If consciousness is some sort of force, it should be able to explained mathematically and should be able to be measured. This has not been done, and no serious porposals have been made to do it. There isn't even a staring point ot this endeavor.
<br>
<br>
Throw away the first 90% of the article and you finally get down to the nitty gritty of consciousness - information space and patterns of information. To me this is all that matters. By speculating on replacing neurons with silicon, and the consciousness of simpler animals and devices, the author neccessarily accepts that it is not a "special" force of nature but a pattern of information that can be reproduced by mathematical representation and understood by reference to basic physical laws. 
<br>
<br>
Here is my theory of consciousness: I have a certain network of neurons that sit back and observe everything else that is going on in the brain and body. Not only does this supra-network of neurons recieve information by eletronic signals from nearby neurons, but also through electromanetic fields generated by other activity in the brain, and through chemical signals delivered by blood from other areas of the body. The combination of all these signals is congealed into "experience".
<br>
<br>
I feel that further study of the brain will reveal where this (or these) region(s) of the brain is(are). I know this may sound a lot like the Id, Ego and Super-Ego theory of the brain, but it makes a lot more sense to me than proposing some "new force" of nature.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9078"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Head Spinning<br><span class="mindxheader"><i>posted on 08/19/2002 11:00 AM by derecho@charter.net</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9078" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9078" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I do not like the analogy between Maxwell adding to the fundemental forces of nature, and consciousness being added to the fundemental forces of nature (adding to the ontology). Maxwell's theories succeeded because we could MEASURE the forces involved. His was a purely mathematical derivation that was proven in the lab. If consciousness is some sort of force, it should be able to explained mathematically and should be able to be measured. This has not been done, and no serious porposals have been made to do it. There isn't even a staring point ot this endeavor.
<br>
<br>
Throw away the first 90% of the article and you finally get down to the nitty gritty of consciousness - information space and patterns of information. To me this is all that matters. By speculating on replacing neurons with silicon, and the consciousness of simpler animals and devices, the author neccessarily accepts that it is not a "special" force of nature but a pattern of information that can be reproduced by mathematical representation and understood by reference to basic physical laws. 
<br>
<br>
Here is my theory of consciousness: I have a certain network of neurons that sit back and observe everything else that is going on in the brain and body. Not only does this supra-network of neurons recieve information by eletronic signals from nearby neurons, but also through electromanetic fields generated by other activity in the brain, and through chemical signals delivered by blood from other areas of the body. The combination of all these signals is congealed into "experience".
<br>
<br>
I feel that further study of the brain will reveal where this (or these) region(s) of the brain is(are). I know this may sound a lot like the Id, Ego and Super-Ego theory of the brain, but it makes a lot more sense to me than proposing some "new force" of nature.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9079"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Head Spinning<br><span class="mindxheader"><i>posted on 08/19/2002 11:01 AM by derecho@charter.net</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9079" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9079" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Sorry about the duplication. The first message has the wrong email address.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9113"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/20/2002 4:23 PM by shai_op@netvision.net.il</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9113" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9113" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I believe the answer for the hard problem is not so hard, and is found in the following:
<br>
<br>
1. Image and Objects
<br>
<br>
By 'image' I call the overall content which is under our attention, at a given moment. This definition includes all data we sense, all thoughts we process, as well as all related data stored in our memory and being accessed at that specific moment. (The image therefore is not related to pictorial data only, but to various types of data, such as voice, smell, as well as ideas, feelings, thoughts.)
<br>
<br>
An image is composed of objects. An object can represent any portion of an image, and may be composed of other objects. For example, the table in front of us is an object, but each one of its legs can be another object. The picture hanging on the wall is an object, but each one of its details can an object as well. The question of the resolution depends on our attention. If our attention is given to each one of chair legs, then each one becomes an object in our mind. If we look at the picture but not for any specific detail, only the picture as a whole is an object for us. 
<br>
<br>
Objects are stored in our memory, and are the elementary particles composing the memory, its building blocks. 
<br>
<br>
<br>
<br>
2. Links
<br>
<br>
An 'object link' is a pointer from one object to another. An object is poiting another object if there is a certain relation between them. To this relation I call 'similarity'. If object A is similar to object B, a link is created by the brain. The similarity occurs if some of the components composing object A exist in B, or partially exists. 
<br>
<br>
The brain tries to match every new object with the inventory of old objects stored in memory. Take for example the case where we perceive a face of a movie actor which seems familiar. After a few moments of fail attempts to recognize the face, the match is taking place (if we are lucky) with a great relief. The constant matching operation is therefore an essence of the brain (along with other essential functions). Think of a music which sounds familiar to you, but you can not recognize it . It is ineviatle for the brain not to try and look for a match with the inventory of music stored in your memory.
<br>
<br>
When a match takes place, both objects, the old and the new, are being updated with that link. If a new song reminds us an old music, both the song and the old music objects are updated, as a part of the activation process of the old music object. The links therefore is not an independent entity in the space of memory, but embedded within the objects.
<br>
<br>
The matching operation is not a trivial one. Take the example of solving a mathenatical problem. The process of thinking invloves various objects, but finding the appropriate links is the creative part.
<br>
<br>
Links has a 'degree of strenght' attribute, where high level of strength represent a closer relationship. The objects stored in memory are sorted according to several keys, enabling fast search and retrieval. The familiar face invokes a search with movies as a primary key, and faces with a secondary key, for example (or vice versa?)
<br>
<br>
<br>
<br>
<br>
<br>
3. Active Objects
<br>
<br>
By 'active objects' I refer to objects brought into our attention at a given moment, i.e belong to the current image. The image therefore is composed of active objects only. Active object can be a completely new object, brought to our attention as a result of an interaction with the external world via our senses, with our internal world via our feelings, thoughts, etc., or an old object activated from our memory storage. An old object can be activated therefore as a result of a match with a new object, or as a result of a link from another (already activated) old object. A third option would be an activation based on the degree of strength. Sometime an item pops into our attention from our memory without any reasonable association, or we start thinking of an item without any specific reason known to us. In that case, the object is activated because of its relative strength, i.e it is the object with the highest degree of strength for that moment.
<br>
<br>
The strength of objects gets updated continuously. Each link which is resolved and activates an existing object brings to an update of the object strength. The strength is also a function of the number of links associated with an object, the time passed since the object has been created, and then activated. If we appreciated someone, then what he said about us might be very meaningful and stored with a high degree of strength in our memory. If, after some time, we realise that the amount of appreciation was too high, the strength of that object would significantly decrease. 
<br>
<br>
When an object becomes active, not all of its links are resolved. The links to the strongest objects are being resolved first. The links contain the information of the degree of strength of the objects they are pointing to, so a link does not have to be resolved first, and an object need not be activated first, in order to find out what is its strength. At every moment, the strongest link among all links of all active objects is being resolved. The next activated object (whether a new object or an existing one) will add its inventory of links to the current pool, from which the next strongest link will be resolved. I call this description the 'link resolution algorithm'.
<br>
<br>
The capacity of the active image is limitted. As long as objects are being activated and added to the image, other objects are dropped from the image. The object with the lowest degree of strength are dropped, and stored in memory.
<br>
<br>
A key point in the algorithm described below, is that there is no 'selector' that selects the active objects, and determines which links to resolve. There is no need for a manager, for an entity which exists on top of the objects, running the activation process. This is a major fact for the understanding of our consciousness. 
<br>
<br>
<br>
<br>
<br>
<br>
4. Consciousness and Self Consciousness
<br>
<br>
An object that is presented in several images is our body. Our senses perceive our body as a part of the external world, creating a 'body' object. Since it appears again and again, the object becomes stronger, and pointed by a growing number of links. In fact, the body object is activated most of the time, taking a share in most of the temporary images. It becomes a 'framework' for all other objects, a kind of background. Our internal feelings that originate in our body, which also repeat themselves several times, are being added to the body object, enriching its content. The body object (I'll call it the self object) becomes the object with the highest level of strength, and with the largest amount of content, much higher and larger than all other objects.
<br>
<br>
<br>
<br>
Whenever the self object is part of the current image, along with another activated object X, we say that we are aware of X, or conscious of X.  Consciousness is therefore a state of objects, the relation between the self object and other objects. Consciousness is not an observer, which exists on top of the objects. There is no such observer, because all entities are established as objects, and are all on the same level. The term image is misleading, there is no observer for the current image, for our current awareness. The self is not located above the objects, but aside of them. When we say 'I am conscious of X', that means the self object is conscios of X, that the self object has a relation to X object. The 'I' is the self object, there is no 'I' beyond that.
<br>
<br>
There are relations between many pairs of activated objects. But only the self object has the level of strength and amount of content that captures our attention.
<br>
<br>
The self object (as any other object) can initiate other operations, and activate other objects. In case the self is activating itself, as a subject of interest, we call this a self consciousness. Consciousness in general is a reflection, a relation from the self object to another object. In case of being conscious of X,  the link is from the self object to X object. In case of self-consciousness, the link is from the self object to itself.  END
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9118"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/20/2002 9:00 PM by azb@llnl.gov</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9118" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9118" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Shai_Op,
<br>
<br>
Perhaps we need to distinguish a "formal framework for consciousness" from the subjective sensation of consciousness.  I am not sure which terms should apply to each, and whether the difference is one of degree or something more substantially "different".
<br>
<br>
Your image-object-linking framework is a fine formalism for approaching the organization of "AI-mind".  The description you give could be (and I imagine, has been) codified in object-oriiented languages.  In this respect, the "self-object" is the one holding and manipulating the current temporal "image", associates objects to one another, either from external stimuli or from memory, strengthens or weakens associations accordingly.
<br>
<br>
And if presented with "input" whose processing requires or "leads to" reference to the "self-object", a "self-referential link" is forged or strengthened withing the current image.
<br>
<br>
Ok.  But all of this can be accomplished with a relatively small C++ or Java implementation, and when it runs, and happens to be "entertaining" the self-reference link, do you suppose that this ... "system" is experiencing "conscious awareness" as you or I might experience?
<br>
<br>
We have a nice clean formal description, and we can implement this in a model.  So the system is "formally conscious" (by DEFINITION) when it is entertaining the self-reference link.
<br>
<br>
Is this the same as the "feeling of consciousness" (i.e., sentient consciousness)? 
<br>
<br>
I think that this is the issue at hand.
<br>
<br>
Cheers! ____tony b____
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9119"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/20/2002 9:15 PM by azb@llnl.gov</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9119" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9119" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>The Image-Object-Linking model "accounts" for consciousness (as a formalism) is much the way that the quark-model (MODEL) "accounts" for protons and neutrons and mesons, etc.
<br>
<br>
Even if accurate, I can make cardborad cut-outs of red, blue and green quarks of various flavors (up, down, strange) and arrange those "cardboard quarks" to correctly represent (cardboard) protons and neutrons.
<br>
<br>
But how "good" are my cardboard representations?  Is it enough to manifest "just anything" that conforms to the model?
<br>
<br>
For cardboard quark-protons, I think not.  For mere formal algorithmic modeling of consciousness or sentience, I think perhaps not again.
<br>
<br>
For a synthesis of algorithm and "materia" manifest as system, ... maybe.
<br>
<br>
Cheers! ____tony b____</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9156"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/22/2002 3:59 AM by shai_op@netvision.net.il</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9156" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9156" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Tony,
<br>
What is needed for the system to be conscious, in addition to the C++ implementation, is the content itself. The huge amount of objects, the relations and the references, and the repetition of some of the objects, so the self object is being created, as I explained. This is the more difficult part..</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9161"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/22/2002 6:43 AM by wclary5424@aol.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9161" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9161" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Shai..
<br>
<br>
    Your idea is actually quite similar to an explanation for the mind worked out by one of the pre-Socratic Greek philosophers 2500 years ago. (although he didn't put it in terms of object-oriented programming, obviously.)  I can't remember which one it was...Zeno maybe (?)
<br>
    Anyway, I don't think it answers all the questions about consciousness.  For instance, is it possible for us to be aware of something without being conscious of it?  This is not just semantics--I've seen research which indicates our body responds to possible danger before we consciously realize what's happening.  We have all had the sensation of going on autopilot while doing some routine task...or while driving on the highway.  The French existentialist philosopher Sartre gave an example of a man counting the contents of a pack of cigarettes...the task is so boring that the man does it without any thought..until a friend comes up and asks him what he is doing....at that moment, the task comes back into his conscious mind, although, at some level, he was aware of it all the time.
<br>
     There seems to be several different subroutines operating in the brain at a time.  As you indicate, the self-conscious observer is not somehow above and over the rest of the mind, but it is much harder to model than a simple hierarchy of objects.
<br>
    Although I think that the metaphysical superstructure of Buddhism is quite possibly bogus, one can come to a better understanding of just how complex the conscious mind is by engaging in zazen or another meditative practice regularly.  I have yet to see an AI proposal which is subtle enough to deal with all of this--although I would not say that such a program is impossible...just a little farther away than many of us would like.
<br>
<br>
BC
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9173"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="80"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="599"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/22/2002 10:50 AM by grantc4@hotmail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9173" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9173" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>&gt;is it possible for us to be aware of something without being conscious of it?
<br>
<br>
SEEING WHAT YOU DON'T SEE? 
<br>
<br>
Following certain kinds of brain lesions, patients report an inability to see objects, but if pressed to guess at their location they display a capacity to point at them with reasonable accuracy. The phenomenon, called "blindsight", is one of the more dramatic of a number of lines of evidence suggesting that being aware of doing something is distinguishable from doing something, that areas of the brain underlying the experience of doing at least some things are distinct from those needed to actually do those things.
<br>
<br>
Such a dissociation has a number of interesting implications. In a general sense, it provides evidence for the existence and significance of an "unconscious" as a contributor to human behavior (and hence for "consciousness" as distinctive part rather than synomous with the totality of brain function). Blindsight also provides a possible explanation for some experiences of "magical" or "transcendent" abilities, at least insofar as these relate to performance characteristics of individuals for which the individuals themselves cannot account. A dissociation between unconscious and conscious processing is also of significance in an educational context, since the two sorts of processing may acquire, process, and make use of experiences in different ways.
<br>
<br>
Blindsight - the ability to respond appropriately to visual inputs while lacking the feeling of having seen them - might be something which only occurs in cases of brain damage, but seems much more likely to be a significant phenomenon of intact brain function as well. Indeed, it seems likely that blindsight (and similar phenomena in other spheres) is an important ingredient of of a variety of activities where one wants to move quickly and appropriately, without "thinking about it". 
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9187"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="100"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="579"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/22/2002 4:10 PM by azb@llnl.gov</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9187" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9187" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I think much (1/2 ?) of the confusion is that the single term "consciousness" is standing-in for too many "related things".
<br>
<br>
As I wrote much earlier, if I am exploring a cave, and a "tiger" in the distance makes a growling sound, it might not be "loud enough" that I "consciously" sit up and take notice.  But the sound still reached my ears, and some part of my neural system "took notice", and as part of its evolved response to such a sound, might start a bit of additional adrenaline flowing through my system, causing my heart to speed up, etc.
<br>
<br>
I might then become "consciously aware" that my "nervousness" has increased, yet I do not know the exact reason.  I might just suddenly feel "spooked".
<br>
<br>
Another distinction, (perhaps impossible to resolve except, as John B might argue, from "reasonableness") is whether a system with a formal "self-concept" exercised in the course of information processing is ever "feeling conscious" the way you or I experience the feeling.  This was my question to Shai_op.  The system of "Image-Object-Links", and the growing accumulation of relationships that serve to bolster the "self-concept" may well give rise to an intelligence that "functionally acts as a conscious being".  But this is perhaps not the same as "feeling awake" as we experience consciousness.
<br>
<br>
Thus, we have three (roughly) separable things that might be referred to when someone says "conciousness".
<br>
<br>
1.  The formal "has a programmatic concept of self".
<br>
<br>
To understand why I feel this is inadequate, Imagine a sophisticated object-oriented software system that is exposed to external "objects" and can access and create new "internal" objects, including the "self-onject", and update link-relations in strengths, etc.  All of this is running on a Pentium processsor.
<br>
<br>
Why not just eliminate the Pentium processor, and conduct all the operations on paper, with crayons?  Give me a new object, I seek into "memory" (stack of paper) for related objects, use an abacus to calculate a revised "linkage strength", take out a crayon and update the cell that maintains the "strength" of that link, etc.
<br>
<br>
The overall system MIGHT behave consistent with having a true self-concept, and indeed, it would thus possess such a "working concept".  But MUST the system possess "subjective feeling of awareness" just by this formalism?
<br>
<br>
Put more simply, note that my "formalism with paper and crayons" involves no "electricity" (per se).
<br>
<br>
I wonder to what degree the parallel between "neural-electric" and "transistor-electric" lends me to feel that consciousness-feeling must involve a physical "charge-dynamic", which would be lacking in the "pure-paper-analogy".
<br>
<br>
2.  The Human(-like) Conscious Waking State
<br>
<br>
3.  The Human(-like) Subconscious Autonomous State
<br>
<br>
If we continually confuse these three things, at the outset, by referring to them all as "consciousness", we will get into endless misunderstandings.  Better to find three separate names, explore those carefully, and if it turns out that the distinction (in some ways) is needless, let that be a conclusion.
<br>
<br>
Cheers! ____tony b____</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id12579"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="120"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="559"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 12/12/2002 9:08 PM by AZ</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id12579" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D12579" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>&gt;Why not just eliminate the Pentium processor, and &gt;conduct all the operations on paper, with crayons? &gt;Give me a new object, I seek into "memory" (stack &gt;of paper) for related objects, use an abacus to &gt;calculate a revised "linkage strength", take out a &gt;crayon and update the cell that maintains the &gt;"strength" of that link, etc.
<br>
<br>
&gt;The overall system MIGHT behave consistent with &gt;having a true self-concept, and indeed, it would &gt;thus possess such a "working concept". But MUST the &gt;system possess "subjective feeling of awareness" &gt;just by this formalism?
<br>
<br>
Please do tell me WHY NOT?
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id12590"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="140"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="539"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 12/13/2002 2:28 AM by <a href="http://web.archive.org/web/20071011094955/mailto:azb0@earthlink.net">tony_b</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id12590" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D12590" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>AZ,
<br>
<br>
I don't know, one way or another, of course.
<br>
<br>
My diatribe just intends to point out that "we chemical things", having advanced to the point of thoughts where "formal symbol logic" can be "recognized" (perhaps more accurately, constructed), and we employ it so thoroughly in our logical/rational lives, that we begin to use it to "approximate" the analog, the fuzzy, the less-than-Boolean world.  Oddly, "logical thought" seems to be nature's latest (most advanced) development, and yet as we embark upon the creation of thinking machines, it turns out to be the easiest to emulate.
<br>
<br>
Far easier to program software to calculate the "logical deductions" (A &gt; B, and B &gt; C, thus A &gt; C) which humans have only recently formalized, than to program it to appreciate nuances of humor, or the joy of a summer breeze. 
<br>
<br>
The question is whether our human ability to have such appreciations is, in part, due to the physical nature of our construction (chemicals, etc., and of course the complexity of our form), or is it merely the complexity?
<br>
<br>
Are we akin, purely, to software running on (interchangeable) hardware, or are we the hardware as well?  Are the varying ion-concentrations at our neural synaptic sites critical to our (subjective) "feeling of the world", or would an equivalent complexity of glass marbles shifting between chutes in a large glass machine engender the same subjective sensations of "feeling"?
<br>
<br>
I don't know, one way or the other.  But I don't think the answer is arrived at easily, either.
<br>
<br>
Cheers! ____tony b____</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id86229"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="160"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="519"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 09/16/2007 4:50 AM by <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/profile.php?id=2905">BeAfraid</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id86229" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D86229" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>[quote}Are we akin, purely, to software running on (interchangeable) hardware, or are we the hardware as well? Are the varying ion-concentrations at our neural synaptic sites critical to our (subjective) "feeling of the world", or would an equivalent complexity of glass marbles shifting between chutes in a large glass machine engender the same subjective sensations of "feeling"?  </p></td></tr></table></td></tr></table></td></tr></table></body>
<br>
DEFINITELY the hardware as well.
<br>
<br>
This is Ben Goertzel position as well, that any intelligent agent is going to need to be embodied. That body may well be virtual, but it will need something telling it that it has an environment in which it lives and interacts (I almost said "Breaths"... That would be silly, unless it was a fully physical construct that needed some form of gas with which to perform some sort of chemical process necessary to its operation/survival).
<br>
<br>
Several of the participants at the Singularity Summit made this claim as well. Siting that a disembodied agency may well be able to gain a form of intelligence, but that intelligence would be far more alien to us than an embodied agency. A disembodied agency may well be so alien as to not recognize us as being intelligent (the same can be said of an embodied agency). 
<br>
<br>
It is likely however that some form of communication could be established with either should it not recognize us immediately. Considering that we created it, it would be likely that we would know how to control ts imputs at least well enough to make it aware of some form of ttempted communication. If it was what we called a human+ intelligence, it would be a little dim to think that it wouldn't have the capacity to recognize an attempt to communicate with it... This will just be easier to do if that agency is embodied and contains sensory inputs that are equivalent to our own... 

<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>

<a name="id86227"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="120"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="559"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 09/16/2007 4:40 AM by <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/profile.php?id=2905">BeAfraid</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id86227" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D86227" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p> <center><p class="mindxquote"> Why not just eliminate the Pentium processor, and conduct all the operations on paper, with crayons? Give me a new object, I seek into "memory" (stack of paper) for related objects, use an abacus to calculate a revised "linkage strength", take out a crayon and update the cell that maintains the "strength" of that link, etc.   </p></center>
<br>
Isn't this just another form of the "Chinese Box" problem?</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9297"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/25/2002 3:20 AM by dvolfson@juno.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9297" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9297" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>&gt; "attention, at a given moment"
<br>
<br>
Conscious, or unconscious attention?
<br>
<br>
You're using a network model. Tell me, how does such an object -&gt; link system synthesize new images. How does it create (artistic) images that it has never linked before?
<br>
<br>
You seem to be using zero-dimensional links. How do you show specific relationships between objects, like father of, next to, far away from, greener than, etc?
<br>
<br>
&gt; "By 'active objects' I refer to objects brought into our attention at a given moment, i.e belong to the current image."
<br>
<br>
Active in the conscious, or in the unconscious "images"?
<br>
<br>
&gt; "Whenever the self object is part of the current image, along with another activated object X, we say that we are aware of X, or conscious of X. Consciousness is therefore a state of objects, the relation between the self object and other objects."
<br>
<br>
You are describing attention, which can occur at an unconscious level.
<br>
<br>
Have you ever read an introductory textbook on cognitive psychology?
<br>
<br>
-- Dimitry</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9321"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/26/2002 1:02 PM by shai_op@netvision.net.il</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9321" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9321" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>&gt; Have you ever read an introductory textbook on &gt; cognitive psychology? 
<br>
<br>
&gt; -- Dimitry
<br>
<br>
Dear Dimitry,
<br>
The cognitive psychology could succeed in explaining consciousness so far. I don't plan to build my conclusions on top of their introductory books.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9322"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/26/2002 2:03 PM by azb@llnl.gov</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9322" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9322" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>jwayt and scottswall5,
<br>
<br>
&gt; "The metal and plastic spinning wheel analogy does not apply because they don't have "same fine-grained functional organization". You start with one function and then switch to another."
<br>
<br>
Actually, the metal-wheel/plastic-wheel example serves and interesting purpose.  It begs the question "what functionality is being sought"?
<br>
<br>
A plastic wheel of identical shape and density as a metal one will serve perfectly well as a replacement for a flywheel, in storing angular momentum, but will not serve to induce the same electromagmetic effects.  So what are we "looking for"?
<br>
<br>
The brain is engaged in who-knows how many "activities", of which "rational thought" is just the tip of the iceberg.  The issue of AI and consciousness ask us to consider a "new medium" supporting the same "fine-grained functional organization", but this cannot be done before you identify which "functionality" you seek to support.
<br>
<br>
If the functionality is the rational-logical problem-solving domain, then (perhaps) a wider variety of different media exhibiting "same fine-grained functional organization" may be possible, than if the functionality sought is "human sensory experience of self-awareness".  The former (rationality) is (relatively) easy to "test", as the success is defined entirely in terms of externally observable result.  The latter (subjective consciousness) can only be inferred from external behaviors.
<br>
<br>
How much "fine-grained functional similarity" is required to support equivalent quality of consciousness?  I don't know, but it seems reasonable to suspect it is more than the similarity required for "intelligent behavior".
<br>
<br>
Cheers! ____tony b____
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9323"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/26/2002 3:26 PM by shai_op@netvision.net.il</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9323" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9323" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I meant:
<br>
The cognitive psychology could NOT succeed in explaining consciousness so far. I don't plan to build my conclusions on top of their introductory books.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9272"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/24/2002 10:00 AM by cyberdyno4@hotmail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9272" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9272" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>ORDER (mind &amp; matter) arose from interactions within disorder giving rise to self-dependent, separated, cybernetic systems, which, in turn, learned to take full advantage of matter's properties after billions of years interacting with each other, to the point they evolved into human brains, for the only purpose of experiencing/perceiving/measuring existence a bit better (from a 4D perspective), so they can continue to improve in their methods to use information to their advantage, as a tool against entropy or disorder. Why? because all thermodynamic systems tend to MOVE towards thermal equilibrium, and in doing so they have to interact forming physical, geometrical, relationships which are preserved in matter and are accessible by this cybernetic systems (including brains), when needed, as they evolve towards thermal efficiency.
<br>
<br>
Take music for example... it isn't periodic and yet is a great example of order and harmony, whose meaning and beauty can only be perceived as a whole. Like thoughts or ideas, if I try to explain an idea in writing that takes 10 lines and you only read three words you won't get the concept I am try to convey. The idea is an ordered whole which must be perceived as such.
<br>
<br>
Take a look at waves as an example of order, thanks to wave superposition you may have one simple wave which may be contained as a whole in another more complex wave which may also be contained as a whole in an even more complex wave... to infinite complexity.
<br>
<br>
Process or activity within hyperspace does not depend on linear time.
<br>
<br>
Information is created and preserved in matter even thou the medium itself does not move.
<br>
<br>
The components, the ones generating this information, are all floating_in and interacting_with space, as particles, molecules, galaxies... brains... all of which continuously exchange information as they continuously emit and absorb electromagnetic radiation as spatially separated systems. EMR is the tool which Nature has successfully been using since the beginning of time to overcome space-like intervals between objects in order to evolve as a whole.
<br>
<br>
And what are inertia and momentum but a resistance to change in the rate of space/information flow? 
<br>
<br>
Mass comes from the tension or 'informational drag' created by a system as it moves within the chaotic medium.
<br>
<br>
While a particle is moving at a constant speed and all the geometrical parameters are set, it won't experience any inertial forces, but as it accelerates and the relationships CHANGE it needs to keep adjusting to its new energy/space consumption settings. That's why relativistic effects are so real. When accelerated in relation to other particles, length shortens, time slows down and mass grows (space flow tension) within the particle to balance energy usage in momentum space and maintain its dependence and relation to spacetime in accordance to energy/information conservation laws.
<br>
<br>
People talk about gravitational non-linearities and what are they but radial information flow? As space from hyperspace is converted to spacetime and matter by a self-creative process which is driven by LOGIC and the laws of thermodynamics.
<br>
<br>
Gravity, momentum and inertia are caused by the tension in information flow created by 'process time'. That's why we only have mass in spacetime... after particles are fully formed.
<br>
<br>
Mass is a result of 'aether drag', a resistance to change in space flow rate, into and from the particle, as the particle moves thru space/medium, and this is what relates it to angular momentum. 
<br>
<br>
All those who wanted to detect aether drag had to do was take a direct measurement of either gravity, momentum or inertia and that would be the amount of aether drag.
<br>
<br>
If you immerse in water a bullet shaped object (one foot in diameter) and then accelerate it to supersonic speeds, this projectile will inexplicably pull with a body of water attached to its rear, never allowing the formation of a void as the theory predicts, so they invented 'bow drag' to explain this phenomenon and derive the drag coefficient they were looking for.
<br>
<br>
It's like Timothy Boyer's piston, if you were to pull it with high acceleration, the force resisting you would be higher than what Newton's second law predicts. Russians have obtained fields of 25 million oersteds generated from the void with a similar method. They used explosives to pull the piston.
<br>
<br>
This anti-void tension force may easily be what fuels eternal particle spin, tornado spin, and this is its connection to angular momentum.
<br>
<br>
It's a 100% elastic medium, so motion (or information propagation) *at these level* is instantaneous, this property is what makes possible phenomena like momentum, inertia and even gravity, facilitated by the holographic properties of a 100% elastic medium and the instantaneous information propagation properties of momentum space. This is why there can't be displacement without replacement. This is where this 'anti-void force' comes from, as it is the aether's nature not to allow separation (or tearing of the space fabric) as it needs to maintain its wholeness for stuff like momentum, inertia and non-local (or spacetime independent) communications to be possible.
<br>
<br>
<br>
Mass is equivalent to process...
<br>
<br>
Mass simply refers to the amount of information processing of all the energetic relationships that exist between matter and space, when a particle is at rest this spatial relationships stay constant and there is no informational lag created space/information flow within the particle, as the particle is accelerated the energetic relations between the particle and space keep changing causing this space/information flow tension we call inertia.
<br>
<br>
Gravity is caused by the space/information drag caused by its radial flow towards the center of all matter as space/information crystallizes from hyperspace into spacetime, moment to moment, as the Universe's wave function continues to develop forward in time.
<br>
<br>
Each object that moves (and they all move) in space must follow the laws of energy conservation. But how else could the Universe know how much energy is being used by some galaxy 5 billion light years away if it isn't thru hyperspace... momentum space... a 100% elastic non-material medium from which all matter and space emerges as a product of active information.
<br>
<br>
According to present day theory the total energy in this Universe must be a constant, and each of its parts must know how much energy it is using in relation to the whole Universe.
<br>
<br>
Matter is aware of its surroundings, but this doesn't mean it can think (unless it had previously being formed into a brain).
<br>
<br>
These internal oversight can only happen in hyperspace.
<br>
<br>
Holistic awareness is a secondary function of matter which enabled Nature to evolve. 
<br>
<br>
Interactions within the system (brain) depend on more than the information it gets thru its five senses, there is an interaction occurring at a deeper level between the system and its environment. Thoughts are formed very much in the same manner particles are, and just like particle systems depend on EMR so does our mind. Processes forming ideas are very much like the processes that form matter. Mind and matter both depend on the magic of superposition, non-locality and non-linear information processing, all phenomena which gives them the ability to self-organize into ever more efficient systems.
<br>
<br>
Consciousness, thanks to this function, is what enables us to think and exist in 4D, in a continuum unbounded from causality (or linear time). And that makes Bohm correct when he says state vector reduction occurs thanks to this 'wholeness in space' function of matter and consciousness is possible thanks a 'wholeness in time' function of matter, and it is this 'holistic awareness' function of Nature which Bohm mathematically represented as the quantum potential (Q).
<br>
<br>
Stapp's projection operator (P) stands for perception, but not for just human perception, but for all matter. According to Mach and others, any movement by any object within the Universe will instantaneously be sensed thru momentum space, and even though this hasn't been directly measured, it can be derived thru other phenomena... like inertia. 
<br>
<br>
And that's what (P) ends up being, as a particle perceives other particles it completes the information exchange, realizing the spatial relationships between particles and space that is needed to collapse the wave packet in hyperspace and be crystallized into spacetime. Not an exclusively human ability since perception is a very old natural function of matter.
<br>
<br>
Information about a material system must be contained within the system, it doesn't come from anywhere else in space. The only external information being brought to the system by EM waves is the momentum and hence location of the particle in relation to the world. But the system must be comprised by a particle AND its particular inwardly flowing concentric space/information waves. So gravitational non-linearities may still be viewed as radial space/information flow. Information which is picked and organized by concentric waves as space is condensed into the particle/system. But the parts (not the information) to construct and maintain the system intact as it moves through the medium do come from the chaotic hyperspace. 
<br>
<br>
So there is no ordered information in hyperspace, just randomly fluctuating quanta, which is ordered as a particle/wave system moves through it.
<br>
<br>
Hyperspace is filled with information bits, matter precursors, a pre-geometry made of non-material units of information which exist in chaos and are ordered by logic and activity into spacetime. But for natural reasons, i.e. energy conservation laws, everything that comes into spacetime must be perceived and energetically measured before it can materialize. There has to be a measuring device sensing the particle's location and momentum in relation with the rest of that inertial frame of reference before it can crystallize, as the information that constitutes it flows radially from hyperspace towards its centre in spacetime. But this measuring device isn't some external being, it is the Universe itself, each particle senses each other and their relation to space, building an information network filled with geometrical relationships (spacetime), which are in turn used as the future is built on the already existing information.
<br>
<br>
The big MISTERY was - why do I have to watch the cat in order to know whether it's alive or not? And the answer is that we are measuring devices, just like the rest of all matter. We are the best measuring device that ever emerged from all the information processing done in our neighborhood to this date.
<br>
<br>
Von Neumann was partly right when he said that the evolution of the Schrodinger wave could only depend on quantum mechanical 'observables' (implying that this information can only come from spacetime) yet including the observer (mind) as an efficacious operator (since the theory considers brains to be measuring instruments). The only reason human brains entered the equation was that as they observed and perceived light (EMR) coming from the particle, information about momentum and location, which is vital to maintain energy conservation laws, became known to the particle/system allowing it to complete the loop and continue to condense.
<br>
<br>
Bohm, Hiley and Penrose are also partly right when they claim particle complementarity is due to an indivisible process which originates in a common background, but the only necessary information being transferred from the aether to the particles is that concerning momentum and location in relation with that inertial frame and the rest of Universe. There is no need for some mega information storage system which must contain the history of the Universe, all the information needed for the evolution of the system in spacetime is contained by the system itself IN SPACETIME.
<br>
<br>
Quantum mechanical process is indeterminate going forwards or backwards. Reality (like thought), is about becoming, it IS process and this process is *totally dependent* on the uncertainty of the movement in quanta. Uncertainty is what causes activity, it is due to the natural indeterminism of quanta that the Universe exists, you take the uncertainty away and it will freeze.
<br>
<br>
All matter is accompanied by a real indeterminate wave movement governed by the laws of quantum mechanics, just as de Broglie described it. 
<br>
<br>
Objective reality is a continuous self-maintained thermodynamically open process developing in a sea of discontinuities (background radiation). Even atoms are open thermodynamical systems, there is always energy/information/space being exchanged between matter and the environment. The same can be said about living biological systems they are open energy dissipating systems restricted by the laws of thermodynamics. 
<br>
<br>
Schrodinger's equation develops in real uncertainty, quantum mechanical theory will never reach 100% accuracy because indeterminism is the NATURE of reality.
<br>
<br>
As Schrodinger's (wave-function) equation evolves the system will have some tendencies or propensities that will depend on the systems properties in spacetime. There will always be some preferred outcomes (where the wave peaks in the function) whose probabilities are going to be much higher than others which will not be so well related to the system.
<br>
<br>
Photons are carried by a matter-waves and move in a wavy indeterminate manner ruled by the Heisenberg principle of indeterminacy, that's where hbar came from, you take hbar away from the equations and reality freezes up!
<br>
<br>
Uncertainty is inherent to evolutive process, if you don't believe in the indeterminism of Nature then you will have to reject Darwin and substitute evolution by creationism. If everything was already known why do we keep having process? I mean the Sun is still shinning isn't it...
<br>
<br>
Information contained in photons, even though it may contained in each photon coming from a single source, has to be seen as ensembles ruled by the laws of probability, that is the current approach of Quantum Field Theory.
<br>
<br>
Some of the information about the environment (about the Universe) comes from this aether, as it rules the whole Universe, all at once, with just a few fundamental laws (constants). Thanks to the WHOLENESS of the aether this information can be transmitted instantaneously as wave-phase angle or slope, allowing at the same time all kinds of emergent informational systems to observe themselves in wholeness helping them to evolve. 
<br>
<br>
How? If we allow for three different scales of reality it can be done, with the aether as the ETERNAL substrate for hyperspace and then spacetime. 
<br>
<br>
When we rotate the plane of polarization in a beam of light the whole beam changes at once, so what kind of medium is this? Is it a particulated fluid, a super-elastic gel, or a hyper-solid?
<br>
<br>
See, the aether is non-dimensional, events occurring within the aether occur without motion, the manifestations we have in hyperspace (Television, cell phones, radio, virtual particles and all EMR), and the objective reduction of matter-waves into spacetime are ruled by laws coming from the aether, that's why I said Tachyons may be considered to be imaginary, as a tool to comprehend non-locality and instantaneous communication.
<br>
<br>
Everything is connected to the aether because everything is made from it. The aether is made from the same stuff Hawking's singularities are made, it is also the stuff from which wavefronts/shockwaves in EMR are made. It is fluid and yet INDIVISIBLE... you could stretch it and create huge volumes of 'space' WITHIN it but you can't divide it into two separate entities, the aether is ONE. 
<br>
<br>
All the evidence points to a precipitation or condensation of space, but particles are still volumes of solid space filled by a 'false vacuum', in fact it can be argued that space density and pressure are greater on the outside than they are on the inside. Solid space is an effect caused by shockwaves created by the high speed spinning of fields, and fields are made from the same 'false vacuum' the whole Universe is filled with.
<br>
<br>
If we could conceive this medium to be a gel, to be made of this non-material (because neither time nor length apply to it) indivisible stuff that makes the points that make the lines that make the strings that make the quanta that makes the quarks... then we get hyperspace sharing the properties of both - the aether's non-locality, and spacetime's linear time, motion and information processing - finally we get spacetime, which contains the properties of all three scales or realms. What else could you ask for?
<br>
<br>
This three level reality coupled with a 'gel' aether model can explain non-locality, holistic awareness and evolution. It's a fluid, elastic, indivisible and eternal singularity which has inflated and stretched to what the Universe is today. It has no parts and no process within it - it IS the process. Motion, time, extension, order, size, beginning or ending are notions that do not apply, and yet everything is made from it, even space. 
<br>
<br>
To us (spacetime scale) it seems as if it became a bunch of unrelated separated entities, but in reality it's all connected thru the all pervading aether, even desolated space regions are part of the one single process that started it all, it's all made of the same aether that gave birth to it. Everything that changes will experience inertial forces, simply because in reality there is only one process (the Uni-verse) from where a myriad of informational nodes (objects) evolved to become apparently separated systems. For any process to continue evolving there must be internal oversight as a whole, which is only possible if all the parts are interconnected, and that can be a huge problem when we are talking about a system the size of the Universe. We knew it had to be a non-local function, and this is only possible because of the ONENESS quality at the aether scale. 
<br>
<br>
WITHIN the aether motion/information/momentum is reported instantaneously, distance doesn't apply, the aether has no parts, it is one. Within hyperspace, we have only EMR, where information propagation is limited by moving mass (process) to the speed of light. Within spacetime most things obey Newton's motion laws but everything is non-locally interconnected to everything else in its neighborghood and the rest of the Universe.
<br>
<br>
Hegel was right... we owe ourselves to the state, individualistic behavior is against Nature. 
<br>
<br>
The REAL unfolds as the History of Mankind. (Hegel)
<br>
<br>
Reality is not about things, it is about process. (Smolin)
<br>
<br>
<br>
--
<br>
Laurent</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9296"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/25/2002 3:00 AM by dvolfson@juno.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9296" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9296" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>"Mass is equivalent to process... "
<br>
<br>
Yeah, and all nouns can be shown to be nominalizations at some level. What does your post have to do with consciousness?
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9302"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/25/2002 10:05 AM by cyberdyno4@hotmail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9302" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9302" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>How could there be a mind where there is no space, no time and therefore no motion.
<br>
<br>
I can imagine a realm where static information is in the 'form' of algorithms which are then translated into a spacetime type reality as they acquire the dimensions of length and duration, but even that seems impossible since everything indicates that information must always be material. I mean, how could there exist any form where there are no dimensions of length or time?
<br>
<br>
I can imagine many things, but we can't just go by intuition, we have to rely on what is already known.
<br>
<br>
Do you know of any examples of nonmaterial information storage mechanisms?
<br>
<br>
First there had to be matter before there could be any brains, and matter is spacetime dependent. Brains emerged from the evolution of information that existed in spacetime, there can't be evolution outside of spacetime. 
<br>
<br>
Interactions within the system (brain) depend on more than the information it gets thru its five senses, there is an interaction occurring at a deeper level between the system and its environment. Thoughts are formed very much in the same manner particles are, and just like particle systems depend on EMR so does our mind. Processes forming ideas are very much like the processes that form matter. Mind and matter both depend on the magic of superposition, non-locality and non-linear information processing, all phenomena which gives them the ability to self-organize into ever more efficient systems. 
<br>
<br>
Mind and matter are different aspects of the same underlying process, that which IS is PROCESS itself. Waves are forms that carry information, they in-form matter and mind. 
<br>
<br>
Stapp's projection operator (P) stands for perception, but not for just human perception, but for all matter. According to Mach and others, any movement by any object within the Universe will instantaneously be sensed thru momentum space, and even though this hasn't been directly measured, it can be derived thru other phenomena... like inertia. 
<br>
<br>
And that's what (P) ends up being, as a particle perceives other particles it completes the information exchange, realizing the spatial relationships between particles and space that is needed to collapse the wave packet in hyperspace and be crystallized into spacetime. Not an exclusively human ability since perception is a very old natural function of matter. 
<br>
<br>
Holistic awareness is a secondary function of matter which enabled Nature to
<br>
evolve. 
<br>
<br>
Consciousness, thanks to this function, is what enables us to think and exist in 4D, in a continuum unbounded from causality (or linear time). And that makes Bohm correct when he says state vector reduction occurs thanks to this 'wholeness in space' function of matter and consciousness is possible thanks a 'wholeness in time' function of matter, and it is this 'holistic awareness' function of Nature which Bohm mathematically represented as the quantum potential (Q).
<br>
<br>
Time is the dimension that ties and relates all the frames together. You know that a TV screen (a 2D plane) has a refresh rate of about 30 frames per second, and when we watch a movie we need to see a long series of frames to be able to tie up all the causal relations between all the frames, and that's how we are able to get 'into' the movie (unlike any other species in the planet). Time is the 4th dimension and the glue that ties all the frames that make up our stream of consciousness. We humans have apparently become the first animal able to efficaciously perceive the fourth dimension. 
<br>
<br>
It's like music, you can't compare what you feel when you listen to a whole Bethoven simphony to what you perceive when you hit a single note in the piano. 
<br>
<br>
Remember Penrose's quasicrystals (The Emperor's New Mind, p. 564), how he explained that it appears as if the 'whole' crystal is observing itself (each 'present' atom configuration pattern is embedded into its pilot-wave) and choosing from qualia, using some holistic awareness mechanism, by which they can, compare 'present qualia' to 'past qualia' and all the possible 'rock-like' outcomes, which are limited to the system's tendencies or potentialities, until the 'right' atom configurations are found, while constructing their forbidden and very complex icosahedral symmetries. 
<br>
<br>
Experience plays an important role in the correct development of the crystals (as well as in all self-organized systems). The crystals accomplish their self-observation by following information contained in their pilot-wave (Bohm-de Broglie) , which contains past information about the crystal, as a whole. Proto-qualia for a quasicrystal would be how all the possible atom configurations would feel like as they remain in superposition until the right one is found and then would come the collapse of the wave packet. 
<br>
<br>
From the moment the first self-organizing systems appeared in nature to the moment the first human brain appeared its being a few billion years, but in both occasions the objective has been the same: to experience existence. The state wave a human being follows (or should I say - the measure by which a human being exists) is defined its brain state wave. Penrose's quasicrystals don't have a brain, but they follow their state wave as the measure by which they must exist, if by any reason they were to stop following their state wave as they add new atoms to their 'body', they would end up becoming a different type of material. 
<br>
<br>
Past experiences (our beliefs) are closely related to what new qualia will feel like. When we find what feels right, be it a color or be it a thought, an idea, ...a knowing, there is wave coherence, and that's when the collapse of the brain state wave occurs. 
<br>
<br>
All input from the senses cause physical changes in the brain as it registers and stores reality. The same way light in actual holograms leave weird interference patterns on photographic plates. When using the right tool you are able to recreate the image out of what really are - the interference 'Moire patterns' left on the photographic plate. When you remember, you are back-tracking the interference patterns physically engraved in your brain, recreating past reality. 
<br>
<br>
We are constantly choosing the present out of an infinitude of possibilities offered by quantum superpositions. 
<br>
<br>
Events (or moments) happen in spacetime. There are all kinds of events (or happenings). Like when photons are emitted while electrons drop an orbit, or when atoms decay and radiate energy. Or when someone is telling us a joke and we suddenly explode in laughter when we 'get it', that's an event. When we reach an understanding of a new concept (a knowing), or when we realize that which is an eternal truth, those are also events.
<br>
<br>
--
<br>
Laurent
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9304"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>The Hoffding Step<br><span class="mindxheader"><i>posted on 08/25/2002 11:38 AM by dvolfson@juno.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9304" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9304" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>&gt; Interactions within the system (brain) depend on more than the information it gets thru its five senses, there is an interaction occurring at a deeper level between the system and its environment.
<br>
<br>
While there are built-in structuring processes in the brain, without sensory input they would have nothing to work with.
<br>
<br>
&gt; Mind and matter both depend on the magic of superposition, non-locality and non-linear information processing, all phenomena which gives them the ability to self-organize into ever more efficient systems. 
<br>
<br>
If you're trying to say that quantum effects are necessary for self-organization, then take a look at autopoesis -- no quantum events are needed.
<br>
<br>
&gt; Mind and matter are different aspects of the same underlying process, that which IS is PROCESS itself.
<br>
<br>
Yes, fine, as I noted before, any noun can be seen as a process (a nominalization) at some level. This is too reductionistic to have any relevance to consciousness.
<br>
<br>
&gt; perception is a very old natural function of matter.
<br>
<br>
You're saying that interaction equals perception. It doesn't. Perception requires some cursory internal modeling of the interaction. The Hoffding step.
<br>
<br>
&gt; We humans have apparently become the first animal able to efficaciously perceive the fourth dimension. 
<br>
<br>
I doubt it.
<br>
<br>
&gt; the objective has been the same: to experience existence.
<br>
<br>
Whose objective?
<br>
<br>
&gt; Past experiences (our beliefs) are closely related to what new qualia will feel like. When we find what feels right, be it a color or be it a thought, an idea, ...a knowing, there is wave coherence, and that's when the collapse of the brain state wave occurs.
<br>
<br>
Wave coherence? That's simply not how it works. Searching processes in the brain do not work that way. There are a number of discrete attempts to match, not a holistic wave equation.
<br>
<br>
&gt; When you remember, you are back-tracking the interference patterns physically engraved in your brain, recreating past reality. 
<br>
<br>
Remembering can consist of more than one type of process. Elaboration does not necessarily have anything to do with the coded memory itself, but with its related factors. In other words, what you think you remember is often the product of its similarity to other events, not to the original coding.
<br>
<br>
&gt; We are constantly choosing the present out of an infinitude of possibilities offered by quantum superpositions.
<br>
<br>
Really? I've never had a quantum level choice offered to me.
<br>
<br>
&gt; Holistic awareness is a secondary function of matter which enabled Nature to 
<br>
evolve. Consciousness, thanks to this function, is what enables us to think and exist in 4D, in a continuum unbounded from causality (or linear time).
<br>
<br>
I have no idea what you're trying to say here. Human beings ARE constrained by linear time.
<br>
<br>
-- Dimitry</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9308"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="80"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="599"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: The Hoffding Step<br><span class="mindxheader"><i>posted on 08/25/2002 4:30 PM by cyberdyno4@hotmail.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9308" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9308" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>&gt;&gt; Interactions within the system (brain) depend on more than the information it gets thru its five senses, there is an interaction occurring at a deeper level between the system and its environment. 
<br>
<br>
&gt; While there are built-in structuring processes in the brain, without sensory input they would have nothing to work with. 
<br>
<br>
I was talking about de Broglie matter-waves and the brain's own wave function...
<br>
<br>
&gt;&gt; Mind and matter both depend on the magic of superposition, non-locality and non-linear information processing, all phenomena which gives them the ability to self-organize into ever more efficient systems. 
<br>
<br>
&gt; If you're trying to say that quantum effects are necessary for self-organization, then take a look at autopoesis -- no quantum events are needed. 
<br>
<br>
Autopoesis depends on the laws of Nature and Nature is ruled by quantum indeterminism. 
<br>
<br>
<br>
&gt;&gt; Mind and matter are different aspects of the same underlying process, that which IS is PROCESS itself. 
<br>
<br>
&gt; Yes, fine, as I noted before, any noun can be seen as a process (a nominalization) at some level. This is too reductionistic to have any relevance to consciousness. 
<br>
<br>
&gt;&gt; perception is a very old natural function of matter. 
<br>
<br>
&gt; You're saying that interaction equals perception. It doesn't. Perception requires some cursory internal modeling of the interaction. The Hoffding step. 
<br>
<br>
Perception is an old function of matter that has evolved with matter to what we have today.
<br>
<br>
&gt;&gt; We humans have apparently become the first animal able to efficaciously perceive the fourth dimension. 
<br>
<br>
&gt; I doubt it. 
<br>
<br>
Do you know of any other creature that can remember past experiences and plan the future from those memories with the same facility and efficiency humans can? Our mind is unbounded by the rigors of time, lower creatures can only experience and react to reality in snap shots, frame to frame. We can perceive written word in a paragraph as a whole, a passage of music as a whole... a thought...
<br>
<br>
&gt;&gt; the objective has been the same: to experience existence. 
<br>
<br>
&gt; Whose objective?
<br>
<br>
Nature's... in its eternal quest to beat entropy... armed with the laws of LOGIC and harmony.
<br>
<br>
&gt;&gt; Past experiences (our beliefs) are closely related to what new qualia will feel like. When we find what feels right, be it a color or be it a thought, an idea, ...a knowing, there is wave coherence, and that's when the collapse of the brain state wave occurs. 
<br>
<br>
&gt; Wave coherence? That's simply not how it works. Searching processes in the brain do not work that way. There are a number of discrete attempts to match, not a holistic wave equation. 
<br>
<br>
&gt;&gt; When you remember, you are back-tracking the interference patterns physically engraved in your brain, recreating past reality. 
<br>
<br>
&gt; Remembering can consist of more than one type of process. Elaboration does not necessarily have anything to do with the coded memory itself, but with its related factors. In other words, what you think you remember is often the product of its similarity to other events, not to the original coding. 
<br>
<br>
&gt;&gt; We are constantly choosing the present out of an infinitude of possibilities offered by quantum superpositions. 
<br>
<br>
&gt; Really? I've never had a quantum level choice offered to me. 
<br>
---------------------------
<br>
<br>
Separate sets of laws apply to microscopic and macroscopic phenomena
<br>
and EMR is bounded by the laws of the unseen, the invisible but very
<br>
real Hyperspace.
<br>
<br>
The Copenhagen interpretation of quantum mechanics, particle
<br>
complementarity, the uncertainty principle and Planck's constant are
<br>
key to understanding Heisenberg's determinism.
<br>
<br>
There are Classical 'Newtonian' Motion Laws and there are Quantum
<br>
motion laws. Quantum motion laws are mathematically described by
<br>
Schrodinger's wave mechanics which develops in vector space (another
<br>
mathematical construct), one of this vectors is the State Vector, which
<br>
determines whether the particle is in a wave-like state or a rock-like
<br>
(particle) state. State vector reduction refers to the event in which the
<br>
wave takes the form of a particle (wave packet collapse). State vector
<br>
reduction obeys to external factors, some developing in Spacetime,
<br>
which are called projection operators. As QM theory developed, the
<br>
founders had to include the observer (mind) as a critical factor
<br>
(projection operator) in the state vector reduction, and these new set
<br>
of quantum motion laws (Schrodinger's equation), which we so accurately
<br>
use to predict sub-atomic particle behavior, are non-deterministic by
<br>
nature, since they are based on the Uncertainty Principle.
<br>
<br>
Every motion of any object in Spacetime (4D) could be described to the
<br>
accuracy of a Planck unit by its wave function, even the history of
<br>
Mankind... if we had all the input information.  And yet there still will
<br>
exist a degree of uncertainty (Planck's constant h defines the size of
<br>
the uncertainty), there is always some degree of freedom, specially
<br>
when we only have to choose between two very similar options, [and
<br>
that's where 'free will' comes in].
<br>
<br>
The way I see it, if it wasn't for Heisenberg and Planck there would be
<br>
no probability waves, not even a Schrodinger wave. The wave model
<br>
describing a particle's trajectory was created because of the uncertainty
<br>
in the measurement of such small amounts.
<br>
<br>
I think Dennett, Crick and Koch, the Churchlands... they all make some 
<br>
very convincing arguments, but at the same time I believe that if AT&amp;T 
<br>
Labs sees no real obstacles in producing a quantum computer capable of 
<br>
a million million computations in tandem, then quantum computation and 
<br>
the ideas of Eccles, Hameroff, Penrose, Pribran... become very attractive. 
<br>
I mean, if anthropophagus little creatures like us have already discovered quantum superposition, you can only imagine since when has Nature
<br>
been using this great tool to her advantage.
<br>
-----------------------------------
<br>
<br>
&gt;&gt; Holistic awareness is a secondary function of matter which enabled 
<br>
Nature to evolve. Consciousness, thanks to this function, is what enables 
<br>
us to think and exist in 4D, in a continuum unbounded from causality (or 
<br>
linear time). 
<br>
<br>
&gt; I have no idea what you're trying to say here. Human beings ARE 
<br>
constrained by linear time. 
<br>
-------------------------------
<br>
Bohm's quantum potential (Q) links the Aether to spacetime...
<br>
<br>
" The Bohm approach makes a logical distinction between the two but
<br>
then the quantum potential links them together again so that they are
<br>
actually not separate. It is this factor that gives rise to context
<br>
dependence, and to the irreducible feature of participation between
<br>
relevant features of the environment in the evolution of the system
<br>
itself... " -- Basil Hiley
<br>
<br>
*************************
<br>
<br>
" Central to understanding the Bohm interpretation is the appearance
<br>
of the quantum potential, Q. It is not ad hoc as suggested
<br>
by Heisenberg (1959) but emerges directly from the Schr'dinger
<br>
equation and without it, energy would not be conserved.
<br>
<br>
The quantum potential does not have the usual properties expected
<br>
from a classical potential. It does not arise from an external source;
<br>
it does not fall off with distance. It seems to indicate a new quality
<br>
of internal energy and more importantly from our point of view, it
<br>
give rise to the notion of participation, non-separation and
<br>
nonlocality. At the deeper level it arises because, as Bohr often
<br>
stressed, it is not possible to make a sharp separation between the
<br>
observing instrument and the quantum process while the interaction is
<br>
taking place. The Bohm approach makes a logical distinction between
<br>
the two but then the quantum potential links them together again so
<br>
that they are actually not separate. It is this factor that gives rise
<br>
to context dependence, and to the irreducible feature of participation
<br>
between relevant features of the environment in the evolution of the
<br>
system itself. It was this factor that was not incorporated into by
<br>
the no-go theorems discussed above. " --- B. Hiley
<br>
<br>
*********************
<br>
<br>
"...This potential is totally unlike any classical potential. It has
<br>
features more akin to a selforganising potential. Indeed this
<br>
self-organisation occurs in response to the environment in which the
<br>
quantum process finds itself. " --- B. Hiley
<br>
<br>
**********************
<br>
<br>
--
<br>
Laurent
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9306"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/25/2002 2:21 PM by prj@ruf.dk</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9306" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9306" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>After a few very cmplicated explanations I think it is time to remember the principle called "Occam's Razor".
<br>
It says that if you have one or more theories explaning your observed data, you should choose the simplest theory since it is most likely to be true.
<br>
<br>
After having said that I would like to point at my own very simple explanation for the "hard" problem of consciousness.
<br>
<br>
The theory is called TRANS
<br>
Thought by Repetitive Activation of Neural Sequence.
<br>
<br>
A report about the theory can be downloaded from:
<br>
www.ruf.dk/trans2.doc
<br>
<br>
In short the theory is that the brain has the potential to generate its own neural activity by activating a loop of interconnected neurons. The brain is a generator when we feel conscious, not just a computer processing sensory inputs.
<br>
<br>
Palle R Jensen</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id23161"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 01/26/2004 11:01 PM by <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/profile.php?id=1028">Smarag</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id23161" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D23161" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Just read your post re: David Chalmers hypotheses about consciouisness. A very telling point in the notion that each "particle" must be conscious or they would not collapse their wave functions and become real -- or something like that. I'd like to read more. I'm very much into transpersonal psych and quantum and post qunatum physics, and I love David Bohm.
<br>
<br>
Jim Dodds</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9313"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/26/2002 1:56 AM by scottwall5@attbi.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9313" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9313" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I read this discussion until I got to the logically flawed argument in 7.2, which began as follows:
<br>
<br>
2. The principle of organizational invariance. This principle states that any two systems with the same fine-grained functional organization will have qualitatively identical experiences.
<br>
<br>
A metal spinning wheel and a plastic one may spin thread in exactly the same way, but one conducts electricity and the other does not. What if the conscious correlate is somehow contained in the electrical conduction! If you replace a metal spinning wheel with a plastic one atom by atom, you will notice no difference in the spinning, but the conductivity will diminish by increments. 
<br>
<br>
Chalmers has done a much better job than most of explaining what cannot be the source of consciousness, but I suspect that he is nowhere near explaining what it is. 
<br>
<br>
I am beginning to suspect that the real source of our inability to grasp consciousness stems from the discrete nature of our reasoning faculties (no bearing on consciousness). The on/off, signal/no-signal nature of how our minds process information may make it impossible for us to formulate models relevant to some natural phenomena. 
<br>
<br>
Moreover, I suspect that consciousness is not a force alongside gravity and mass, but our first hint that we are completely missing the point. Gravity, mass, space-time, etc. are certainly all aspects of some deeper and richer construct that is not immediately accessible to us. 
<br>
<br>
The people that have given up on trying to explain consciousness are probably closer to the truth, but we don't hear form them because they have given up. 
<br>
<br>
&gt;After a few very complicated explanations I think it is time to remember the principle called "Occam's Razor".
<br>
<br>
Occam's Razor only applies when you have a working model. None exist.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9315"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/26/2002 8:49 AM by jwayt</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9315" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9315" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>The metal and plastic spinning wheel analogy does not apply because they don't have "same fine-grained functional organization". You start with one function and then switch to another. 
<br>
<br>
In this quote, Chalmers attributes the quality of experience to the medium of experience. As long as the medium FUNCTIONS the same way, the quality of the experience should be the same. Consider the differences between watching a movie on television, as contrasted with the silver screen. The quality of the experience is better and richer in the theater because the sound system has higher fidelity, the screen is brighter, much larger, and has higher resolution. So the difference in the experience is due to the differences in the medium. In some respects the quality of the experience can be the same; the audio-visual components are experienced using the same sensory organs and convey essentially the same information content. More importantly, Chalmers claims different mediums for thought, awareness, and consciousness can can yield the same experience to the degree in which they  function the same way upon information.
<br>
<br>
&gt;"The on/off, signal/no-signal nature of how our minds process information may make it impossible for us to formulate models relevant to some natural phenomena."
<br>
<br>
A binary presumption of mental processes will handicap formulating an accurate picture of our minds. We only rarely operate in a strictly boolean fashion. Most of our values are gradients. Logic is a recent (Greek) concept.
<br>
<br>
It amazes me that so many people believe that our mind uses binary digits like a computer does. Even our DNA is quaternary. The Russions have observed 44 distinct brain wave frequencies (11 at 4 harmonics), so in what way is our brain so binary as to be on/off?</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9320"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/26/2002 12:17 PM by scottwall5@attbi.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9320" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9320" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Study some Neuroscience, try to understand what Chalmers is actually saying, and read what I said again.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9325"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/26/2002 3:36 PM by wclary5424@aol.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9325" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9325" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>&gt;It amazes me that so many people believe that our mind uses binary digits like a computer does. Even our DNA is quaternary. The Russions have observed 44 distinct brain wave frequencies (11 at 4 harmonics), so in what way is our brain so binary as to be on/off?
<br>
<br>
<br>
When I was a kid, when even the IBM 360 was still just a glimmer in some engineer's eyes, people used telephone switchboards as an analogical model for the brain.  Now, digital computers are favored.  But at least in this case, there is some evidence...neurons do seem to "turn on and off".  But I think some people run too far from the evidence.
<br>
<br>
BC
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9338"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/27/2002 7:05 AM by jwayt</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9338" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9338" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I appreciate the current fashion in mind analogies. On the old switchboards, the human operators were the transistors!
<br>
<br>
Switching on and off is no evidence of binary coding. Two ships at sea can exchange messages by flashing lights at each other, on and off. What is CODED is Morse code, not binary code. There are also pauses for phrasing, sentences and listening: presence and absence of signal.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9450"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 08/31/2002 2:52 PM by prj@ruf.dk</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9450" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9450" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>&gt;Occam's Razor only applies when you have a working model. None exist. 
<br>
<br>
It is true that I don't have experimental data to support the TRANS theory at this stage. I still think that a theory which in a simple way can explain a lot of observations made by others can be of tremendous value.
<br>
<br>
Thought by Repetitive Activation of Neural Sequence is a theory which takes a completely different approach than most others and this seems to be necessary in order to fully understand the special qualities of consciousness.
<br>
<br>
Palle R Jensen</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9327"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Alternity and Self-reference<br><span class="mindxheader"><i>posted on 08/26/2002 5:16 PM by jwayt</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9327" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9327" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Alternity is the set of our imaginary worlds, as they partly and robustly model the memory of the reality we experience. It is our cognitive workspace where we leave out some details for ease of manipulation. In alternity, we can plan a more desirable (or fear a disastrous) future as rich in experiential detail as we need to. We can create many alternates to choose from. Alternities are not merely states, but processes, routes, actions, strategies themselves. We may encapsulate these alternities and imbed them in others.. They become recursive and self-referent. We are continuously in the process of creating alternity, unconsciously, and at almost every level high enough to express it. This gives us huge adaptive power and this aptitude has been honed in our species for the last 200,000 generations.
<br>
<br>
In G'del, Escher, Bach: The Eternal Golden Braid, Douglas Hofstadter expands G'del's self-references in strong, formal systems to include the human brain. The formality of the neurons and how they function so reliably should be beyond doubt. Once our brain develops sufficiently, the formal system it represents becomes so complex that self-reference is inevitable. This actually occurs in human children around three years of age. Their ability to embrace symbols advances to the point where memory systems begin converting from eidetic to iconic strategies. It is also the point when children develop the concept of self. In the simpler forms of awareness, our minds model and symbolize uncounted objects in our world. How grossly negligent would we be to overlook ourselves? Self-consciousness must include the symbol of the self as an object in the mind. It must also employ recursion; I know that I know that I know' Gorillas, orangutans and chimpanzees also show they can manipulate symbols. Chimps show this beginning at 4 years of age. These primates have demonstrated they can use their imagination of what a room looks like from another perspective to get a fruit reward.
<br>
<br>
When we encapsulate alternity, we objectify it as a symbol. We call it a 'plan'. Objectifying this alternity is the mechanism by which we can mentally distance ourselves from the symbol. Once accomplished, we need only to be aware of the symbol for self and the alternity are two separate things. Thus self is dualistically imbedded in alternity and alternity is imbedded in self. 
<br>
<br>
The quality of what it is like to experience something comes from relating self to the process of recalling the memory of that experience. In the case of what it is like to be someone else, we employ alternity as a substitute. This was advantageous in our evolution as we began to model the quality of what it would be like to be alpha male or female, or what it would be like to be someone else in our society so we can better predict their behavior. This is of prime importance when dealing with a member of the opposite sex.
<br>
<br>
To summarize what it is, how it forms, when we get it, and why: Self-consciousness is the inescapable product of sufficiently complete, formal, symbolic systems. Self-consciousness develops in three year-olds when symbol manipulation does. The aptitude for self-consciousness is naturally (even sexually) selected in our species because it is so highly adaptive.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9329"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Alternity and Self-reference<br><span class="mindxheader"><i>posted on 08/26/2002 6:38 PM by azb@llnl.gov</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9329" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9329" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>jwayt,
<br>
<br>
How would you distinguish "formalism" from "realism"?
<br>
<br>
You write:
<br>
<br>
&gt; "Once our brain develops sufficiently, the formal system it represents becomes so complex that self-reference is inevitable."
<br>
<br>
A formal system is a conceptual invention, an axiomatization, the presumes certain postulates and rules, and then determines the consequences, capabilities or limitations of that formalism.  Formal systems are models created with the attempt to "map to" reality.  Reality itself is not a formalism. 
<br>
<br>
&gt; "The quality of what it is like to experience something comes from relating self to the process of recalling the memory of that experience."
<br>
<br>
Certainly, consciousness will involve self-reference to memory retrival processes, etc.  This "formalism" can be "modeled" with an almost arbitrarily small software program, and "formally speaking", that program would meet the definition you have given for "formally conscious."
<br>
<br>
But none of that speaks to the presense (or absense) of a subjective sensation of consciousness, akin to that of human experience.
<br>
<br>
&gt; "Self-consciousness is the inescapable product of sufficiently complete, formal, symbolic systems."
<br>
<br>
Aside from the slippery qualifier "complete" (is it complete when it is conscious?), you are really referring to "will meet the definition of formal consciousness".  Since many algorithmic implementations can (and do) meet this criteria, yet are almost certainly NOT conscious in the human-experiential sense, we abuse the term "consciousness" by employing it in this way.  We have, as yet, no good way to ascertain whether an arbitrary construct possesses the "subjective sensation" of a conscious, waking state.  You say "Self-consciousness", but you mean "formal access to the self-other relation", which is a syntactic description that can be applied independent of a physical implementation.
<br>
<br>
I think the "sensation of self-awareness" requires physics, and moreover, not just any physics that might support syntactic transformations, no matter the complexity.  It might act intelligently (super-intelligently!) and even act consciously, so we could not arbitrarily claim it has no consciousness.  But there is no guarantee that it represents a "sensation of consciousness".  There is really no way I can imagine to know that, nor that it must follow simply because a "formalism" is satisfied.
<br>
<br>
Cheers! ____tony b____</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9337"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Alternity and Self-reference<br><span class="mindxheader"><i>posted on 08/27/2002 6:46 AM by jwayt</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9337" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9337" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Formalism is, as you say, a map of reality, or a method we use to map the way we think about reality. To qualify for Godelian incompleteness, a system must be sufficiently complete. Your average human being models--maps--reality as best he can. He discovers rules about reality and builds it into his map. When the map is at par with average human intelligence, it is a sufficiently complete, formal system. That map is not a trivial item. Such a system cannot be expressed in an arbitrarily small software program, any more than an arbitrarily small software program can do much to map reality.
<br>
<br>
My term "completeness" is not so slippery that you can slide it into your "formal consciousness". Consciousness is not merely relating the self symbol with just any old thing. You may have missed that little part about objectifying a transcendental cognitive space. Conscousness requires a complete, formal system to jump out of. For a more complete discussion of completeness, I recommend the book I sited in my first post.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9550"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 09/04/2002 1:27 AM by szeldich@netzero.net</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9550" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9550" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>The really hard problem of consciousness is the problem
<br>
                            of experience. When we think and perceive, there is a
<br>
                            whir of information-processing, but there is also a
<br>
                            subjective aspect. As Nagel (1974) has put it, there is
<br>
                            something it is like to be a conscious organism. This
<br>
                            subjective aspect is experience. 
<br>
<br>
Hi, 
<br>
<br>
It looks like the really hard problem of consciousness is the problem of understanding that all our experience is subjective. 
<br>
Intelligence is ability to represent the accessible world.
<br>
Consciousness is function of the system capable to produce own behavior on the base of the own representation.
<br>
<br>
To make the artificial conscious organism we are should give to machine ability to do so.
<br>
<br>
It is rather simple than hard, at least I know how to approach.
<br>
<br>
Michael Zeldich
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9551"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 09/04/2002 2:22 AM by azb0@earthlink.net</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9551" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9551" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Michael,
<br>
<br>
&gt; "It is rather simple than hard, at least I know how to approach."
<br>
<br>
If we conceptualize the world in terms of objects and relationships, then clearly "consciousness" involves acting upon a "self-representation" and its conceptual relation to "other things".  Little else would make sense, and this would be a natural and obvious aspect of a deliberate attempt to enable an artificial consciousness, at least algorithmically.
<br>
<br>
But to claim that consciousness is a _function_ of the system capable to produce its own behavior on the basis of its own representation" is reaching (unless one implies a great deal already by the very word "own".)
<br>
<br>
It is not clear to my why a system cannot manifest behavior based upon its "self-representation relation to other", and do so without every being conscious of doing so "as you or I experience the sensation of consciousness."  As you begin in your post, experience is a "subjective measure", unless one uses "experience" in the simple sense that a block of wood struck by a hammer "experiences a dent".
<br>
<br>
Moreover, I wonder why we are interested in artificial consciousness, as opposed to (merely) superior intelligence?
<br>
<br>
The only reason I can imagine is that we want to be sure we are not "hurting" an artificial being, to determine if and when it should have the "rights" we bestow upon advanced sentience.
<br>
<br>
Cheers! ____tony b____
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9726"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Self<br><span class="mindxheader"><i>posted on 09/11/2002 7:40 PM by daniel@singdango.net</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id9726" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9726" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>As a layman, I'm struck by the number of times
<br>
the word "self" comes up in the responses. The
<br>
original essay studiously avoids the term.
<br>
Personally, I think "self" is the key to the
<br>
puzzle. All the rest seems to be attributes-of-
<br>
a-self.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id19116"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Self<br><span class="mindxheader"><i>posted on 07/27/2003 4:14 PM by <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/profile.php?id=201">prothe113</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id19116" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D19116" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>This hits the nail on the head.  Consciousness is just the experience of "self" incarnate.  These phenomena must happen "to" something (the thinking goes) -- and that "thing" is the essence or experience of being "in" something -- that's the "selfness" of that thing.  So experience is simply the result of very explainable physical processes impinging upon a "self."  But "self" is actually the problem.  What is "self?"  Who does the experiencing?  What is it that experiences?
<br>
<br>
At the risk of getting mystical, these are some of the core problems pondered by one of the deepest schools of metaphysics -- Buddhism.  I'm not talking about the karma and reincarnation malarky, but the core questions.  What is self?  What experiences?
<br>
<br>
Part of the problem is what the Buddhists call "finger pointing at the moon."  This is the old metaphor of the master pointing at the moon, and the student mistaking the finger for the moon.  Another way of saying it is that the map is not the terrain.  The best model of a thing or process is that thing or process itself.  The point of language is to reduce (hence reductionism) the chaotic complexity of the world down to a manageable set of symbols -- hence "dog" instead of the billions of details that make up the experience of a dog.  But asking the word "dog" to BE a dog is impossible -- it's contradicting the fundamental point of language, which is to reduce and symbolize.  Remember that logic is just an extension (and formalization) of language, and mathematics is just logic encoded.  All of these representational systems can never recreate the original thing through representation.  That's the fundamental POINT.
<br>
<br>
This is why everybody knows what I mean when I say that "light of a certain wavelength and chemicals in the air producing a particular olfactory pattern" is NOT a rose.  It's a particular (scientific language) representation of some aspects of a rose (its appearance and smell) but it completely ignores other aspects (the role of the rose in mythology, the evocative feelings it brings up in me, the sharp prick of the thorns).  I can heap symbol upon symbol and produce a clearer representation of the rose, but it's asymptotic -- I can never achieve a REAL rose through language (or its children, logic, math, and science).
<br>
<br>
So science can never recreate consciousness simply because consciousness is a "brute fact" -- something in the world that just IS.  Science can DESCRIBE it and REDUCE it to functional parts, but it cannot recreate it.  And the "explanatory gap" that Chalmers struggles with is precisely another way of apprehending this inability.  "Consciousness" is the thing being described.  The language of science and biology is the inexact tool being used to represent it.  Never the twain shall meet...  Language can never recreate ANYTHING.
<br>
<br>
Given the limitations of language however, can we even use language to DESCRIBE this mysterious, elusive "self?"
<br>
<br>
A bodily description is unsatisfactory because the body can be divided, and because there's not a clear delineation between any part of the body and the "rest of the world."
<br>
<br>
A description of "self" as the result of neurochemical reactions is probably more accurate, but it leads us to the inevitable and disturbing conclusion that "self" is just an ephemera -- it's the result of a number of brain circuits producing a particular feeling.
<br>
<br>
This is difficult to grasp, because so many things that we assume about the world seem to require a "self."  How can there be any action if there is no "self?"  Who does the action?  If I am not "me" then who am I?
<br>
<br>
But also note that these are just word games.  There's no concrete fact about the world that REQUIRES there to be such a thing as "self."  In fact, almost every line of objective evidence leads us back to the inevitable conclusion that "self" (that feeling that I'm a unique, discrete individual) is just a sometimes convenient illusion.  It's a tool.  In fact, it's the basis for all dualistic thinking; it's the original distinction.  All distinctions start from me/not me.  Since making distinctions is the purpose of language (saying the ball is blue implies that it is both not a box and not red, among infinite other things), you could say that the CONCEPT of self is the basis of language, logic, math, and science.  But just as the map is not the terrain, so in this case the CONCEPT is not the same thing as reality.  When we mistake the useful CONCEPT of self-as-separate-thing for a REAL thing that must reside SOMEWHERE or be the result of SOME physical process, we get into epistemological hot water.
<br>
<br>
Self is an illusion created by the workings of the brain.  It most likely evolved to support the useful traits of language and logical thought.  However it's not a real thing in any physical sense.  It's not even a real concept; rather it's an epistemological brute fact -- I exist, therefore I can think (with apologies to R. Descartes).
<br>
<br>
A concept can be useful in one domain but not another -- for instance, relativistic effects are useful at the macro scale, but irrelevant at the quantum level, and vice versa, leading to one of the great current unknowns of physics.  Similarly the concept of "self" is useful as a basis for language and logic and science, but it's woefully inadequate when brought into the experiential realm, as it's by definition THAT WHICH EXPERIENCES.  Any further definitions instantly become circular.  It's important to figure out what the right tool for the job is, and language and science, which are tools born of the concept of self, are not useful for examining the validity of the concept of self -- they assume what they're investigating.
<br>
<br>
And without "self" the whole "hard problem" of consciousness simply evaporates.  Once we quit trying to use a screwdriver to pound in nails and switch to our epistemological hammer, things proceed more smoothly.
<br>
<br>
This is very wordy, but there's no direct way to express the idea that self is an illusion, a convenient one, but an illusion nonetheless.  In words, you end up forced to "talk around" it, which tends to become pretty convoluted and metaphysical rather quickly.  
<br>
<br>
Good luck unraveling this.  I need to formulate this more concisely and coherently, since I've been forced to retype essentially this theory (there is no self) several times now...
<br>
<br>
-- Tom
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id14572"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 02/08/2003 2:26 PM by Pav1</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id14572" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D14572" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I think a system as complex as the brain can be modelled by studying its behaviour, but cannot be reproduced as easily.
<br>
<br>
The nervous impulses emanating from our eyes manifest themselves to us as sight along with advanced features such as motion detection and recognition, courtesy of those neural nets in our brains. Pain is also a manifestation of nerve impulses. Therein lies the problem. This manifestation cannot be reproduced electronically. That lump of robotic wires can 'know' but cannot 'hurt' - in the sense that a human 'hurts'. For how do you manifest pain electronically? According to me, that is the true mystery.
<br>
<br>
This area has been covered by Isaac Asimov - he mentions brains that are positronic, rather than electronic (the correlation of quantum mechanics to thought isnt going to get us anywhere, but no doubt its convenient :-) ); The robots he conceived of are capable of 'feeling', and he reminds us that we should accept the fact that machines modelling the human brain are due the same levels of respect.
<br>
<br>
The mechanism of feeling, it seems to me is a multistep  process. The brain first registers the impulse received, and the fact that something has been registered causes subsequent nervous impulses which are manifested as 'feeling'. Neuronic processing is circular in nature, with layers of 'feedback' to other layers.
<br>
<br>
Conciousness - its like a daemon, running in the background, tracking the total of all impulses received from all senses, plus any 'thoughts going through our minds'... if we  focus our attention to it, the thought processes/ neural activity can be 'felt', because the impulses being registered are causing subsequent impulses manifested as 'feeling'.
<br>
<br>
One possible way of looking at it from a neural structure point of view can be that there are two kinds of structures - those which compute, and those which track the computation, manifesting what we call conciousness.
<br>
<br>
Conciousness is then, by my definition, simply the awareness of neural activity itself.
<br>
<br>
P.S. Gosh its 4 am - gotta get to bed - please disregard the above as crap without taking due offence.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id14598"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 02/09/2003 1:30 AM by zoe</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id14598" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D14598" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>i think we need to not make any problems
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id19177"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 07/31/2003 7:08 PM by <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/profile.php?id=35">grantcc</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id19177" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D19177" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>It seems to me that too many people are trying to explain the emergence of a system that is greater than the sum of its parts by simply examining the parts.  Understanding the parts is necessary for an explanation but not sufficient.  I think the "hard" part of the problem is explaining how the parts in combination produce something above and beyond what each part is capable of contributing to the process.  A solution to the problem may lie in theories about complexity that are being developed by the Santa Fe Institute.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id20322"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 09/23/2003 3:33 AM by <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/profile.php?id=651">Specter</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id20322" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D20322" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I'm a year late posting. I suppose this is for posterity's sake. I very much enjoyed the article. I have a couple comments about conscioiusness, at least human consciousness. There are a number of Buddhist writings on the matter. The general agreement between the various sects is that consciousness is transitory in nature. At any given time it is a belief that we are whatever that state is that we are focused on. Every state holds a certain number of behaviors, emotions, attitudes, and beliefs. We tend to verify this belief of who we are, or of our own consciouisness, by comparing ourselves to others, especially others in similar states. And so consciousness tends to take on a belief of what a group, community, or society believes it is or should be. Buddhism believes that pure consciousness really cannot be measured or observed because it really isn't manifested in a physical sense, thus the reason for a body, to house and allow consciousness to experience. Zen texts go on to say that this consciousness is not truly separate in the sense that there is really a "you" and really an "I". Instead it is more of an all-inclusive "I". Instead it, in a sense, separates itself to become a "you" and an "I" so that it has a way of experiencing. Yoga texts explain this phenomenon by asking the question, "How can the eye observe itself?" This idea of conscioiusness needing and object so that it can become a subject and therby identify and understand itself is in a number of psychological theories. Probably the earliest that comes to mind is by Martin Buber, a Jewish mystic, who wrote, "I and Thou". What I'm saying is that maybe you're chasing a phantom of your own creation. If we don't even understand our own consciousness, as Buddhists believe, it is transitory in nature, then how can we truly apply this to AI? And yet wouldn't we truly be missing the whole experience of the attempt to explore consciousness, both human and AI? 
<br>
While I'm rambling, my answer to the author's question of why we have such rich internal experiences from physical experiences is based on a more esoteric theory. That theory proposes that the body is made up of a number of major systems, each complemented by a number of subsystems. As the experience of the physical system moves through the other systems it triggers further textures and meanings that the physical system itself cannot supply. The Zen theory of any phenomenon is that it is experienced in small packets of space and time called Nen. These Nen are are processed by the body in 3 ways simultaneously. There is the actual raw experience, there is the observation of the experience, and there is the interpretation of the observation of the experience. I'm going much farther than I thought I was going to go. I guess I had more than I thought. There is much more that I wish to say but my point is that if you look at human functioning, really look, you can see that almost everything a human does, thinks, even feels, cal be likened to a very sophisticated computer housed in a very sophisticated body. These notions have been theorized over and over again by Yogis and Buddhists probably for thousands of years. Certain Yogic texts actually call it science, but it isn't objective science. It is considered a subjective science of one's inner and outer life. Please consider that maybe much of your work about consciousness has been done if you look in other areas. I wish you much luck. In Buddhism the journey itself is enlightenment. 
<br>
<br>
Happy awareness-seeking
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id30346"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 01/12/2005 10:44 AM by <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/profile.php?id=1513">anyguy</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id30346" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D30346" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I think conciousness is something that comes with your ability to control your environment. Toolmaking or  technology. Put some more order to your environment (R. Kurzweil, Law of Time and Chaos) and soonly you will reach a perception of time. Because you have control on the sequence of events.
<br>
<br>
Conciousness is an inevitable phenomenon simply because at certain point you have so much control over and intervention with the physical world around that you suddenly find your self to be 'I', the very subject(1). Since you have the capacity to act like one.
<br>
<br>
 Counciousness may be defined as constructing a conceptual interaction among self, universe and time. Time comes with conciousness, when you have so much control over the universe (or in a way your self,)- lets say, being able to mate, eat anytime you want, either because you have better tools or intellect to hunt or collect and keep-; then a different or more meaningful sequence of events comes to your perception.  Simply because you have at some degree, control over it, enough to make it a sequence, in other words create information.   
<br>
<br>
(1) Gottlob Frege, the great logician of the early 20th century, made the obvious but crucial observation that a first-person subject has to be the subject of something. In which case we can ask, what kind of something is up to doing the job? What kind of thing is of sufficient metaphysical weight to supply the experiential substrate of a self ' or, at any rate, a self worth having '
<br>
<br>
R.Kurzweil's
<br>
<br>
Law of Accelerating Returns As order exponentially increases, time exponentially speeds up (i.e., the time interval between salient events grows shorter as time passes).
<br>
Law of Increasing Chaos As chaos exponentially increases, time exponentially slows down (i.e., the time interval between salient events grows longer as time passes).
<br>
Law of Time and Chaos In a process, the time interval between salient events (i.e., events that change the nature of the process, or significantly affect the future of the process) expands or contracts along with the amount of chaos.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id30687"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 01/24/2005 4:54 PM by <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/profile.php?id=1674">itopal</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id30687" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D30687" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p> <center><p class="mindxquote">  I've seen research which indicates our body responds to possible danger before we consciously realize what's happening.  </p></center>
<br>
1.) Option 1: That would simply be a delay in transmission to the cerebral cortex; your lower more primitive areas; functioning; your lower brain reacting; motorizing; your body parts; or causing adrenaline to be released; prior to arrival in the higher level; or arena of a complex sensory experience processing (the cerebral cortex). 
<br>
2.) Option 2: You did perceive it, but not sure how. Example: it might be a inaudible sound wave detected yet not heard in terms of a audible sound, or a scent you are unaware you are smelling.
<br>
__________________________________________________  _______
<br>
<br>
After reading the article and all the subsequent posts;
<br>
I have a few general comments:
<br>
<br>
Some of the attempts to define 'consciousness' sound like typical philosophical obfuscation.
<br>
<br>
The first error is the assumption consciousness exists.
<br>
That would lead you to believe you can create it, replicate it.
<br>
Simulate it - yes.
<br>
My assumption is that: you can simulate mind, reduce a mind to processes without 'consciousness' this seems more plausible, the philosophical implication being no 'ghost' in the AI-machine, nor in the biological-machine.
<br>
<br>
The complexity of sensory experiences does not equate to the mystical ambiguity of the term: consciousness. 
<br>
Nor does a centralized experience of simultaneous multiple sensory inputs; simultaneous multiple sense processing; of experiences equate to the mystical ambiguity of the term: consciousness.  This is just complexity of mind.
<br>
<br>
A plant in a sense has consciousness; in terms of a sensory experience, it is heliotropism - the ability to determine; by sensory perceptions; the location of the sun; and to modify its physical structures, by turning itself in the direction of the sun, in response to that sensory input determination.
<br>
<br>
But this (plant example) is not complexity of mind, nor does it 'feel' like it implies 'consciousness' in terms of what we want to consider what our human 'consciousness' is.
<br>
<br>
It seems to me the reason why we feel 'consciousness' has more to do with the complexity of emotional effects on perception; the feel of an experience; the senses them-self; together with the brains ability to store the knowledge of a 'feeling' along with the associated imagery; or vice versa. 
<br>
<br>
Idea!
<br>
To make a AI-robot think it possesses consciousness would require an intricate and integrated component structure that makes the AI-mind think it's feeling; it mirrors the complexity of feeling. Without a sensory feel to all of reality, we will not be able to delude an AI-mind into thinking that it is consciousness.
<br>
<br>
A robot would not just calculate the temperature of a fire when it put its robot finger into the flame. It would feel pain and react to the pain; not the calculation. Then its AI-mind would have to be able to contemplate upon that experience; and store the feel along with value along with imagery and there be a connection bound in the memory of such. Even then it would still be a simulation. Unless the complexity becomes so great the AI-mind can't tell it's a simulation, then the delusion of mystical 'consciousness' would be complete and it (AI) might think that it was 'conscious.'
<br>
<br>
It seems to me that an experience is a coalescence of multiple centers of sensory experience; including feeling the experience; we remember the feeling as well as words and/or imagery.
<br>
<br>
Idea!
<br>
Remove emotion and all of the 'feel' from experiences and a human; lacking this additional coloring of all experiences; might conclude that it is merely a living thinking machine. The living thinking machine might conclude there is no such thing as this mystical ambiguity called 'consciousness.'
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id48632"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 09/30/2005 5:57 PM by <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/profile.php?id=2209">Scottbert</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id48632" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D48632" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Okay, I'm many years late and haven't read all the discussion up to this point, but I felt the need to post my thoughts. I wonder how many posts just like this one, in intent and perhaps content, are already here.
<br>
<br>
At first reading this, I feared that the entire article would go on and on about how all attempts to explain consciousness have failed, and thus it cannot be explained - I was pleasantly surprised by just how far the article went. An interesting thing to me is that I inferred ahead of the article at one point - as soon as Experience was proposed to be a basic thing like electromagnetism or gravity or matter or force, it did occur to me to wonder then, what if everything has experience? 
<br>
<br>
As given with the later example of mouse and thermostat, I pondered similarly the experiences of a dog and a cardboard box, and the moral implications. Hypothetically, if a cardboard box or thermostat has experience, is it immoral to damage such an object? It seems to me that the reason we consider causing physical damage to people and animals immoral is that it causes them unpleasant experiences, those of pain and perhaps of reduced quality of life after the injury. First off, of course, a thermostat has no structure through which to sense pain, but even a paralyzed person might dislike the idea of having their immobile, unfeeling body damaged. Perhaps tommorrow I'll look back at this post and laugh at myself for writing a sentence like this, but if a thermostat had experience, it would be an experience incapable of concieving of, let alone actually having, any desire for its 'body' to continue in an undamaged state, or even, supposing that information gives rise to experience, to concieve of or experience fear for its ability to measure temperature, and thus its experience, destroyed. Animals, on the other hand, have an interest in survival even if they lack the capacity to philosophize about it.
<br>
<br>
And with that out of the way, now I'm typing as I think. What just popped into my head, then, is the question of, would it be immoral to, say, destroy a computer? It certainly is capable of processing a lot of information, and thus may have complicated experiences. But another component I think the article mentioned was not only the ability to process information, but to act on it, and a computer cannot act on its own. Of course, neither can a paralyzed person. Hmm. Obviously, I consider destroying the paralyzed person to be immoral, unless they desire it... I guess the question here then is what gives rise to a desire for continued existence in the first place? Humans, for example, normally desire to continue to exist. Suicidal humans are so because they feel that no experience would be better than their present, extremely unpleasant experience. Perhaps a question to pursue here is, for something to desire life, must it be capable of, in some theoretical situation, desiring death? But before even pondering what gives rise to the capability to desire death, it comes to mind there should be observable evidence, since I've postulated that animals desire continued existance, that animals in terribly unpleasant situations might desire death. Animals may not be smart enough to take drugs, but they're smart enough to think of _something_, surely. I've never heard of any reports of suicidal animals, but that could be because I lack any fascination with death and so would not have gone out of my way to encounter such accounts. Anyway, at the moment I feel like saying animals have enough experience to desire continued life, so I shall continue on that assumption.
<br>
Now where was I? Ah yes, what makes the paralyzed person different from the computer? Perhaps it is that the paralyzed person was once able to affect his environment of his own free will, and even after losing it retains something that allows him to wish he could affect it, and thus wish for continued life or an end thereto. Perhaps it's more than that - humans wish for events they cannot bring about (or see a way to bring about) all the time. Two things to me occur quick in succession after this: First, that humans are different from almost all animals in that they can actually achieve far more than what is implied by the physical limits of their bodies - they can make and use tools to do things impossible for an unaided human. Following this, humans are able to _concieve_ of doing such things. I can concieve of building some powerful machine, and I can concieve more abstract things like making a great scientific discovery.
<br>
Clearly it is impossible for a being to do such things purposefully without the ability to concieve of them first. Therfore, humans (or rather, their ancestors) must have first developed the ability to _concieve_ of abstracts such as '_what if_ I chip parts of this rock off with another rock until I get something sharp?' before actually doing things like tool use. I suppose perhaps to some extent tool use could be instinctual, but at some point scientific understanding, however basic and limited, is required.
<br>
Now back to the computer. It processes a lot of information, but it is told how to process it - all of it. Even 'empty' hard drive space. Perhaps there is an experience related to all those electrons moving around, but there is no structure to support memory of that experience or for the computer to concieve of anything or even just think at all on its own. So, this is different from the experience of, say, an intelligent computer program itself, which could have structures in place to use RAM and hard drives for memory and self-guided cognition.
<br>
At first, a computer program seems different from a human because it lives in an electronic world, isolated from the physical world or any way of feeling with the box that houses it. But that's no different from the idea of a human mind hooked up, Matrix-like, to nonphysical world. And of course, it could be given a robot body. Though at first I'm still imagining this imaginary electronic entity living inside the hard drive rather than as a living thing complete with body, but when I think about it, it's no different from humans - whatever causes experience as humans know it, it is somehow tied to psychological processes that go on in our brain, even if we don't know how they work or understand our brain's counterpart to, say, the computer's file system.
<br>
Of course, there is no logical reason why an intelligent computer program by definition must understand how its 'brain' works at the basic level. Heck, it wouldn't even have to know how to use a computer!
<br>
Perhaps that's a problem with one typical mental image of a new AI. When I think of an artificial intelligence being developed, my first mental image is of a program that, aside from being able to think and remember, all it can do is send and recieve text. But perhaps it is impossible to develop an AI that way. Certainly you could take a fully-developed AI program (and thus one that already has memory of concepts) and stick it in a box with nothing else to do, but it would be impossible to develop an AI into that state, just as humans did not evolve as hugely intelligent brains with nothing to do. A human blind, deaf, numb, and paralyzed from birth would develop retarded, even if medicine restored its body and senses as an adult. The ability to be aware of words alone will never give rise to the cognitive processes necessary to understand them. But now I'm back in territory already covered by that Cog project, though I postulate that the physical world needn't necessarily be the world an AI is developed in - a virtual approximation would probably do as well, as long as anything the AI needs a physical understanding of can exist in it.
<br>
All this still leaves me with one question: Why did humans develop the ability to understand, to think about, to process _ideas_? I can't think of an answer to that, perhaps it was only a random chance mutation. (The question is only what started it, why humans' ancestors developed the ability in the first place - once they've got it, there's a clear evolutionary advantage to being better at it, and chance mutations in being slightly better or slightly worse at something an organism can already do seem reasonably likely compared to the chance of just developing a new ability, one like nothing before, out of the blue. Perhaps it's a natural development of something else - I can imagine instinctive use of very simple, natural tools, and perhaps the mental processes involved in that start a creature down the path of intelligence... or not, if some other niche proved more evolutionarily useful, which would explain why, if apes and humans share a common ancestor, apes didn't evolve to be just as smart as we are.)
<br>
Anyway, I think I've been writing and thinking for like an hour or so now, and so I caution that everything I've typed, especially near the end, may not have been thought through clearly (evolutionarily doesn't sound like a real word...). In any case, you now have a window into the train of thought of a human with ADD philosophising. Thank you, and goodnight.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id75408"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 02/03/2007 6:56 PM by <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/profile.php?id=3755">ellumbra</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id75408" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D75408" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>An age old topic, so no penalties for adding a reply 2 years later.
<br>
To my mind, this topic spins upons a very fine point, like a top spinning, a dog chasing it's own tale. Would we agree that at the precise centre of the point (does such a point exist at all?) upon which it spins there is a place of stillness, where nothing is spinning?
<br>
Unfortunately, philosophical discussions are sometimes deemed to be at odds with rational, traditional scientific methods (for whatever reasons).
<br>
When it comes to the subject of consciousness however, I feel that the answers may only come through philosophical debate.
<br>
<br>
My reasons are as follows:
<br>
<br>
*Consciousness is purely and entirely known subjectively. It may be deduced objectively, but not experienced.
<br>
*The only suitable method of studying consciousness therefore is with consciousness itself. No other means can measure or have access to it accurately or meaningfully.
<br>
*Consciousness belongs, holistically in the universe. It only has meaning when viewed holistically in our lives. It is the central point at which all our internal/external activity is experienced, felt, known. 
<br>
It is the knowledge of being.
<br>
*It is so profound, that this universe possesses consciousness, that I would go so far as saying that it is THE most profound aspect.
<br>
<br>
I know little of any use about quantum physics, wave theory, ERM etc. But the previous poster did make (to me) a lot of sense.
<br>
My life only makes sense to me when I view it holistically, not stripping it down to a list of components. The universe will only make sense when viewed holistically (some task, eh?). Certainly not by reducing it's most profound aspect to "just another component".
<br>
What possible rhyme or reason could there be, for a whole universe (OK we're bordering on the "spiritual" now folks, hold on to your tempers) this whole creation without consciousness?
<br>
That would simply reduce everything to non-feeling, non-knowing robotics, even at it's highest level.
<br>
Ultimately, everything, from the big bang, backwards &amp; forwards in time must be viewed holistically, at which point all of us must throw in the towel and concede to some sort of power being responsible for the whole conception.
<br>
Consciousness, in it's mind numbing novelty, it's awesome originality (it is isn't it?)surely is not a bi-product, a side effect?
<br>
<br>
BOLD STATEMENT:
<br>
Science will never touch consciousness.
<br>
All matter is conscious, because that consciousness itself is the finest, most subtle form of energy that exists, therefore it is everywhere, all at once, in all things and is self-knowing.
<br>
It is indestructable. 
<br>
It is experienced by all things (as that is it's nature) but can only be expressed or demonstrated or acted upon by those things that have the wherewithall to express, demonstrate or act upon it.
<br>
It can only be known by those things that have the ability to reflect upon it.
<br>
Or you could say "It is the holy breath within creation".
<br>
<br>
I tried to crystalise these thoughts poetically
<br>
some while ago:
<br>
<br>
The Zen garden
<br>
A moment of stillness
<br>
Petrified in time
<br>
Ripples in the gravel
<br>
So devotionally raked
<br>
Halted in their disturbance
<br>
Caught in mid pace
<br>
Shades of grey
<br>
The middle path they say
<br>
Between black and white
<br>
Half the way to certainty
<br>
<br>
Worn smooth
<br>
By mountain torrents
<br>
Quite at ease
<br>
Though far from home
<br>
The centrepiece
<br>
A dome of stone
<br>
Frozen
<br>
Flexing its back
<br>
Like a cat
<br>
A glimpse perhaps
<br>
A crack in continuity
<br>
A portal for intuition
<br>
Sentient feeling
<br>
Knowledge and will
<br>
Always existed
<br>
<br>
Soon after
<br>
That first long
<br>
Wistful sigh
<br>
When space
<br>
Clotted into worlds
<br>
Before the gardener came
<br>
To rake and tend
<br>
Were stones the guardians
<br>
Of awareness
<br>
Perfectly at one
<br>
Silent and sure
<br>
Today tomorrow
<br>
And evermore
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id75418"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 02/03/2007 11:27 PM by <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/profile.php?id=3414">mystic7</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id75418" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D75418" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Thanks mindxmoderator for that post. I found that very enlightening. I like Chalmers idea that experience is a fundamental of the cosmos like matter and energy.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id75977"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 02/14/2007 8:09 AM by <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/profile.php?id=2832">extrasense</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id75977" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D75977" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>It should be said, that this article is real stuff. It passes the smell test that 99.9% of the articles that are discussed here fail :)
<br>
<br>
e:)s
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id86225"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Facing Up to the Problem of Consciousness<br><span class="mindxheader"><i>posted on 09/16/2007 4:08 AM by <a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/profile.php?id=4839">NotEqualwithGod</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9076%23id86225" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011094955/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D86225" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I think we have to begin understanding our experience of Consciousness under the idea that a part(s) (i.e. redundancy) of the brain is specialized at integrating all the other specialized data into a unified/focused point which we call our "awake" state.  When we experience consciousness, we are really looking at the DATA inside our visual memory, we aren't experiencing the "outside world" so much as we are experiencing the "inside world".
<br>
<br>
"Subjective experience" is simply a "modality", in other words they are irrelevant.
<br>
<br>
If we really think about it "objective" and "subjective" as concepts break down, we all experience consciousness in our minds imagination, we don't experience outside ourselves, we experience the outside world from the inside out, not vice versa.  
<br>
<br>
I think "phantom limb" syndrome seen in amputees is an excellent example of subjective experience being "hardwired" or "hardcoded" into the brains modalities, what we experience as subjective is in fact simply the result of how that part of the brain is structured to interpret the world.
<br>
<br>
I really don't see "reductionism" is such a problem, I think it's really a matter of understanding the physics of it.  We simply are not advanced enough (in terms of physics + biology + information science) to figure it out just yet.
<br>
<br>
Our consciousness is really is only possible because the certain part of the brain controlling ou awake vs non-awake state is functioning, 
<br>
<br>
We might call this "consciousness center" the 'integrated awake modality', where seperate specialized networks in the brain are connected to each other each other in "Unified rings", that make sense disparate data and this data is woven together in real time (literally woven out of data in the 'subconscious' autonmous processes of our mind).
<br>
<br>
There's a reason the brain tries to connect neurons to so many other neurons, it's this ability to take any data and translate it back and forth between the different formats other modalities (parts of the brain) use, since there what the brain really is, is a fractal similarity engine, it can make and find extremely comparisons and relationships in mere seconds.
<br>
<br>
We also INVENT new relationships and create new objects on the fly depending on the data, I think of it like Set theory, we create and destroy sets of information over time depending on use and value to the mind.
<br>
<br>
You can also see our minds ability to find complicated fractal relationships, in our metaphors and analogies, THIS is SIMILAR to THAT because it has these similarly shaped data-elements (patterns).
<br>
<br>
When the things we're speaking about are damn complex and "subjective" (i.e. vague, we don't even understand its structure of what we perceive consciously as discrete units of data or signals).</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011094955im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p>
<td>&#160;</td>




</html>