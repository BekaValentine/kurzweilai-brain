<html>
<head><base href="https://kurzweilai-brain.gothdyke.mom/"><link href="articlemaster.css" rel="stylesheet" title="style1" type="text/css">
<style>
.sidebar {border-left-width: 2px; border-right-width: 0px; border-top-width: 0px; border-bottom-width: 0px; border-color: #000000; border-style: solid; padding-left: 12px;}
</style>
<title>Essentials of General Intelligence: The direct path to AGI</title>
</head>
<body leftmargin="0" marginheight="0" marginwidth="0" topmargin="0"><div id="centering-column"><div id="header">
  <div id="logo">
    <img src="logo.gif" />
  </div>
  <div id="title">
    <h1>Brain Archive</h1><br />
    <a href="">Entry Index</a>
  </div>
  <div class="clearer"></div>
</div>
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" height="100%" width="780">
<tr height="100%">
<td align="left" valign="top">
<table align="center" bgcolor="#EEEEEE" border="0" cellpadding="0" cellspacing="0" width="780">
<tr>
<td><img alt="" border="0" height="5" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/blank.gif" width="20"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/blank.gif" width="90"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/blank.gif" width="375"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/blank.gif" width="200"></td>
<td><img alt="" border="0" height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/blank.gif" width="30"></td>
</tr>
<tr>
<td> &#160; </td>
<td colspan="5"> <span class="breadcrumb"><a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/" target="_top">Origin</a> &gt;
 <a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/meme/memelist.html?m=3">How to Build a Brain</a> &gt; 
Essentials of General Intelligence: The direct path to AGI
<br>
Permanent link to this article: <a href="http://web.archive.org/web/20071011200143/http://www.kurzweilai.net/meme/frame.html?main=/articles/art0513.html" target="_top">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0513.html</a></span>
<br>
<a class="printable" href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/articles/art0513.html?printable=1" target="_new">Printable Version</a></td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="50" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/blank.gif" width="1"></td></tr>
<tr>
<td> &#160; </td>
<td> &#160; </td>
<td valign="top"><span class="Title">Essentials of General Intelligence: The direct path to AGI</span>
<br>
<span class="Subtitle"></span>
<table border="0" cellpadding="0" cellspacing="0">
<td valign="top"><span class="Authors">by &#160;</span></td>
<td><span class="Authors">
<a class="Authors" href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/bios/frame.html?main=/bios/bio0202.html" target="_top">Peter Voss</a><br></span></td>
</table>
<br>
<div class="TeaserText">General intelligence comprises the essential, domain-independent skills necessary for acquiring a wide range of domain-specific knowledge -- the ability to learn anything. Achieving this with "artificial general intelligence" (AGI) requires a highly adaptive, general-purpose system that can autonomously acquire an extremely wide range of specific knowledge and skills and can improve its own cognitive ability through self-directed learning. This chapter in the forthcoming book, Real AI: New Approaches to Artificial General Intelligence, describes the requirements and conceptual design of a prototype AGI system. </div>
<br>
<br> <h1>1. Introduction </h1>
<p>This paper explores the <a class="thought" href="entries/concept_entry.html">concept</a> of "artificial <i>general</i> <a class="thought" href="entries/intelligence_entry.html">intelligence</a>" (AGI) -- its
<a class="thought" href="entries/nature_entry.html">nature</a>, <a class="thought" href="entries/import_entry.html">import</a>ance, and how best to achieve it. Our<a href="#_ftn1" name="_ftnref1" title="">[1]</a>
theoretical model posits that general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> comprises a limited <a class="thought" href="entries/number_entry.html">number</a>
of distinct, yet highly integrated, foundational functional <a class="thought" href="entries/component_entry.html">component</a>s.
Successful <a class="thought" href="entries/implement_entry.html">implement</a>ation of this model will yield a highly adaptive,
general-purpose <a class="thought" href="entries/system_entry.html">system</a> that can autonomously acquire an extremely wide range of
specific <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and skills. Moreover, it will be able to improve its own
cognitive ability through self-directed <a class="thought" href="entries/learning_entry.html">learning</a>. We believe that, given the
right design, current <a class="thought" href="entries/hardware_entry.html">hardware</a>/ <a class="thought" href="entries/software_entry.html">software</a> <a class="thought" href="entries/technology_entry.html">technology</a> is adequate for <a class="thought" href="entries/engine_entry.html">engine</a>ering
practical AGI <a class="thought" href="entries/system_entry.html">system</a>s. Our current <a class="thought" href="entries/implement_entry.html">implement</a>ation of a functional prototype is
described below.</p>
<p>The idea of "general <a class="thought" href="entries/intelligence_entry.html">intelligence</a>" is quite controversial; I
do not substantially engage this debate here but rather take the <a class="thought" href="entries/existence_entry.html">existence</a> of
such non <a class="thought" href="entries/domain_entry.html">domain</a>-specific abilities as a given (Gottfredson 1998). It must also be noted that this essay focuses
primarily on low-level (i.e. roughly <a class="thought" href="entries/animal_entry.html">animal</a> level) cognitive ability.
Higher-level functionality, while an integral part of our model, is only
addressed peripherally. Finally, certain <a class="thought" href="entries/algorithm_entry.html">algorithm</a>ic details are omitted for
<a class="thought" href="entries/reason_entry.html">reason</a>s of proprietary ownership.</p>
<h1>2. General <a class="thought" href="entries/intelligence_entry.html">Intelligence</a> </h1>
<p><a class="thought" href="entries/intelligence_entry.html">Intelligence</a> can be defined simply as an <a class="thought" href="entries/entity_entry.html">entity</a>'s ability to
achieve goals -- with greater <a class="thought" href="entries/intelligence_entry.html">intelligence</a> coping with more complex and <a class="thought" href="entries/novel_entry.html">novel</a>
situations. <a class="thought" href="entries/complexity_entry.html">Complexity</a> ranges from the trivial -- thermostats and mollusks (that
in most <a class="thought" href="entries/context_entry.html">context</a>s don't even justify the label "<a class="thought" href="entries/intelligence_entry.html">intelligence</a>") -- &#173;to the
fantastically complex; autonomous flight control <a class="thought" href="entries/system_entry.html">system</a>s and humans.</p>
<p>Adaptivity, the ability to deal with changing and <a class="thought" href="entries/novel_entry.html">novel</a>
requirements, also covers a wide spectrum: from rigid, narrowly <a class="thought" href="entries/domain_entry.html">domain</a>-specific
to highly flexible, general purpose. Furthermore, flexibility can be defined in
terms of <i>scope</i> and <i>permanence</i> -- how much, and how often it
changes. Imprinting is an example of limited scope and high permanence, while
innovative, abstract problem solving is at the other end of the spectrum. While
entities with high adaptivity and flexibility are clearly superior -- they can
potentially learn to achieve any possible goal -- there is a hefty efficiency
price to be paid: For example, had <a class="thought" href="entries/deep_blue_entry.html">Deep Blue</a> also been designed to learn
<a class="thought" href="entries/language_entry.html">language</a>, direct airline traffic, and do medical diagnosis, it would not have
become <a class="thought" href="entries/chess_entry.html">Chess</a> champion (all other things being equal).</p>
<p><i>General</i>
<a class="thought" href="entries/intelligence_entry.html">Intelligence</a> comprises <i>the essential,
<a class="thought" href="entries/domain_entry.html">domain</a>-independent skills necessary for acquiring</i> a wide range of <a class="thought" href="entries/domain_entry.html">domain</a>-specific
<a class="thought" href="entries/knowledge_entry.html">knowledge</a> (<a class="thought" href="entries/data_entry.html">data</a> &amp; skills) -- i.e. the ability to learn anything (in
principle). More specifically, this <a class="thought" href="entries/learning_entry.html">learning</a> ability needs to be autonomous,
goal-directed, and highly adaptive:</p>
<blockquote>
<p>Autonomous -- <a class="thought" href="entries/learning_entry.html">Learning</a> occurs both automatically, through exposure to <a class="thought" href="entries/sense_entry.html">sense</a>
<a class="thought" href="entries/data_entry.html">data</a> (unsupervised), and through bi-directional interaction with the environment, 
    including exploration/ <a class="thought" href="entries/experiment_entry.html">experiment</a>ation (self-supervised).</p>
<p>Goal-directed -- <a class="thought" href="entries/learning_entry.html">Learning</a> is directed (autonomously) towards achieving varying 
    and <a class="thought" href="entries/novel_entry.html">novel</a> goals and sub-goals -- be they "hard-<a class="thought" href="entries/wired_entry.html">wired</a>," externally specified, 
    or self-generated. Goal-directedness also implies very selective <a class="thought" href="entries/learning_entry.html">learning</a> 
    and <a class="thought" href="entries/data_entry.html">data</a> acquisition (from a massively <a class="thought" href="entries/data_entry.html">data</a>-rich, noisy, complex environment).</p>
<p>Adaptive -- <a class="thought" href="entries/learning_entry.html">Learning</a> is cumulative, integrative, <a class="thought" href="entries/context_entry.html">context</a>ual and adjusts to 
    changing goals and environments. General adaptivity not only copes with gradual 
    changes, but also seeds and facilitates the acquisition of totally <a class="thought" href="entries/novel_entry.html">novel</a> abilities.</p></blockquote>
<p>General cognitive ability stands in sharp contrast to inherent specializations 
    such as speech- or face-recognition, <a class="thought" href="entries/knowledge_entry.html">knowledge</a> <a class="thought" href="entries/database_entry.html">database</a>s/ ontologies, expert 
    <a class="thought" href="entries/system_entry.html">system</a>s, or <a class="thought" href="entries/search_entry.html">search</a>, regression or optimization <a class="thought" href="entries/algorithm_entry.html">algorithm</a>s. It allows an <a class="thought" href="entries/entity_entry.html">entity</a> 
    to acquire a virtually unlimited range of new specialized abilities. The mark 
    of a <i>generally</i> intelligent <a class="thought" href="entries/system_entry.html">system</a> is not <i>having</i> a lot of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> 
    and skills, but being able to <i>acquire</i> and <i>improve</i> them -- and 
    to be able to appropriately <i>apply</i> them. Furthermore, <a class="thought" href="entries/knowledge_entry.html">knowledge</a> must 
    be acquired and stored in ways appropriate both to the <a class="thought" href="entries/nature_entry.html">nature</a> of the <a class="thought" href="entries/data_entry.html">data</a>, 
    and to the goals and tasks at hand.</p>
<p>For example, given the correct <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of <a class="thought" href="entries/basic_entry.html">basic</a> core
capabilities, an AGI <a class="thought" href="entries/system_entry.html">system</a> should be able to learn to recognize and categorize
a wide range of <a class="thought" href="entries/novel_entry.html">novel</a> perceptual <a class="thought" href="entries/pattern_entry.html">pattern</a>s that are acquired via different
senses, in many different environments and <a class="thought" href="entries/context_entry.html">context</a>s. Additionally, it should be
able to autonomously learn appropriate, goal-directed responses to such input
<a class="thought" href="entries/context_entry.html">context</a>s (given some feedback mechanism).</p>
<p>We take this <a class="thought" href="entries/concept_entry.html">concept</a> to be valid not only for high-level
<a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, but for lower-level <a class="thought" href="entries/animal_entry.html">animal</a>-like ability. The degree of
"generality" (i.e., adaptability) varies along a continuum from genetically
"hard-coded" responses (no adaptability), to high-level <a class="thought" href="entries/animal_entry.html">animal</a> flexibility
(significant <a class="thought" href="entries/learning_entry.html">learning</a> ability as in, say, a dog), and finally to self-aware
<a class="thought" href="entries/human_entry.html">human</a> general <a class="thought" href="entries/learning_entry.html">learning</a> ability.</p>
<p class="StyleHeading3Heading3Char1Heading3CharCharHeading3Char1">Core
Requirements for General <a class="thought" href="entries/intelligence_entry.html">Intelligence</a></p>
<p>General <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, as described above, demands a <a class="thought" href="entries/number_entry.html">number</a>
of irreducible features and capabilities. In <a class="thought" href="entries/order_entry.html">order</a> to proactively accumulate
<a class="thought" href="entries/knowledge_entry.html">knowledge</a> from various (and/ or changing) environments, it requires:</p>
<p>1. Senses to obtain features from "the world" (virtual or actual),</p>
<p>2. A coherent means for storing <a class="thought" href="entries/knowledge_entry.html">knowledge</a> obtained this way, and</p>
<p>3. Adaptive output/ actuation mechanisms (both static and dynamic).</p>
<p>Such <a class="thought" href="entries/knowledge_entry.html">knowledge</a> also needs to be automatically adjusted and
updated on an ongoing basis; new <a class="thought" href="entries/knowledge_entry.html">knowledge</a> must be appropriately related to
existing <a class="thought" href="entries/data_entry.html">data</a>. Furthermore, perceived entities/ <a class="thought" href="entries/pattern_entry.html">pattern</a>s must be stored in a
way that facilitates <a class="thought" href="entries/concept_entry.html">concept</a> formation and generalization. An effective way to
represent complex feature relationships is through vector encoding (Churchland
1995).</p>
<p>Any practical applications of AGI (and certainly any
real-<a class="thought" href="entries/time_entry.html">time</a> uses) must <i>inherently</i> be
able to process temporal <a class="thought" href="entries/data_entry.html">data</a> as <a class="thought" href="entries/pattern_entry.html">pattern</a>s in <a class="thought" href="entries/time_entry.html">time</a> -- not just as static <a class="thought" href="entries/pattern_entry.html">pattern</a>s
with a <a class="thought" href="entries/time_entry.html">time</a> dimension. Furthermore, AGIs must cope with <a class="thought" href="entries/data_entry.html">data</a> from different
<a class="thought" href="entries/sense_entry.html">sense</a> probes (e.g., visual, auditory, and <a class="thought" href="entries/data_entry.html">data</a>), and deal with such <a class="thought" href="entries/attribute_entry.html">attribute</a>s
as: noisy, scalar, unreliable, incomplete, multi-dimensional (both <a class="thought" href="entries/space_entry.html">space</a>/ <a class="thought" href="entries/time_entry.html">time</a>
dimensional, and having a large <a class="thought" href="entries/number_entry.html">number</a> of simultaneous features), etc. Fuzzy
<a class="thought" href="entries/pattern_entry.html">pattern</a> matching helps deal with <a class="thought" href="entries/pattern_entry.html">pattern</a> variability and <a class="thought" href="entries/noise_entry.html">noise</a>.</p>
<p>Another essential requirement of general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is to
cope with an overabundance of <a class="thought" href="entries/data_entry.html">data</a>. <a class="thought" href="entries/reality_entry.html">Reality</a> presents massively more features
and detail than is (<a class="thought" href="entries/context_entry.html">context</a>ually) relevant, or that can be usefully processed.
This is why the <a class="thought" href="entries/system_entry.html">system</a> needs to have some control over what input <a class="thought" href="entries/data_entry.html">data</a> is
selected for analysis and <a class="thought" href="entries/learning_entry.html">learning</a> -- both in terms of <i>which</i> <a class="thought" href="entries/data_entry.html">data</a>, and also the degree of detail. Senses ("probes") are
needed not only for selection and focus, but also in <a class="thought" href="entries/order_entry.html">order</a> to ground <a class="thought" href="entries/concept_entry.html">concept</a>s --
to give them (<a class="thought" href="entries/reality_entry.html">reality</a>-based) meaning. </p>
<p>While input <a class="thought" href="entries/data_entry.html">data</a> needs to be severely limited by focus and
selection, it is also extremely <a class="thought" href="entries/import_entry.html">import</a>ant to obtain multiple views of <a class="thought" href="entries/reality_entry.html">reality</a> --
<a class="thought" href="entries/data_entry.html">data</a> from different feature extractors or senses. Provided that these different
input <a class="thought" href="entries/pattern_entry.html">pattern</a>s are properly associated, they can help to provide <a class="thought" href="entries/context_entry.html">context</a> for
each other, aid recognition, and add meaning.</p>
<p>In addition to being able to <a class="thought" href="entries/sense_entry.html">sense</a> via its multiple,
adaptive input groups and probes, the AGI must also be able to act on the world
-- be it for exploration, <a class="thought" href="entries/experiment_entry.html">experiment</a>ation, <a class="thought" href="entries/communication_entry.html">communication</a>, or to perform useful
<a class="thought" href="entries/action_entry.html">action</a>s. These mechanisms need to provide both static and dynamic output
(states and behavior). They too, need to be adaptive and capable of <a class="thought" href="entries/learning_entry.html">learning</a>.</p>
<p>Underlying all of this functionality is <a class="thought" href="entries/pattern_entry.html">pattern</a> processing.
What is more, not only are sensing and <a class="thought" href="entries/action_entry.html">action</a> based on generic <a class="thought" href="entries/pattern_entry.html">pattern</a>s, but so
is internal cognitive activity. In fact, even high-level abstract <a class="thought" href="entries/thought_entry.html">thought</a>,
<a class="thought" href="entries/language_entry.html">language</a>, and formal <a class="thought" href="entries/reason_entry.html">reason</a>ing -- abilities outside the scope of our current
project -- are "just" higher-<a class="thought" href="entries/order_entry.html">order</a> elaborations of this (Margolis 1987).</p>
<p>
<p class="StyleHeading3Heading3Char1Heading3CharCharHeading3Char1">Advantages of
<a class="thought" href="entries/intelligence_entry.html">Intelligence</a> being General</p>
<p>The advantages of general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> are almost too
obvious to merit listing; how many of us would <a class="thought" href="entries/dream_entry.html">dream</a> of giving up our ability
to adapt and learn new things? In the <a class="thought" href="entries/context_entry.html">context</a> of <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> this
issue takes on a new significance.</p>
<p>There exists an inexhaustible demand for <a class="thought" href="entries/computer_entry.html">computer</a>ized
<a class="thought" href="entries/system_entry.html">system</a>s that can assist humans in complex tasks that are highly repetitive,
dangerous, or that require <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, senses or abilities that its users may
not possess (e.g., expert <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, "photographic" recall, overcoming
disabilities, etc.). These applications stretch across almost all <a class="thought" href="entries/domain_entry.html">domain</a>s of
<a class="thought" href="entries/human_entry.html">human</a> endeavor.</p>
<p>Currently, these needs are filled primarily by <a class="thought" href="entries/system_entry.html">system</a>s
<a class="thought" href="entries/engine_entry.html">engine</a>ered specifically for each <a class="thought" href="entries/domain_entry.html">domain</a> and application (e.g., <a class="thought" href="entries/expert_system_entry.html">expert system</a>s).
Problems of cost, lead-<a class="thought" href="entries/time_entry.html">time</a>, reliability, and the lack of adaptability to new
and unforeseen situations, severely limit market potential. Adaptive AGI <a class="thought" href="entries/technology_entry.html">technology</a>,
as described in this paper, promises to significantly reduce these limitations
and to open up these markets. It specifically implies -- </p>
<blockquote>
<p>That <a class="thought" href="entries/system_entry.html">system</a>s can learn (and be taught) a wide spectrum of <a class="thought" href="entries/data_entry.html">data</a> and functionality</p>
<p>They can adapt to changing <a class="thought" href="entries/data_entry.html">data</a>, environments and uses/ goals</p>
<p>This can be achieved without <a class="thought" href="entries/program_entry.html">program</a> changes -- capabilities are learned, 
    not coded.</p>
<p>More specifically, this <a class="thought" href="entries/technology_entry.html">technology</a> can potentially:</p>
<p>Significantly reduce <a class="thought" href="entries/system_entry.html">system</a> "brittleness"<a href="#_ftn2" name="_ftnref2" title="">[2]</a> 
    through fuzzy <a class="thought" href="entries/pattern_entry.html">pattern</a> matching and adaptive <a class="thought" href="entries/learning_entry.html">learning</a> -- increasing robustness 
    in the face of changing and unanticipated conditions or <a class="thought" href="entries/data_entry.html">data</a>.</p>
<p>Learn autonomously, by automatically accumulating <a class="thought" href="entries/knowledge_entry.html">knowledge</a> about new environments 
    through exploration.</p>
<p>Allow <a class="thought" href="entries/system_entry.html">system</a>s to be operator-trained to identify new <a class="thought" href="entries/object_entry.html">object</a>s and <a class="thought" href="entries/pattern_entry.html">pattern</a>s; 
    to respond to situations in specific ways, and to acquire new behaviors.</p>
<p>Eliminate <a class="thought" href="entries/program_entry.html">program</a>ming in many applications. <a class="thought" href="entries/system_entry.html">System</a>s can be employed in many 
    different environments, and with different <a class="thought" href="entries/parameter_entry.html">parameter</a>s simply through self-training.</p>
<p>Facilitate easy deployment in new <a class="thought" href="entries/domain_entry.html">domain</a>s. A general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> <a class="thought" href="entries/engine_entry.html">engine</a> 
    with pluggable custom input/ output probes allows rapid and inexpensive <a class="thought" href="entries/implement_entry.html">implement</a>ation 
    of specialized applications.</p>
</blockquote>
<p>From a design perspective, AGI offers the advantage that all
effort can be focused on achieving the best <i>general</i>
solutions -- solving them once, rather than once for each particular <a class="thought" href="entries/domain_entry.html">domain</a>. AGI
obviously also has huge economic implications: because AGI <a class="thought" href="entries/system_entry.html">system</a>s acquire most
of their <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and skills (and adapt to changing requirements) autonomously,
<a class="thought" href="entries/program_entry.html">program</a>ming lead times and costs can be dramatically reduced, or even eliminated.</p>
<p>The fact that no (artificial!) <a class="thought" href="entries/system_entry.html">system</a>s with these
capabilities currently exist seems to imply that it is very hard (or
impossible) to achieve these <a class="thought" href="entries/object_entry.html">object</a>ives. However, I believe that, as with other
examples of <a class="thought" href="entries/human_entry.html">human</a> discovery and <a class="thought" href="entries/invention_entry.html">invention</a>, the solution will seem rather
obvious in retrospect. The trick is correctly choosing a few critical
development options.</p>
<h1>3. Shortcuts to AGI</h1>
<p>When explaining Artificial General <a class="thought" href="entries/intelligence_entry.html">Intelligence</a> to the
uninitiated one often hears the remark that, surely, everyone in <a class="thought" href="entries/ai_entry.html">AI</a> is working
to achieve general <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. This indicates how deeply misunderstood
<a class="thought" href="entries/intelligence_entry.html">intelligence</a> is. While it is true that <i>eventually</i>
conventional (<a class="thought" href="entries/domain_entry.html">domain</a>-specific) <a class="thought" href="entries/research_entry.html">research</a> efforts will converge with those of
AGI, without deliberate guidance this is likely to be a long, inefficient
process. High-level <a class="thought" href="entries/intelligence_entry.html">intelligence</a> <i>must</i>
be adaptive, must be general -- yet very little work is being done to
specifically identify what general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> <i>is</i>, what it <i>requires</i>, and
how to achieve it.</p>
<p>In addition to understanding general <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, AGI
design also requires an appreciation of the differences between <i>artificial</i> (synthetic) and <a class="thought" href="entries/biological_entry.html">biological</a>
<a class="thought" href="entries/intelligence_entry.html">intelligence</a>, and between <i>designed</i>
and evolved <a class="thought" href="entries/system_entry.html">system</a>s.</p>
<p>Our particular approach to achieving AGI capitalizes on
extensive analysis of these issues, and on an incremental development path that
aims to minimize development effort (<a class="thought" href="entries/time_entry.html">time</a> and cost), technical <a class="thought" href="entries/complexity_entry.html">complexity</a>, and
overall project risks. In particular, we are focusing on <a class="thought" href="entries/engine_entry.html">engine</a>ering a series
of functional (but low-resolution/ <a class="thought" href="entries/capacity_entry.html">capacity</a>) proof-of-<a class="thought" href="entries/concept_entry.html">concept</a> prototypes.
Performance issues specifically related to <a class="thought" href="entries/commercial_entry.html">commercial</a>ization are assigned to
separate development tracks. Furthermore, our initial effort concentrates on
identifying and <a class="thought" href="entries/implement_entry.html">implement</a>ing the most general and foundational <a class="thought" href="entries/component_entry.html">component</a>s
first, leaving high-level cognition such as abstract <a class="thought" href="entries/thought_entry.html">thought</a>, <a class="thought" href="entries/language_entry.html">language</a>, and
formal <a class="thought" href="entries/logic_entry.html">logic</a> for later development (more on that later). We also focus more on
selective, unsupervised, dynamic, incremental, interactive <a class="thought" href="entries/learning_entry.html">learning</a>; on noisy,
complex, <a class="thought" href="entries/analog_entry.html">analog</a> data; and on integrating <a class="thought" href="entries/entity_entry.html">entity</a> features and <a class="thought" href="entries/concept_entry.html">concept</a> <a class="thought" href="entries/attribute_entry.html">attribute</a>s
in one comprehensive <a class="thought" href="entries/network_entry.html">network</a>.</p>
<p>While our project may not be the only one proceeding on this
particular path, it is clear that by far the majority of <a class="thought" href="entries/ai_entry.html">AI</a> work being done
today follows a substantially different overall approach. Our work focuses on:</p>
<blockquote>
<p><b>General</b> rather than <a class="thought" href="entries/domain_entry.html">domain</a>-specific cognitive ability </p>
<p><b>Acquired <a class="thought" href="entries/knowledge_entry.html">knowledge</a></b> and skills, versus loaded <a class="thought" href="entries/database_entry.html">database</a>s and coded skills 
  </p>
<p><b>Bi-directional, real-<a class="thought" href="entries/time_entry.html">time</a></b> interaction, versus <a class="thought" href="entries/batch_processing_entry.html">batch processing</a> </p>
<p><b>Adaptive attention</b> (focus &amp; selection), versus <a class="thought" href="entries/human_entry.html">human</a> pre-selected 
    <a class="thought" href="entries/data_entry.html">data</a> </p>
<p>Core support for <b>dynamic <a class="thought" href="entries/pattern_entry.html">pattern</a>s</b>, versus static <a class="thought" href="entries/data_entry.html">data</a> </p>
<p>Unsupervised and <b>self-supervised</b>, versus supervised <a class="thought" href="entries/learning_entry.html">learning</a> </p>
<p>Adaptive, <b>self-organizing <a class="thought" href="entries/data_structure_entry.html">data structure</a>s</b>, versus fixed neural nets 
    or <a class="thought" href="entries/database_entry.html">database</a>s </p>
<p><b><a class="thought" href="entries/context_entry.html">Context</a>ual, grounded <a class="thought" href="entries/concept_entry.html">concept</a>s</b>, versus hard-coded, <a class="thought" href="entries/symbol_entry.html">symbol</a>ic <a class="thought" href="entries/concept_entry.html">concept</a>s 
  </p>
<p>Explicitly <b><a class="thought" href="entries/engine_entry.html">engine</a>ering</b> functionality, versus evolving it</p>
<p><b><a class="thought" href="entries/concept_entry.html">Concept</a>ual design</b>, versus reverse-<a class="thought" href="entries/engine_entry.html">engine</a>ering</p>
<p><b>General proof-of-<a class="thought" href="entries/concept_entry.html">concept</a></b>, versus specific real applications development 
  </p>
<p><b><a class="thought" href="entries/animal_entry.html">Animal</a> level cognition</b>, versus abstract <a class="thought" href="entries/thought_entry.html">thought</a>, <a class="thought" href="entries/language_entry.html">language</a>, and formal 
    <a class="thought" href="entries/logic_entry.html">logic</a>.</p>
</blockquote>
<p>Let's look at each of these choices in greater detail. </p>
<p><b>General rather than
<a class="thought" href="entries/domain_entry.html">domain</a>-specific cognitive ability.</b> The advantages listed in the previous
section flow from the fact that generally intelligent <a class="thought" href="entries/system_entry.html">system</a>s can ultimately
learn <i>any</i> specialized <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and skills possible -- <a class="thought" href="entries/human_entry.html">human</a>
<a class="thought" href="entries/intelligence_entry.html">intelligence</a> is the proof! The reverse is obviously not true. </p>
<p>A complete, well-designed AGI's ability to acquire
<a class="thought" href="entries/domain_entry.html">domain</a>-specific capabilities is limited only by processing and storage
<a class="thought" href="entries/capacity_entry.html">capacity</a>. What is more, much of its <a class="thought" href="entries/learning_entry.html">learning</a> will be autonomous -- without
teachers, and certainly without explicit <a class="thought" href="entries/program_entry.html">program</a>ming. This approach <a class="thought" href="entries/implement_entry.html">implement</a>s
(and capitalizes on) the essence of "Seed <a class="thought" href="entries/ai_entry.html">AI</a>" -- <a class="thought" href="entries/system_entry.html">system</a>s with a limited, but
carefully chosen <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of <a class="thought" href="entries/basic_entry.html">basic</a>, initial capabilities that allow them (in a
"bootstrapping" process) to dramatically increase their <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and skills
through self-directed <a class="thought" href="entries/learning_entry.html">learning</a> and adaptation. By concentrating on carefully
designing the seed of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, and then nursing it to maturity, one essentially
bootstraps <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. In our AGI design this self-improvement takes two
distinct forms/ phases:</p>
<blockquote>
<p>1. Coding the <a class="thought" href="entries/basic_entry.html">basic</a> skills that allow the <a class="thought" href="entries/system_entry.html">system</a> to acquire a large amount 
    of specific <a class="thought" href="entries/knowledge_entry.html">knowledge</a>.</p>
<p>2. The <a class="thought" href="entries/system_entry.html">system</a> reaching sufficient <a class="thought" href="entries/intelligence_entry.html">intelligence</a> and <a class="thought" href="entries/concept_entry.html">concept</a>ual understanding 
    of its own design, to enable it to deliberately improve its own design.</p>
</blockquote>
<p><b>&#160;</b><b>Acquired <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and skills, versus loaded <a class="thought" href="entries/database_entry.html">database</a>s and 
  coded skills. </b>One crucial measure of general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is its ability 
  to <i>acquire</i> <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and skills, not how much it possesses. Many <a class="thought" href="entries/ai_entry.html">AI</a> efforts 
  concentrate on accumulating huge <a class="thought" href="entries/database_entry.html">database</a>s of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and coding massive amounts 
  of specific skills. If AGI is possible -- and evidence presented here and elsewhere 
  seems overwhelming -- then much of this effort will be wasted. Not only will 
  an AGI be able to acquire these additional smarts (largely) by itself, but moreover, 
  it will also be able to keep its <a class="thought" href="entries/knowledge_entry.html">knowledge</a> up-to-date, and to improve it. Not 
  only will this save initial <a class="thought" href="entries/data_entry.html">data</a> collection and preparation as well as <a class="thought" href="entries/program_entry.html">program</a>ming, 
  it will also dramatically reduce maintenance.</p>
<p>An <a class="thought" href="entries/import_entry.html">import</a>ant feature of our design is that there are no
traditional <a class="thought" href="entries/database_entry.html">database</a>s containing <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, nor <a class="thought" href="entries/program_entry.html">program</a>s encoding learned
skills: All acquired <a class="thought" href="entries/knowledge_entry.html">knowledge</a> is integrated into an adaptive central
<a class="thought" href="entries/knowledge_entry.html">knowledge</a>/ skills <a class="thought" href="entries/network_entry.html">network</a>. <a class="thought" href="entries/pattern_entry.html">Pattern</a>s representing <a class="thought" href="entries/knowledge_entry.html">knowledge</a> are associated in a
manner that facilitates <a class="thought" href="entries/concept_entry.html">concept</a>ualization and sensitivity to <a class="thought" href="entries/context_entry.html">context</a>. Naturally,
such a design is potentially far less prone to brittleness, and more
resiliently fault-tolerant.</p>
<p><b>Bi-directional,
real-<a class="thought" href="entries/time_entry.html">time</a> interaction, versus <a class="thought" href="entries/batch_processing_entry.html">batch processing</a>. </b>Adaptive <a class="thought" href="entries/learning_entry.html">learning</a> <a class="thought" href="entries/system_entry.html">system</a>s
must be able to interact bi-directionally with the environment -- virtual or
real. They must both <a class="thought" href="entries/sense_entry.html">sense</a> <a class="thought" href="entries/data_entry.html">data</a> and act/ react on an ongoing basis. Many <a class="thought" href="entries/ai_entry.html">AI</a>
<a class="thought" href="entries/system_entry.html">system</a>s do all of their <a class="thought" href="entries/learning_entry.html">learning</a> in batch mode and have little or no ability to
learn <i>incrementally</i>. Such <a class="thought" href="entries/system_entry.html">system</a>s
cannot easily adjust to changing environments or requirements -- in many cases
they are unable to adapt beyond the initial training <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> without reprogramming
or retraining.</p>
<p>In addition to real-<a class="thought" href="entries/time_entry.html">time</a> <a class="thought" href="entries/perception_entry.html">perception</a> and <a class="thought" href="entries/learning_entry.html">learning</a>, intelligent
<a class="thought" href="entries/system_entry.html">system</a>s must also be able to act. Three distinct areas of <a class="thought" href="entries/action_entry.html">action</a> capability are
required:</p>
<p>1. Acting on the "world" -- be it to communicate, to navigate or 
              explore, or to manipulate some external function or <a class="thought" href="entries/device_entry.html">device</a> in <a class="thought" href="entries/order_entry.html">order</a> 
              to achieve goals.</p>
<p>2. Controlling or modifying the <a class="thought" href="entries/system_entry.html">system</a>'s internal <a class="thought" href="entries/parameter_entry.html">parameter</a>s
(such as <a class="thought" href="entries/learning_entry.html">learning</a> rate or <a class="thought" href="entries/noise_entry.html">noise</a> tolerance, etc.) in <a class="thought" href="entries/order_entry.html">order</a> to <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> or improve
functionality.</p>
<p>3. Controlling the <a class="thought" href="entries/system_entry.html">system</a>'s <a class="thought" href="entries/sense_entry.html">sense</a> input <a class="thought" href="entries/parameter_entry.html">parameter</a>s such as focus,
selection, resolution (granularity) as well as adjusting feature extraction
<a class="thought" href="entries/parameter_entry.html">parameter</a>s.</p>
<p><b>Adaptive attention
(focus &amp; selection), versus <a class="thought" href="entries/human_entry.html">human</a> pre-selected <a class="thought" href="entries/data_entry.html">data</a>.</b> As mentioned
earlier, <a class="thought" href="entries/reality_entry.html">reality</a> presents far more <a class="thought" href="entries/sense_entry.html">sense</a> <a class="thought" href="entries/data_entry.html">data</a> abundance, detail, and <a class="thought" href="entries/complexity_entry.html">complexity</a>
than are required for any given task -- or than can be processed. Traditionally,
this problem has been dealt with by carefully selecting and formatting <a class="thought" href="entries/data_entry.html">data</a>
before feeding it to the <a class="thought" href="entries/system_entry.html">system</a>. While this <a class="thought" href="entries/human_entry.html">human</a> assistance can improve
performance in specific applications, it is often not realized that this additional
<a class="thought" href="entries/intelligence_entry.html">intelligence</a> resides in the <a class="thought" href="entries/human_entry.html">human</a>, not the <a class="thought" href="entries/software_entry.html">software</a>.</p>
<p>Outside guidance and training can obviously speed <a class="thought" href="entries/learning_entry.html">learning</a>;
however, AGI <a class="thought" href="entries/system_entry.html">system</a>s must <i>inherently</i>
be designed to acquire <a class="thought" href="entries/knowledge_entry.html">knowledge</a> by themselves. In particular, they need to
control what input <a class="thought" href="entries/data_entry.html">data</a> is processed -- where specifically to obtain <a class="thought" href="entries/data_entry.html">data</a>, in
how much detail, and in what format. Absent this capability the <a class="thought" href="entries/system_entry.html">system</a> will
either be overwhelmed by irrelevant <a class="thought" href="entries/data_entry.html">data</a> or, conversely, be unable to obtain
crucial <a class="thought" href="entries/information_entry.html">information</a>, or get it in the required format. Naturally, such <a class="thought" href="entries/data_entry.html">data</a>
focus and selection mechanisms must themselves be adaptive.</p>
<p><b>Core support for
dynamic <a class="thought" href="entries/pattern_entry.html">pattern</a>s, versus static <a class="thought" href="entries/data_entry.html">data</a>.</b> Temporal <a class="thought" href="entries/pattern_entry.html">pattern</a> processing is
another fundamental requirement of interactive <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. At least three
aspects of AGI rely on it: <i><a class="thought" href="entries/perception_entry.html">perception</a></i>
needs to learn/ recognize dynamic entities and sequences, <i><a class="thought" href="entries/action_entry.html">action</a></i> usually comprises complex behavior, and <i>cognition</i> (internal processing) is inherently temporal. In spite of
this obvious need for intrinsic support for dynamic <a class="thought" href="entries/pattern_entry.html">pattern</a>s, many <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s
only process static data; temporal sequences, if supported at all, are often
converted ("flattened") externally to eliminate the <a class="thought" href="entries/time_entry.html">time</a> dimension. Real-<a class="thought" href="entries/time_entry.html">time</a>
temporal <a class="thought" href="entries/pattern_entry.html">pattern</a> processing is technically quite challenging, so it is not surprising
that most designs try to avoid it.</p>
<p><b>Unsupervised and
self-supervised, versus supervised <a class="thought" href="entries/learning_entry.html">learning</a>.</b> Auto-adaptive <a class="thought" href="entries/system_entry.html">system</a>s such as
AGIs require comprehensive capabilities to learn without supervision. Such
teacher-independent <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and skill acquisition falls into two broad
categories: unsupervised (<a class="thought" href="entries/data_entry.html">data</a>-driven, bottom-up), and self-supervised
(goal-driven, top-down). Ideally these two modes of <a class="thought" href="entries/learning_entry.html">learning</a> should seamlessly
integrate with each other -- and of course, also with other, supervised <a class="thought" href="entries/method_entry.html">method</a>s.</p>
<p>Here, as in other design choices, general adaptive <a class="thought" href="entries/system_entry.html">system</a>s are harder to design 
  and tune than more specialized, unchanging ones. We see this particularly clearly 
  in the overwhelming focus on back-propagation<a href="#_ftn3" name="_ftnref3" title="">[3]</a> 
  in artificial <a class="thought" href="entries/neural_network_entry.html">neural network</a> (ANN) development. Relatively little <a class="thought" href="entries/research_entry.html">research</a> aims 
  at better understanding and improving incremental, autonomous <a class="thought" href="entries/learning_entry.html">learning</a>. Our 
  own design places heavy emphasis on these aspects.</p>
<p><b>Adaptive, self-organizing <a class="thought" href="entries/data_structure_entry.html">data structure</a>s, versus fixed
neural nets or <a class="thought" href="entries/database_entry.html">database</a>s. </b>Another core requirement imposed by <a class="thought" href="entries/data_entry.html">data</a>/
goal-driven, real-<a class="thought" href="entries/time_entry.html">time</a> <a class="thought" href="entries/learning_entry.html">learning</a> is having a flexible, self-organizing <a class="thought" href="entries/data_entry.html">data</a>
<a class="thought" href="entries/structure_entry.html">structure</a>. On the one hand, <a class="thought" href="entries/knowledge_representation_entry.html">knowledge representation</a> must be highly integrated,
while on the other hand it must be able to adapt to changing <a class="thought" href="entries/data_entry.html">data</a> densities
(and other properties), and to varying goals or solutions. Our AGI encodes <i>all</i>
acquired <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and skills in one integrated <a class="thought" href="entries/network_entry.html">network</a>-like <a class="thought" href="entries/structure_entry.html">structure</a>. This
central repository features a flexible, dynamically self-organizing topology.
The vast majority of other <a class="thought" href="entries/ai_entry.html">AI</a> designs rely either on loosely-coupled <a class="thought" href="entries/data_entry.html">data</a>
<a class="thought" href="entries/object_entry.html">object</a>s or agents, or on fixed <a class="thought" href="entries/network_entry.html">network</a> topologies and pre-defined ontologies,
<a class="thought" href="entries/data_entry.html">data</a> hierarchies or <a class="thought" href="entries/database_entry.html">database</a> layouts. This often severely limits their
self-<a class="thought" href="entries/learning_entry.html">learning</a> ability, adaptivity and robustness, or creates massive
<a class="thought" href="entries/communication_entry.html">communication</a> bottlenecks or other performance overhead.</p>
<p><b><a class="thought" href="entries/context_entry.html">Context</a>ual, grounded
<a class="thought" href="entries/concept_entry.html">concept</a>s, versus hard-coded, <a class="thought" href="entries/symbol_entry.html">symbol</a>ic <a class="thought" href="entries/concept_entry.html">concept</a>s.</b> <a class="thought" href="entries/concept_entry.html">Concept</a>s are probably the
most <a class="thought" href="entries/import_entry.html">import</a>ant design aspect of AGI; in fact, one can say that "high-level <a class="thought" href="entries/intelligence_entry.html">intelligence</a>
<i>is</i> <a class="thought" href="entries/concept_entry.html">concept</a>ual <a class="thought" href="entries/intelligence_entry.html">intelligence</a>." Core
characteristics of <a class="thought" href="entries/concept_entry.html">concept</a>s include their ability to represent
ultra-high-dimensional fuzzy sets that are grounded in <a class="thought" href="entries/reality_entry.html">reality</a>, yet fluid with
regard to <a class="thought" href="entries/context_entry.html">context</a>. In other words, they encode related sets of complex, coherent,
multi-dimensional <a class="thought" href="entries/pattern_entry.html">pattern</a>s that represent features of entities. <a class="thought" href="entries/concept_entry.html">Concept</a>s obtain
their grounding (and thus their meaning) by virtue of <a class="thought" href="entries/pattern_entry.html">pattern</a>s emanating from
features sensed directly from entities that exist in <a class="thought" href="entries/reality_entry.html">reality</a>. Because <a class="thought" href="entries/concept_entry.html">concept</a>s
are defined by <i>value ranges</i> within each feature dimension (sometimes in
complex relationships), some kind of fuzzy <a class="thought" href="entries/pattern_entry.html">pattern</a> matching is essential. In
addition, the <i>scope</i> of <a class="thought" href="entries/concept_entry.html">concept</a>s must be fluid; they must be sensitive
and adaptive to both environmental and goal <a class="thought" href="entries/context_entry.html">context</a>s.</p>
<p>Autonomous <a class="thought" href="entries/concept_entry.html">concept</a> formation is one of the key tests of
<a class="thought" href="entries/intelligence_entry.html">intelligence</a>. The many <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s based on hard-coded or <a class="thought" href="entries/human_entry.html">human</a>-defined <a class="thought" href="entries/concept_entry.html">concept</a>s
fail this fundamental test. Furthermore, <a class="thought" href="entries/system_entry.html">system</a>s that do not derive their
<a class="thought" href="entries/concept_entry.html">concept</a>s via interactive <a class="thought" href="entries/perception_entry.html">perception</a> are unable to ground their <a class="thought" href="entries/knowledge_entry.html">knowledge</a> in
<a class="thought" href="entries/reality_entry.html">reality</a>, and thus lack crucial meaning. Finally, <a class="thought" href="entries/concept_entry.html">concept</a> <a class="thought" href="entries/structure_entry.html">structure</a>s whose
activation cannot be modulated by <a class="thought" href="entries/context_entry.html">context</a> and degree of fit are unable to
capture the subtlety and fluidity of intelligent generalization. In combination,
these limitations will cripple any aspiring AGI.</p>
<p><b>Explicitly
<a class="thought" href="entries/engine_entry.html">engine</a>ering (and <a class="thought" href="entries/learning_entry.html">learning</a>) functionality, versus evolving it.</b> Design by
<a class="thought" href="entries/evolution_entry.html">evolution</a> is extremely inefficient -- whether in <a class="thought" href="entries/nature_entry.html">nature</a> or in <a class="thought" href="entries/computer_science_entry.html">computer science</a>.
Moreover, <a class="thought" href="entries/evolution_entry.html">evolution</a>ary solutions are generally opaque; optimized only to some
specified "cost function," not comprehensibility, modularity, or
maintainability. Furthermore, <a class="thought" href="entries/evolution_entry.html">evolution</a>ary <a class="thought" href="entries/learning_entry.html">learning</a> also requires more <a class="thought" href="entries/data_entry.html">data</a> or
trials than are available in everyday problem solving.</p>
<p>Genetic and <a class="thought" href="entries/evolution_entry.html">evolution</a>ary <a class="thought" href="entries/program_entry.html">program</a>ming <i>do</i> have their uses -- they are powerful <i>tools</i> that can be used to solve very specific problems, such as
optimization of large sets of variables; however they generally are not
appropriate for creating large <a class="thought" href="entries/system_entry.html">system</a>s of infrastructures. Artificially
evolving general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> <i>directly</i>
seems particularly problematic because there is no known function measuring
such capability along a single continuum -- and absent such direction, <a class="thought" href="entries/evolution_entry.html">evolution</a>
doesn't know what to optimize. One approach to deal with this problem is to try
to coax <a class="thought" href="entries/intelligence_entry.html">intelligence</a> out of a complex <a class="thought" href="entries/ecology_entry.html">ecology</a> of competing agents -- essentially
replaying natural <a class="thought" href="entries/evolution_entry.html">evolution</a>.</p>
<p>Overall, it seems that <a class="thought" href="entries/genetic_programming_entry.html">genetic programming</a> techniques are
appropriate when one runs out of specific <a class="thought" href="entries/engine_entry.html">engine</a>ering ideas. Here is a short
summary of advantages of explicitly <a class="thought" href="entries/engine_entry.html">engine</a>ered functionality:</p>
<p>
<blockquote>
<p> Designs can directly capitalize on and encode the designer's <a class="thought" href="entries/knowledge_entry.html">knowledge</a> and 
    insights.</p>
<p> Designs have comprehensible design documentation.</p>
<p> Designs can be more far more modular -- less need for multiple functionality 
    and high inter-dependency of sub-<a class="thought" href="entries/system_entry.html">system</a>s than found in evolved <a class="thought" href="entries/system_entry.html">system</a>s.</p>
<p> <a class="thought" href="entries/system_entry.html">System</a>s can have a more flow-chart like, logical design -- <a class="thought" href="entries/evolution_entry.html">evolution</a> has 
    no foresight.</p>
<p> They can be designed with <a class="thought" href="entries/debugging_entry.html">debugging</a> aids -- <a class="thought" href="entries/evolution_entry.html">evolution</a> didn't need that.</p>
<p> These features combine to make <a class="thought" href="entries/system_entry.html">system</a>s easier to understand, debug, <a class="thought" href="entries/interface_entry.html">interface</a>, 
    and -- <a class="thought" href="entries/import_entry.html">import</a>antly -- for multiple teams to simultaneously work on the design.</p>
</blockquote>
<p><b><a class="thought" href="entries/concept_entry.html">Concept</a>ual design,
versus reverse-<a class="thought" href="entries/engine_entry.html">engine</a>ering.</b> In addition to avoiding the shortcomings of
<a class="thought" href="entries/evolution_entry.html">evolution</a>ary techniques, there are also numerous advantages to designing and <a class="thought" href="entries/engine_entry.html">engine</a>ering
intelligent <a class="thought" href="entries/system_entry.html">system</a>s based on <i>functional</i>
requirements rather than trying to copy <a class="thought" href="entries/evolution_entry.html">evolution</a>'s design of the <a class="thought" href="entries/brain_entry.html">brain</a>. As
aviation has amply demonstrated, it is much easier to build planes than it is
to reverse-<a class="thought" href="entries/engine_entry.html">engine</a>er birds -- much easier to achieve flight via thrust than
flapping wings. </p>
<p>Similarly, in creating <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> it makes
<a class="thought" href="entries/sense_entry.html">sense</a> to capitalize on our <a class="thought" href="entries/human_entry.html">human</a> intellectual
and <a class="thought" href="entries/engine_entry.html">engine</a>ering strengths -- to ignore design <a class="thought" href="entries/parameter_entry.html">parameter</a>s unique to
<a class="thought" href="entries/biological_entry.html">biological</a> <a class="thought" href="entries/system_entry.html">system</a>s, instead of struggling to copy <a class="thought" href="entries/nature_entry.html">nature</a>'s designs. Designs explicitly <a class="thought" href="entries/engine_entry.html">engine</a>ered to achieve desired
functionality are much easier to understand, debug, modify, and enhance.
Furthermore, using known and existing <a class="thought" href="entries/technology_entry.html">technology</a> allows us to best leverage
existing resources. So why limit ourselves to the single solution to
<a class="thought" href="entries/intelligence_entry.html">intelligence</a> created by a blind, unconscious Watchmaker with his own agenda
(survival in an <a class="thought" href="entries/evolution_entry.html">evolution</a>ary environment very different from that of today)?</p>
<p>Intelligent <a class="thought" href="entries/machine_entry.html">machine</a>s
designed from scratch carry neither the <a class="thought" href="entries/evolution_entry.html">evolution</a>ary baggage, nor the
additional <a class="thought" href="entries/complexity_entry.html">complexity</a> for epigenesis, reproduction, and integrated self-repair
of <a class="thought" href="entries/biological_entry.html">biological</a> brains. Obviously this doesn't imply that we can learn nothing
from studying brains, just that we don't have to limit ourselves to <a class="thought" href="entries/biological_entry.html">biological</a>
feasibility in our designs. Our (currently) only working example of high-level
general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> (the <a class="thought" href="entries/brain_entry.html">brain</a>) provides a crucial <i><a class="thought" href="entries/concept_entry.html">concept</a>ual</i> model of cognition, and can clearly inspire numerous
specific design features.</p>
<p>Here are some
desirable cognitive features that can be included in an AGI design that would
not (and in some cases, could not) exist in a reverse-<a class="thought" href="entries/engine_entry.html">engine</a>ered brain:</p>
<blockquote>
<p>More effective control of neurochemistry ("<a class="thought" href="entries/emotion_entry.html">emotion</a>al states")</p>
<p>Selecting the appropriate degree of logical <a class="thought" href="entries/thinking_entry.html">thinking</a> versus <a class="thought" href="entries/intuition_entry.html">intuition</a></p>
<p>More effective control over focus and attention</p>
<p>Being able to learn instantly, on demand</p>
<p>Direct and rapid interfacing with <a class="thought" href="entries/database_entry.html">database</a>s, the <a class="thought" href="entries/internet_entry.html">Internet</a>, and other <a class="thought" href="entries/machine_entry.html">machine</a>s 
    -- potentially having instant <a class="thought" href="entries/access_entry.html">access</a> to all available <a class="thought" href="entries/knowledge_entry.html">knowledge</a></p>
<p>Optional "photographic" <a class="thought" href="entries/memory_entry.html">memory</a> and recall ("playback") on all senses!</p>
<p>Better control over remembering and forgetting (freezing <a class="thought" href="entries/import_entry.html">import</a>ant <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, 
    and being able to unlearn)</p>
<p>The ability to accurately backtrack and review <a class="thought" href="entries/thought_entry.html">thought</a> and decision processes 
    (retrace and explore <a class="thought" href="entries/logic_entry.html">logic</a> pathways)</p>
<p><a class="thought" href="entries/pattern_entry.html">Pattern</a>s, nodes and links can easily be tagged (labeled) and categorized</p>
<p>The ability to optimize the design for the available <a class="thought" href="entries/hardware_entry.html">hardware</a> instead of 
    being forced to conform to the <a class="thought" href="entries/brain_entry.html">brain</a>'s requirements</p>
<p>The ability to utilize the best existing <a class="thought" href="entries/algorithm_entry.html">algorithm</a>s and <a class="thought" href="entries/software_entry.html">software</a> techniques 
    -- irrespective of whether they are <a class="thought" href="entries/biological_entry.html">biological</a>ly plausible</p>
<p>Custom designed AGI (unlike brains) can have a simple speed/ <a class="thought" href="entries/capacity_entry.html">capacity</a> upgrade 
    path</p>
<p>The possibility of comprehensive integration with other <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s (like 
    <a class="thought" href="entries/expert_system_entry.html">expert system</a>s, <a class="thought" href="entries/robotics_entry.html">robotics</a>, specialized <a class="thought" href="entries/sense_entry.html">sense</a> pre-processors, and problem solvers)</p>
<p>The ability to construct AGIs that are highly optimized for specific <a class="thought" href="entries/domain_entry.html">domain</a>s</p>
<p><a class="thought" href="entries/node_entry.html">Node</a>, link, and internal <a class="thought" href="entries/parameter_entry.html">parameter</a> <a class="thought" href="entries/data_entry.html">data</a> is available as "input <a class="thought" href="entries/data_entry.html">data</a>" (full 
    introspection)</p>
<p>Design specifications are available (to the designer and to the AGI itself!)</p>
<p>Seed <a class="thought" href="entries/ai_entry.html">AI</a> design: A <a class="thought" href="entries/machine_entry.html">machine</a> can inherently be designed to more easily understand 
    and improve its own functioning -- thus bootstrapping <a class="thought" href="entries/intelligence_entry.html">intelligence</a> to ever 
    higher levels.</p>
</blockquote>
<p><b>General
proof-of-<a class="thought" href="entries/concept_entry.html">concept</a>, versus specific real applications development.</b> Applying
given resources to minimalist proof-of-<a class="thought" href="entries/concept_entry.html">concept</a> designs improves the likelihood
of cutting a swift, direct path towards an ultimate goal. Having identified
high-level artificial general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> as our goal, it makes little <a class="thought" href="entries/sense_entry.html">sense</a>
to squander resources on inessentials. In addition to focusing our efforts on
the ability to <i>acquire</i> <a class="thought" href="entries/knowledge_entry.html">knowledge</a>
autonomously, rather than capturing or coding it, we further aim to speed
<a class="thought" href="entries/progress_entry.html">progress</a> towards full AGI by reducing cost and <a class="thought" href="entries/complexity_entry.html">complexity</a> through -- </p>
<blockquote>
<p>Concentrating on proof-of-<a class="thought" href="entries/concept_entry.html">concept</a> prototypes, not <a class="thought" href="entries/commercial_entry.html">commercial</a> performance. 
    This includes working at low <a class="thought" href="entries/data_entry.html">data</a> resolution and volume, and putting aside 
    optimization. Scalability is addressed only at a theoretical level, and not 
    necessarily <a class="thought" href="entries/implement_entry.html">implement</a>ed.</p>
<p>Working with radically-reduced <a class="thought" href="entries/sense_entry.html">sense</a> and motor capabilities. The fact that 
    deaf, blind, and severely paralyzed people can attain high <a class="thought" href="entries/intelligence_entry.html">intelligence</a> (Helen 
    Keller, <a class="thought" href="entries/hawking_entry.html">Stephen Hawking</a>) indicates that these are not essential to developing 
    AGI.</p>
<p>Coping with <a class="thought" href="entries/complexity_entry.html">complexity</a> through a willingness to <a class="thought" href="entries/experiment_entry.html">experiment</a> and <a class="thought" href="entries/implement_entry.html">implement</a> 
    poorly understood <a class="thought" href="entries/algorithm_entry.html">algorithm</a>s -- i.e. using an <a class="thought" href="entries/engine_entry.html">engine</a>ering approach. Using 
    self-tuning feedback loops to minimize free <a class="thought" href="entries/parameter_entry.html">parameter</a>s.</p>
<p>Not being sidetracked by attempting to match the performance of <a class="thought" href="entries/domain_entry.html">domain</a>-specific 
    designs -- focusing more on <i>how</i> capabilities are achieved (e.g. learned 
    <a class="thought" href="entries/concept_entry.html">concept</a>ualization, instead of <a class="thought" href="entries/program_entry.html">program</a>med or manually specified <a class="thought" href="entries/concept_entry.html">concept</a>s) rather 
    than raw performance.</p>
<p>Developing and testing in virtual environments, not physical <a class="thought" href="entries/implement_entry.html">implement</a>ations. 
    Most aspects of AGI can be fully evaluated without the overhead (<a class="thought" href="entries/time_entry.html">time</a>, money, 
    and <a class="thought" href="entries/complexity_entry.html">complexity</a>) of <a class="thought" href="entries/robotics_entry.html">robotics</a>.</p>
</blockquote>
<p><b><a class="thought" href="entries/animal_entry.html">Animal</a> level
cognition, versus abstract <a class="thought" href="entries/thought_entry.html">thought</a>, <a class="thought" href="entries/language_entry.html">language</a>, and formal <a class="thought" href="entries/logic_entry.html">logic</a>.</b> There is
ample evidence that achieving high-level cognition requires only modest <i>structural</i> improvements from <a class="thought" href="entries/animal_entry.html">animal</a>
capability. Discoveries in cognitive <a class="thought" href="entries/psychology_entry.html">psychology</a> point towards generalized
<a class="thought" href="entries/pattern_entry.html">pattern</a> processing being the foundational mechanism for all higher level
functioning. On the other hand, relatively small differences between higher
<a class="thought" href="entries/animal_entry.html">animal</a>s and humans are also witnessed by studies of <a class="thought" href="entries/genetics_entry.html">genetics</a>, the <a class="thought" href="entries/evolution_entry.html">evolution</a>ary
timetable, and developmental <a class="thought" href="entries/psychology_entry.html">psychology</a>.</p>
<p>The core challenge
of AGI is achieving the robust, adaptive <a class="thought" href="entries/concept_entry.html">concept</a>ual <a class="thought" href="entries/learning_entry.html">learning</a> ability of higher
primates or young children. If <a class="thought" href="entries/human_entry.html">human</a> level <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is the goal, then
pursuing <a class="thought" href="entries/robotics_entry.html">robotics</a>, <a class="thought" href="entries/language_entry.html">language</a>, or formal <a class="thought" href="entries/logic_entry.html">logic</a> (at this stage) is a costly
sideshow - whether motivated by misunderstanding the problem, or by <a class="thought" href="entries/commercial_entry.html">commercial</a>
or "political" considerations.</p>
<p><b>Summary.</b>
While our project leans heavily on <a class="thought" href="entries/research_entry.html">research</a> done in many specialized disciplines,
it is one of the few efforts dedicated to integrating such interdisciplinary
<a class="thought" href="entries/knowledge_entry.html">knowledge</a> with the specific goal of developing <i>general</i> <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>. We firmly believe that many of the
issues raised above are crucial to the early achievement of truly intelligent
adaptive <a class="thought" href="entries/learning_entry.html">learning</a> <a class="thought" href="entries/system_entry.html">system</a>s.</p>
<h1>4. Foundational Cognitive Capabilities </h1>
<p>General <a class="thought" href="entries/intelligence_entry.html">intelligence</a> requires a <a class="thought" href="entries/number_entry.html">number</a> of foundational
cognitive abilities. At a first approximation, it must be able to -- </p>
<blockquote>
<p>Remember and recognize <a class="thought" href="entries/pattern_entry.html">pattern</a>s representing coherent features of <a class="thought" href="entries/reality_entry.html">reality</a></p>
<p>Relate such <a class="thought" href="entries/pattern_entry.html">pattern</a>s by various similarities, differences, and associations</p>
<p>Learn and perform a variety of <a class="thought" href="entries/action_entry.html">action</a>s</p>
<p>Evaluate and encode feedback from a goal <a class="thought" href="entries/system_entry.html">system</a></p>
<p>Autonomously adjust its <a class="thought" href="entries/system_entry.html">system</a> control <a class="thought" href="entries/parameter_entry.html">parameter</a>s.</p>
</blockquote>
<p>As mentioned earlier, this functionality must handle a very
wide variety of <a class="thought" href="entries/data_entry.html">data</a> types and characteristics (including temporal), and must
operate interactively, in real-<a class="thought" href="entries/time_entry.html">time</a>. The expanded description below is based on
our particular <a class="thought" href="entries/implement_entry.html">implement</a>ation; however, the features listed would generally be
required (in some form) in <i>any</i>
<a class="thought" href="entries/implement_entry.html">implement</a>ation of artificial general <a class="thought" href="entries/intelligence_entry.html">intelligence</a>.</p>
<p><b><a class="thought" href="entries/pattern_entry.html">Pattern</a> <a class="thought" href="entries/learning_entry.html">learning</a>,
matching, completion, and recall.</b> The primary <a class="thought" href="entries/method_entry.html">method</a> of <a class="thought" href="entries/pattern_entry.html">pattern</a> acquisition
consists of a proprietary adaptation of lazy <a class="thought" href="entries/learning_entry.html">learning</a> (Aha 1997, Yip 1997). Our
<a class="thought" href="entries/implement_entry.html">implement</a>ation stores feature <a class="thought" href="entries/pattern_entry.html">pattern</a>s (static and dynamic) with adaptive fuzzy
tolerances that subsequently determine how similar <a class="thought" href="entries/pattern_entry.html">pattern</a>s are processed. Our
recognition <a class="thought" href="entries/algorithm_entry.html">algorithm</a> matches <a class="thought" href="entries/pattern_entry.html">pattern</a>s on a competitive winner-take-all basis,
as a <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> or aggregate of similar <a class="thought" href="entries/pattern_entry.html">pattern</a>s, or by forced choice. It also offers
inherent support for <a class="thought" href="entries/pattern_entry.html">pattern</a> completion, and recall (where appropriate). </p>
<p><b><a class="thought" href="entries/data_entry.html">Data</a> accumulation and
forgetting.</b> Because our <a class="thought" href="entries/system_entry.html">system</a> learns <a class="thought" href="entries/pattern_entry.html">pattern</a>s incrementally, mechanism are
needed for consolidating and pruning excess <a class="thought" href="entries/data_entry.html">data</a>. Sensed <a class="thought" href="entries/pattern_entry.html">pattern</a>s (or
sub-<a class="thought" href="entries/pattern_entry.html">pattern</a>s) that fall within a dynamically <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> <a class="thought" href="entries/noise_entry.html">noise</a>/ error tolerance of
existing ones are automatically consolidated by a hebbian-like mechanism that
we call "nudging." This <a class="thought" href="entries/algorithm_entry.html">algorithm</a> also accumulates certain statistical
<a class="thought" href="entries/information_entry.html">information</a>. On the other hand, <a class="thought" href="entries/pattern_entry.html">pattern</a>s that turn out not to be <a class="thought" href="entries/import_entry.html">import</a>ant (as
judged by various criteria) are deleted.</p>
<p><b>Categorization and
clustering.</b> Vector-coded feature <a class="thought" href="entries/pattern_entry.html">pattern</a>s are acquired in real-<a class="thought" href="entries/time_entry.html">time</a> and
stored in a highly adaptive <a class="thought" href="entries/network_entry.html">network</a> <a class="thought" href="entries/structure_entry.html">structure</a>. This central self-organizing
repository automatically clusters <a class="thought" href="entries/data_entry.html">data</a> in hyper-dimensional vector-<a class="thought" href="entries/space_entry.html">space</a>. Our
matching <a class="thought" href="entries/algorithm_entry.html">algorithm</a>'s ability to recall <a class="thought" href="entries/pattern_entry.html">pattern</a>s by any dimension provides
inherent support for flexible, dynamic categorization. Additional
categorization mechanisms facilitate grouping <a class="thought" href="entries/pattern_entry.html">pattern</a>s by additional
<a class="thought" href="entries/parameter_entry.html">parameter</a>s, associations, or functions.</p>
<p><b><a class="thought" href="entries/pattern_entry.html">Pattern</a> hierarchies
and associations.</b> <a class="thought" href="entries/pattern_entry.html">Pattern</a>s of perceptual features do not stand in isolation
-- they are derived from coherent external <a class="thought" href="entries/reality_entry.html">reality</a>. Encoding relationships between
<a class="thought" href="entries/pattern_entry.html">pattern</a>s serves the crucial functions of added meaning, <a class="thought" href="entries/context_entry.html">context</a>, and
anticipation. Our <a class="thought" href="entries/system_entry.html">system</a> captures low-level, <a class="thought" href="entries/perception_entry.html">perception</a>-driven <a class="thought" href="entries/pattern_entry.html">pattern</a>
associations such as: sequential or coincidental in <a class="thought" href="entries/time_entry.html">time</a>, nearby in <a class="thought" href="entries/space_entry.html">space</a>,
related by feature group or <a class="thought" href="entries/sense_entry.html">sense</a> modality. Additional relationships are
encoded at higher levels of the <a class="thought" href="entries/network_entry.html">network</a>, including actuation layers. This
overall <a class="thought" href="entries/structure_entry.html">structure</a> somewhat resembles the "dual <a class="thought" href="entries/network_entry.html">network</a>" described by Goertzel
(1993).</p>
<p><b><a class="thought" href="entries/pattern_entry.html">Pattern</a> priming and
activation spreading.</b> The core function of association links is to prime<a href="#_ftn4" name="_ftnref4" title="">[4]</a>
related nodes. This helps to disambiguate <a class="thought" href="entries/pattern_entry.html">pattern</a> matching, and to select <a class="thought" href="entries/context_entry.html">context</a>ual
alternatives. In the case where activation is particularly strong and
perceptual activity is low, stored <a class="thought" href="entries/pattern_entry.html">pattern</a>s will be "recognized" spontaneously.
Both the scope and decay rate of such activation spreading are controlled
adaptively. These <a class="thought" href="entries/dynamics_entry.html">dynamics</a> combine with the primary, <a class="thought" href="entries/perception_entry.html">perception</a>-driven
activation to form the <a class="thought" href="entries/system_entry.html">system</a>'s short-term <a class="thought" href="entries/memory_entry.html">memory</a>.</p>
<p><b><a class="thought" href="entries/action_entry.html">Action</a> <a class="thought" href="entries/pattern_entry.html">pattern</a>s.</b>
Adaptive <a class="thought" href="entries/action_entry.html">action</a> <a class="thought" href="entries/circuit_entry.html">circuit</a>s are used to control <a class="thought" href="entries/parameter_entry.html">parameter</a>s in the following three
<a class="thought" href="entries/domain_entry.html">domain</a>s: </p>
<p>1)--Senses, including adjustable feature extractors, focus and
selection mechanisms&#160; </p>
<p>Output actuators for navigation and manipulation&#160; </p>
<p>Meta-cognition and internal controls. </p>
<p>Different <a class="thought" href="entries/action_entry.html">action</a>s states and behaviors (<a class="thought" href="entries/action_entry.html">action</a> sequences)
for each of these control outputs can be created at design <a class="thought" href="entries/time_entry.html">time</a> (using a
<a class="thought" href="entries/configuration_entry.html">configuration</a> script) or acquired interactively. Real-<a class="thought" href="entries/time_entry.html">time</a> <a class="thought" href="entries/learning_entry.html">learning</a> occurs
either by means of explicit teaching, or autonomously through random exploration.
Once acquired, these <a class="thought" href="entries/action_entry.html">action</a>s can be tied to specific perceptual stimuli or
whole <a class="thought" href="entries/context_entry.html">context</a>s through various stimulus-response mechanisms. These S-R links
(both activation and inhibition) are dynamically modified through ongoing
reinforcement <a class="thought" href="entries/learning_entry.html">learning</a>.</p>
<p><b>Meta-cognitive
control.</b> In addition to adaptive <a class="thought" href="entries/perception_entry.html">perception</a> and <a class="thought" href="entries/action_entry.html">action</a> functionality, an
AGI design must also allow for extensive monitoring and control of overall
<a class="thought" href="entries/system_entry.html">system</a> <a class="thought" href="entries/parameter_entry.html">parameter</a>s and functions. Any complex interactive <a class="thought" href="entries/learning_entry.html">learning</a> <a class="thought" href="entries/system_entry.html">system</a>
contains numerous crucial control <a class="thought" href="entries/parameter_entry.html">parameter</a>s such as <a class="thought" href="entries/noise_entry.html">noise</a> tolerance, <a class="thought" href="entries/learning_entry.html">learning</a>
and exploration rates, priorities and goal management, and a myriad others. Not
only must the <a class="thought" href="entries/system_entry.html">system</a> be able to adaptively control these many interactive
vectors, it must also appropriately manage its various cognitive functions
(such as recognition, recall, <a class="thought" href="entries/action_entry.html">action</a>, etc.). Our design deals with these
requirements by means of a highly adaptive introspection/ control "probe."</p>
<p><b>High-level
<a class="thought" href="entries/intelligence_entry.html">intelligence</a>.</b> Our AGI model posits that no additional <i>foundational</i> functions are necessary for higher-level cognition.
Abstract <a class="thought" href="entries/thought_entry.html">thought</a>, <a class="thought" href="entries/language_entry.html">language</a>, and logical <a class="thought" href="entries/thinking_entry.html">thinking</a> are all elaborations of core
abilities. This controversial point is elaborated on further on.</p>
<h1>5. An AGI in the making </h1>
<p>The functional prototype currently under development at
Adaptive A.I. Inc. aims to embody all the abovementioned choices, requirements,
and features. Our development path is as follows: </p>
<p>1) Development framework</p>
<p>2) <a class="thought" href="entries/memory_entry.html">Memory</a> core and <a class="thought" href="entries/interface_entry.html">interface</a> <a class="thought" href="entries/structure_entry.html">structure</a></p>
<p>3) <a class="thought" href="entries/individual_entry.html">Individual</a> foundational cognitive <a class="thought" href="entries/component_entry.html">component</a>s</p>
<p>4) Integrated low-level cognition</p>
<p>5) Increasing level of functionality. </p>
<p>The <a class="thought" href="entries/software_entry.html">software</a> comprises an AGI <a class="thought" href="entries/engine_entry.html">engine</a> framework with the
following <a class="thought" href="entries/basic_entry.html">basic</a> <a class="thought" href="entries/component_entry.html">component</a>s:</p>
<blockquote>
<p>A <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of pluggable, <a class="thought" href="entries/program_entry.html">program</a>mable (virtual) sensors and actuators (called 
    "probes")</p>
<p>A central <a class="thought" href="entries/pattern_entry.html">pattern</a> store/ <a class="thought" href="entries/engine_entry.html">engine</a> including all <a class="thought" href="entries/data_entry.html">data</a> and cognitive <a class="thought" href="entries/algorithm_entry.html">algorithm</a>s</p>
<p>A configurable, dynamic 2D virtual world, plus various training and diagnostic 
    tools.</p>
</blockquote>
<p><img alt="Adaptive A.I.'s AGI Framework" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/articles/images/agiframework.jpg" width="400"></p>
<p>The AGI <a class="thought" href="entries/engine_entry.html">engine</a> design is based on, and embodies insights
from a wide range of <a class="thought" href="entries/research_entry.html">research</a> in <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a> -- including <a class="thought" href="entries/computer_entry.html">computer</a>
<a class="thought" href="entries/science_entry.html">science</a>, <a class="thought" href="entries/neuroscience_entry.html">neuroscience</a>, <a class="thought" href="entries/epistemology_entry.html">epistemology</a> (Rand 1990, Kelley 1986), and <a class="thought" href="entries/psychology_entry.html">psychology</a>
(Margolis 1987). Particularly strong influences include: embodied <a class="thought" href="entries/system_entry.html">system</a>s
(Brooks 1994), vector encoded representation (Churchland 1995), adaptive
self-organizing neural nets (esp. Growing Neural Gas, Fritzke 1995),
unsupervised and self-supervised <a class="thought" href="entries/learning_entry.html">learning</a>, perceptual <a class="thought" href="entries/learning_entry.html">learning</a> (Goldstone 1998), and <a class="thought" href="entries/fuzzy_logic_entry.html">fuzzy logic</a>
(Kosko 1997). </p>
<p><i>While our design
includes several <a class="thought" href="entries/novel_entry.html">novel</a>, and proprietary <a class="thought" href="entries/algorithm_entry.html">algorithm</a>s, our key innovation is the
particular selection and integration of established technologies and prior
insights.</i> </p>
<blockquote>
<p><i>&#160;</i>AGI <a class="thought" href="entries/engine_entry.html">Engine</a> <a class="thought" href="entries/architecture_entry.html">Architecture</a> &amp; Design Features</p>
<p>Our AGI <a class="thought" href="entries/engine_entry.html">engine</a> (which provides this foundational cognitive ability) can logically 
    be divided into three parts (See figure above.): </p>
<p>Cognitive core</p>
<p>Control/ <a class="thought" href="entries/interface_entry.html">interface</a> <a class="thought" href="entries/logic_entry.html">logic</a></p>
<p>Input/ output probes </p>
</blockquote>
<p>This "situated <a class="thought" href="entries/agent_entry.html">agent</a> <a class="thought" href="entries/architecture_entry.html">architecture</a>" reflects the <a class="thought" href="entries/import_entry.html">import</a>ance
of having an AGI <a class="thought" href="entries/system_entry.html">system</a> that can dynamically and adaptively interact with the
environment. From a theory-of-<a class="thought" href="entries/mind_entry.html">mind</a> perspective it acknowledges both the crucial
need for <a class="thought" href="entries/concept_entry.html">concept</a> grounding (via senses), plus the absolute need for
experiential, self-supervised <a class="thought" href="entries/learning_entry.html">learning</a>.</p>
<p>The <a class="thought" href="entries/component_entry.html">component</a>s listed below have been specifically designed
with features required for adaptive general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> in (ultimately) real
environments. Among other things, they deal with a great variety and volume of
static and dynamic <a class="thought" href="entries/data_entry.html">data</a>, cope with fuzzy and uncertain <a class="thought" href="entries/data_entry.html">data</a> and goals, foster
coherent integrated representations of <a class="thought" href="entries/reality_entry.html">reality</a>, and -- most of all -- promote
adaptivity.</p>
<p><b>Cognitive Core:</b>
This is the central repository of all static and dynamic <a class="thought" href="entries/data_entry.html">data</a> <a class="thought" href="entries/pattern_entry.html">pattern</a>s --
including all learned cognitive and behavioral states and sequences. All <a class="thought" href="entries/data_entry.html">data</a>
is stored in a single, integrated <a class="thought" href="entries/node_entry.html">node</a>-link <a class="thought" href="entries/structure_entry.html">structure</a>. The design innovates the
specific encoding of <a class="thought" href="entries/pattern_entry.html">pattern</a> "fuzziness" (in addition to other <a class="thought" href="entries/attribute_entry.html">attribute</a>s). The
core allows for several <a class="thought" href="entries/node_entry.html">node</a>/ link types with differing <a class="thought" href="entries/dynamics_entry.html">dynamics</a> to help define
the <a class="thought" href="entries/network_entry.html">network</a>'s cognitive <a class="thought" href="entries/structure_entry.html">structure</a>.</p>
<p>The <a class="thought" href="entries/network_entry.html">network</a>'s topology is dynamically self-organizing -- a
feature inspired by "Growing Neural Gas" design (Fritzke 1995). This allows
<a class="thought" href="entries/network_entry.html">network</a> density to adjust to actual <a class="thought" href="entries/data_entry.html">data</a> feature and/ or goal requirements.
Various adaptive local and global <a class="thought" href="entries/parameter_entry.html">parameter</a>s further define <a class="thought" href="entries/network_entry.html">network</a> <a class="thought" href="entries/structure_entry.html">structure</a>
and <a class="thought" href="entries/dynamics_entry.html">dynamics</a> in real <a class="thought" href="entries/time_entry.html">time</a>.</p>
<p><b>Control and <a class="thought" href="entries/interface_entry.html">Interface</a>
Logic:</b> An overall control <a class="thought" href="entries/system_entry.html">system</a> coordinates the <a class="thought" href="entries/network_entry.html">network</a>'s execution cycle,
drives various cognitive and housekeeping <a class="thought" href="entries/algorithm_entry.html">algorithm</a>s, and controls/ adapts
<a class="thought" href="entries/system_entry.html">system</a> <a class="thought" href="entries/parameter_entry.html">parameter</a>s. Via an <a class="thought" href="entries/interface_entry.html">Interface</a> Manager, it also communicates <a class="thought" href="entries/data_entry.html">data</a> and
control <a class="thought" href="entries/information_entry.html">information</a> to and from the probes.</p>
<p><b>Probes:</b> The
<a class="thought" href="entries/interface_entry.html">Interface</a> Manager provides for dynamic addition and <a class="thought" href="entries/configuration_entry.html">configuration</a> of probes.
Key design features of the probe <a class="thought" href="entries/architecture_entry.html">architecture</a> include the ability to have <a class="thought" href="entries/program_entry.html">program</a>mable
feature extractors, variable <a class="thought" href="entries/data_entry.html">data</a> resolution, and focus &amp; selection mechanisms.
Such mechanisms for <a class="thought" href="entries/data_entry.html">data</a> selection are imperative for general <a class="thought" href="entries/intelligence_entry.html">intelligence</a>:
even moderately complex environments have a richness of <a class="thought" href="entries/data_entry.html">data</a> that far exceeds
any <a class="thought" href="entries/system_entry.html">system</a>'s ability to usefully process.</p>
<p>The <a class="thought" href="entries/system_entry.html">system</a> handles a very wide variety of <a class="thought" href="entries/data_entry.html">data</a> types and
control signal requirements -- including those for visual, sound, and raw <a class="thought" href="entries/data_entry.html">data</a>
(e.g., <a class="thought" href="entries/database_entry.html">database</a>, <a class="thought" href="entries/internet_entry.html">internet</a>, keyboard), as well as various output actuators. A
<a class="thought" href="entries/novel_entry.html">novel</a> "<a class="thought" href="entries/system_entry.html">system</a> probe" provides the <a class="thought" href="entries/system_entry.html">system</a> with monitoring and control of its
internal states (a form of meta-cognition). Additional probes -- either custom
<a class="thought" href="entries/interface_entry.html">interface</a>s with other <a class="thought" href="entries/system_entry.html">system</a>s or additional real-world sensors/ actuators -- can
easily be added to the <a class="thought" href="entries/system_entry.html">system</a>.</p>
<p><b>Development
Environment/ <a class="thought" href="entries/language_entry.html">Language</a>/ <a class="thought" href="entries/hardware_entry.html">Hardware</a></b>. The complete AGI <a class="thought" href="entries/engine_entry.html">engine</a> plus associated
support <a class="thought" href="entries/program_entry.html">program</a>s are <a class="thought" href="entries/implement_entry.html">implement</a>ed in (<a class="thought" href="entries/object_oriented_entry.html">Object Oriented</a>) C# under <a class="thought" href="entries/microsoft_entry.html">Microsoft</a>'s .NET
framework. The <a class="thought" href="entries/system_entry.html">system</a> is designed for optional remoting of various <a class="thought" href="entries/component_entry.html">component</a>s,
thus allowing for some distributed processing. Current tests show that
practical (proof-of-<a class="thought" href="entries/concept_entry.html">concept</a>) prototype performance can be achieved on a single,
conventional <a class="thought" href="entries/personal_computer_entry.html">PC</a> (2 Ghz, 512 Meg). Even a non-performance-tuned <a class="thought" href="entries/implement_entry.html">implement</a>ation
can process several complex <a class="thought" href="entries/pattern_entry.html">pattern</a>s per second on a <a class="thought" href="entries/database_entry.html">database</a> of well over a
million stored features.</p>
<h1>6. From <a class="thought" href="entries/algorithm_entry.html">Algorithm</a>s to General <a class="thought" href="entries/intelligence_entry.html">Intelligence</a> </h1>
<p>This section covers some of our near-term <a class="thought" href="entries/research_entry.html">research</a> and
development; it aims to illustrate our expected path toward meaningful general
<a class="thought" href="entries/intelligence_entry.html">intelligence</a>. While this work barely approaches higher-level <i><a class="thought" href="entries/animal_entry.html">animal</a></i> cognition (exceeding it in some
aspects, but falling far short in others such as sensory-motor skills), we take
it to be a crucial step in proving the validity and practicality of our model.
Furthermore, the actual functionality achieved should be highly competitive, if
not unique, in applications where significant autonomous adaptivity and <a class="thought" href="entries/data_entry.html">data</a>
selection, lack of brittleness, dynamic <a class="thought" href="entries/pattern_entry.html">pattern</a> processing, flexible actuation,
and self-supervised <a class="thought" href="entries/learning_entry.html">learning</a> are central requirements.</p>
<p>General <a class="thought" href="entries/intelligence_entry.html">intelligence</a> doesn't comprise one single, brilliant
knock-out <a class="thought" href="entries/invention_entry.html">invention</a> or design feature; instead, it emerges from the synergetic
integration of a <a class="thought" href="entries/number_entry.html">number</a> of essential fundamental <a class="thought" href="entries/component_entry.html">component</a>s. On the structural
side, the <a class="thought" href="entries/system_entry.html">system</a> must integrate <a class="thought" href="entries/sense_entry.html">sense</a> inputs, <a class="thought" href="entries/memory_entry.html">memory</a>, and actuators, while on
the functional side various <a class="thought" href="entries/learning_entry.html">learning</a>, recognition, recall and <a class="thought" href="entries/action_entry.html">action</a>
capabilities must operate seamlessly on a wide range of static and dynamic
<a class="thought" href="entries/pattern_entry.html">pattern</a>s. In addition, these cognitive abilities must be <a class="thought" href="entries/concept_entry.html">concept</a>ual and
<a class="thought" href="entries/context_entry.html">context</a>ual -- they must be able to generalize <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, and interpret it
against different backgrounds.</p>
<p>A key milestone in our project is testing the <i>integrated</i> functionality of the <a class="thought" href="entries/basic_entry.html">basic</a>
cognitive <a class="thought" href="entries/component_entry.html">component</a>s within our overall AGI framework. A <a class="thought" href="entries/number_entry.html">number</a> of
custom-developed, highly-configurable test utilities are used to test the
cohesive functioning of the whole <a class="thought" href="entries/system_entry.html">system</a>. This automated training and
evaluation is supplemented by manual <a class="thought" href="entries/experiment_entry.html">experiment</a>ation in numerous different
environments and applications. <a class="thought" href="entries/experience_entry.html">Experience</a> gained by these tests helps to refine
the complex <a class="thought" href="entries/dynamics_entry.html">dynamics</a> of interacting <a class="thought" href="entries/algorithm_entry.html">algorithm</a>s and <a class="thought" href="entries/parameter_entry.html">parameter</a>s.</p>
<p>One of the general difficulties with AGI development is to
determine absolute measures of success. Part of the <a class="thought" href="entries/reason_entry.html">reason</a> is that this field
is still nascent, and thus no agreed definitions, let alone tests or measures
of low-level general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> exist. As we proceed with our project we expect
to develop ever more effective protocols and metrics for assessing cognitive
ability. Our <a class="thought" href="entries/system_entry.html">system</a>'s performance evaluation is guided by this description:
"General <a class="thought" href="entries/intelligence_entry.html">intelligence</a> comprises the ability to acquire (and adapt) the
<a class="thought" href="entries/knowledge_entry.html">knowledge</a> and skills required for achieving a wide range of goals in a variety
of <a class="thought" href="entries/domain_entry.html">domain</a>s."</p>
<p>In this <a class="thought" href="entries/context_entry.html">context</a>, "acquisition" includes all of the
following: automatic, via <a class="thought" href="entries/sense_entry.html">sense</a> inputs (feature/ <a class="thought" href="entries/data_entry.html">data</a> driven); explicitly
taught; discovered through exploration or <a class="thought" href="entries/experiment_entry.html">experiment</a>ation; internal processes
(e.g., association, categorization, statistics, etc.). </p>
<p>"Adaptation" implies that new <a class="thought" href="entries/knowledge_entry.html">knowledge</a> is integrated
appropriately. </p>
<p>"<a class="thought" href="entries/knowledge_entry.html">Knowledge</a> and skills" refer to all kinds of <a class="thought" href="entries/data_entry.html">data</a> and
abilities (states and behaviors) that the <a class="thought" href="entries/system_entry.html">system</a> acquires for the short or long
term.</p>
<p>Our initial protocol for evaluating AGIs aims to cover a
wide spectrum of <a class="thought" href="entries/domain_entry.html">domain</a>s and goals by simulating sample applications in 2D
virtual worlds. In particular, these tests should assess the degree to which
the foundational abilities operate as an integrated, mutually supportive whole
-- and without <a class="thought" href="entries/program_entry.html">program</a>mer intervention! Here are three examples:</p>
<h3>Sample Test <a class="thought" href="entries/domain_entry.html">Domain</a>s for Initial Performance Criteria</h3>
<p><b>Adaptive Security
Monitor</b>. This <a class="thought" href="entries/system_entry.html">system</a> scans video monitors and alarm panels that oversee a
secure area (say, factory, office building, etc.), and responds appropriately
to abnormal conditions. Note, this is somewhat similar to a site monitoring
application at MIT (Grimson 1998).</p>
<p>This simulation calls for a visual environment that contains
a lot of detail but has only limited dynamic activity -- this is its normal
state (green). Two levels of abnormality exist: (i) minor, or known disturbance
(yellow); (ii) major, or unknown disturbance (red).</p>
<p>The <a class="thought" href="entries/system_entry.html">system</a> must initially learn the normal state by simple
exposure (automatically scanning the environment) at different resolutions
(detail). It must also learn "yellow" conditions by being shown a <a class="thought" href="entries/number_entry.html">number</a> of
samples (some at high resolution). All other states must output "red."</p>
<p>Standard <a class="thought" href="entries/operation_entry.html">operation</a> is to continuously scan the environment
at low resolution. If any abnormal condition is detected the <a class="thought" href="entries/system_entry.html">system</a> must learn
to change to higher resolution in <a class="thought" href="entries/order_entry.html">order</a> to discriminate between "yellow" and
"red."</p>
<p>The <a class="thought" href="entries/system_entry.html">system</a> must adapt to changes in the environment (and
totally different environments) by simple exposure training.</p>
<p><b>Sight Assistant</b>.
The <a class="thought" href="entries/system_entry.html">system</a> controls a movable "eye" (by voice command) that enables the
identification (by voice output) of at least a hundred different <a class="thought" href="entries/object_entry.html">object</a>s in the
world. A trainer will dynamically teach the <a class="thought" href="entries/system_entry.html">system</a> new names, associations, and
eye movement commands.</p>
<p>The visual probe can select among different scenes
(simulating rooms) and focus on different parts of each scene. The scenes
depict <a class="thought" href="entries/object_entry.html">object</a>s of varying <a class="thought" href="entries/attribute_entry.html">attribute</a>s: color, size, shape, various <a class="thought" href="entries/dynamics_entry.html">dynamics</a>,
etc. (and combinations of these), against different backgrounds.</p>
<p>Initial training will be to attach simple sound commands to
maneuver the "eye," and to associate word labels with selected <a class="thought" href="entries/object_entry.html">object</a>s. The
<a class="thought" href="entries/system_entry.html">system</a> must then reliably execute voice commands and respond with appropriate
identification (if any). Additional functionality could be to have the <a class="thought" href="entries/system_entry.html">system</a>
scan the various scenes when idle, and to automatically report selected
<a class="thought" href="entries/import_entry.html">import</a>ant <a class="thought" href="entries/object_entry.html">object</a>s.</p>
<p><a class="thought" href="entries/object_entry.html">Object</a> identification must cover a wide spectrum of
different <a class="thought" href="entries/attribute_entry.html">attribute</a> combinations and tolerances. The <a class="thought" href="entries/system_entry.html">system</a> must easily learn
new scenes, <a class="thought" href="entries/object_entry.html">object</a>s, words and associations, and also adapt to changes in any
of these variables.</p>
<p><b>Maze Explorer</b>. A
(virtual) <a class="thought" href="entries/entity_entry.html">entity</a> explores a moderately complex environment. It discovers what
types of <a class="thought" href="entries/object_entry.html">object</a>s aid or hinder its <a class="thought" href="entries/object_entry.html">object</a>ives, while <a class="thought" href="entries/learning_entry.html">learning</a> to navigate this
dynamic world. It can also be trained to perform certain behaviors.</p>
<p>The virtual world is filled with a great <a class="thought" href="entries/number_entry.html">number</a> of different
<a class="thought" href="entries/object_entry.html">object</a>s (see previous example). In addition, some of these <a class="thought" href="entries/object_entry.html">object</a>s move in
<a class="thought" href="entries/space_entry.html">space</a> at varying speeds and <a class="thought" href="entries/dynamics_entry.html">dynamics</a>, and may be solid and/ or immovable.
Groups of different kinds of <a class="thought" href="entries/object_entry.html">object</a>s have pre-assigned <a class="thought" href="entries/attribute_entry.html">attribute</a>s that indicate
negative or positive. The AGI <a class="thought" href="entries/engine_entry.html">engine</a> controls the direction and speed of an
<a class="thought" href="entries/entity_entry.html">entity</a> in this virtual world. Its goal is to learn to navigate around immovable
and negative <a class="thought" href="entries/object_entry.html">object</a>s to reliably reach hidden positives.</p>
<p>The <a class="thought" href="entries/system_entry.html">system</a> can also be trained to respond to operator
commands to perform behaviors of varying degrees of <a class="thought" href="entries/complexity_entry.html">complexity</a> (for example,
<a class="thought" href="entries/action_entry.html">action</a>s similar to "tricks" one might teach a dog). This "Maze Explorer" can easily
be <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> up to deal with fairly complex tasks.</p>
<h3> Towards Increased <a class="thought" href="entries/intelligence_entry.html">Intelligence</a> </h3>
<p>Clearly, the tasks described above do not by themselves
represent any kind of breakthrough in <a class="thought" href="entries/ai_entry.html">artificial intelligence</a> <a class="thought" href="entries/research_entry.html">research</a>. They
have been achieved many times before. However, what we <i>do</i> believe to be significant and unique is the achievement of these
various tasks without any task-specific <a class="thought" href="entries/program_entry.html">program</a>ming or <a class="thought" href="entries/parameter_entry.html">parameter</a>ization. It is
not <i>what</i> is being done, but <i>how</i> it is done.</p>
<p>Development beyond these <a class="thought" href="entries/basic_entry.html">basic</a> proof-of-<a class="thought" href="entries/concept_entry.html">concept</a> tests will
advance in two directions: 1) to significantly increase resolution, <a class="thought" href="entries/data_entry.html">data</a>
volume, and <a class="thought" href="entries/complexity_entry.html">complexity</a> in applications similar to the tests; 2) to add
higher-level functionality. In addition to work aimed at further developing and
proving our general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> model, there are also numerous practical
enhancements that can be done. These would include <a class="thought" href="entries/implement_entry.html">implement</a>ing multi-processor
and <a class="thought" href="entries/network_entry.html">network</a> versions, and integrating our <a class="thought" href="entries/system_entry.html">system</a> with <a class="thought" href="entries/database_entry.html">database</a>s or with other
existing <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/technology_entry.html">technology</a> such as <a class="thought" href="entries/expert_system_entry.html">expert system</a>s, <a class="thought" href="entries/voice_recognition_entry.html">voice recognition</a>, <a class="thought" href="entries/robotics_entry.html">robotics</a>, or
<a class="thought" href="entries/sense_entry.html">sense</a> modules with specialized feature extractors.</p>
<p>By far the most <a class="thought" href="entries/import_entry.html">import</a>ant of these <a class="thought" href="entries/future_entry.html">future</a> developments
concern higher-level ability. Here is a partial list of <a class="thought" href="entries/action_entry.html">action</a> items, all of
which are derived from lower-level foundations: </p>
<blockquote>
<p>Spread activation and retain <a class="thought" href="entries/context_entry.html">context</a> over extended period</p>
<p>Support more complex internal temporal <a class="thought" href="entries/pattern_entry.html">pattern</a>s, both for enhanced recognition 
    and anticipation, and for cognitive and <a class="thought" href="entries/action_entry.html">action</a> sequences</p>
<p>Internal activation feedback for processing without input</p>
<p><a class="thought" href="entries/deduction_entry.html">Deduction</a>, achieved through selective <a class="thought" href="entries/concept_entry.html">concept</a> activation</p>
<p>Advanced categorization by arbitrary dimensions</p>
<p><a class="thought" href="entries/learning_entry.html">Learning</a> of more complex behavior</p>
<p>Abstract and merged <a class="thought" href="entries/concept_entry.html">concept</a> formation</p>
<p><a class="thought" href="entries/structure_entry.html">Structure</a>d <a class="thought" href="entries/language_entry.html">language</a> acquisition</p>
<p>Increased awareness and control of internal states (introspection)</p>
<p><a class="thought" href="entries/learning_entry.html">Learning</a> <a class="thought" href="entries/logic_entry.html">logic</a> and other problem-solving <a class="thought" href="entries/method_entry.html">method</a>ologies.</p>
</blockquote>
<h1>7. Other <a class="thought" href="entries/research_entry.html">Research</a><a href="#_ftn5" name="_ftnref5" title=""><sup>[5]</sup></a></h1>
<p>Many different approaches to <a class="thought" href="entries/ai_entry.html">AI</a> exist; some of the
differences are straight forward while others are subtle and hinge on difficult
philosophical issues. As such the exact placement of our work relative to that
of others is difficult and, indeed, open to debate. Our view that "<a class="thought" href="entries/intelligence_entry.html">intelligence</a>
is a property of an <a class="thought" href="entries/entity_entry.html">entity</a> that engages in two way interaction with an external
environment," technically puts us in the area of "<a class="thought" href="entries/agent_entry.html">agent</a> <a class="thought" href="entries/system_entry.html">system</a>s" (Russel 1995).
However, our emphasis on a connectionist rather than classical approach to
cognitive modeling, places our work in the field of "embodied cognitive
<a class="thought" href="entries/science_entry.html">science</a>." (See Pfeifer and Scheier 1999 for a comprehensive overview.)</p>
<p>While our <i>approach</i>
is similar to other <a class="thought" href="entries/research_entry.html">research</a> in embodied <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a>, in some respects
our <i>goals</i> are substantively
different. A key difference is our belief that a core <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of cognitive
abilities working together is sufficient to produce general <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. This
is in marked contrast to others in embodied <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a> who consider
<a class="thought" href="entries/intelligence_entry.html">intelligence</a> to be necessarily specific to a <a class="thought" href="entries/single_electron_transfer_entry.html">set</a> of problems within a given
environment. In other words, they believe that autonomous agents always exist
in ecological niches. As such they focus their <a class="thought" href="entries/research_entry.html">research</a> on building very
limited <a class="thought" href="entries/system_entry.html">system</a>s that effectively deal with only a small <a class="thought" href="entries/number_entry.html">number</a> of problems
within a specific limited environment. Almost all work in the area follows this
-- see Braitenberg (1984), Brooks (1994) or Arbib (1992) for just a few well
known examples. Their stance contradicts the fact that humans possess general
<a class="thought" href="entries/intelligence_entry.html">intelligence</a>; we are able to effectively deal with a wide range of problems
that are significantly beyond anything that could be called our "ecological
niche."</p>
<p>Perhaps the closest project to ours that is strictly in the
area of embodied <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a> is the <a class="thought" href="entries/cog_entry.html">Cog</a> project at MIT (Brooks 1993). The
project aims to understand the <a class="thought" href="entries/dynamics_entry.html">dynamics</a> of <a class="thought" href="entries/human_entry.html">human</a> interaction by the
construction of a <a class="thought" href="entries/human_entry.html">human</a>-like <a class="thought" href="entries/robot_entry.html">robot</a> complete with upper torso, a head, eyes,
arms and hands. While this project is significantly more ambitious than other
projects in terms of the level and <a class="thought" href="entries/complexity_entry.html">complexity</a> of the <a class="thought" href="entries/system_entry.html">system</a>'s <a class="thought" href="entries/dynamics_entry.html">dynamics</a> and
abilities, the <a class="thought" href="entries/system_entry.html">system</a> is still essentially niche focused (<a class="thought" href="entries/element_entry.html">element</a>ary <a class="thought" href="entries/human_entry.html">human</a>
social and physical interaction) when compared to our own efforts at general
<a class="thought" href="entries/intelligence_entry.html">intelligence</a>.</p>
<p>Probably the closest work to ours in the <a class="thought" href="entries/sense_entry.html">sense</a> that it also
aims to achieve general rather than niche <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is the Novamente project
under the direction of Ben Goertzel. (The project was formerly known as Webmind
-- see Goertzel 1997, 2001.) Novamente relies on a hybrid of low-level neural
net-like <a class="thought" href="entries/dynamics_entry.html">dynamics</a> for activation spreading and <a class="thought" href="entries/concept_entry.html">concept</a> priming, coupled with
high-level semantic constructs to represent a variety of logical, causal and
spatial-temporal relations. While the <a class="thought" href="entries/semantics_entry.html">semantics</a> of the <a class="thought" href="entries/system_entry.html">system</a>'s internal state
are relatively easy to understand compared to a strictly connectionist
approach, the classical <a class="thought" href="entries/element_entry.html">element</a>s in the <a class="thought" href="entries/system_entry.html">system</a>'s design open the door to many
of the fundamental problems that have plagued classical <a class="thought" href="entries/ai_entry.html">AI</a> over the last fifty
years. For example, high-level <a class="thought" href="entries/semantics_entry.html">semantics</a> require a complex meta-<a class="thought" href="entries/logic_entry.html">logic</a> contained
in hard coded high-level <a class="thought" href="entries/reason_entry.html">reason</a>ing and other high-level cognitive <a class="thought" href="entries/system_entry.html">system</a>s.
These high-level <a class="thought" href="entries/system_entry.html">system</a>s contain significant implicit <a class="thought" href="entries/semantics_entry.html">semantics</a> that may not be
grounded in environmental interaction but are rather hard coded by the designer
-- thus causing <a class="thought" href="entries/symbol_entry.html">symbol</a> grounding problems (Harnad 1990). The relatively fixed,
high-level <a class="thought" href="entries/method_entry.html">method</a>s of <a class="thought" href="entries/knowledge_representation_entry.html">knowledge representation</a> and manipulation that this
approach entails are also prone to "frame of reference" (McCarthy and Hayes 1969; Pylyshyn 1987)
and "brittleness" problems. In a strictly embodied <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a> approach,
as we have taken, all <a class="thought" href="entries/knowledge_entry.html">knowledge</a> is derived from <a class="thought" href="entries/agent_entry.html">agent</a>-environment interaction
thus avoiding these long-standing problems of classical <a class="thought" href="entries/ai_entry.html">AI</a>.</p>
<p>--<a class="thought" href="entries/clark_entry.html">Andy Clark</a> (1997) is another
<a class="thought" href="entries/research_entry.html">research</a>er whose model closely resembles our own, but there are no
<a class="thought" href="entries/implement_entry.html">implement</a>ations specifically based on his theoretical work. Igor Aleksander's
(now dormant) MAGNUS project (1996) also incorporated many key AGI <a class="thought" href="entries/concept_entry.html">concept</a>s
that we have identified, but it was severely limited by a classical <a class="thought" href="entries/ai_entry.html">AI</a>,
finite-<a class="thought" href="entries/state_machine_entry.html">state machine</a> approach. Valeriy Nenov and Michael Dyer of UCLA (1994)
used "massively" parallel <a class="thought" href="entries/hardware_entry.html">hardware</a> (a CM-2 <a class="thought" href="entries/connection_machine_entry.html">Connection Machine</a>) to <a class="thought" href="entries/implement_entry.html">implement</a> a
virtual, interactive perceptual design close to our own, but with a more rigid,
pre-<a class="thought" href="entries/program_entry.html">program</a>med <a class="thought" href="entries/structure_entry.html">structure</a>. Unfortunately, this ambitious, ground-breaking work
has since been abandoned. The project was probably severely hampered by limited
(at the <a class="thought" href="entries/time_entry.html">time</a>) <a class="thought" href="entries/hardware_entry.html">hardware</a>.--</p>
<p>Moving further away from embodied <a class="thought" href="entries/cognitive_science_entry.html">cognitive science</a> to
purely classical <a class="thought" href="entries/research_entry.html">research</a> in general <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, perhaps the best known
<a class="thought" href="entries/system_entry.html">system</a> is the <a class="thought" href="entries/cyc_entry.html">Cyc</a> project being pursued by Lenat (1990). Essentially Lenat sees
general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> as being "<a class="thought" href="entries/common_sense_entry.html">common sense</a>." He hopes to achieve this goal by
adding many millions of facts about the world into a huge <a class="thought" href="entries/database_entry.html">database</a>. After many
years of work and millions of dollars in funding there is still a long way to
go as the sheer <a class="thought" href="entries/number_entry.html">number</a> of facts that humans know about the world is truly staggering.
We doubt that a very large <a class="thought" href="entries/database_entry.html">database</a> of <a class="thought" href="entries/basic_entry.html">basic</a> facts is enough to give a <a class="thought" href="entries/computer_entry.html">computer</a>
much general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> -- the mechanisms for autonomous <a class="thought" href="entries/knowledge_entry.html">knowledge</a> acquisition
are missing. Being a classical approach to <a class="thought" href="entries/ai_entry.html">AI</a> this also suffers from the
fundamental problems of classical <a class="thought" href="entries/ai_entry.html">AI</a> listed above. For example the <a class="thought" href="entries/symbol_entry.html">symbol</a>
grounding problem again: if facts about cats and dogs are just added to a
<a class="thought" href="entries/database_entry.html">database</a> that the <a class="thought" href="entries/computer_entry.html">computer</a> can use even though it has never seen or interacted
with an <a class="thought" href="entries/animal_entry.html">animal</a>, are those <a class="thought" href="entries/concept_entry.html">concept</a>s really meaningful to the <a class="thought" href="entries/system_entry.html">system</a>? While his
project also claims to pursue "general <a class="thought" href="entries/intelligence_entry.html">intelligence</a>," it is really very
different from our own, both in its approach and in the difficulties it faces.</p>
<p>Analysis of <a class="thought" href="entries/ai_entry.html">AI</a>'s ongoing failure to overcome its
long-standing limitations reveals that it is not so much that Artificial
General <a class="thought" href="entries/intelligence_entry.html">Intelligence</a> has been tried and that it has failed, but rather that the
field has largely been abandoned -- be it for theoretical, historic, or <a class="thought" href="entries/commercial_entry.html">commercial</a>
<a class="thought" href="entries/reason_entry.html">reason</a>s. Certainly, our particular type of approach, as detailed in previous sections,
is receiving scant attention.</p>
<h1>8. Fast-track AGI -- Why so Rare?</h1>
<p>Widespread application of <a class="thought" href="entries/ai_entry.html">AI</a> has been hampered by a <a class="thought" href="entries/number_entry.html">number</a>
of core limitations that have plagued the field since the beginning, namely:</p>
<blockquote>
<p>The expense and delay of custom <a class="thought" href="entries/program_entry.html">program</a>ming <a class="thought" href="entries/individual_entry.html">individual</a> applications</p>
<p><a class="thought" href="entries/system_entry.html">System</a>s' inability to automatically learn from <a class="thought" href="entries/experience_entry.html">experience</a>, or to be user 
    teachable/ trainable</p>
<p>Reliability and performance issues caused by "brittleness" (the inability 
    of <a class="thought" href="entries/system_entry.html">system</a>s to automatically adapt to changing requirements, or <a class="thought" href="entries/data_entry.html">data</a> outside 
    of a predefined range)</p>
<p>Their limited <a class="thought" href="entries/intelligence_entry.html">intelligence</a> and <a class="thought" href="entries/common_sense_entry.html">common sense</a>.</p>
</blockquote>
<p>The most direct path to solving these long-standing problems
is to <a class="thought" href="entries/concept_entry.html">concept</a>ually identify the fundamental characteristics common to all
high-level <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, and to <a class="thought" href="entries/engine_entry.html">engine</a>er <a class="thought" href="entries/system_entry.html">system</a>s with this <a class="thought" href="entries/basic_entry.html">basic</a> functionality,
in a manner that capitalizes on <a class="thought" href="entries/human_entry.html">human</a> and technological strength.</p>
<p>General <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is the key to achieving robust
autonomous <a class="thought" href="entries/system_entry.html">system</a>s that can learn and adapt to a wide range of uses. It is also
the cornerstone of self-improving, or Seed <a class="thought" href="entries/ai_entry.html">AI</a> -- using <a class="thought" href="entries/basic_entry.html">basic</a> abilities to
bootstrap higher-level ones. This essay identified foundational <a class="thought" href="entries/component_entry.html">component</a>s of
general <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, as well as crucial considerations particular to the
effective development of the artificial variety. It highlighted the fact that
very few <a class="thought" href="entries/research_entry.html">research</a>ers are actually following this most direct route to AGI.</p>
<p>If the approach outlined above is so promising, then why is
has it received so little attention? Why is hardly anyone actually working on
it?</p>
<p>A short answer: Of all the people working in the field called "<a class="thought" href="entries/ai_entry.html">AI</a>":</p>
<blockquote>
<p>80% don't believe in the <a class="thought" href="entries/concept_entry.html">concept</a> of General <a class="thought" href="entries/intelligence_entry.html">Intelligence</a> (but instead, in 
    a large collection of specific skills and <a class="thought" href="entries/knowledge_entry.html">knowledge</a>)</p>
<p>Of those that do, 80% don't believe that artificial, <a class="thought" href="entries/human_entry.html">human</a>-level <a class="thought" href="entries/intelligence_entry.html">intelligence</a> 
    is possible - either ever, or for a long, long <a class="thought" href="entries/time_entry.html">time</a></p>
<p>Of those that do, 80% work on <a class="thought" href="entries/domain_entry.html">domain</a>-specific <a class="thought" href="entries/ai_entry.html">AI</a> projects for <a class="thought" href="entries/commercial_entry.html">commercial</a> 
    or academic-political <a class="thought" href="entries/reason_entry.html">reason</a>s (results are more immediate)</p>
<p>Of those left, 80% have a poor <a class="thought" href="entries/concept_entry.html">concept</a>ual framework...</p>
</blockquote>
<p>Even though the above is a caricature, in contains more than
a grain of truth.</p>
<p>A great <a class="thought" href="entries/number_entry.html">number</a> of <a class="thought" href="entries/research_entry.html">research</a>ers reject the validity or
<a class="thought" href="entries/import_entry.html">import</a>ance of "general <a class="thought" href="entries/intelligence_entry.html">intelligence</a>." For many, controversies in <a class="thought" href="entries/psychology_entry.html">psychology</a>
(such as those stoked by <i>The Bell Curve</i>)
make this an unpopular, if not taboo subject. Others, conditioned by decades of
<a class="thought" href="entries/domain_entry.html">domain</a>-specific work, simply do not see the benefits of Seed <a class="thought" href="entries/ai_entry.html">AI</a> -- solving the
problems only once.</p>
<p>Of those that do not in principle <a class="thought" href="entries/object_entry.html">object</a> to general
<a class="thought" href="entries/intelligence_entry.html">intelligence</a>, many don't believe that AGI is possible -- in their <a class="thought" href="entries/life_entry.html">life</a>-<a class="thought" href="entries/time_entry.html">time</a>, or
ever. Some hold this position because they themselves tried and failed "in
their youth." Others believe that AGI is not the <i>best</i> approach to achieving "<a class="thought" href="entries/ai_entry.html">AI</a>," or are at a total loss on how to
go about it. Very few <a class="thought" href="entries/research_entry.html">research</a>ers have actually studied the problem from our
(the general <a class="thought" href="entries/intelligence_entry.html">intelligence</a>/ Seed <a class="thought" href="entries/ai_entry.html">AI</a>) perspective. Some are actually trying to
reverse-<a class="thought" href="entries/engine_entry.html">engine</a>er the <a class="thought" href="entries/brain_entry.html">brain</a> -- one function at a <a class="thought" href="entries/time_entry.html">time</a>. There are also those who
have moral <a class="thought" href="entries/object_entry.html">object</a>ions, or who are afraid of it.</p>
<p>Of course, a great many are so focused on particular, narrow
aspects of <a class="thought" href="entries/intelligence_entry.html">intelligence</a> that they simply don't get around to looking at the big
picture -- they leave it to others to make it happen. It is also <a class="thought" href="entries/import_entry.html">import</a>ant to
note that there are often strong financial and institutional pressures to
pursue specialized <a class="thought" href="entries/ai_entry.html">AI</a>.</p>
<p>All of the above combine to create a dynamic where Real <a class="thought" href="entries/ai_entry.html">AI</a>
is not "fashionable" -- getting little respect, funding, and support -- further
reducing the <a class="thought" href="entries/number_entry.html">number</a> of people drawn into it!</p>
<p>These should be more than enough <a class="thought" href="entries/reason_entry.html">reason</a>s to account for the
dearth of AGI <a class="thought" href="entries/progress_entry.html">progress</a>. But it gets worse. <a class="thought" href="entries/research_entry.html">Research</a>ers actually trying to build
AGI <a class="thought" href="entries/system_entry.html">system</a>s are further hampered by a myriad of misconceptions, poor choices,
and lack of resources (funding and <a class="thought" href="entries/research_entry.html">research</a>). Many of the technical issues were
explored previously (See sections 3 and 7.), but a few others are worth
mentioning:</p>
<p><b><a class="thought" href="entries/epistemology_entry.html">Epistemology</a>.</b>
Models of AGI can only be as good as their underlying theory of <a class="thought" href="entries/knowledge_entry.html">knowledge</a> -- the
<a class="thought" href="entries/nature_entry.html">nature</a> of <a class="thought" href="entries/knowledge_entry.html">knowledge</a>, and how it relates to <a class="thought" href="entries/reality_entry.html">reality</a>. The realization that
high-level <a class="thought" href="entries/intelligence_entry.html">intelligence</a> is based on <i><a class="thought" href="entries/concept_entry.html">concept</a>ual</i>
representation of <a class="thought" href="entries/reality_entry.html">reality</a> underpins design decisions such as adaptive, fuzzy
vector encoding, and an interactive, embodied approach. Other consequences are
the need for <a class="thought" href="entries/sense_entry.html">sense</a>-based focus and selection, and <a class="thought" href="entries/context_entry.html">context</a>ual activation. The
central <a class="thought" href="entries/import_entry.html">import</a>ance of a highly-integrated <a class="thought" href="entries/pattern_entry.html">pattern</a> <a class="thought" href="entries/network_entry.html">network</a> -- especially
including dynamic ones -- becomes obvious on understanding the relationship
between entities, <a class="thought" href="entries/attribute_entry.html">attribute</a>s, <a class="thought" href="entries/concept_entry.html">concept</a>s, <a class="thought" href="entries/action_entry.html">action</a>s, and <a class="thought" href="entries/thought_entry.html">thought</a>s. These and
several other insights lay the foundation for solving problems related to
grounding, brittleness, and <a class="thought" href="entries/common_sense_entry.html">common sense</a>. Finally, there is still a lot of
unnecessary confusion about the relationship between <a class="thought" href="entries/concept_entry.html">concept</a>s and <a class="thought" href="entries/symbol_entry.html">symbol</a>s. A
dynamic that continues to handicap <a class="thought" href="entries/ai_entry.html">AI</a> is the lingering schism between
traditionalists and connectionists. This unfortunately helps to perpetuate a
false dichotomy between explicit <a class="thought" href="entries/symbol_entry.html">symbol</a>s/ <a class="thought" href="entries/schema_entry.html">schema</a>, and incomprehensible
<a class="thought" href="entries/pattern_entry.html">pattern</a>s.</p>
<p><b>Theory of <a class="thought" href="entries/mind_entry.html">Mind</a></b>.
Another area of concern is sloppy formulation and poor understanding of several
key <a class="thought" href="entries/concept_entry.html">concept</a>s: <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, <a class="thought" href="entries/intelligence_entry.html">intelligence</a>, volition, meaning, <a class="thought" href="entries/emotion_entry.html">emotion</a>s, common
<a class="thought" href="entries/sense_entry.html">sense</a>, and "qualia." The fact that hundreds of <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/research_entry.html">research</a>ers attend
conferences every year where key speakers proclaim that "we don't understand
<a class="thought" href="entries/consciousness_entry.html">consciousness</a> (or qualia, or whatever), and will probably <i>never</i> understand it' indicates just how pervasive this problem is.
<a class="thought" href="entries/minsky_entry.html">Marvin Minsky</a>'s characterization of <a class="thought" href="entries/consciousness_entry.html">consciousness</a> being a "suitcase word"<a href="#_ftn6" name="_ftnref6" title="">[6]</a>
is correct. Let's just unpack it!</p>
<p>Errors like these are often behind <a class="thought" href="entries/research_entry.html">research</a> going off at a
tangent relative to stated long-term goals. Two examples are an undue emphasis
on <a class="thought" href="entries/biological_entry.html">biological</a> feasibility, and the belief that embodied <a class="thought" href="entries/intelligence_entry.html">intelligence</a> cannot be
virtual, that it has to be <a class="thought" href="entries/implement_entry.html">implement</a>ed in physical robots.</p>
<p><b>Cognitive <a class="thought" href="entries/psychology_entry.html">psychology</a>.</b>
It goes without saying that a proper understanding of the <a class="thought" href="entries/concept_entry.html">concept</a> "<a class="thought" href="entries/intelligence_entry.html">intelligence</a>"
is key to <a class="thought" href="entries/engine_entry.html">engine</a>ering it. In addition to <a class="thought" href="entries/epistemology_entry.html">epistemology</a>, several areas of cognitive
<a class="thought" href="entries/psychology_entry.html">psychology</a> are crucial to unraveling its meaning. Misunderstanding <a class="thought" href="entries/intelligence_entry.html">intelligence</a>
has led to some costly disappointments, such as manually accumulating huge
amounts of largely useless <a class="thought" href="entries/data_entry.html">data</a> (<a class="thought" href="entries/knowledge_entry.html">knowledge</a> without meaning), efforts to achieve
<a class="thought" href="entries/intelligence_entry.html">intelligence</a> by combining masses of dumb agents, or trying to obtain meaningful
<a class="thought" href="entries/conversation_entry.html">conversation</a> from an isolated <a class="thought" href="entries/network_entry.html">network</a> of <a class="thought" href="entries/symbol_entry.html">symbol</a>s.</p>
<p><b>Project focus.</b>
The few projects that <i>do</i> pursue AGI
based on relatively sound models run yet another risk: they can easily lose
focus. Sometimes <a class="thought" href="entries/commercial_entry.html">commercial</a> considerations hijack a project's direction, while
others get sidetracked by (relatively) irrelevant technical issues, such as
trying to match an unrealistically high level of performance, fixating on
<a class="thought" href="entries/biological_entry.html">biological</a> feasibility of design, or attempting to <a class="thought" href="entries/implement_entry.html">implement</a> high-level
functions before their <a class="thought" href="entries/time_entry.html">time</a>. A clearly mapped-out developmental path to
<a class="thought" href="entries/human_entry.html">human</a>-level <a class="thought" href="entries/intelligence_entry.html">intelligence</a> can serve as a powerful antidote to losing sight of
"the big picture." A vision of how to get from "here" to "there" also helps to
maintain motivation in such a difficult endeavor. </p>
<p><b><a class="thought" href="entries/research_entry.html">Research</a> support.</b>
AGI utilizes, or more precisely, is an integration of a large <a class="thought" href="entries/number_entry.html">number</a> of
existing <a class="thought" href="entries/ai_entry.html">AI</a> technologies. Unfortunately, many of the most crucial areas are
sadly under-<a class="thought" href="entries/research_entry.html">research</a>ed. They include: </p>
<blockquote>
<p>Incremental, real-<a class="thought" href="entries/time_entry.html">time</a>, unsupervised/ self-supervised <a class="thought" href="entries/learning_entry.html">learning</a> (vs. back-propagation)</p>
<p>Integrated support for temporal <a class="thought" href="entries/pattern_entry.html">pattern</a>s</p>
<p>Dynamically-adaptive <a class="thought" href="entries/neural_network_entry.html">neural network</a> topologies</p>
<p>Self-tuning of <a class="thought" href="entries/system_entry.html">system</a> <a class="thought" href="entries/parameter_entry.html">parameter</a>s, integrating bottom-up (<a class="thought" href="entries/data_entry.html">data</a> driven) and 
    top-down (goal/ meta-cognition driven) auto-adaptation</p>
<p><a class="thought" href="entries/sense_entry.html">Sense</a> probes with auto-adaptive feature extractors.</p>
</blockquote>
<p>Naturally, these very limitations feed back to reduce
support <i>for</i> AGI <a class="thought" href="entries/research_entry.html">research</a>.</p>
<p><b>Cost and difficulty</b>.
Achieving high-level AGI will be hard. However, it will not be nearly as
difficult as most experts think. A key <a class="thought" href="entries/element_entry.html">element</a> of "Real <a class="thought" href="entries/ai_entry.html">AI</a>" theory (and its
<a class="thought" href="entries/implement_entry.html">implement</a>ation) is to concentrate on the essentials of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>. Seed <a class="thought" href="entries/ai_entry.html">AI</a>
becomes a manageable problem -- in some respects much simpler than other
mainstream <a class="thought" href="entries/ai_entry.html">AI</a> goals - by eliminating huge areas of difficult, but inessential
<a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/complexity_entry.html">complexity</a>. Once we get the crucial fundamental functionality working, much
of the additional "<a class="thought" href="entries/intelligence_entry.html">intelligence</a>" (ability) required is taught or learned, not
<a class="thought" href="entries/program_entry.html">program</a>med. Having said this, I do believe that very substantial resources will
be required to scale up the <a class="thought" href="entries/system_entry.html">system</a> to <a class="thought" href="entries/human_entry.html">human</a>-level storage and processing
<a class="thought" href="entries/capacity_entry.html">capacity</a>. However, the far more moderate initial prototypes will serve as
proof-of-<a class="thought" href="entries/concept_entry.html">concept</a> for AGI while potentially seeding a large <a class="thought" href="entries/number_entry.html">number</a> of practical
new applications.</p>
<h1>9. Conclusion</h1>
<p>Understanding general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> and identifying its
essential <a class="thought" href="entries/component_entry.html">component</a>s are key to building next-generation <a class="thought" href="entries/ai_entry.html">AI</a> <a class="thought" href="entries/system_entry.html">system</a>s -- <a class="thought" href="entries/system_entry.html">system</a>s
that are far less expensive, yet significantly more capable. In addition to
concentrating on <i>general</i> <a class="thought" href="entries/learning_entry.html">learning</a>
abilities, a fast-track approach should also seek a path of least resistance --
one that capitalizes on <a class="thought" href="entries/human_entry.html">human</a> <a class="thought" href="entries/engine_entry.html">engine</a>ering strengths and available <a class="thought" href="entries/technology_entry.html">technology</a>.
Sometimes, this involves selecting the <a class="thought" href="entries/ai_entry.html">AI</a> road <i>less</i> traveled.</p>
<p>We believe that the theoretical model, cognitive <a class="thought" href="entries/component_entry.html">component</a>s,
and framework described above, joined with our other strategic design decisions
provide a solid basis for achieving practical AGI capabilities in the
foreseeable <a class="thought" href="entries/future_entry.html">future</a>. Successful <a class="thought" href="entries/implement_entry.html">implement</a>ation will significantly address many
traditional problems of <a class="thought" href="entries/ai_entry.html">AI</a>. Potential benefits include:</p>
<blockquote>
<p>Minimizing <i>initial</i> environment-specific <a class="thought" href="entries/program_entry.html">program</a>ming (through self-adaptive 
    <a class="thought" href="entries/configuration_entry.html">configuration</a>)</p>
<p>Substantially reducing <i>ongoing</i> <a class="thought" href="entries/software_entry.html">software</a> changes, because a large amount 
    of additional functionality and <a class="thought" href="entries/knowledge_entry.html">knowledge</a> will be acquired autonomously via 
    self-supervised <a class="thought" href="entries/learning_entry.html">learning</a></p>
<p>Greatly increasing the <i>scope of applications</i>, as users teach and train 
    additional capabilities</p>
<p>Improved <i>flexibility</i> and <i>robustness</i> resulting from <a class="thought" href="entries/system_entry.html">system</a>s' 
    ability to adapt to changing <a class="thought" href="entries/data_entry.html">data</a> <a class="thought" href="entries/pattern_entry.html">pattern</a>s, environments and goals.</p>
</blockquote>
<p>AGI promises to make an <a class="thought" href="entries/import_entry.html">import</a>ant contribution toward realizing <a class="thought" href="entries/software_entry.html">software</a> and 
  robotic <a class="thought" href="entries/system_entry.html">system</a>s that are more usable, intelligent, and <a class="thought" href="entries/human_entry.html">human</a>-friendly. The <a class="thought" href="entries/time_entry.html">time</a> 
  seems ripe for a major initiative down this new path of <a class="thought" href="entries/human_entry.html">human</a> advancement that 
  is now open to us.</p>
<p><i>To be published in the forthcoming book, </i>Real AI: New Approaches 
              to Artificial General <a class="thought" href="entries/intelligence_entry.html">Intelligence</a><i>. Reproduced with permission. 
              See </i><a href="http://web.archive.org/web/20071011200143/http://adaptiveai.com/RealAI.htm">Essentials of 
              General Intelligence: The direct path to AGI</a><i> for updates.</i></p>
<p>References </p>
<p><b>Aha, D.W.</b>
(Ed.) (1997). Lazy <a class="thought" href="entries/learning_entry.html">Learning</a>. <i>Artificial
<a class="thought" href="entries/intelligence_entry.html">Intelligence</a> Review,</i>11:1-5 Kluwer Academic Publishers </p>
<p><b>Aleksander, I.</b>
(1996). Impossible Minds. Imperial College Press</p>
<p><b>Arbib, M.A</b>.
(1992). <i><a class="thought" href="entries/schema_entry.html">Schema</a> theory</i>. In S. <a class="thought" href="entries/c_entry.html">C</a>.
Shapiro (Ed.), <i>Encyclopedia of Artificial
<a class="thought" href="entries/intelligence_entry.html">Intelligence</a>, </i>2nd ed (pp. 1427-1443).&#160;
John Wiley.</p>
<p><b>Braitenberg, V.</b>
(1984). <i>Vehicles: <a class="thought" href="entries/experiment_entry.html">Experiment</a>s in
synthetic <a class="thought" href="entries/psychology_entry.html">psychology</a></i>. MIT Press.</p>
<p><b>Brooks, R.A</b>.,
and Stein, L. A. (1993). Building brains for bodies. Memo 1439, Artificial
<a class="thought" href="entries/intelligence_entry.html">Intelligence</a> Lab, Massachusetts Institute of <a class="thought" href="entries/technology_entry.html">Technology</a></p>
<p><b>Brooks, R.A</b>.
(1994). Coherent behavior from many adaptive processes. In D. Cliff, P.
Husbands, J.A. Meyer, and S.W. Wilson (Eds.), <i>From <a class="thought" href="entries/animal_entry.html">animal</a>s to animats: Proceedings of the third International
Conference on Simulation of Adaptive Behavior </i>(421-430).MIT Press.</p>
<p><b>Churchland, P.M.</b>
(1995). <i>The <a class="thought" href="entries/engine_entry.html">Engine</a> of <a class="thought" href="entries/reason_entry.html">Reason</a>, the Seat of
the Soul: A Philosophical Journey into the <a class="thought" href="entries/brain_entry.html">Brain</a>.</i> MIT Press</p>
<p><b>Clark, A.</b>
(1997. <i>Being There: Putting <a class="thought" href="entries/brain_entry.html">Brain</a>, Body
and World Together Again. </i>MIT Press</p>
<p><b>Fritzke, B.</b>
(1995). <i>A growing neural gas <a class="thought" href="entries/network_entry.html">network</a>
learns topologies</i>. In Tesauro, G., Touretzky, D. S., and Leen, T. K.
(Eds.), <i>Advances in Neural <a class="thought" href="entries/information_entry.html">Information</a>
Processing <a class="thought" href="entries/system_entry.html">System</a>s 7</i> (pp. 625-632). MIT Press.</p>
<p><b>Goertzel, B.</b>
(1997). <i>From <a class="thought" href="entries/complexity_entry.html">complexity</a> to <a class="thought" href="entries/creativity_entry.html">creativity</a>:
Explorations in <a class="thought" href="entries/evolution_entry.html">evolution</a>ary, autopoietic, and cognitive <a class="thought" href="entries/dynamics_entry.html">dynamics</a>.</i>&#160; Plenum Press.</p>
<p><b>Goertzel, B.</b>
(2001). <i>Creating <a class="thought" href="entries/internet_entry.html">internet</a> <a class="thought" href="entries/intelligence_entry.html">intelligence</a>:
Wild computing, distributed <a class="thought" href="entries/digital_entry.html">digital</a> <a class="thought" href="entries/consciousness_entry.html">consciousness</a>, and the emerging global
<a class="thought" href="entries/brain_entry.html">brain</a> </i>Plenum Press.</p>
<p><b>Goldstone, R.L.</b>
(1998). Perceptual <a class="thought" href="entries/learning_entry.html">Learning</a>. <i>Annual
Review of <a class="thought" href="entries/psychology_entry.html">Psychology</a></i>, 49, 585-612.</p>
<p><b>Gottfredson, L.S.</b> (1998). <i>The general <a class="thought" href="entries/intelligence_entry.html">intelligence</a> factor.</i>&#160;[Special
Issue]. <i>Scientific American, 9</i>(4), 2, 24-29. </p>
<p><b>Grimson, W.E.L</b>.,
Stauffer, <a class="thought" href="entries/c_entry.html">C</a>., Lee L., Romano R. (1998). Using
Adaptive Tracking to Classify and Monitor Activities in a Site. <i>Proc.
IEEE Conf. on <a class="thought" href="entries/computer_entry.html">Computer</a> Vision and <a class="thought" href="entries/pattern_recognition_entry.html">Pattern Recognition</a></i>, pp. 22-31, 1998</p>
<p><b>Harnad, S.</b>
(1990). The <a class="thought" href="entries/symbol_entry.html">symbol</a> grounding problem. <i>Physica
D, 42</i>, 335-346.</p>
<p><b>Kelley, D.</b>
(1986). <i>The Evidence of the Senses</i>
Louisiana State University Press</p>
<p><b>Kosko, B.</b>
(1997). <i>Fuzzy <a class="thought" href="entries/engine_entry.html">Engine</a>ering.</i>&#160; Prentice Hall</p>
<p><b>Lenat, D.B.,</b>
Guha, R.V.(1990). <i>Building Large
<a class="thought" href="entries/knowledge_base_entry.html">Knowledge Base</a>d <a class="thought" href="entries/system_entry.html">System</a>s</i>. Addison-Wesley.</p>
<p><b>Margolis, H.</b>
(1987). <i><a class="thought" href="entries/pattern_entry.html">Pattern</a>s, <a class="thought" href="entries/thinking_entry.html">Thinking</a>, and
Cognition: A Theory of Judgment</i>. University of Chicago<a name="product-details"> Press</a></p>
<p><b>McCarthy, J.</b>
and Hayes, P.J.(1969).&#160; Some
philosophical problems from the standpoint of <a class="thought" href="entries/ai_entry.html">artificial intelligence</a>. <i><a class="thought" href="entries/machine_entry.html">Machine</a> <a class="thought" href="entries/intelligence_entry.html">Intelligence</a>, 4</i>, 463-502.</p>
<p><b>Nenov, V.I.</b>
and Dyer, M.G. (1994). <i><a class="thought" href="entries/language_entry.html">Language</a> <a class="thought" href="entries/learning_entry.html">Learning</a>
via Perceptual/ Motor Association: A Massively Parallel Model.</i> In: Kitano,
H., Hendler, J.A. (Eds.), <i>Massively
Parallel <a class="thought" href="entries/ai_entry.html">Artificial Intelligence</a></i> (pp. 203-245) AAAI Press/The MIT Press.</p>
<p><b>Pfeifer, R</b>.,
and Scheier, <a class="thought" href="entries/c_entry.html">C</a>. (1999). <i>Understanding
<a class="thought" href="entries/intelligence_entry.html">intelligence</a>.</i> MIT Press.</p>
<p><b>Pylyshyn, Z.W</b>.(Ed.)(1987).
<i>The <a class="thought" href="entries/robot_entry.html">Robot</a>'s Dilemma: The frame problem in
A.I..&#160; </i>Ablex.</p>
<p><b>Rand, A</b>.
(1990). <i>Introduction to <a class="thought" href="entries/object_entry.html">Object</a>ivist
<a class="thought" href="entries/epistemology_entry.html">Epistemology</a></i>. Meridian</p>
<p><b>Russell, S.J</b>.,
Norvig, P.(1995). <i>Artificial
<a class="thought" href="entries/intelligence_entry.html">Intelligence</a>: A modern approach.</i> Prentice Hall.</p>
<p><b>Wang, P. </b>(1995).
<i>Non-axiomatic <a class="thought" href="entries/reason_entry.html">reason</a>ing <a class="thought" href="entries/system_entry.html">system</a>: Exploring
the essence of <a class="thought" href="entries/intelligence_entry.html">intelligence</a>.</i> PhD thesis, Indiana University.</p>
<p><b>Yip, K.</b>, and
Sussman, G.J. (1997). Sparse Representations for Fast, One-shot <a class="thought" href="entries/learning_entry.html">learning</a>.&#160; <i>Proc.
of National Conference on <a class="thought" href="entries/ai_entry.html">Artificial Intelligence</a></i>, July 1997.</p>
<p><a name="seedAI"></a><a name="billion_dollar_budget"></a><a name="no_support"></a><a name="few_researchers"></a><a name="different_approach"></a><b><u>&#160;</u></b></p>
<h1>Footnotes</h1>
<div id="ftn1">
<p><a href="#_ftnref1" name="_ftn1" title="">[1]</a> Intellectual
property is owned by Adaptive A.I. Inc.</p>
</div>
<div id="ftn2">
<p><a href="#_ftnref2" name="_ftn2" title="">[2]</a>
"Brittleness" in <a class="thought" href="entries/ai_entry.html">AI</a> refers to a <a class="thought" href="entries/system_entry.html">system</a>'s inability to automatically adapt to
changing requirements, or to cope with <a class="thought" href="entries/data_entry.html">data</a> outside of a predefined range --
thus "breaking."</p>
</div>
<div id="ftn3">
<p><a href="#_ftnref3" name="_ftn3" title="">[3]</a>
Back-propagation is one of the most powerful <i>supervised</i> training
<a class="thought" href="entries/algorithm_entry.html">algorithm</a>s; it is, however, <i>not</i>
particularly amenable to incremental <a class="thought" href="entries/learning_entry.html">learning</a>.</p>
</div>
<div id="ftn4">
<p><a href="#_ftnref4" name="_ftn4" title="">[4]</a> "Priming,"
as used in <a class="thought" href="entries/psychology_entry.html">psychology</a>, refers to an increase in the speed or accuracy of a
decision that occurs as a consequence of prior exposure or activation.</p>
</div>
<div id="ftn5">
<p><a href="#_ftnref5" name="_ftn5" title="">[5]</a> This section
was co-authored with Shane Legg</p>
</div>
<div id="ftn6">
<p><a href="#_ftnref6" name="_ftn6" title="">[6]</a> meaning that
many different meanings are thrown together in a jumble -- or at least packaged
together in one "box," under one label.</p>
</div>
</p></p></td><td>&#160;</td><td valign="top"><a href="#discussion">Join the discussion about this article on Mind&#183;X!</a><p></p></td><td> &#160; </td>
</tr>
<tr><td colspan="6"><img alt="" border="0" height="35" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/blank.gif" width="35"></td></tr>
<tr>
<td>&#160;</td>
<td colspan="4">
<a name="discussion"></a><p><span class="mindxheader">&#160;&#160;&#160;[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9236" target="_top">Post New Comment</a>]<br>&#160;&#160;&#160;</span>Mind&#183;X Discussion About This Article:</p><a name="id9237"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>AGI Machine<br><span class="mindxheader"><i>posted on 08/23/2002 5:18 PM by St_Automatos@canada.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id9237" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9237" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Select one scenario in which the AGI Machine would be functioning as an AGI which would exemplify that it is a real THINKING MACHINE.
<br>
It doesn't even have to be a highly complex situation-could be quite simple.
<br>
<br>
St Automatos</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9332"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: AGI Machine<br><span class="mindxheader"><i>posted on 08/26/2002 7:08 PM by azb@llnl.gov</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id9332" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9332" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>St Automatos,
<br>
<br>
It is difficult to imagine a particular scenario.  The attempt to create a "purist AGI machine", would need to resist "teaching it" too much, like an understanding of natural language.  That would ba a "short-cut" (in order to "interact" with it on less than a child-like level), but would involve so much "in-depth" assumptions about the multiple meanings behind human words that it would obscure (and taint) any claimed "natural learning" ability that might be demonstrated.
<br>
<br>
If done "well", it might be like dealing with a small child or infant.  It would need to learn language and "acceptable behaviors" by interacting with the world.  Clearly, it would need access to "sensory" inputs (sight, sound, etc) and also the physical ability to "act out" and experiment.
<br>
<br>
If it reached the point of understanding spoken or written language (without simply being spoon-feed every word and concept), and were then released into a library containing "unfamiliar works" (and words), and it emerged with the ability to carry on a meaningful conversation about some of those works, then we would have something indeed.
<br>
<br>
But that is not a "simple demonstration", and your point (I believe) was to try to identify some "minimalist evidence" that a given AGI was "succeeding".
<br>
<br>
Cheers!  ____tony b____</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9336"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: AGI Machine<br><span class="mindxheader"><i>posted on 08/27/2002 3:36 AM by rws1st@yahoo.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id9336" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9336" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Allow me to offer a working definition of general intelligence (borrowed from Shane Legg). 
<br>
<br>
General Intelligence is the ability to solve a wide range of problems over a wide range of contexts.  The range of problems itself will be in part a measure of the level of complexity of the problems you can solve, as there as just so many simple problems that are possible.  The range of context is a measure in part of your ability to solve the fundamental problems under different circumstances, and so acts as a measure of ones ability to abstract.  Adding in Adaptive would mean that the system was not fixed in the range or contexts of its problem set.
<br>
<br>
The problem then, given your question, is to create &#8220;one scenario&#8221; that can test such a thing.  And unless the scenario is very complex, to the point that in includes a number of problems in a number of contexts then by my definition it just won&#8217;t be able to show AGI.
<br>
<br>
So now that I have shot your question down, let me give a single scenario that I use as a metal model.  I will call it &#8220;Dog fetch toy.&#8221;  Dogs are able to recognize a wide number of objects as toys, and are able to locate those toys in a wide range of environment, even when the toy is partially covered or altered in some way.   This model stresses the different context part of the definition fairly well, while not doing a very good job of pushing on the range of problems.  On the other hand it is an example that does not require human level of intelligence or specifically abstraction ability, but none the less is beyond the capacity of current technology. (at least as that I know of&#8230;If someone knows of an artificial system that could do this I would be very interested to learn of it)  The problem also has the adaptive feature that dogs are able to learn new toys and new environments.
<br>
<br>
Robert Sperry
<br>
A2i2 Adaptive A.I. Inc
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9347"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: AGI Machine<br><span class="mindxheader"><i>posted on 08/27/2002 6:29 PM by azb@llnl.gov</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id9347" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9347" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Robert,
<br>
<br>
I like "Dog Fetch Toy".  It is "simple", yet highlights the difficulties faced by a robotic system whose highest-levels of "cognizance" are (initially) a raw AGI.
<br>
<br>
Such a "dog" would already need raw visual, tactile, and motor capability, while beginning with no idea of "toy", or "walk/run" etc.
<br>
<br>
I am reminded of the work depicted in a Scientific American article about (10?) years back.  I don't recall the researcher's name, but he was builing robotic insects (ant-like) that has to "learn" how to walk on their own.
<br>
<br>
In this limited realm, the "brain" was a very simple process that would give (or relay) a command to "move forward" or "move right" to its "legs-complex", while maintaining a sensor that could determine if and when the desired motion was occuring.  It would constantly give feedback to the legs regarding its satisfaction (or lack of satisfaction) with the progress being made".
<br>
<br>
The "legs" would begin (initially random) attempts as movement, correlating their selection of motion with that of nearby-leg-selections and the "good-bad" feedback from the "brain".  Before very long, the six-legged "ant" developed an effective walking gait identical to that of real ants, and could respond almost instantly to effect the desired motion.
<br>
<br>
The challenge of AGI is to generalize that type of "ant-brain", or to create a hierarchy of ever-less-specific AGI nodes, with the least-specific nodes "at the top".  To "fetch the toy", the dog-AGI must (effectively) issue high-level directives that are interpreted by a "lower-brain" AGI responsible for overall leg-coordination, whose "desires" are in turn interpreted by an AGI for each leg that serves to coordinate leg-joint activities.  Meanwhile, the same dog-AGI desire to "fetch" must be interpreted by the visual-management-AGI, coordinating eye-direction AGIs, object-identification AGIs, etc.
<br>
<br>
And all of this must begin with a dog-AGI that known not how to walk, how to correlate image movement to body/eye/object movement, etc.
<br>
<br>
Quite the challenge.  I wonder why I have not heard of great strides or advancements in the robo-insect "bottom-up learning" systems or hierarchies.
<br>
<br>
Cheers! ____tony b____   </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9367"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: AGI Machine<br><span class="mindxheader"><i>posted on 08/28/2002 9:37 AM by wclary5424@aol.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id9367" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9367" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>&gt;I wonder why I have not heard of great strides or advancements in the robo-insect "bottom-up learning" systems or hierarchies. 
<br>
<br>
<br>
<br>
Perhaps because there is no consequence for failure of the robots to learn...no equivalent of natural selection.
<br>
<br>
<br>
BC
<br>
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9370"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="80"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="599"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: AGI Machine<br><span class="mindxheader"><i>posted on 08/28/2002 4:20 PM by azb@llnl.gov</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id9370" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9370" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>BC,
<br>
<br>
&gt; &gt;"I wonder why I have not heard of great strides or advancements in the robo-insect "bottom-up learning" systems or hierarchies." 
<br>
<br>
&gt; "Perhaps because there is no consequence for failure of the robots to learn...no equivalent of natural selection."
<br>
<br>
True, but I was not intending to go so far as to expect (at this stage) that robo-ants should variably reproduce in an environment where natural selection rewards the "better adapted".
<br>
<br>
Rather, I look to how the robo-ant-system was designed, with no built-in rules about how to walk, but rather the ability of each "leg" to correlate its behaviors to nearby legs and to some global "satisfaction/dissatisfaction" signal, that signal coming from a "brain" that also has no idea about how to make legs "walk", and remains ignorant of this even after successful walking occurs.  It is almost the antithesis of the classic "top-down AI", which one envisions "knowing how to perform every task", as in "now, lift legs 1,3,5, now 2,4,6", etc.
<br>
<br>
It seems to be a more natural architecture, whose success (in the robo-ant walking example) could have been extended to other "problem domains".
<br>
<br>
The "Artificial General Intelligence" (AGI) effort, although quite "distinct" from the more narrow-domain designs of AI (dedicated expert systems, etc.,) still allows for a variety of architectures to be deployed initially.  The most "common theme" I get from most AI (and even AGI) efforts involves a vision of "master thread of serial control" to which all other processes are not only subordinate, but effectively detailed.  The vision tends to suggest a one-great-AGI-process that does all the "learning" and generates all the answers or directives.  I doubt that our human intelligence actually works that way, and I wonder how an "AGI-machine" might be architected more along the lines suggested by the robo-ant example.
<br>
<br>
If one follows the former vision, the "one-AGI" must be exceedingly broad and capable, effectively able to "learn everything eventually", while the latter vision affords the "top-AGI" to deal more exclusively with higher-level issues, effectively ignorant of the "how" of loosely subordinate AGIs that "specialize themselves" to various supporting roles.  Thus, all of the AGIs that make up this "brain" might be simpler individual implementations.  Even the "top-AGI" is as simple as the "toe-wiggling" AGI, just differently tasked and specialized.
<br>
<br>
Cheers! ____tony b____</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9371"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="100"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="579"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: AGI Machine<br><span class="mindxheader"><i>posted on 08/28/2002 5:06 PM by wclary5424@aol.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id9371" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9371" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Tony,
<br>
<br>
I guess I didn't make myself clear enough, or perhaps I misread your original post.  You and I are actually in agreement.  This bottom-up approach makes a lot more sense to me than the standardized approach.
<br>
<br>
<br>
BC
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id12857"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: AGI Machine<br><span class="mindxheader"><i>posted on 12/23/2002 2:26 AM by <a href="http://web.archive.org/web/20071011200143/mailto:DennisBirney@msn.com">ArtIntell</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id12857" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D12857" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I read about some research done several years ago regarding the sounds that babies make. It seems that all babies all over the world make the same group of sounds, initially, immediately following birth. That, of course, changes over time as each individual baby begins to learn to produce the sounds associated with its own surrounding environment. We wouldn't need to have an AGI recite the Pledge of Allegiance. But, if we could get an AGI to progress, on its own, from its own initial sounds to perhaps say, "Mama" it would give us some indication that we were proceeding in the correct direction. This seems to me like it's a do-able thing. "Simple", yet robust enough to prove the point.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9324"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Essentials of General Intelligence: The direct path to AGI<br><span class="mindxheader"><i>posted on 08/26/2002 3:29 PM by shyone0202@aol.com</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id9324" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9324" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>&lt;&lt;For example, had Deep Blue also been designed to learn language, direct airline traffic, and do medical diagnosis, it would not have become Chess champion (all other things being equal).&gt;&gt;
<br>
<br>
Had Deep Blue's human opponent also been required to learn those things, he probably would not have become the World Chess champion, either (all other things being equal).
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id9331"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Essentials of General Intelligence: The direct path to AGI<br><span class="mindxheader"><i>posted on 08/26/2002 6:55 PM by azb@llnl.gov</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id9331" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D9331" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>shyone0202,
<br>
<br>
True.  But if Gary Kasparov was asked today to become a medical technician, or to manage airline schedules, or a thousand other tasks (and he agreed), I imagine within a few years he might be quite proficient.
<br>
<br>
Try asking the same of Deep Blue.  It could not even process the request.
<br>
<br>
That machine is dedicated to a very narrow realm of behavior, and about as far from and AGI as one can get.  I doubt it can even reveal whether the move you make is "clever" or "obvious".  It simply generates the best responding chess move.
<br>
<br>
Cheers! ____tony b____</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id12877"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Essentials of General Intelligence: The direct path to AGI<br><span class="mindxheader"><i>posted on 12/23/2002 5:54 PM by ArtIntell</i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id12877" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D12877" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>AGI Review Notes
<br>
- Dennis Birney
<br>
<br>
The following are my review notes of "Essentials of General Intelligence: The direct path to AGI" by Peter Voss.
<br>
<br>
Most cogent, pragmatistic, computer systems engineering approach to creating Artificial Intelligence I have seen in 20 years of research. I am reminded of a pertinent quote attributed to Henry Ford, "If you think you can, you're right. If you think you can't, you're right." I would be honored if I were allowed to sweep the floor.
<br>
<br>
Permit me a few minor observations.
<br>
<br>
"General Intelligence comprises the essential, domain-independent skills necessary for acquiring a wide range of domain-specific knowledge (data &amp; skills) -- i.e., the ability to learn anything (in principle). More specifically, this learning ability needs to be autonomous, goal-directed, and highly adaptive:
<br>
<br>
Autonomous -- &#8230;
<br>
<br>
Goal-directed -- Learning is directed (autonomously) towards achieving varying and novel goals and sub-goals -- be they "hard-wired," externally specified, or self-generated. Goal-directedness also implies very selective learning and data acquisition (from a massively data-rich, noisy, complex environment.)"
<br>
<br>
I may be misinterpreting the use of the concept of "goal_directed" but I believe that dealing with goals such as identifying, prioritizing, and taking the necessary steps to achieve, is learned behavior. If "goals" are hardwired it seems this becomes contrary to the concept of Autonomous.
<br>
<br>
"Furthermore, knowledge must be acquired and stored in ways appropriate both to the nature of the data, and to the goals and tasks at hand."
<br>
<br>
It's one thing to store data with the intent to recall the correct piece(s) in response to a query but something entirely different to autonomously recall the potentially correct piece(s) of data to creatively/innovatively solve a particular dilemma. There should be storage considerations regarding the relationship usage relative to the current focus, i.e., if I'm trying to complete a sentence relating to a particular aspect of artificial intelligence it would be of no use to recall items needed to bake a pumpkin pie. Some kind of contextual relationship is apparently necessary.
<br>
<br>
"Such knowledge also needs to be automatically adjusted and updated on an ongoing basis; new knowledge must be appropriately related to existing data."
<br>
<br>
At one point in time this was the theory of what humans do during their sleep period.
<br>
<br>
"Furthermore, perceived entities/patterns must be stored in a way that facilitates concept formation and generalization."
<br>
<br>
Some humans are better at this than others.
<br>
<br>
"Another essential requirement of general intelligence is to cope with an overabundance of data. Reality presents massively more features and detail than is (contextually) relevant, or that can be usefully processed. This is why the system needs to have some control over what input data is selected for analysis and learning -- both in terms of which data, and also the degree of detail. Senses ("probes") are needed not only for selection and focus, but also in order to ground concepts -- to give them (reality-based) meaning."
<br>
<br>
This sounds like some kind of dynamic filtering process is needed.
<br>
<br>
"While input data needs to be severely limited by focus and selection, it is also extremely important to obtain multiple views of reality -- data from different feature extractors or senses. Provided that these different input patterns are properly associated, they can help to provide context for each other, aid recognition, and add meaning."
<br>
<br>
What if we approach the subject from the direction of emulating a blind, quadriplegic and add sight and extremity sensors later?
<br>
<br>
"From a design perspective, AGI offers the advantage that all effort can be focused on achieving the best general solutions -- solving them once, rather than once for each particular domain."
<br>
<br>
Problem: one general solution cannot fix all seemingly related problems. Let's not "reinvent in the wheel" but, sometimes, reinventing the wheel leads to a better solution. Better -- the enemy of good!
<br>
<br>
"AGI obviously also has huge economic implications: because AGI systems acquire most of their knowledge and skills (and adapt to changing requirements) autonomously, programmed lead times and costs can be dramatically reduced, or even eliminated."
<br>
<br>
On the surface this seems to be true. However, let's not throw the baby out with the bath water! Necessary time is required to acquire knowledge and skills and adapt.
<br>
<br>
This sounds like the most fun project ever! Where do I sign up?
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id25987"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Essentials of General Intelligence: The direct path to AGI<br><span class="mindxheader"><i>posted on 07/06/2004 2:56 PM by <a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/profile.php?id=864">Bradski</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id25987" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D25987" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I guess Voss et al are still at this in LA:
<br>
<a href="http://web.archive.org/web/20071011200143/http://www.adaptiveai.com/index.htm" target="_blank">http://www.adaptiveai.com/index.htm</a>
<br>
I wish them luck, or that someone will get it right.
<br>
<br>
I wonder whether intelligence can be separated from development?  That is, the very act(s) of having to learn to move, to see, to fear, to feed etc form the scaffolding of later thought. This is the theme of George Lakoff and Mark Johnson in their book, &#8220;Metaphors We Live By&#8221;, later expanded in  &#8220;Philosophy In The Flesh&#8221;, Basic Books, 1999.   That is, our higher thinking is largely metaphoric &#8211; for example, &#8220;ideas&#8221; are objects that can be &#8220;seen&#8221;, &#8220;grasped&#8221;, dissected etc.  As a baby, you understood something by seeing it and grasping this and we carry this metaphor over to ideas.  Thus, it is by our embedded body experience that later symbols are grounded, and by these means that we generalize thought or feel that we understand something&#8230;it also provides limitations to our thought in the places where our metaphors break down such as quantum phenomena where it might be that a future robot with nano fingers may well have good intuitions in that realm that we cannot access &#8230; or readily understand even if said robot were to try to communicate this information to us.
<br>
<br>
There is an institute at Berkeley, CA trying to meld such ideas with biological data and turn this into computational models: <a href="http://web.archive.org/web/20071011200143/http://www.icsi.berkeley.edu/NTL/overview.html," target="_blank">http://www.icsi.berkeley.edu/NTL/overview.html,</a> though I haven&#8217;t really investigated their work&#8230;yet.
<br>
<br>
The other thing I might have missed is that our brain makes extensive use of spatial maps &#8211; motor maps, visual maps, tactile maps.  My guess is that this is not just an accidental bio-byproduct, but that maps allow generalization &#8211; you don&#8217;t need to experience all parts of a control space if you can linearly interpolate between points for example.   I don&#8217;t really see that being covered here.
<br>
<br>
My $0.02.
<br>
<br>
Gary
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id25999"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Essentials of General Intelligence: The direct path to AGI<br><span class="mindxheader"><i>posted on 07/06/2004 9:53 PM by <a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/profile.php?id=18">claireatcthisspace</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id25999" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D25999" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>your 2 cents are well accepted,
<br>
<br>
"it also provides limitations to our thought in the places where our metaphors break down such as quantum phenomena where it might be that a future robot with nano fingers may well have good intuitions in that realm that we cannot access &#8230; or readily understand even if said robot were to try to communicate this information to us."
<br>
<br>
Is a step foward. It's allways usefull to move ahead form pre assumed ideas. Another example is matter and its uique finite qualities along its infinite qualities. Symbiosis.
<br>
<br>
Claire
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id26006"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Essentials of General Intelligence: The direct path to AGI<br><span class="mindxheader"><i>posted on 07/06/2004 10:14 PM by <a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/profile.php?id=18">claireatcthisspace</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id26006" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D26006" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>"The other thing I might have missed is that our brain makes extensive use of spatial maps &#8211; motor maps, visual maps, tactile maps. My guess is that this is not just an accidental bio-byproduct, but that maps allow generalization &#8211; you don&#8217;t need to experience all parts of a control space if you can linearly interpolate between points for example. I don&#8217;t really see that being covered here. "
<br>
<br>
can you explain this in more detail? because I am very interested.
<br>
<br>
Claire
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id26018"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="60"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="619"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Essentials of General Intelligence: The direct path to AGI<br><span class="mindxheader"><i>posted on 07/07/2004 3:21 AM by <a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/profile.php?id=864">Bradski</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id26018" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D26018" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p> <center><p class="mindxquote">  The other thing I might have missed is that our brain makes extensive use of spatial maps &#8211; motor maps, visual maps, tactile maps... </p></center> <center><p class="mindxquote">  can you explain this in more detail? because I am very interested.  </p></center>
<br>
The brain maps your body&#8217;s sensory inputs and puts them &#8220;face to face&#8221; with motor control outputs as shown in this diagram of the sensory-motor homunculus.
<br>
<a href="http://web.archive.org/web/20071011200143/http://www.wirescript.net/magazine/lv9901/lvfig5.jpg" target="_blank">http://www.wirescript.net/magazine/lv9901/lvfig5.j  pg</a>
<br>
Note that more area/processing power/detail is given to important areas like the hand and mouth.  If you were to make a model of how the body is computationally represented, it would look something like:
<br>
<a href="http://web.archive.org/web/20071011200143/http://anatomy.yonsei.ac.kr/LWT/images/Homunculus.JPG" target="_blank">http://anatomy.yonsei.ac.kr/LWT/images/Homunculus.  JPG</a>
<br>
Pretty, isn&#8217;t it?
<br>
<br>
Similarly auditory and visual signals are converted into 2D spatial maps.  Our brain is really a 2D computational device &#8211; you can think of the cerebral cortex as a crumpled sheet of paper stuffed into our skull.  These map areas are then connected with a level of indirection through the thalamus &#8211; a smaller &#8220;crumpled piece of paper&#8221; in the middle.   Why 2D maps and not 3D (or higher)?   My guess is that no matter the data set, one can always map the &#8220;affinity&#8221; (sameness) of any given data point to any other and this can be represented in a 2D structure.   What good are maps?  If I can lay out my sensory, control, visual or auditory space in a consistent fashion so that near points are physically near, and far points far.  Then, if I learn how to reach to point A and later learn to reach to point C, I can probably just interpolate between A and C and do pretty good at reaching point B.  But even more important, since I can&#8217;t physically represent all of space in infinite detail, I&#8217;m going to need to interpolate anyhow to reach between physically represented points.  That is, maps allow generalization and interpolation.  
<br>
<br>
This brings up lots of other issues that aren&#8217;t often discussed in robotics &#8211; a chief one being that our brains and presumably successful robotic brains in the future are premised upon stability.  The mappings you create stay the same for long periods of time.  People often try to register things through SLAM (Simultaneous Localization and Mapping) where you are always trying to recognize where you are&#8230;but this is like some horrific stroke victim.   The stability should be built in as a primitive &#8211; part of the substrate.  This is what allows you to make computational maps &#8211; signals that are highly correlated in behavior are physically close together for example.  
<br>
<br>
Anyhow, these are some of my initial thoughts as I prepare to turn my research to robotics next year.
<br>
<br>
Gary
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id26026"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="80"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="599"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Essentials of General Intelligence: The direct path to AGI<br><span class="mindxheader"><i>posted on 07/07/2004 2:31 PM by <a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/profile.php?id=18">claireatcthisspace</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id26026" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D26026" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Bradski,
<br>
<br>
I'll have athink about this post and pehaps reply later. Good luck with your research!
<br>
<br>
Claire</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id24027"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Essentials of General Intelligence: The direct path to AGI<br><span class="mindxheader"><i>posted on 02/28/2004 1:48 PM by <a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/profile.php?id=1097">bobcoop</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id24027" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D24027" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>I appreciate your paper giving a review of the field. I was impressed with the scope and the new concepts since I last explored this area. I would like to add some points to ponder.
<br>
<br>
1. On memory learning and forgetting. I think deleting memory for forgetting is counterproductive. Another approach might be more useful. If each time a piece of memory was accessed and proved useful, an access parameter would be incremented. Each time a piece of memory was accessed and not useful, a fraction of the access parameter would be decremented. Then in the future only memories with high access parameter values would be accessed first and memories with lower access parameter values would be accessed only if the solution was not found with the high access parameter information. This would speed access to the memories that were more useful but would allow slower access to not as useful on a daily basis memories when needed.
<br>
<br>
2. I think in order to be realistic, a general intelegent machine must have a limited number of inputs. This would limit the number of rules that would have to be created for each expert system implemented. The scope of the project must be limited to be useful. This in no way limits the scope of problems it could work upon, only the amount of data for each task. Do you need aural data to solve a shape problem? (Only in very specialized cercumstances.)
<br>
<br>
3. Everyone believes that the amount of knowledge that a general expert system must have is huge and this is why people think that it is impossible to do. If there was a general interface that everybody aggreed to and everybody working on their narrow piece of AI could make their info available through this interface, then the scope of the problem could be reduced substantially. Your area of tying all these expert systems together would  be the new area of research. This should be a goal of the government and the scientific fallout would be very valuable for the country.
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id26024"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Cognitive Architecture for AGI<br><span class="mindxheader"><i>posted on 07/07/2004 10:41 AM by <a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/profile.php?id=26">Mentifex</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id26024" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D26024" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>An Artificial General Intelligence (AGI) needs a Cognitive Architecture.
<br>
<br>
<a href="http://web.archive.org/web/20071011200143/http://mind.sourceforge.net/aisteps.html#aitree" target="_blank">http://mind.sourceforge.net/aisteps.html#aitree</a> is the
<br>
<br>
Alife main artificial intelligence loop calling mind-modules:
<br>
enBoot English Bootstrap module for pre-loading concepts
<br>
Security module for the Joint Stewardship of Earth
<br>
--- HCI (Human-Computer Interaction)
<br>
--- Rejuvenate module for cyborg immortality
<br>
--- psiDecay concept-deactivation module
<br>
--- Ego self-assertion module
<br>
Sensorium for input into sensory memory channels
<br>
--- Audition module for the sense of hearing in robots
<br>
--- --- Listen for event-driven perception of input
<br>
--- --- --- audSTM (auditory Short Term Memory)
<br>
--- --- --- --- audRecog for auditory Recognition
<br>
--- --- oldConcept for recognition of known concepts
<br>
--- --- --- Parser module for language comprehension
<br>
--- --- --- --- Instantiate for each new instance of a concept
<br>
--- --- --- Activate for reactivation of old concepts
<br>
--- --- --- --- spreadAct for spreading activation among concepts
<br>
--- --- newConcept for machine learning of new concepts
<br>
--- --- --- enVocab module for English vocabulary
<br>
--- --- --- Parser module for language comprehension
<br>
--- --- --- --- Instantiate for each new instance of a concept
<br>
Emotion module for the sensation of feelings in robots as persons 
<br>
--- Cognitive component 
<br>
--- --- Physiological component
<br>
Think module for thinking by means of a linguistic superstructure
<br>
--- Activate module for activating concepts in the Psi mindcore
<br>
--- --- spreadAct module for spreading activation
<br>
--- English as one of many languages for a robot to think in
<br>
--- --- Ask module for asking questions about novel concepts
<br>
--- --- --- wtAuxSDo (whatDoSubjectsDo?)
<br>
--- --- --- --- Speech output of verbal thought
<br>
--- --- --- --- --- Reentry for hearing oneself think
<br>
--- --- negSVO for Chomskyan negative transformations
<br>
--- --- --- auxVerb for auxiliary verbs in negation
<br>
--- --- --- --- Speech output of verbal thought
<br>
--- --- --- --- --- Reentry output back into mind
<br>
--- --- SVO (Subject+Verb+Object)
<br>
--- --- --- nounPhrase for thinking of subjects in a syntax tree
<br>
--- --- --- --- Reify -- conversion of concepts to words
<br>
--- --- --- --- Speech output of verbal thought
<br>
--- --- --- --- --- Reentry of output into memory
<br>
--- --- --- --- Activate for activating concepts
<br>
--- --- --- --- --- spreadAct for spreading activation
<br>
--- --- --- verbPhrase for thinking of verbs in a syntax tree
<br>
--- --- --- --- Reify -- conversion of concepts to words
<br>
--- --- --- --- Speech output of verbal thought
<br>
--- --- --- --- --- Reentry of output as input
<br>
--- --- --- --- nounPhrase for thinking of a direct object
<br>
--- --- --- Conjoin module for thinking with conjunctions
<br>
--- --- --- --- Speech output of verbal thought
<br>
--- --- --- --- --- Reentry mental self-perception
<br>
Volition module for free will in autonomous mobile robots
<br>
Motorium module for actuators in lieu of human muscles
<br>
<br>
ATM
<br>
-- 
<br>
<a href="http://web.archive.org/web/20071011200143/http://isbn.nu/0595654371" target="_blank">http://isbn.nu/0595654371</a> = ISBN of hardbound AI4U textbook 
<br>
<a href="http://web.archive.org/web/20071011200143/http://isbn.nu/0595259227" target="_blank">http://isbn.nu/0595259227</a> = ISBN of paperback AI4U textbook 
<br>
<a href="http://web.archive.org/web/20071011200143/http://pub.ufasta.edu.ar/ohcop/curso2003/27-Actividad12.ppt" target="_blank">http://pub.ufasta.edu.ar/ohcop/curso2003/27-Activi  dad12.ppt</a>
<br>
<a href="http://web.archive.org/web/20071011200143/http://www.amazon.com/exec/obidos/ASIN/0595654371/" target="_blank">http://www.amazon.com/exec/obidos/ASIN/0595654371/  </a> reviewed </p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id45537"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="20"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="659"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Cognitive Architecture for AGI<br><span class="mindxheader"><i>posted on 08/16/2005 12:49 PM by <a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/profile.php?id=471">eldras</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id45537" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D45537" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>If you reverse engineer the human brain, you will end up with a human .... without a body....trapped in a machine.
<br>
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id78154"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="40"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="639"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Cognitive Architecture for AGI<br><span class="mindxheader"><i>posted on 03/29/2007 10:03 AM by <a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/profile.php?id=4051">jurgen</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id78154" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D78154" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>Not correct because the brain is the body.</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id78162"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Essentials of General Intelligence: The direct path to AGI<br><span class="mindxheader"><i>posted on 03/29/2007 12:56 PM by <a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/profile.php?id=2832">extrasense</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id78162" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D78162" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>This is a good one. Actually, a very good high level view. It has a real chance to evolve into practical SAI / AGI.
<br>
<br>
e:S
<br>
</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<a name="id79248"></a>
<table border="0" cellpadding="5" cellspacing="0" width="100%">
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="0"></td>
<td colspan="4"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="679"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-left.gif"></td>
<td bgcolor="#CCCCCC"><p>Re: Essentials of General Intelligence: The direct path to AGI<br><span class="mindxheader"><i>posted on 04/19/2007 5:49 PM by <a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/profile.php?id=4154">MikeSar</a></i></span></p></td>
<td align="right" bgcolor="#CCCCCC" valign="top"><span class="mindxheader">[<a href="#discussion">Top</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=show_thread.php?rootID%3D9236%23id79248" target="_top">Mind&#183;X</a>]<br>[<a href="https://web.archive.org/web/20071011200143/http://www.kurzweilai.net/mindx/frame.html?main=post.php?reply%3D79248" target="_top">Reply to this post</a>]</span></td>
<td align="right" bgcolor="#CCCCCC" style="padding: 0px;" valign="top"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-right.gif"></td>
</tr>
<tr>
<td></td>
<td bgcolor="#DDDDDD" colspan="4"><p>4. Foundational Cognitive Capabilities 
<br>
Categorizing
<br>
<br>
I was happily surprised to read the above. 
<br>
Following an entirely different approach, closer to Aristotle than AI, I arrived at the conclusion that the key to simulate the brain is the use of Categories. 
<br>
All beings have a list of Categories and those with a Category in common share something important, even essential.
<br>
The other adjunct is Accidents. The "accidental" details that specialize the Category for each being that may, or may not, be shared with others with category in common. Go forward!</p></td>
</tr>
<tr>
<td><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-left.gif"></td>
<td bgcolor="#DDDDDD" colspan="2"><img height="1" src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/images/blank.gif" width="1"></td>
<td align="right" bgcolor="#DDDDDD" style="padding: 0px;" valign="bottom"><img src="https://web.archive.org/web/20071011200143im_/http://www.kurzweilai.net/mindx/images/round-bottom-right.gif"></td>
</tr>
</table>
<p></p></td>
<td>&#160;</td>
</tr>
</table>
</td></tr></table>
</body>
</html>